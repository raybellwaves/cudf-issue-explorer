{"assignees":[],"author":{"id":"MDQ6VXNlcjg0NTczODg=","is_bot":false,"login":"beckernick","name":"Nick Becker"},"body":"Rolling window aggregations are slow with large window sizes. I believe this is known behavior to many contributors but a user ran into this yesterday and I couldn't find an issue or reference documentation from an initial search.\r\n\r\nThis is more likely to occur with time-oriented window sizes (e.g., \"60min\" or \"9h\") on high-frequency data rather than fixed integer length windows (as these windows are less likely to be as long). \r\n\r\nThe examples below illustrates this behavior. Observed GPU utilization is at 100% throughout the operations. \r\n\r\n```python\r\nimport cudf\r\n\r\ndf = cudf.datasets.timeseries(\r\n    start='2000-01-01',\r\n    end='2000-06-30',\r\n    freq='1s',\r\n)\r\npdf = df.to_pandas()\r\nprint(df.shape)\r\nprint(df.head())\r\n(15638401, 4)\r\n                       id     name         x         y\r\ntimestamp                                             \r\n2000-01-01 00:00:00  1069    Edith -0.208702  0.451685\r\n2000-01-01 00:00:01  1053   Yvonne -0.383893 -0.846287\r\n2000-01-01 00:00:02   986    Sarah -0.718822 -0.980082\r\n2000-01-01 00:00:03   999  Norbert -0.547608 -0.291836\r\n2000-01-01 00:00:04   999   George -0.534662  0.300049\r\n```\r\n\r\n```python\r\nwindows = [\"1min\", \"60min\", \"3h\", \"12h\", \"1d\"]\r\n\r\nprint(\"cuDF Rolling Windows\")\r\nfor w in windows:\r\n    %time out = df.rolling(w).x.max()\r\n    \r\nprint(\"\\n\"*3)\r\nprint(\"Pandas Rolling Windows\")\r\nfor w in windows:\r\n    %time out = pdf.rolling(w).x.max()\r\ncuDF Rolling Windows\r\nCPU times: user 8.25 ms, sys: 20.2 ms, total: 28.5 ms\r\nWall time: 49.2 ms\r\nCPU times: user 400 ms, sys: 8 ms, total: 408 ms\r\nWall time: 437 ms\r\nCPU times: user 1.08 s, sys: 150 µs, total: 1.08 s\r\nWall time: 1.09 s\r\nCPU times: user 4.3 s, sys: 7.07 ms, total: 4.31 s\r\nWall time: 4.36 s\r\nCPU times: user 8.69 s, sys: 11.4 ms, total: 8.7 s\r\nWall time: 8.76 s\r\n\r\n\r\n\r\nPandas Rolling Windows\r\nCPU times: user 516 ms, sys: 44.1 ms, total: 560 ms\r\nWall time: 558 ms\r\nCPU times: user 511 ms, sys: 40 ms, total: 551 ms\r\nWall time: 550 ms\r\nCPU times: user 522 ms, sys: 28.1 ms, total: 550 ms\r\nWall time: 549 ms\r\nCPU times: user 494 ms, sys: 48 ms, total: 542 ms\r\nWall time: 541 ms\r\nCPU times: user 499 ms, sys: 44 ms, total: 544 ms\r\nWall time: 542 ms\r\n```\r\n\r\n```python\r\nwindows = [10, 100, 1000, 10000, 100000]\r\n\r\nprint(\"cuDF Rolling Windows\")\r\nfor w in windows:\r\n    %time out = df.rolling(w).x.max()\r\n    \r\nprint(\"\\n\"*2)\r\nprint(\"Pandas Rolling Windows\")\r\nfor w in windows:\r\n    %time out = pdf.rolling(w).x.max()\r\ncuDF Rolling Windows\r\nCPU times: user 4.14 ms, sys: 7 µs, total: 4.15 ms\r\nWall time: 3.01 ms\r\nCPU times: user 7.92 ms, sys: 4 ms, total: 11.9 ms\r\nWall time: 11.7 ms\r\nCPU times: user 91.6 ms, sys: 3.8 ms, total: 95.4 ms\r\nWall time: 104 ms\r\nCPU times: user 726 ms, sys: 58 µs, total: 726 ms\r\nWall time: 726 ms\r\nCPU times: user 6.76 s, sys: 3.61 ms, total: 6.77 s\r\nWall time: 6.79 s\r\n\r\n\r\n\r\nPandas Rolling Windows\r\nCPU times: user 430 ms, sys: 80.1 ms, total: 510 ms\r\nWall time: 519 ms\r\nCPU times: user 425 ms, sys: 76.1 ms, total: 502 ms\r\nWall time: 500 ms\r\nCPU times: user 435 ms, sys: 64.2 ms, total: 499 ms\r\nWall time: 498 ms\r\nCPU times: user 416 ms, sys: 79.7 ms, total: 495 ms\r\nWall time: 494 ms\r\nCPU times: user 420 ms, sys: 72.1 ms, total: 492 ms\r\nWall time: 491 ms\r\n```\r\n```\r\nconda list | grep cudf\r\ncudf                      23.02.00        cuda_11_py38_g5ad4a85b9d_0    rapidsai\r\ncudf_kafka                23.02.00        py38_g5ad4a85b9d_0    rapidsai\r\ndask-cudf                 23.02.00        cuda_11_py38_g5ad4a85b9d_0    rapidsai\r\nlibcudf                   23.02.00        cuda11_g5ad4a85b9d_0    rapidsai\r\nlibcudf_kafka             23.02.00          g5ad4a85b9d_0    rapidsai\r\n```\r\n\r\nFiling an issue to document this performance behavior If already captured elsewhere, will close as a duplicate.","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5VO0AU","author":{"login":"bdice"},"authorAssociation":"CONTRIBUTOR","body":"This is a duplicate of https://github.com/rapidsai/cudf/issues/12551 but this issue summarizes the problem well and has useful context / code snippets for validation. I believe the person who posted that diagnosed the reason for the slowness correctly:\r\n\r\n> I think it calculates the whole window every time rather than just replacing the first and last elements of the moving window of 400000 elements, causing this delay whereas pandas does not do it that way.\r\n\r\nWe would need to investigate some kind of cooperative groups or consider the use of thrust/cub if appropriate (and not already used). I'm not sure how much of that we can combine with the JIT approaches to custom rolling aggregations.","createdAt":"2023-02-14T15:36:42Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/12774#issuecomment-1429946388","viewerDidAuthor":false}],"createdAt":"2023-02-14T15:20:34Z","id":"I_kwDOBWUGps5eb1Z4","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTM5NzQxMjEz","name":"cuDF (Python)","description":"Affects Python cuDF API.","color":"1d76db"},{"id":"MDU6TGFiZWwxMzIyMjUyNjE3","name":"Performance","description":"Performance related issue","color":"C2E0C6"}],"milestone":null,"number":12774,"projectCards":[],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] Faster rolling window aggregations with large window sizes","updatedAt":"2023-06-06T03:13:50Z","url":"https://github.com/rapidsai/cudf/issues/12774"}
