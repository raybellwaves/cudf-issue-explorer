{"assignees":[{"id":"MDQ6VXNlcjc0MTY5MzU=","login":"ttnghia","name":"Nghia Truong"}],"author":{"id":"MDQ6VXNlcjM0NDEzMjE=","is_bot":false,"login":"revans2","name":"Robert (Bobby) Evans"},"body":"**Is your feature request related to a problem? Please describe.**\r\nIn the Spark plugin we have a push to try and support as much of structs as we can.  Cudf supports sorting of nested structs (no lists just basic types and other structs).  It would really be great if we could support max and min aggregations on these as well. There are a lot of different types of max/min aggregations and if we cannot get them all at once we can take it a bit at a time too. We would like to be able to support this for.\r\n\r\n- [X] Sort-based group by aggregations\r\n- [ ] Hash-based group by aggregations\r\n- [X] Group by scans\r\n- [X] reductions\r\n- [X] scans\r\n- [X] window operations\r\n\r\nlike described in https://github.com/rapidsai/cudf/issues/8964 null child column values would come before non-null child column values.\r\n\r\n**Describe the solution you'd like**\r\nJust what I asked for min/max aggregations that can work on structs.\r\n\r\n**Describe alternatives you've considered**\r\nI'm not sure there is an alternative that we can support.\r\n\r\n**Additional context**\r\nAdd any other context, code examples, or references to existing implementations about the feature request here.\r\n","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps44SozW","author":{"login":"ttnghia"},"authorAssociation":"CONTRIBUTOR","body":"This issue should cover the previous one: https://github.com/rapidsai/cudf/issues/7995","createdAt":"2021-10-15T15:51:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-944409814","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps46kwrZ","author":{"login":"ttnghia"},"authorAssociation":"CONTRIBUTOR","body":"Currently, there are two more places we need to support struct `min` and `max` ops:\r\n  * Hash-based groupby aggregates\r\n  * Window ops\r\n\r\nIn these places, currently the internal functions call a kernel very early, which prohibits injecting any additional host function call. As such, supporting structs in those functions requires refactoring the entire computation pipeline. Thus, supporting structs in them will be postponed until such refactoring is done.","createdAt":"2021-11-30T14:58:05Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-982715097","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps47_HTw","author":{"login":"res-life"},"authorAssociation":"CONTRIBUTOR","body":"@ttnghia What's behavior when comparing struct with null in it?  For example:\r\n\r\n For max value of (2147483647,-930759675) and (2147483647,None), GPU returns (2147483647,None),  but CPU returns (2147483647,-930759675) \r\nAll the configurations are default.\r\n\r\n","createdAt":"2022-01-06T09:15:51Z","includesCreatedEdit":true,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1006400752","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps47_2n1","author":{"login":"ttnghia"},"authorAssociation":"CONTRIBUTOR","body":"Null is considered as `less` in general (for example: `[null, 1] < [-1, 1]`). Null rows are treated differently. If there are only null rows, the result will be a null row. If there are non-null rows, the result will never be null row but instead be selected from the non-null rows.","createdAt":"2022-01-06T13:31:00Z","includesCreatedEdit":true,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1006594549","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps47_4An","author":{"login":"ttnghia"},"authorAssociation":"CONTRIBUTOR","body":"> @ttnghia What's behavior when comparing struct with null in it? For example:\r\n> \r\n> For max value of (2147483647,-930759675) and (2147483647,None), GPU returns (2147483647,None), but CPU returns (2147483647,-930759675).\r\n\r\nAs from my test, I got different GPU exec result:\r\n```\r\nscala> import org.apache.spark.sql.types._\r\nscala> import org.apache.spark.sql.Row\r\nscala> val data = Seq(Row(1, Row(2147483647, -930759675)), Row(1, Row(2147483647, null)))\r\nscala> val struct = StructType(Seq(StructField(\"b\", IntegerType), StructField(\"a\", StructType(Seq(StructField(\"a_1\", IntegerType), StructField(\"a_2\", IntegerType))))))\r\nscala> val df = spark.createDataFrame(spark.sparkContext.parallelize(data), struct)\r\n\r\nscala> df.show\r\n+---+--------------------+\r\n|  b|                   a|\r\n+---+--------------------+\r\n|  1|{2147483647, -930...|\r\n|  1|  {2147483647, null}|\r\n+---+--------------------+\r\n\r\n\r\nscala> df.selectExpr(\"max(a)\", \"min(a)\").show()\r\n+--------------------+------------------+\r\n|              max(a)|            min(a)|\r\n+--------------------+------------------+\r\n|{2147483647, -930...|{2147483647, null}|\r\n+--------------------+------------------+\r\n\r\n```","createdAt":"2022-01-06T13:40:17Z","includesCreatedEdit":true,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1006600231","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps48AAbR","author":{"login":"res-life"},"authorAssociation":"CONTRIBUTOR","body":"I got the following result on CPU, the min value is different from yours.\r\nSeems the Spark uses nulls first sorting.\r\n\r\nCode is like you mentioned.\r\n```\r\nvar ret = null\r\nfor each value\r\n    compare by nulls first sorting (current, ret)\r\n    if satisfies,  ret = current\r\nreturn ret\r\n```\r\n\r\ndetail log\r\n```\r\n$./spark-3.1.2-bin-hadoop3.2/bin/spark-shell \r\nscala> import org.apache.spark.sql.types._\r\nimport org.apache.spark.sql.types._\r\n\r\nscala> import org.apache.spark.sql.Row\r\nimport org.apache.spark.sql.Row\r\n\r\nscala> val data = Seq(Row(1, Row(2147483647, -930759675)), Row(1, Row(2147483647, null)))\r\ndata: Seq[org.apache.spark.sql.Row] = List([1,[2147483647,-930759675]], [1,[2147483647,null]])\r\n\r\nscala> val struct = StructType(Seq(StructField(\"b\", IntegerType), StructField(\"a\", StructType(Seq(StructField(\"a_1\", IntegerType), StructField(\"a_2\", IntegerType))))))\r\nstruct: org.apache.spark.sql.types.StructType = StructType(StructField(b,IntegerType,true), StructField(a,StructType(StructField(a_1,IntegerType,true), StructField(a_2,IntegerType,true)),true))\r\n\r\nscala> val df = spark.createDataFrame(spark.sparkContext.parallelize(data), struct)\r\ndf: org.apache.spark.sql.DataFrame = [b: int, a: struct<a_1: int, a_2: int>]\r\n\r\nscala> df.show\r\n+---+--------------------+                                                      \r\n|  b|                   a|\r\n+---+--------------------+\r\n|  1|{2147483647, -930...|\r\n|  1|  {2147483647, null}|\r\n+---+--------------------+\r\n\r\n\r\nscala> df.selectExpr(\"max(a)\", \"min(a)\").show()\r\n+--------------------+------------------+\r\n|              max(a)|            min(a)|\r\n+--------------------+------------------+\r\n|{2147483647, -930...|{2147483647, null}|\r\n+--------------------+------------------+\r\n\r\n\r\n```","createdAt":"2022-01-06T14:29:31Z","includesCreatedEdit":false,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1006634705","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps48ADfF","author":{"login":"ttnghia"},"authorAssociation":"CONTRIBUTOR","body":"Sorry didn't pull the latest branch. I updated the result above --- the same as your.\r\nNevertheless, the max value is always correct, not like what you mentioned.","createdAt":"2022-01-06T14:46:04Z","includesCreatedEdit":true,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1006647237","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps48AGe5","author":{"login":"res-life"},"authorAssociation":"CONTRIBUTOR","body":"When grouping, the max value is wrong\r\n\r\n```\r\n(base) [chong@chong-pc spark-rapids]$ $SPARK_HOME/bin/pyspark --master local[*] \\\r\n> --conf spark.executor.cores=12 \\\r\n> --driver-memory 40G  \\\r\n> --executor-memory 10G  \\\r\n> --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=file:/tmp/spark-history \\\r\n> --conf spark.executor.extraClassPath=${ML_JAR}:${SPARK_CUDF_JAR}:${SPARK_RAPIDS_PLUGIN_JAR} \\\r\n> --conf spark.driver.extraClassPath=${ML_JAR}:${SPARK_CUDF_JAR}:${SPARK_RAPIDS_PLUGIN_JAR} \\\r\n> --jars ${SPARK_CUDF_JAR},${SPARK_RAPIDS_PLUGIN_JAR} \\\r\n> --conf spark.plugins=com.nvidia.spark.SQLPlugin \\\r\n> --conf spark.rapids.sql.enabled=true \\\r\n> --conf spark.rapids.memory.pinnedPool.size=1G \\\r\n> --conf spark.rapids.memory.gpu.allocFraction=0.35 \\\r\n> --conf spark.rapids.memory.gpu.maxAllocFraction=0.6 \\\r\n> --conf spark.rapids.memory.gpu.pooling.enabled=false \\\r\n> --conf spark.rapids.memory.gpu.pool=NONE \\\r\n> --conf spark.rapids.sql.explain=ALL \\\r\n> --conf spark.executor.extraJavaOptions=\"-Dai.rapids.cudf.nvtx.enabled=true\" \\\r\n> --conf spark.driver.extraJavaOptions=\"-Dai.rapids.cudf.nvtx.enabled=true\"\r\nPython 3.8.8 (default, Apr 13 2021, 19:58:26) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n22/01/06 22:57:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\r\nSetting default log level to \"WARN\".\r\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\r\n22/01/06 22:57:15 WARN RapidsPluginUtils: RAPIDS Accelerator 22.02.0-SNAPSHOT using cudf 22.02.0-SNAPSHOT. To disable GPU support set `spark.rapids.sql.enabled` to false\r\n\r\n\r\n22/01/06 22:57:19 WARN Plugin: Installing rapids UDF compiler extensions to Spark. The compiler is disabled by default. To enable it, set `spark.rapids.sql.udfCompiler.enabled` to true\r\nWelcome to\r\n      ____              __\r\n     / __/__  ___ _____/ /__\r\n    _\\ \\/ _ \\/ _ `/ __/  '_/\r\n   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.0.1\r\n      /_/\r\n\r\nUsing Python version 3.8.8 (default, Apr 13 2021 19:58:26)\r\nSparkSession available as 'spark'.\r\n>>> \r\n>>> \r\n>>> \r\n>>> from pyspark.sql.types import *\r\n>>> schema = StructType([\r\n...     StructField(\"a\", \r\n...         StructType([\r\n...             StructField(\"aa\", IntegerType()),\r\n...             StructField(\"ab\", IntegerType()),\r\n...         ])),\r\n...     StructField(\"b\", IntegerType()),\r\n... ])\r\n>>> \r\n>>> \r\n>>> data = [\r\n...     ((2147483647,-930759675),1773868988),\r\n...     ((2147483647,None),1773868988),\r\n... ]\r\n>>> \r\n>>> df = spark.createDataFrame(\r\n...         SparkContext.getOrCreate().parallelize(data, numSlices=1),\r\n...         schema)\r\n>>> \r\n>>> df.createOrReplaceTempView(\"t\")\r\n>>> \r\n>>> spark.conf.set(\"spark.rapids.sql.enabled\", True)\r\n>>> spark.sql(\"select b, max(a) from t group by b\").show()\r\n22/01/06 22:57:40 WARN GpuOverrides: \r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <SortAggregateExec> will run on GPU\r\n    *Expression <AggregateExpression> max(a#0) will run on GPU\r\n      *Expression <Max> max(a#0) will run on GPU\r\n    *Expression <Alias> cast(b#1 as string) AS b#10 will run on GPU\r\n      *Expression <Cast> cast(b#1 as string) will run on GPU\r\n    *Expression <Alias> cast(max(a#0)#4 as string) AS max(a)#11 will run on GPU\r\n      *Expression <Cast> cast(max(a#0)#4 as string) will run on GPU\r\n    #Exec <SortExec> could run on GPU but is going to be removed because replacing sort aggregate with hash aggregate\r\n      #Expression <SortOrder> b#1 ASC NULLS FIRST could run on GPU but is going to be removed because parent plan is removed\r\n      *Exec <ShuffleExchangeExec> will run on GPU\r\n        *Partitioning <HashPartitioning> will run on GPU\r\n        *Exec <SortAggregateExec> will run on GPU\r\n          *Expression <AggregateExpression> partial_max(a#0) will run on GPU\r\n            *Expression <Max> max(a#0) will run on GPU\r\n          #Exec <SortExec> could run on GPU but is going to be removed because replacing sort aggregate with hash aggregate\r\n            #Expression <SortOrder> b#1 ASC NULLS FIRST could run on GPU but is going to be removed because parent plan is removed\r\n            ! <RDDScanExec> cannot run on GPU because GPU does not currently support the operator class org.apache.spark.sql.execution.RDDScanExec\r\n              @Expression <AttributeReference> a#0 could run on GPU\r\n              @Expression <AttributeReference> b#1 could run on GPU\r\n\r\n+----------+-------------+                                                      \r\n|         b|       max(a)|\r\n+----------+-------------+\r\n|1773868988|[2147483647,]|\r\n+----------+-------------+\r\n\r\n```","createdAt":"2022-01-06T15:02:11Z","includesCreatedEdit":false,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1006659513","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps48AI3i","author":{"login":"ttnghia"},"authorAssociation":"CONTRIBUTOR","body":"This is my groupby result:\r\n```\r\nscala> df.groupBy(\"b\").agg(max(col(\"a\")), min(col(\"a\"))).show\r\n+---+--------------------+------------------+\r\n|  b|              max(a)|            min(a)|\r\n+---+--------------------+------------------+\r\n|  1|{2147483647, -930...|{2147483647, null}|\r\n+---+--------------------+------------------+\r\n```\r\n\r\nOr:\r\n```\r\nscala> spark.sql(\"select b, max(a) from t group by b\").show()\r\n+---+--------------------+\r\n|  b|              max(a)|\r\n+---+--------------------+\r\n|  1|{2147483647, -930...|\r\n+---+--------------------+\r\n```\r\n\r\nPS: I'm running the latest spark-rapid branch.","createdAt":"2022-01-06T15:14:34Z","includesCreatedEdit":true,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1006669282","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps48AKOp","author":{"login":"ttnghia"},"authorAssociation":"CONTRIBUTOR","body":"BTW, make sure to enable struct for `min` and `max` expr:\r\n```\r\ndiff --git a/sql-plugin/src/main/scala/com/nvidia/spark/rapids/GpuOverrides.scala b/sql-plugin/src/main/scala/com/nvidia/spark/rapids/GpuOverrides.scala\r\nindex abeb3f1fb..e987d6202 100644\r\n--- a/sql-plugin/src/main/scala/com/nvidia/spark/rapids/GpuOverrides.scala\r\n+++ b/sql-plugin/src/main/scala/com/nvidia/spark/rapids/GpuOverrides.scala\r\n@@ -2237,9 +2237,12 @@ object GpuOverrides extends Logging {\r\n     expr[Max](\r\n       \"Max aggregate operator\",\r\n       ExprChecks.fullAgg(\r\n-        TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL, TypeSig.orderable,\r\n+        (TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL +\r\n+            TypeSig.STRUCT).nested(),\r\n+        TypeSig.orderable,\r\n         Seq(ParamCheck(\"input\",\r\n-          (TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL)\r\n+          (TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL +\r\n+              TypeSig.STRUCT).nested()\r\n               .withPsNote(TypeEnum.DOUBLE, nanAggPsNote)\r\n               .withPsNote(TypeEnum.FLOAT, nanAggPsNote),\r\n           TypeSig.orderable))\r\n@@ -2259,9 +2262,12 @@ object GpuOverrides extends Logging {\r\n     expr[Min](\r\n       \"Min aggregate operator\",\r\n       ExprChecks.fullAgg(\r\n-        TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL, TypeSig.orderable,\r\n+        (TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL +\r\n+            TypeSig.STRUCT).nested(),\r\n+        TypeSig.orderable,\r\n         Seq(ParamCheck(\"input\",\r\n-          (TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL)\r\n+          (TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL +\r\n+              TypeSig.STRUCT).nested()\r\n               .withPsNote(TypeEnum.DOUBLE, nanAggPsNote)\r\n               .withPsNote(TypeEnum.FLOAT, nanAggPsNote),\r\n           TypeSig.orderable))\r\n```","createdAt":"2022-01-06T15:21:45Z","includesCreatedEdit":false,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1006674857","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps48APZe","author":{"login":"res-life"},"authorAssociation":"CONTRIBUTOR","body":"Enabled: https://github.com/NVIDIA/spark-rapids/pull/4434/files\r\n```\r\n        ExprChecks.reductionAndGroupByAgg(\r\n          // Max supports single level struct, e.g.:  max(struct(string, string))\r\n          (TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL + TypeSig.STRUCT)\r\n            .nested(TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL),\r\n          TypeSig.orderable,\r\n          Seq(ParamCheck(\"input\",\r\n            (TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL + TypeSig.STRUCT)\r\n              .nested(TypeSig.commonCudfTypes + TypeSig.DECIMAL_128_FULL + TypeSig.NULL)\r\n\r\n```\r\n","createdAt":"2022-01-06T15:48:41Z","includesCreatedEdit":false,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1006696030","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps48QC0T","author":{"login":"res-life"},"authorAssociation":"CONTRIBUTOR","body":"@ttnghia This case failed: \r\n```\r\ndata = [\r\n    ((None,None),1773868988),\r\n    ((-2147483648,None),1773868988),\r\n]\r\n\r\n// GPU\r\n+----------+--------------+--------------+                                      \r\n|         b|        min(a)|        max(a)|\r\n+----------+--------------+--------------+\r\n|1773868988|[-2147483648,]|[-2147483648,]|\r\n+----------+--------------+--------------+\r\n\r\n// CPU\r\n+----------+------+--------------+\r\n|         b|min(a)|        max(a)|\r\n+----------+------+--------------+\r\n|1773868988|   [,]|[-2147483648,]|\r\n+----------+------+--------------+\r\n```","createdAt":"2022-01-12T09:36:43Z","includesCreatedEdit":false,"isMinimized":true,"minimizedReason":"off-topic","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8974#issuecomment-1010838803","viewerDidAuthor":false}],"createdAt":"2021-08-05T18:04:00Z","id":"MDU6SXNzdWU5NjIwNzE5Nzc=","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"}],"milestone":{"number":2,"title":"List and Struct data types and operations","description":"","dueOn":null},"number":8974,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] support max and min aggregations for nested structs","updatedAt":"2022-03-08T18:36:56Z","url":"https://github.com/rapidsai/cudf/issues/8974"}
