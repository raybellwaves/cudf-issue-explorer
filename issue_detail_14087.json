{"assignees":[],"author":{"id":"MDQ6VXNlcjM0NDEzMjE=","is_bot":false,"login":"revans2","name":"Robert (Bobby) Evans"},"body":"**Is your feature request related to a problem? Please describe.**\r\nIn Spark we have had multiple customers that try to process really long strings with simple regular expressions. The reality is that in most cases they don't need a regular expression but the API/expression Spark exposes is for a regular expression so they use it.  An example of this is string split, where what is being split on is a regular expression. They will split on things like a comma `,` or try to parse JSON like formatted strings by splitting on `}` or `}}` sequences. But they do this on very large strings. Strings that are over 120KiB in size.  When this happens we see really bad performance on the GPU. Even worse than single threaded performance on the CPU to process the same data.  Here is an example where we are essentially doing an `explode(split(column_name, \"}}\"))` on 500 rows. It is 500 rows, because the length of the strings involved end up making that about 1 row group in parquet, so this is the data that a single Spark task sees.\r\n\r\nString Length | GPU Median Time | CPU Median Time | Hacked GPU Median Time\r\n-- | -- | -- | --\r\n10 | 316 | 249 | 395\r\n100 | 321 | 298 | 371\r\n1,000 | 333 | 753 | 377\r\n10,000 | 1,352 | 5,401 | 407\r\n20,000 | 4,914 | 10,630 | 459\r\n40,000 | 15,810 | 21,261 | 564\r\n80,000 | 66,409 | 43,487 | 773\r\n100,000 | 111,781 | 54,989 | 902\r\n120,000 | 134,409 | 66,066 | 1,035\r\n140,000 | 212,333 | 76,900 | 1,232\r\n\r\n![chart(1)](https://github.com/rapidsai/cudf/assets/3441321/70bc2bb0-6eea-4c26-95df-33b397a0c567)\r\n\r\nIn this the `Hacked GPU Median Time` is when I hacked the Spark plugin to ignore the regular expression and instead use the non-regular expression CUDF API to split the string.\r\n\r\n**Describe the solution you'd like**\r\nIn the Rapids Plugin we have put in place a number of optimizations where we will parse the regular expression and if possible transpile it to a string that we can do a non regular expression split on. We think it is worth pushing this type of optimization into CUDF itself and not just for splits.  It would really be nice if CUDF could spend time to look for alternative ways to execute a regular expression, especially for really long string, that don't need a single thread per string to work properly.\r\n\r\nExamples include \r\n\r\n  * Seeing if a regular expression can be transpiled to static string and using an alternative string operation instead. This could apply to split, matches, etc.\r\n  * When just checking if a regular expression matches a string we could match things like `FOO.*` and convert it into a starts with operation instead. This could also apply to contains or ends with. \r\n\r\nI would like it in CUDF because I think it would benefit everyone, not just the Spark plugin, but also I think the RAPIDS team could do a better job in many cases of finding these optimizations than we are doing.\r\n\r\n**Describe alternatives you've considered**\r\nUpdate our own regular expression checker code to start doing more of these optimizations.","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5mxb93","author":{"login":"GregoryKimball"},"authorAssociation":"CONTRIBUTOR","body":"Thank you @revans2 for raising this issue. It's true that often the faster regex accelerator is the one that doesn't use regex at all. \r\n>I would like it in CUDF because I think it would benefit everyone, not just the Spark plugin, but also I think the RAPIDS team could do a better job in many cases of finding these optimizations than we are doing.\r\n\r\nWe'll have to think more about the design of this. It doesn't seem like a great solution for libcudf to expose an option in the regex engine to try and avoid the regex engine. The best idea I have for now is that Regex transformation to Strings API could happen in a JIT submodule. ","createdAt":"2023-09-18T19:23:12Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14087#issuecomment-1724235639","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5mxnEB","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"> It doesn't seem like a great solution for libcudf to expose an option in the regex engine to try and avoid the regex engine.\r\n\r\nI don't see this as an option, I see it as an optimization. Why would an end user ever know or care that when they asked to split a string on the regular expression \"}}\" that CUDF called one kernel vs another and got the answer back much faster. We already do this kind of thing for long strings where we have separate kernels and look at the average length of the string to decide which to call.  How is this any different?","createdAt":"2023-09-18T19:57:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14087#issuecomment-1724281089","viewerDidAuthor":false}],"createdAt":"2023-09-12T14:22:02Z","id":"I_kwDOBWUGps5wz1AR","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMzIyMjUyNjE3","name":"Performance","description":"Performance related issue","color":"C2E0C6"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"},{"id":"MDU6TGFiZWwxNTE1NjE2MjUz","name":"strings","description":"strings issues (C++ and Python)","color":"0e8a16"}],"milestone":null,"number":14087,"projectCards":[],"projectItems":[],"reactionGroups":[{"content":"EYES","users":{"totalCount":1}}],"state":"OPEN","title":"[FEA] Better scaling for simple regular expressions on long strings","updatedAt":"2023-09-27T02:49:32Z","url":"https://github.com/rapidsai/cudf/issues/14087"}
