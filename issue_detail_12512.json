{"assignees":[],"author":{"id":"MDQ6VXNlcjE5OTQ5MjA3","is_bot":false,"login":"ayushdg","name":"Ayush Dattagupta"},"body":"**Describe the bug**\r\nWhen using `cudf.read_parquet` or `read_orc` with the filters argument to filter out rows based on certain predicates, the methods today just filter out reading row groups (or stripes) that can be completely eliminated based on the given condition, but does return all rows from the read row groups without applying the given filters again. This behavior can be confusing to users assuming that all the relevant data has already been filtered out and is contrary to how dask, dask-cuDF and PyArrow behave today.\r\n\r\nExample:\r\n\r\nData:\r\n```\r\nCol Name: A\r\nRow Group 0: 1,5,1\r\nRow Group 1: 5,5,5\r\n```\r\n```python\r\ncudf.read_parquet(\"data\", filters=[('a','!=',5)])\r\n```\r\nWould return 1 , 5, 1 which is all elements from RG0 (RG1 gets filtered out).\r\nExpected output would be 1,1\r\n\r\n\r\n**Steps/Code to reproduce bug**\r\n```python\r\ndf = cudf.DataFrame()\r\n\r\nIn [6]: df[\"a\"] = [1,5]*2500 + [5]*5000\r\n\r\nIn [7]: df.to_parquet(\"rg_test.parquet\", row_group_size_rows=5000)\r\n\r\nIn [8]: cudf.read_parquet(\"rg_test.parquet\")\r\n[10000 rows x 1 columns]\r\n\r\nIn [9]: cudf.read_parquet(\"rg_test.parquet\", filters=[(\"a\", \"!=\", 5)])\r\n[5000 rows x 1 columns]\r\n```\r\n\r\n**Expected behavior**\r\nThe 5's from row group 0 also get filtered returning only 1's, which is inline with how pyarrow, dask/dask-cudf return return the result.\r\n\r\n**Environment overview (please complete the following information)**\r\n - Environment location: bare-metal\r\n - Method of cuDF install: conda\r\n   - If method of install is [Docker], provide `docker pull` & `docker run` commands used\r\n\r\n**Environment details**\r\nPlease run and paste the output of the `cudf/print_env.sh` script here, to gather any other relevant environment details\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5aVEqY","author":{"login":"GregoryKimball"},"authorAssociation":"CONTRIBUTOR","body":"Hello I would like to update this issue now that we have support for libcudf ASTs in cuDF's `DataFrame.query`. I propose that we add a filtering step to `cudf.read_parquet` if the `filters` argument is present, similar to the following approach:\r\n\r\n```\r\ndf = cudf.DataFrame({'a': range(10), 'b': range(10,20)})\r\ndf.to_parquet('test.parquet')\r\nfilters = [\r\n    [('a', '>', 7),('b', '>', 15)],\r\n    [('a', '<', 2)],\r\n]\r\ndf = cudf.read_parquet('test.parquet', filters=filters)\r\n\r\nassert isinstance(filters, list) and len(filters) > 0, \"Invalid filters\"\r\nif isinstance(filters[0], tuple):\r\n    filters = [filters]\r\nexpr = ' or '.join([f'(({\") and (\".join([f\"{col} {o} {val}\" for col, o, val in f])}))' for f in filters])\r\ndf_filtered = df.query(expr)\r\n```\r\n\r\n```\r\n   a   b\r\n0  0  10\r\n1  1  11\r\n8  8  18\r\n9  9  19\r\n```\r\n\r\nEdit: now that we have string scalar support in libcudf ASTs we might want to add a pattern for double-quoting string values\r\n\r\nSee [pyarrow.parquet.read_table](https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html) for more information about the grammar of `filters`. The grammar is single-column disjunctive normal form (DNF) and a subset of what ASTs can represent. We are missing `in` and `not in` operators but these could be converted to ANDed `==` or `!=`.","createdAt":"2023-04-19T22:42:13Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/12512#issuecomment-1515473560","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5cgadr","author":{"login":"GregoryKimball"},"authorAssociation":"CONTRIBUTOR","body":"For the parquet reader, this issue was addressed in #13334. We still need to verify/modify the ORC reader.","createdAt":"2023-05-17T20:14:46Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/12512#issuecomment-1552000875","viewerDidAuthor":false}],"createdAt":"2023-01-10T13:15:09Z","id":"I_kwDOBWUGps5bCd-7","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NTk=","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTM5NzQxMjEz","name":"cuDF (Python)","description":"Affects Python cuDF API.","color":"1d76db"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"}],"milestone":{"number":23,"title":"ORC continuous improvement","description":"","dueOn":null},"number":12512,"projectCards":[{"project":{"name":"Bug Squashing"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[BUG] read_parquet/read_orc with filters do not filter specific rows","updatedAt":"2023-06-06T03:41:51Z","url":"https://github.com/rapidsai/cudf/issues/12512"}
