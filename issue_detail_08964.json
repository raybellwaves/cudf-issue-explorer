{"assignees":[{"id":"MDQ6VXNlcjEwNjQ1NTUy","login":"rwlee","name":"Ryan Lee"}],"author":{"id":"MDQ6VXNlcjM0NDEzMjE=","is_bot":false,"login":"revans2","name":"Robert (Bobby) Evans"},"body":"**Is your feature request related to a problem? Please describe.**\r\nFor Spark we are pushing to get more support for structs in a number of operators.  We already have some support for sorting structs, so we should be able to come up with a way to do comparisons of nested structs too.  NOTE this does not include lists as children of the structs just structs that contains basic types including strings and other structs.\r\n\r\nThe operations we would like to support include the BINARY ops EQUAL, NOT_EQUAL, LESS, GREATER, LESS_EQUAL, GREATER_EQUAL, NULL_EQUALS, and if possible NULL_MAX and NULL_MIN.\r\n\r\nThis should follow the same pattern we have supported for sorting with the order of precedence for the children in a struct go from first to last.  In this case we would like nulls within the struct columns to be less than other values, but equal to each other. meaning `Struct(null)` is less than `Struct(5)` and `Struct(null)` == `Struct(null)`.  Nulls at the top level still depend on the operator being performed. For NULL_EQUALS nulls are equal to each other.\r\n\r\n**Describe the solution you'd like**\r\nIt would be great if we could do this as regular binary ops, but if we need them to be separate APIs that works too. If null equality/etc needs to be configurable for the python APIs a separate API is fine.\r\n\r\n**Describe alternatives you've considered**\r\nWe could flatten the struct columns ourselves and do a number of different operations to combine the results back together to get the right answer. But cudf already has a flatten method behind the scenes so why replicate that when others could benefit from it too.","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps45xqTZ","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2021-11-15T21:04:49Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8964#issuecomment-969319641","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps47gn5z","author":{"login":"sameerz"},"authorAssociation":"CONTRIBUTOR","body":"This is still required","createdAt":"2021-12-21T02:03:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8964#issuecomment-998407795","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Ebw9X","author":{"login":"bdice"},"authorAssociation":"CONTRIBUTOR","body":"This code snippet demonstrates some behavior with NaNs that I investigated with @rwlee. tl;dr Spark treats NaN the same in binary operators `<, <=, ==, ...` as in the comparators `<, ==` used for sorting and equality. This follows the rules in #4760 but with elementwise comparison of structs.\r\n\r\n<details><summary>Show snippet</summary>\r\n\r\nSave as `binops.scala` and run with: `$ spark-shell -i binops.scala`\r\n\r\n```scala\r\nimport org.apache.spark.sql.functions._\r\nimport org.apache.spark.sql.types.{DoubleType, StructType}\r\nimport org.apache.spark.sql.Row\r\n\r\nval schema = new StructType()\r\n  .add(\"struct1\", new StructType()\r\n    .add(\"x\", DoubleType)\r\n    .add(\"y\", DoubleType))\r\n  .add(\"struct2\", new StructType()\r\n    .add(\"x\", DoubleType)\r\n    .add(\"y\", DoubleType))\r\n\r\nval v1 = 1.0\r\nval v2 = Double.NaN\r\n\r\nval structData = Seq(\r\n  Row(Row(v1, v1), Row(v1, v1)),\r\n  Row(Row(v1, v1), Row(v1, v2)),\r\n  Row(Row(v1, v1), Row(v2, v1)),\r\n  Row(Row(v1, v1), Row(v2, v2)),\r\n  Row(Row(v1, v2), Row(v1, v1)),\r\n  Row(Row(v1, v2), Row(v1, v2)),\r\n  Row(Row(v1, v2), Row(v2, v1)),\r\n  Row(Row(v1, v2), Row(v2, v2)),\r\n  Row(Row(v2, v1), Row(v1, v1)),\r\n  Row(Row(v2, v1), Row(v1, v2)),\r\n  Row(Row(v2, v1), Row(v2, v1)),\r\n  Row(Row(v2, v1), Row(v2, v2)),\r\n  Row(Row(v2, v2), Row(v1, v1)),\r\n  Row(Row(v2, v2), Row(v1, v2)),\r\n  Row(Row(v2, v2), Row(v2, v1)),\r\n  Row(Row(v2, v2), Row(v2, v2)),\r\n)\r\n\r\nval df = spark.createDataFrame(\r\n  spark.sparkContext.parallelize(structData), schema)\r\ndf.printSchema()\r\ndf.show(false)\r\n\r\nval df2 = df.selectExpr(\"struct1\", \"struct2\", \"struct1 < struct2\", \"struct1 <= struct2\", \"struct1 == struct2\")\r\ndf2.printSchema()\r\ndf2.show(false)\r\n```\r\n\r\n</details>\r\n\r\n<details><summary>Show output</summary>\r\n\r\nThis is the relevant part of the output for understanding NaN behavior.\r\n\r\n```\r\n+----------+----------+-------------------+--------------------+-------------------+\r\n|struct1   |struct2   |(struct1 < struct2)|(struct1 <= struct2)|(struct1 = struct2)|\r\n+----------+----------+-------------------+--------------------+-------------------+\r\n|{1.0, 1.0}|{1.0, 1.0}|false              |true                |true               |\r\n|{1.0, 1.0}|{1.0, NaN}|true               |true                |false              |\r\n|{1.0, 1.0}|{NaN, 1.0}|true               |true                |false              |\r\n|{1.0, 1.0}|{NaN, NaN}|true               |true                |false              |\r\n|{1.0, NaN}|{1.0, 1.0}|false              |false               |false              |\r\n|{1.0, NaN}|{1.0, NaN}|false              |true                |true               |\r\n|{1.0, NaN}|{NaN, 1.0}|true               |true                |false              |\r\n|{1.0, NaN}|{NaN, NaN}|true               |true                |false              |\r\n|{NaN, 1.0}|{1.0, 1.0}|false              |false               |false              |\r\n|{NaN, 1.0}|{1.0, NaN}|false              |false               |false              |\r\n|{NaN, 1.0}|{NaN, 1.0}|false              |true                |true               |\r\n|{NaN, 1.0}|{NaN, NaN}|true               |true                |false              |\r\n|{NaN, NaN}|{1.0, 1.0}|false              |false               |false              |\r\n|{NaN, NaN}|{1.0, NaN}|false              |false               |false              |\r\n|{NaN, NaN}|{NaN, 1.0}|false              |false               |false              |\r\n|{NaN, NaN}|{NaN, NaN}|false              |true                |true               |\r\n+----------+----------+-------------------+--------------------+-------------------+\r\n```\r\n\r\n</details>","createdAt":"2022-06-07T02:36:13Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8964#issuecomment-1148129111","viewerDidAuthor":false}],"createdAt":"2021-08-05T13:56:27Z","id":"MDU6SXNzdWU5NjE4NTU0MDc=","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"}],"milestone":{"number":2,"title":"List and Struct data types and operations","description":"","dueOn":null},"number":8964,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] Add nested struct support for comparison operations","updatedAt":"2022-06-07T02:36:13Z","url":"https://github.com/rapidsai/cudf/issues/8964"}
