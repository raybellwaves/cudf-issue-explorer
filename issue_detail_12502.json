{"assignees":[],"author":{"id":"MDQ6VXNlcjQzNTMyMDU1","is_bot":false,"login":"infzo","name":"Liu"},"body":"**What is your question?**\r\nThe group by collect performance is insufficient, and the performance deteriorates with the increase of the group by column length.\r\n\r\n```\r\n>>> import cudf\r\n>>> import time\r\n>>>\r\n>>> import pandas\r\n>>> import pyarrow\r\n>>> import numpy as np\r\n>>>\r\n>>> def create_table(n_rows, n_cols, n_range):\r\n...     table = pyarrow.Table.from_pydict(\r\n...         {f'col_{c}': np.random.randint(0, n_range, size=[n_rows]) for c in range(n_cols)})\r\n...     return table\r\n...\r\n>>>\r\n>>> def create_table_with_str(n_rows, n_cols, n_strs, n_strs_cols, n_range):\r\n...     prefix = 'xxxx_' * ((n_strs - 10) // 5)\r\n...     cdf = create_table(n_rows, n_cols, n_range).to_pandas()\r\n...     for i in range(n_strs_cols):\r\n...         cdf[f'col_{i}'] = cdf[f'col_{i}'].apply(lambda x: f'{prefix}{x:010}')\r\n    return pyarrow.Table.from_pandas(cdf)...     return pyarrow.Table.from_pandas(cdf)\r\n...\r\n>>>\r\n>>> def stat_cost(str_len):\r\n...     tbl = create_table_with_str(2000 * 10000, 2, str_len, 1, 1500 * 10000)\r\n...     start = time.time()\r\n...     df = cudf.DataFrame.from_arrow(tbl)\r\n...     print(f'from arrow cost: {time.time() - start} s, '\r\n...           f'bandwidth: {df.shape[0] / 10000 / (time.time() - start)} WRows/s')\r\n...     print(df)\r\n...     start = time.time()\r\n...     result = df.groupby(['col_0']).collect()\r\n...     print(f'group by collect cost: {time.time() - start} s, '\r\n...           f'bandwidth: {df.shape[0] / 10000 / (time.time() - start)} WRows/s')\r\n...\r\n>>>\r\n>>> stat_cost(10)\r\nfrom arrow cost: 0.09801530838012695 s, bandwidth: 20401.15471699949 WRows/s\r\n               col_0     col_1\r\n0         0009882104   3942519\r\n1         0009170270   7183154\r\n2         0000346561  14059698\r\n3         0009672848   6882498\r\n4         0011532285  12876681\r\n...              ...       ...\r\n19999995  0000388357    579814\r\n19999996  0009951171  14008663\r\n19999997  0002681040    318695\r\n19999998  0003139531   5608877\r\n19999999  0007299816  12547343\r\n\r\n[20000000 rows x 2 columns]\r\ngroup by collect cost: 1.317047119140625 s, bandwidth: 1518.522440661447 WRows/s\r\n>>> stat_cost(20)\r\nfrom arrow cost: 0.14093589782714844 s, bandwidth: 14187.992497213516 WRows/s\r\n                         col_0     col_1\r\n0         xxxx_xxxx_0011097676   6734961\r\n1         xxxx_xxxx_0005386896  13758023\r\n2         xxxx_xxxx_0012936583  12093805\r\n3         xxxx_xxxx_0014685588    977351\r\n4         xxxx_xxxx_0002394173   4422859\r\n...                        ...       ...\r\n19999995  xxxx_xxxx_0008602092   1174373\r\n19999996  xxxx_xxxx_0006179928   9909283\r\n19999997  xxxx_xxxx_0004578043   4414022\r\n19999998  xxxx_xxxx_0004295524   9151066\r\n19999999  xxxx_xxxx_0009383727   5630830\r\n\r\n[20000000 rows x 2 columns]\r\ngroup by collect cost: 3.6019299030303955 s, bandwidth: 555.254619538489 WRows/s\r\n>>> stat_cost(30)\r\nfrom arrow cost: 0.1838366985321045 s, bandwidth: 10878.289477949978 WRows/s\r\n                                   col_0     col_1\r\n0         xxxx_xxxx_xxxx_xxxx_0012107927  11093137\r\n1         xxxx_xxxx_xxxx_xxxx_0008415030   6082935\r\n2         xxxx_xxxx_xxxx_xxxx_0001637082   5181973\r\n3         xxxx_xxxx_xxxx_xxxx_0014907884  13010547\r\n4         xxxx_xxxx_xxxx_xxxx_0011395415   8406699\r\n...                                  ...       ...\r\n19999995  xxxx_xxxx_xxxx_xxxx_0013393283   9371961\r\n19999996  xxxx_xxxx_xxxx_xxxx_0012288828   3685424\r\n19999997  xxxx_xxxx_xxxx_xxxx_0011403282  11832112\r\n19999998  xxxx_xxxx_xxxx_xxxx_0014808359  12467674\r\n19999999  xxxx_xxxx_xxxx_xxxx_0007966548   3177904\r\n\r\n[20000000 rows x 2 columns]\r\ngroup by collect cost: 6.546090126037598 s, bandwidth: 305.5246419013939 WRows/s\r\n\r\n```\r\n![捕获](https://user-images.githubusercontent.com/43532055/211317106-522eec4e-6bc4-439f-8eda-4dd889379a24.PNG)\r\n\r\nHow to improve performance?\r\n\r\n\r\n","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5X3nM8","author":{"login":"GregoryKimball"},"authorAssociation":"CONTRIBUTOR","body":"Hello @infzo thank you for raising this issue. I reworked your script a bit and found that `groupby().collect()` was about 15-30x slower than `groupby().sum()`. It looks like we are doing a lot of extra work in constructing a list output type in the `collect` case. Perhaps this could be because `collect` is doing a sort-based groupby whereas `sum` is doing a hash-based groupby. Perhaps there is an opportunity to improve libcudf performance here.\r\n\r\nProfile:\r\n![image](https://user-images.githubusercontent.com/12725111/225979786-ba227afe-3158-40e6-ae83-b2dad707bf45.png)\r\n\r\nScript:\r\n<details>\r\n  <summary>issue12502.py</summary>\r\n  import cudf\r\nimport time\r\nimport pandas\r\nimport pyarrow\r\nimport numpy as np\r\nimport nvtx\r\n\r\n\r\ndef create_table(n_rows, n_cols, n_range):\r\n    table = pyarrow.Table.from_pydict(\r\n        {f'col_{c}': np.random.randint(0, n_range, size=[n_rows]) for c in range(n_cols)})\r\n    return table\r\n\r\ndef create_table_with_str(n_rows, n_cols, n_strs, n_strs_cols, n_range):\r\n    prefix = 'xxxx_' * ((n_strs - 10) // 5)\r\n    cdf = create_table(n_rows, n_cols, n_range).to_pandas()\r\n    for i in range(n_strs_cols):\r\n         cdf[f'col_{i}'] = cdf[f'col_{i}'].apply(lambda x: f'{prefix}{x:010}')\r\n    return pyarrow.Table.from_pandas(cdf)    \r\n\r\n\r\ndef stat_cost(str_len):\r\n    tbl = create_table_with_str(2000 * 10000, 2, str_len, 1, 1500 * 10000)\r\n    start = time.time()\r\n    df = cudf.DataFrame.from_arrow(tbl)\r\n    print(f'from arrow cost: {time.time() - start} s, '\r\n          f'bandwidth: {df.shape[0] / 10000 / (time.time() - start)} WRows/s')\r\n\r\n\r\n    df_mb = (df['col_0'].str.byte_count().sum() + df['col_1'].size*8)/1e6\r\n\r\n    with nvtx.annotate(f'groupby.collect {str_len}', color='orange'):\r\n        t0 = time.time()\r\n        result = df.groupby(['col_0']).collect()\r\n        t1 = time.time()\r\n    result_mb = (cudf.Series(result.index).str.byte_count().sum() + result['col_1'].list.len().sum()*8)/1e6\r\n    \r\n    print(f'group by collect cost: {t1 - t0} s, ',\r\n           #f'bandwidth: {df.shape[0] / 10000 / (t1 - t0)} WRows/s',\r\n           f'df MB: {df_mb}',\r\n           f'result MB: {result_mb} MB',\r\n           f'bandwidth: {(df_mb + result_mb) / (t1 - t0)} MB/s',)\r\n    \r\n    with nvtx.annotate(f'groupby.sum {str_len}', color='orange'):\r\n        t0 = time.time()\r\n        result = df.groupby(['col_0']).sum()\r\n        t1 = time.time()\r\n    result_mb = (cudf.Series(result.index).str.byte_count().sum() + result['col_1'].size*8)/1e6\r\n\r\n    print(f'group by sum cost: {t1 - t0} s, ',\r\n           #f'bandwidth: {df.shape[0] / 10000 / (t1 - t0)} WRows/s',\r\n           f'df MB: {df_mb}',\r\n           f'result MB: {result_mb} MB',\r\n           f'bandwidth: {(df_mb + result_mb) / (t1 - t0)} MB/s',)\r\n\r\n\r\nif __name__ == '__main__':\r\n\r\n    print('stat_cost(10)')\r\n    stat_cost(10)\r\n\r\n    print('stat_cost(20)')\r\n    stat_cost(20)\r\n\r\n\r\n    print('stat_cost(30)')\r\n    stat_cost(30)\r\n\r\n\r\n\r\n</details>\r\n\r\n\r\nConsole output:\r\n```\r\nstat_cost(10)\r\nfrom arrow cost: 0.9572014808654785 s, bandwidth: 2089.36701848911 WRows/s\r\ngroup by collect cost: 0.25451135635375977 s,  df MB: 360.0 result MB: 270.49128 MB bandwidth: 2477.2618755905114 MB/s\r\ngroup by sum cost: 0.020035982131958008 s,  df MB: 360.0 result MB: 198.884304 MB bandwidth: 27894.030865028686 MB/s\r\nstat_cost(20)\r\nfrom arrow cost: 0.05078125 s, bandwidth: 39371.675850222004 WRows/s\r\ngroup by collect cost: 0.6336925029754639 s,  df MB: 560.0 result MB: 380.93408 MB bandwidth: 1484.8433200359832 MB/s\r\ngroup by sum cost: 0.020110130310058594 s,  df MB: 560.0 result MB: 309.307712 MB bandwidth: 43227.353507758904 MB/s\r\nstat_cost(30)\r\nfrom arrow cost: 0.0644078254699707 s, bandwidth: 31043.73859721189 WRows/s\r\ngroup by collect cost: 1.0736150741577148 s,  df MB: 760.0 result MB: 491.42092 MB bandwidth: 1165.6141480518793 MB/s\r\ngroup by sum cost: 0.02320241928100586 s,  df MB: 760.0 result MB: 419.799832 MB bandwidth: 50848.13862345021 MB/s\r\n```\r\n\r\nProfile script:\r\n```\r\n/nfs/nsight-systems-2022.5.1/bin/nsys profile -t nvtx,cuda,osrt -f true --stats=true --cuda-memory-usage=true --gpu-metrics-device=0 --output=p python issue12502.py\r\n```\r\n\r\nSystem: \r\n```\r\n23.02 release docker image, A100 GPU, AMD Epyc\r\n```\r\n\r\n","createdAt":"2023-03-17T17:47:06Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/12502#issuecomment-1474196284","viewerDidAuthor":false}],"createdAt":"2023-01-09T13:18:58Z","id":"I_kwDOBWUGps5a7o7E","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjQ=","name":"question","description":"Further information is requested","color":"D4C5F9"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTM5NzQxMjEz","name":"cuDF (Python)","description":"Affects Python cuDF API.","color":"1d76db"}],"milestone":{"number":28,"title":"Aggregations continuous improvement","description":"","dueOn":null},"number":12502,"projectCards":[{"project":{"name":"Other Issues"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[QST]The group by collect performance is insufficient, and the performance deteriorates with the increase of the group by column length.","updatedAt":"2023-07-22T20:31:28Z","url":"https://github.com/rapidsai/cudf/issues/12502"}
