{"assignees":[],"author":{"id":"MDQ6VXNlcjM0NDEzMjE=","is_bot":false,"login":"revans2","name":"Robert (Bobby) Evans"},"body":"**Is your feature request related to a problem? Please describe.**\r\n\r\nIn an offline discussion with some people in CUDF we expressed how it could be a huge memory savings for the Spark team if we could get columns that we could put into a table/etc but they are really just a scalar with a count. We end up doing this all over the place in all kinds of different situations.\r\n\r\nWe don't currently use dictionary columns at all but we would be okay with that as an alternative if we could get dictionary columns working more broadly. But even then they still have issues.\r\n\r\nIn many cases they are more expensive to use for computation if they do work like concat two columns together requires merging the dictionary column instead of a simple memory operation. Yes, a concat of two scalar columns is going to likely be more expensive than two regular columns, but it should not be that bad, and might be faster than generating the fully columns and then concat-ing them.\r\n\r\nIt also is not always a win from a memory standpoint. With a DICTIONARY32 only values that are on average larger than a 32-bit value result in memory savings, for a scalar column replacement. This can get into really odd cases where an INT32 is not a win from a memory standpoint unless it is null (because the null would add 1 bit per row so 33 bits instead of just 32).\r\n\r\n**Describe the solution you'd like**\r\nIdeally https://github.com/rapidsai/cudf/blob/769c1bd6c05f3734044762c9efe3c65ef22cddbd/cpp/include/cudf/column/column_factories.hpp#L546 would just return this new type, or we could have a new API like is used to create a dictionary column from a scalar. \r\n\r\nEventually we might be able to automatically do some things with them, like if we are reading parquet and determine that all of the values in the column are a single thing (like from a dictionary), then we could automatically replace them with a scalar column.","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps53HwmX","author":{"login":"bdice"},"authorAssociation":"CONTRIBUTOR","body":"This sounds like a special case of a run-length encoded column.","createdAt":"2024-03-14T21:36:21Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"EYES","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/15308#issuecomment-1998522775","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps53H27k","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Could you elaborate on which operations would use this and how they would work?\r\nSo much of our code checks to make sure column-types match.\r\nFor example, even dictionary columns generally operate only against other dictionary columns.\r\n\r\nIt may be easier to overload certain APIs to accept a scalar parameter instead of a column.","createdAt":"2024-03-14T21:57:28Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15308#issuecomment-1998548708","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps53PMQM","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"> This sounds like a special case of a run-length encoded column.\r\n\r\nYes I would accept a run length encoded column too.\r\n\r\n> Could you elaborate on which operations would use this and how they would work?\r\n\r\nThat is kind of hard to do right now. Conceptually we pass tables around in Spark between different operators. It is not really a table, as it is Spark specific, but we treat them the same and convert back and forth between them everywhere. I was hoping to be able to keep this abstraction, and just allow us to have a scalar column, or run length encoded column as the case may be. \r\n\r\nIf there is no simple way to add an abstraction to get this, then we should go back and see how much of this we can do ourselves outside of using a table everywhere. ","createdAt":"2024-03-15T21:32:43Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15308#issuecomment-2000471052","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps53Plmp","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"I assume the scalar column would only be for fixed-width-types and strings. There are certain APIs where the internal implementation converts (non-nested) inputs to iterators and here a scalar could easily be represented as a column using a constant iterator. And so these APIs could have an alternate signature to plumb the scalar (column or rle column) through.\r\nOf course, not all internal implementations are coded this way so the amount of effort here depends on what APIs need to be targeted.","createdAt":"2024-03-15T22:16:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15308#issuecomment-2000574889","viewerDidAuthor":false}],"createdAt":"2024-03-14T21:27:50Z","id":"I_kwDOBWUGps6CX4K6","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"}],"milestone":null,"number":15308,"projectCards":[],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] Support a Scalar only column","updatedAt":"2024-03-15T22:16:24Z","url":"https://github.com/rapidsai/cudf/issues/15308"}
