,title,body,createdAt,n_body_reactions_thumbs_up,n_body_reactions_thumbs_down,author.name,company
0,Support for windows? ,"I use Linux at work but at home I have windows and would like to be able to run it on my main machine with conda. Currently when I run:

`conda env create --name pygdf_dev --file conda_environments/testing_py35.yml`

I am seeing this error:

```
NoPackagesFoundError: Package missing in current win-64 channels:
  - libgdf_cffi >=0.1.0a1.dev
```

I am hoping that this could be easily added to the win-64 channels?",2017-07-01T05:54:03Z,43,0,stephenmm,
1,Add clang-tidy for automatic linting,"<!--

Thanks for opening an issue! To help the libGDF team handle your information
efficiently, please first ensure that there is no other issue present that
already describes the issue you have
(search at https://github.com/gpuopenanalytics/libgdf/issues?&q=is%3Aissue).

If there is no issue present please jump to a section below and delete the
irrelevant one depending on whether you are:

 * Making a feature request.
 * Reporting a bug.

For more general ""how do I do X?"" type questions, please speak visit
http://gpuopenanalytics.com/#/COMMUNITY for links to Slack and Google
Groups.

-->

## Feature request

In similar spirit of #117, would be good to start using [`clang-tidy`](https://clang.llvm.org/extra/clang-tidy/) as a linter on the codebase to catch some errors, style violations, etc.

Arrow's setup would be a good place to start, which includes a [CMake target](https://github.com/apache/arrow/blob/44c2fa7d7d4e7a1c1645c85f87d557c4fc510c33/cpp/CMakeLists.txt#L552-L560) to run the tool and a [custom version of `run-clang-tidy`](https://github.com/apache/arrow/blob/master/cpp/build-support/run-clang-tidy.sh) which supports ignoring some files.

<!--

Please include details of the feature you would like to see, why you would
like to see it/the use case

-->",2018-08-29T18:00:18Z,0,0,Andrew Seidl,
2,[BUG] Long import times,"**Describe the bug**

It takes a few seconds to import cudf today

**Steps/Code to reproduce bug**

```
In [1]: import numpy, pandas

In [2]: %time import cudf
CPU times: user 432 ms, sys: 132 ms, total: 564 ms
Wall time: 2.44 s
```

<details>

```
**git***
commit ab3f45857f641548f6d64d977908075d63c193bf (HEAD -> repr-html, mrocklin/repr-html)
Author: Matthew Rocklin <mrocklin@gmail.com>
Date:   Thu Jan 3 17:35:10 2019 -0800

    Test repr for both large and small dataframes

***OS Information***
DGX_NAME=""DGX Server""
DGX_PRETTY_NAME=""NVIDIA DGX Server""
DGX_SWBUILD_DATE=""2018-03-20""
DGX_SWBUILD_VERSION=""3.1.6""
DGX_COMMIT_ID=""1b0f58ecbf989820ce745a9e4836e1de5eea6cfd""
DGX_SERIAL_NUMBER=QTFCOU8310024

DGX_OTA_VERSION=""3.1.7""
DGX_OTA_DATE=""Thu Sep 27 20:07:53 PDT 2018""
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=16.04
DISTRIB_CODENAME=xenial
DISTRIB_DESCRIPTION=""Ubuntu 16.04.5 LTS""
NAME=""Ubuntu""
VERSION=""16.04.5 LTS (Xenial Xerus)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 16.04.5 LTS""
VERSION_ID=""16.04""
HOME_URL=""http://www.ubuntu.com/""
SUPPORT_URL=""http://help.ubuntu.com/""
BUG_REPORT_URL=""http://bugs.launchpad.net/ubuntu/""
VERSION_CODENAME=xenial
UBUNTU_CODENAME=xenial
Linux dgx16 4.4.0-135-generic #161-Ubuntu SMP Mon Aug 27 10:45:01 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

***GPU Information***
Thu Jan  3 18:42:10 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |
| N/A   42C    P0    59W / 300W |   1085MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |
| N/A   43C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |
| N/A   42C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |
| N/A   41C    P0    47W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |
| N/A   42C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |
| N/A   42C    P0    44W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
| N/A   44C    P0    45W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
| N/A   41C    P0    44W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     64394      C   ...klin/miniconda/envs/cudf_dev/bin/python   644MiB |
|    0     65545      C   ...klin/miniconda/envs/cudf_dev/bin/python   430MiB |
+-----------------------------------------------------------------------------+

***CPU***
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                80
On-line CPU(s) list:   0-79
Thread(s) per core:    2
Core(s) per socket:    20
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz
Stepping:              1
CPU MHz:               2030.789
CPU max MHz:           3600.0000
CPU min MHz:           1200.0000
BogoMIPS:              4391.76
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              51200K
NUMA node0 CPU(s):     0-19,40-59
NUMA node1 CPU(s):     20-39,60-79
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt ssbd ibrs ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts flush_l1d

***CMake***
/home/nfs/mrocklin/miniconda/envs/cudf_dev/bin/cmake
cmake version 3.13.2

CMake suite maintained and supported by Kitware (kitware.com/cmake).

***g++***
/usr/bin/g++
g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


***nvcc***

***Python***
/home/nfs/mrocklin/miniconda/envs/cudf_dev/bin/python
Python 3.5.5

***Environment Variables***
PATH                            : /home/nfs/mrocklin/miniconda/envs/cudf_dev/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/bin:/home/nfs/mrocklin/.local/bin:/home/nfs/mrocklin/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
LD_LIBRARY_PATH                 :
NUMBAPRO_NVVM                   :
NUMBAPRO_LIBDEVICE              :
CONDA_PREFIX                    : /home/nfs/mrocklin/miniconda/envs/cudf_dev
PYTHON_PATH                     :

***conda packages***
/home/nfs/mrocklin/miniconda/bin/conda
# packages in environment at /home/nfs/mrocklin/miniconda/envs/cudf_dev:
#
# Name                    Version                   Build  Channel
alabaster                 0.7.12                     py_0    conda-forge
arrow-cpp                 0.10.0           py35h70250a7_0    conda-forge
asn1crypto                0.24.0                   py35_3    conda-forge
atomicwrites              1.2.1                      py_0    conda-forge
attrs                     18.2.0                     py_0    conda-forge
babel                     2.6.0                      py_1    conda-forge
backcall                  0.1.0                      py_0    conda-forge
blas                      1.0                         mkl
bleach                    3.0.2                      py_1    conda-forge
bokeh                     0.13.0                   py35_0
boost                     1.67.0           py35h3e44d54_0    conda-forge
boost-cpp                 1.67.0               h3a22d5f_0    conda-forge
bzip2                     1.0.6                h470a237_2    conda-forge
ca-certificates           2018.03.07                    0
certifi                   2018.8.24                py35_1
cffi                      1.11.5           py35h5e8e0c9_1    conda-forge
chardet                   3.0.4                    py35_3    conda-forge
click                     7.0                        py_0    conda-forge
cloudpickle               0.6.1                      py_0    conda-forge
cmake                     3.13.2               h011004d_0    conda-forge
commonmark                0.5.4                      py_2    conda-forge
cryptography              2.3.1            py35hdffb7b8_0    conda-forge
cryptography-vectors      2.3.1                    py35_0    conda-forge
cudatoolkit               9.2                           0
cudf                      0.4.0+385.g81a187d           <pip>
curl                      7.63.0               h74213dd_0    conda-forge
cython                    0.28.5           py35hfc679d8_0    conda-forge
cytoolz                   0.9.0.1          py35h470a237_0    conda-forge
dask                      1.0.0+51.g2ca205b           <pip>
dask-core                 1.0.0                      py_0    conda-forge
dask-cuda                 0.0.0                     <pip>
dask-cudf                 0.0.1+222.g10a9f90.dirty           <pip>
decorator                 4.3.0                      py_0    conda-forge
distributed               1.23.2                   py35_1    conda-forge
distributed               1.25.1+10.ga0d0ed2           <pip>
docutils                  0.14                     py35_1    conda-forge
entrypoints               0.2.3                    py35_2    conda-forge
expat                     2.2.5                hfc679d8_2    conda-forge
future                    0.16.0                   py35_2    conda-forge
gmp                       6.1.2                hfc679d8_0    conda-forge
heapdict                  1.0.0                 py35_1000    conda-forge
icu                       58.2                 hfc679d8_0    conda-forge
idna                      2.7                      py35_2    conda-forge
imagesize                 1.1.0                      py_0    conda-forge
intel-openmp              2019.1                      144
ipykernel                 5.1.0              pyh24bf2e0_0    conda-forge
ipython                   7.0.1            py35h24bf2e0_0    conda-forge
ipython_genutils          0.2.0                      py_1    conda-forge
jedi                      0.12.1                   py35_0    conda-forge
jinja2                    2.10                       py_1    conda-forge
jsonschema                2.6.0                    py35_2    conda-forge
jupyter_client            5.2.4                      py_0    conda-forge
jupyter_core              4.4.0                      py_0    conda-forge
krb5                      1.16.2               hbb41f41_0    conda-forge
libcurl                   7.63.0               hbdb9355_0    conda-forge
libedit                   3.1.20170329         haf1bffa_1    conda-forge
libffi                    3.2.1                hfc679d8_5    conda-forge
libgcc-ng                 8.2.0                hdf63c60_1
libgdf-cffi               0.4.0                     <pip>
libgfortran-ng            7.2.0                hdf63c60_3    conda-forge
librmm-cffi               0.4.0                     <pip>
libsodium                 1.0.16               h470a237_1    conda-forge
libssh2                   1.8.0                h5b517e9_3    conda-forge
libstdcxx-ng              8.2.0                hdf63c60_1
libuv                     1.24.1               h470a237_0    conda-forge
llvmlite                  0.27.0           py35hf484d3e_0    numba
Markdown                  2.6.11                    <pip>
markupsafe                1.0              py35h470a237_1    conda-forge
mistune                   0.8.3            py35h470a237_2    conda-forge
mkl                       2018.0.3                      1
mkl_fft                   1.0.9                    py35_0    conda-forge
mkl_random                1.0.1                    py35_0    conda-forge
more-itertools            4.3.0                    py35_0    conda-forge
msgpack-python            0.5.6            py35h2d50403_3    conda-forge
nbconvert                 5.3.1                      py_1    conda-forge
nbformat                  4.4.0                      py_1    conda-forge
ncurses                   6.1                  hfc679d8_2    conda-forge
notebook                  5.7.0                    py35_0    conda-forge
numba                     0.42.0          np115py35hf484d3e_0    numba
numpy                     1.15.2           py35h1d66e8a_0
numpy-base                1.15.2           py35h81de0dd_0
numpydoc                  0.8.0                      py_1    conda-forge
nvstrings                 0.1.0            cuda9.2_py35_0    nvidia
openssl                   1.0.2p               h14c3975_0
packaging                 18.0                       py_0    conda-forge
pandas                    0.20.3                   py35_1    conda-forge
pandoc                    2.5                           0    conda-forge
pandocfilters             1.4.2                      py_1    conda-forge
parquet-cpp               1.5.0.pre            h83d4a3d_0    conda-forge
parso                     0.3.1                      py_0    conda-forge
pathlib2                  2.3.2                    py35_0    conda-forge
pexpect                   4.6.0                    py35_0    conda-forge
pickleshare               0.7.5                    py35_0    conda-forge
pip                       18.0                  py35_1001    conda-forge
pluggy                    0.8.0                      py_0    conda-forge
prometheus_client         0.5.0                      py_0    conda-forge
prompt_toolkit            2.0.7                      py_0    conda-forge
psutil                    5.4.7            py35h470a237_1    conda-forge
ptyprocess                0.6.0                 py35_1000    conda-forge
py                        1.7.0                      py_0    conda-forge
pyarrow                   0.10.0           py35hfc679d8_0    conda-forge
pycparser                 2.19                       py_0    conda-forge
pygments                  2.3.1                      py_0    conda-forge
pyopenssl                 18.0.0                   py35_0    conda-forge
pyparsing                 2.3.0                      py_0    conda-forge
pysocks                   1.6.8                    py35_2    conda-forge
pytest                    4.0.2                     <pip>
pytest                    3.8.1                    py35_0
python                    3.5.5                h5001a0f_2    conda-forge
python-dateutil           2.7.5                      py_0    conda-forge
pytz                      2018.7                     py_0    conda-forge
pyyaml                    3.13             py35h470a237_1    conda-forge
pyzmq                     17.1.2           py35hae99301_0    conda-forge
readline                  7.0                  haf1bffa_1    conda-forge
recommonmark              0.4.0                      py_2    conda-forge
requests                  2.19.1                   py35_1    conda-forge
rhash                     1.3.6                h470a237_1    conda-forge
send2trash                1.5.0                      py_0    conda-forge
setuptools                40.4.3                   py35_0    conda-forge
simplegeneric             0.8.1                      py_1    conda-forge
six                       1.11.0                   py35_1    conda-forge
snowballstemmer           1.2.1                      py_1    conda-forge
sortedcontainers          2.1.0                      py_0    conda-forge
sphinx                    1.8.1                    py35_0    conda-forge
sphinx-markdown-tables    0.0.9                     <pip>
sphinx_rtd_theme          0.4.2                      py_0    conda-forge
sphinxcontrib-websupport  1.1.0                      py_1    conda-forge
sqlite                    3.26.0               hb1c47c0_0    conda-forge
tblib                     1.3.2                      py_1    conda-forge
terminado                 0.8.1                    py35_1    conda-forge
testpath                  0.3.1                    py35_1    conda-forge
tk                        8.6.9                ha92aebf_0    conda-forge
toolz                     0.9.0                      py_1    conda-forge
tornado                   5.1.1            py35h470a237_0    conda-forge
traitlets                 4.3.2                    py35_0    conda-forge
urllib3                   1.23                     py35_1    conda-forge
wcwidth                   0.1.7                      py_1    conda-forge
webencodings              0.5.1                      py_1    conda-forge
wheel                     0.32.0                py35_1000    conda-forge
xz                        5.2.4                h470a237_1    conda-forge
yaml                      0.1.7                h470a237_1    conda-forge
zeromq                    4.2.5                hfc679d8_6    conda-forge
zict                      0.1.3                      py_0    conda-forge
zlib                      1.2.11               h470a237_3    conda-forge
```

</details>",2019-01-04T02:46:53Z,0,0,Matthew Rocklin,@coiled 
3,[FEA] DatetimeIndex Frequency/TZ,"In Pandas, DatetimeIndexes can report back the frequency and timezone.  I think this would be useful/nice for cuDF but it's not a high priority at all.  

```
In [70]: pd.date_range(end='1/1/2018', periods=8).freq
Out[70]: <Day>
```

For more info on these extended dtypes: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#period-dtypes",2019-06-06T16:09:44Z,0,0,Benjamin Zaitlen,
4,[FEA]Add merge_asof to cudf,Please add merge_asof to cudf to match pandas merge_asof capabilities. Thanks!,2019-07-12T17:04:59Z,0,0,,
5,Support callables in DataFrame.assign,"Value I am trying to compute is a range between two measure variables `v1, v2` within groups defined by `id2, id4` categories.
The following pandas/dask syntax could work
```py
ans = x.groupby(['id2','id4']).agg({'v1': 'max', 'v2': 'min'}).assign(range_v1_v2=lambda x: x['v1'] - x['v2'])[['range_v1_v2']]
#  File ""pyarrow/array.pxi"", line 536, in pyarrow.lib.Array.from_pandas
#  File ""pyarrow/array.pxi"", line 176, in pyarrow.lib.array
#  File ""pyarrow/array.pxi"", line 85, in pyarrow.lib._ndarray_to_array
#  File ""pyarrow/error.pxi"", line 81, in pyarrow.lib.check_status
#pyarrow.lib.ArrowInvalid: Only 1D arrays accepted
```
reproducible example
```py
import os
import gc
import cudf as cu
ver = cu.__version__
print(ver)
#0.8.0+0.g8fa7bd3.dirty
src_grp = ""G1_1e7_1e2_0_0.csv""
x = cu.read_csv(src_grp, skiprows=1,
                names=['id1','id2','id3','id4','id5','id6','v1','v2','v3'],
                dtype=['str','str','str','int','int','int','int','int','float'])
ans = x.groupby(['id2','id4']).agg({'v1': 'max', 'v2': 'min'}).assign(range_v1_v2=lambda x: x['v1'] - x['v2'])[['range_v1_v2']]
```
generate data according to https://github.com/rapidsai/cudf/issues/2494",2019-08-15T09:19:19Z,0,0,Jan Gorecki,
6,[BUG]Cannot query dataframes with categorical columns ,"**Describe the bug**
if i do a simple query on a categorical column, i get an error stating that  `This error is usually caused by passing an argument of a type that is unsupported by the named function.`

**Steps/Code to reproduce bug**
```
import cudf
import pandas as pd

fn = 'test.csv'
lines = """"""id1,id2
1,45
2,3
3, 7
1, 25
""""""
with open(fn, 'w') as fp:
    fp.write(lines)
pdf = pd.read_csv(fn, header=0, dtype={""id1"":""category"", ""id2"":""int32""})
cdf = cudf.read_csv(fn, header=0, dtype={""id1"":""int32"", ""id2"":""int32""}) #see #3960 for why i have to do this
cdf['id1'] = cdf['id1'].astype(""category"")
pdf.query(""id1 == ['1'] and id2 == 45"")
cdf.query(""id1 == ['1'] and id2 == 45"")
```
The cdf query outputs a rather large error
```
---------------------------------------------------------------------------
TypingError                               Traceback (most recent call last)
<ipython-input-27-28a794912e6e> in <module>
----> 1 cdf2.query(""id1 == ['1'] and id2 == 45"")

/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/dataframe.py in query(self, expr, local_dict)
   2893         }
   2894         # Run query
-> 2895         boolmask = queryutils.query_execute(self, expr, callenv)
   2896 
   2897         selected = Series(boolmask)

/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/utils/queryutils.py in query_execute(df, expr, callenv)
    223     # run kernel
    224     args = [out] + colarrays + envargs
--> 225     kernel.forall(nrows)(*args)
    226     out_mask = applyutils.make_aggregate_nullmask(df, columns=columns)
    227     if out_mask is not None:

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in __call__(self, *args)
    264     def __call__(self, *args):
    265         if isinstance(self.kernel, AutoJitCUDAKernel):
--> 266             kernel = self.kernel.specialize(*args)
    267         else:
    268             kernel = self.kernel

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in specialize(self, *args)
    808         argtypes = tuple(
    809             [self.typingctx.resolve_argument_type(a) for a in args])
--> 810         kernel = self.compile(argtypes)
    811         return kernel
    812 

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in compile(self, sig)
    824                 self.targetoptions['link'] = ()
    825             kernel = compile_kernel(self.py_func, argtypes,
--> 826                                     **self.targetoptions)
    827             self.definitions[(cc, argtypes)] = kernel
    828             if self.bind:

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)
     30         def _acquire_compile_lock(*args, **kwargs):
     31             with self:
---> 32                 return func(*args, **kwargs)
     33         return _acquire_compile_lock
     34 

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in compile_kernel(pyfunc, args, link, debug, inline, fastmath, extensions, max_registers)
     60 def compile_kernel(pyfunc, args, link, debug=False, inline=False,
     61                    fastmath=False, extensions=[], max_registers=None):
---> 62     cres = compile_cuda(pyfunc, types.void, args, debug=debug, inline=inline)
     63     fname = cres.fndesc.llvm_func_name
     64     lib, kernel = cres.target_context.prepare_cuda_kernel(cres.library, fname,

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)
     30         def _acquire_compile_lock(*args, **kwargs):
     31             with self:
---> 32                 return func(*args, **kwargs)
     33         return _acquire_compile_lock
     34 

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in compile_cuda(pyfunc, return_type, args, debug, inline)
     49                                   return_type=return_type,
     50                                   flags=flags,
---> 51                                   locals={})
     52 
     53     library = cres.library

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)
    526     pipeline = pipeline_class(typingctx, targetctx, library,
    527                               args, return_type, flags, locals)
--> 528     return pipeline.compile_extra(func)
    529 
    530 

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in compile_extra(self, func)
    324         self.state.lifted = ()
    325         self.state.lifted_from = None
--> 326         return self._compile_bytecode()
    327 
    328     def compile_ir(self, func_ir, lifted=(), lifted_from=None):

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in _compile_bytecode(self)
    383         """"""
    384         assert self.state.func_ir is None
--> 385         return self._compile_core()
    386 
    387     def _compile_ir(self):

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in _compile_core(self)
    363                 self.state.status.fail_reason = e
    364                 if is_final_pipeline:
--> 365                     raise e
    366         else:
    367             raise CompilerError(""All available pipelines exhausted"")

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in _compile_core(self)
    354             res = None
    355             try:
--> 356                 pm.run(self.state)
    357                 if self.state.cr is not None:
    358                     break

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_machinery.py in run(self, state)
    326                     (self.pipeline_name, pass_desc)
    327                 patched_exception = self._patch_error(msg, e)
--> 328                 raise patched_exception
    329 
    330     def dependency_analysis(self):

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_machinery.py in run(self, state)
    317                 pass_inst = _pass_registry.get(pss).pass_inst
    318                 if isinstance(pass_inst, CompilerPass):
--> 319                     self._runPass(idx, pass_inst, state)
    320                 else:
    321                     raise BaseException(""Legacy pass in use"")

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)
     30         def _acquire_compile_lock(*args, **kwargs):
     31             with self:
---> 32                 return func(*args, **kwargs)
     33         return _acquire_compile_lock
     34 

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_machinery.py in _runPass(self, index, pss, internal_state)
    279             mutated |= check(pss.run_initialization, internal_state)
    280         with SimpleTimer() as pass_time:
--> 281             mutated |= check(pss.run_pass, internal_state)
    282         with SimpleTimer() as finalize_time:
    283             mutated |= check(pss.run_finalizer, internal_state)

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_machinery.py in check(func, compiler_state)
    266 
    267         def check(func, compiler_state):
--> 268             mangled = func(compiler_state)
    269             if mangled not in (True, False):
    270                 msg = (""CompilerPass implementations should return True/False. ""

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typed_passes.py in run_pass(self, state)
     92                 state.args,
     93                 state.return_type,
---> 94                 state.locals)
     95             state.typemap = typemap
     96             state.return_type = return_type

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals)
     64 
     65         infer.build_constraint()
---> 66         infer.propagate()
     67         typemap, restype, calltypes = infer.unify()
     68 

/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typeinfer.py in propagate(self, raise_errors)
    949                                   if isinstance(e, ForceLiteralArg)]
    950                 if not force_lit_args:
--> 951                     raise errors[0]
    952                 else:
    953                     raise reduce(operator.or_, force_lit_args)

TypingError: Failed in nopython mode pipeline (step: nopython frontend)
Invalid use of Function(<numba.cuda.compiler.DeviceFunctionTemplate object at 0x7f914147a320>) with argument(s) of type(s): (int32, int32)
 * parameterized
In definition 0:
    TypingError: Failed in nopython mode pipeline (step: nopython frontend)
Invalid use of Function(<built-in function eq>) with argument(s) of type(s): (int32, list(unicode_type))
Known signatures:
 * (bool, bool) -> bool
 * (int8, int8) -> bool
 * (int16, int16) -> bool
 * (int32, int32) -> bool
 * (int64, int64) -> bool
 * (uint8, uint8) -> bool
 * (uint16, uint16) -> bool
 * (uint32, uint32) -> bool
 * (uint64, uint64) -> bool
 * (float32, float32) -> bool
 * (float64, float64) -> bool
 * (complex64, complex64) -> bool
 * (complex128, complex128) -> bool
 * parameterized
In definition 0:
    All templates rejected with literals.
In definition 1:
    All templates rejected without literals.
In definition 2:
    All templates rejected with literals.
In definition 3:
    All templates rejected without literals.
In definition 4:
    All templates rejected with literals.
In definition 5:
    All templates rejected without literals.
In definition 6:
    All templates rejected with literals.
In definition 7:
    All templates rejected without literals.
In definition 8:
    All templates rejected with literals.
In definition 9:
    All templates rejected without literals.
In definition 10:
    All templates rejected with literals.
In definition 11:
    All templates rejected without literals.
In definition 12:
    All templates rejected with literals.
In definition 13:
    All templates rejected without literals.
In definition 14:
    All templates rejected with literals.
In definition 15:
    All templates rejected without literals.
In definition 16:
    All templates rejected with literals.
In definition 17:
    All templates rejected without literals.
In definition 18:
    All templates rejected with literals.
In definition 19:
    All templates rejected without literals.
This error is usually caused by passing an argument of a type that is unsupported by the named function.
[1] During: typing of intrinsic-call at <string> (2)

File ""<string>"", line 2:
<source missing, REPL/exec in use?>

    raised from /opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typeinfer.py:951
In definition 1:
    TypingError: Failed in nopython mode pipeline (step: nopython frontend)
Invalid use of Function(<built-in function eq>) with argument(s) of type(s): (int32, list(unicode_type))
Known signatures:
 * (bool, bool) -> bool
 * (int8, int8) -> bool
 * (int16, int16) -> bool
 * (int32, int32) -> bool
 * (int64, int64) -> bool
 * (uint8, uint8) -> bool
 * (uint16, uint16) -> bool
 * (uint32, uint32) -> bool
 * (uint64, uint64) -> bool
 * (float32, float32) -> bool
 * (float64, float64) -> bool
 * (complex64, complex64) -> bool
 * (complex128, complex128) -> bool
 * parameterized
In definition 0:
    All templates rejected with literals.
In definition 1:
    All templates rejected without literals.
In definition 2:
    All templates rejected with literals.
In definition 3:
    All templates rejected without literals.
In definition 4:
    All templates rejected with literals.
In definition 5:
    All templates rejected without literals.
In definition 6:
    All templates rejected with literals.
In definition 7:
    All templates rejected without literals.
In definition 8:
    All templates rejected with literals.
In definition 9:
    All templates rejected without literals.
In definition 10:
    All templates rejected with literals.
In definition 11:
    All templates rejected without literals.
In definition 12:
    All templates rejected with literals.
In definition 13:
    All templates rejected without literals.
In definition 14:
    All templates rejected with literals.
In definition 15:
    All templates rejected without literals.
In definition 16:
    All templates rejected with literals.
In definition 17:
    All templates rejected without literals.
In definition 18:
    All templates rejected with literals.
In definition 19:
    All templates rejected without literals.
This error is usually caused by passing an argument of a type that is unsupported by the named function.
[1] During: typing of intrinsic-call at <string> (2)

File ""<string>"", line 2:
<source missing, REPL/exec in use?>

    raised from /opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typeinfer.py:951
This error is usually caused by passing an argument of a type that is unsupported by the named function.
[1] During: resolving callee type: Function(<numba.cuda.compiler.DeviceFunctionTemplate object at 0x7f914147a320>)
[2] During: typing of call at <string> (6)


File ""<string>"", line 6:
<source missing, REPL/exec in use?>
```
**Expected behavior**
I expect it to output similar to the `pdf.query`, `pdf.query(""id1 == ['1'] and id2 == 45"")`

id1 | id2
-- | --
1 | 45

**Environment overview (please complete the following information)**
 - Environment location: [Docker]
 - Method of cuDF install: [Docker]

**Additional context**
Converting from cudf to pandas to do the query also inexplicitly fails
```
tdf = cdf.to_pandas()
tdf['id1']
```
will output correctly with 
```
0    1
1    2
2    3
3    1
Name: id1, dtype: category
Categories (3, int64): [1, 2, 3]
```
but when you run the query...
```
tdf.query(""id1 == ['1'] and id2 == 45"")
```
Outputs an empty table 

  | id1 | id2
-- | -- | --






",2020-01-28T11:55:24Z,0,0,Taurean Dyer,
7,[FEA] Support nanValue Spark CSV parse option in cudf CSV reader,"_Description of the request:_ 
Apache Spark CSV reader options include specifying values that should be interpreted as NaNs via `nanValue`.
Refer to  [https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/DataFrameReader.html](url) 
cuDF CSV reader seems to lack an equivalent

_Description of a possible solution_:
It would helpful to have a translation/support for that option in the cudf CSV reader options. (analogous to its na_values)",2020-01-29T22:12:37Z,0,0,Kuhu Shukla,
8,[BUG] expand_bits_to_bytes could be improved by returning ndarray of np.bool,"**Describe the bug**
`expand_bits_to_bytes`, defined below, is a utility function for unit tests which unpacks a bitmask into a list of valids per element. As currently defined, this returns a `list` of `int` where 1 is valid and 0 is invalid. However, in every case where this is used, the caller converts the result to `ndarray` of `bool`. The input to the function is expected to be an `ndarray` anyway, so there could be some numpy transform which gives us the result as `ndarray` directly.
https://github.com/rapidsai/cudf/blob/a831f11bdeb2cb8dfcc2f47ef69b596a2334c3d2/python/cudf/cudf/tests/utils.py#L36-L43

**Expected behavior**
Refactor `expand_bits_to_bytes` to return `ndarray` of `bool`. [unpackbits](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.unpackbits.html) looks like it would be useful here.",2020-02-20T03:05:49Z,0,0,Trevor Smith,
9,[FEA] predicate push down such as bloom filters added to read_orc,"having predicate pushdowns such as bloom filters work as in hive to skip over sections of data on disk during the read would enable better overall performance as the data would never have to be loaded to memory and then discarded if the predicate didn't match in the row group.

support predicate pushdown similar to what is done with hive in read_orc, primary support for bloom filter but also for sorted data as well to enable only loading relevant data to query.


",2020-03-10T22:22:06Z,0,0,,Walmart
10,"[FEA] Async, especially for heavier ops","**Is your feature request related to a problem? Please describe.**

We are currently putting manual `await sleep(0)` points into our cudf code to enable use of cudf alongside Python async code in web server scenarios. Otherwise, cudf hangs our web server when it is used for handling requests. This gets worse as tasks get bigger, complicates having mixed CPU/GPU tasks, and unnecessarily forces architectural decisions like carefully separating processes and 2-level scheduling. 

**Describe the solution you'd like**

Support for Python3's async/await constructor. Part of the Python 2 -> 3 shift is native support for `async`, especially for IO (e.g., when handling web requests) and compute (e.g., compression tasks).  

Ex:

```
@route(/cluster/big/dataset/<datasetid>, method=POST)
async def cluster_big_dataset(dataset_id):
    
    df = await cudf.read_parquet(f'/files/{dataset_id}.parquet')
    ...
```

This would be great universally, but there's probably a ~top 10 list for most slow in practice: to/from I/O, groupby & merge, ... .

**Describe alternatives you've considered**

* Going via Dask also supports this, but with way more overhead and complexity. 

* We currently use multiple Python processes to help with SLAs, but it's clearly avoidable.",2020-03-16T21:44:13Z,0,0,,Graphistry
11,[FEA] dask-cudf groupby with quantile and median methods,"**Is your feature request related to a problem? Please describe.**
I'd like to calculate median and/or quantile on a column after groupbying a dask-cudf data frame. 

**EDIT** 5/10/2024: median is now implemented

**Describe the solution you'd like**
I want the following code to work and generate correct results:

```
cdf =cudf.DataFrame({'id4': 4*list(range(6)), 'id5': 4*list(reversed(range(6))), 'v3': 6*list(range(4))})
ddf = dcu.from_cudf(cdf, npartitions= 1)

ddf.dtypes
id4    int64
id5    int64
v3     int64
dtype: object

ddf.head()

        id4   id5     v3

0	0	5	0
1	1	4	1
2	2	3	2
3	3	2	3
4	4	1	0

#these groupby operations do not work
ans = ddf.groupby(['id4', 'id5'])[['v3']].median().compute()

OR 

ans = ddf.groupby(['id4', 'id5'])[['v3']].quantile(q=0.5).compute()
```

**Additional context**
I am using Rapids 0.13 nightly release in conda env, with dask 2.12.0 version.
",2020-03-26T16:49:09Z,0,0,,
12,[FEA] Snappy Compressed CSV Not Implemented,read_csv doesn't support snappy compression. As a workaround we use snappy-python to uncompress csv files and then load using cudf.,2020-05-08T14:57:47Z,0,0,Lahir Marni,
13,[FEA] cuDF doesn’t support custom class objects as columns,"
**Is your feature request related to a problem? Please describe.**
cuDF doesn’t support custom class objects as columns

**Describe the solution you'd like**
Add support for custom class objects to be used as columns

**Describe alternatives you've considered**
Use strings instead

**Additional context**

Pandas sample
```python

import pandas as pd

class Header:
    def __init__(self, name):
        self.name = name

pd.DataFrame({Header(""name""): [1, 2, 3]})
```

cuDF sample
```python
import cudf as pd

pd.DataFrame({Header(""name""): [1, 2, 3]})
# TypeError: __setitem__ on type <class '__main__.Header'> is not supported

```

Traceback:
```python
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)

~/miniconda3/envs/rapids14/lib/python3.7/site-packages/cudf/core/dataframe.py in __setitem__(self, arg, value)
    616         else:
    617             msg = ""__setitem__ on type {!r} is not supported""
--> 618             raise TypeError(msg.format(type(arg)))
    619 
    620     def __delitem__(self, name):

TypeError: __setitem__ on type <class '__main__.Header'> is not supported
       
```
",2020-06-23T07:19:58Z,0,0,,
14,[FEA] cuDF doesn't work out of the box with `NamedTuple` when constructing a `DataFrame`,"
**Is your feature request related to a problem? Please describe.**

cuDF doesn't work out of the box with `NamedTuple` when constructing a `DataFrame`

**Describe the solution you'd like**

Add support for `NamedTuple`

**Describe alternatives you've considered**

First, create a `NamedTuple` object:

```python
from typing import NamedTuple, Optional, List
class ModelPrediction(NamedTuple):
    suspicious: Optional[bool]
    confidence: Optional[float]
    prediction: Optional[List[float]]

outputs = [ModelPrediction(suspicious=True, confidence=0.1, prediction=60), ModelPrediction(suspicious=False, confidence=0.6, prediction=40), ModelPrediction(suspicious=True, confidence=0.8, prediction=30)]
```

cuDF workaround:
```python
import cudf as pd
pd.DataFrame(list(iter(outputs)), columns=ModelPrediction.__annotations__.keys())
```

**Additional context**

Pandas works out of the box:
```python
import pandas as pd
pd.DataFrame(iter(outputs))
```

while cuDF produces a DataFrame with column names missing:
```python
import cudf as pd
pd.DataFrame(list(iter(outputs))) # column names missing

```

Output:
```
suspicious	confidence	prediction
0	True	0.1	60
1	False	0.6	40
2	True	0.8	30
```",2020-06-23T07:22:34Z,0,0,,
15,[FEA] `fillna()` doesn't accept axis keyword,"
**Is your feature request related to a problem? Please describe.**

`fillna()` doesn't accept axis keyword

**Describe the solution you'd like**

Add support for the `axis` keyword

**Describe alternatives you've considered**

In our use case `axis` keyword was redundant, it worked without it

**Additional context**

Pandas showcase:
```python

import pandas as pd

data = pd.DataFrame(
   data=([[None, None, 100, 1000, 10000], [2, 20, 200, 2000, 20000]]), columns=['a', 'b', 'c', 'd', 'e']
)

data1 = pd.DataFrame(
   data=([[3, 33], [2, 22]]), columns=['a', 'b']
)
data.fillna(data1, axis=1)
```

cuDF showcase:
```python
import cudf as pd

data = pd.DataFrame(
   data=([[None, None, 100, 1000, 10000], [2, 20, 200, 2000, 20000]]), columns=['a', 'b', 'c', 'd', 'e']
)

data1 = pd.DataFrame(
   data=([[3, 33], [2, 22]]), columns=['a', 'b']
)
data.fillna(data1, axis=1) # the axis keyword is not supported

```

Traceback:
```python
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
<ipython-input-9-3b5ff28bd8cb> in <module>
      9    data=([[3, 33], [2, 22]]), columns=['a', 'b']
     10 )
---> 11 data.fillna(data1, axis=1) # the axis keyword is not supported

~/miniconda3/envs/rapids14/lib/python3.7/site-packages/cudf/core/dataframe.py in fillna(self, value, method, axis, inplace, limit)
   3815                 axis=axis,
   3816                 inplace=inplace,
-> 3817                 limit=limit,
   3818             )
   3819 

~/miniconda3/envs/rapids14/lib/python3.7/site-packages/cudf/core/series.py in fillna(self, value, method, axis, inplace, limit)
   1605             raise NotImplementedError(""The limit keyword is not supported"")
   1606         if axis:
-> 1607             raise NotImplementedError(""The axis keyword is not supported"")
   1608 
   1609         data = self._column.fillna(value)

NotImplementedError: The axis keyword is not supported
    ```
",2020-06-23T07:26:33Z,0,0,,
16,[FEA] Hash values in nested columns,"Hashing categorical features to a fixed number of bins is a common preprocessing operation, particularly for tabular deep learning models where memory requirements scale with the number of bins. For extension of CuDF to nested columns, it would be helpful if calls to `Series.hash_values` hashed the values *in* each element's list and not the list itself. This would allow categorical hashing to extend to multi-hot categorical features.

As an example:
```
df = cudf.DataFrame({'a': [[0, 1, 2], [3, 4], [], [5], [6, 7, 8, 9]]})
df['a'].hash_values()

# not sure what this representation will
# print like but some like this
[[ 29140149,  -247539971,  1683430573],  [1098043756,  1851360991], [],
        [100260016],   [154726282, -1778135556, -1793932552,   246633392]]

df['a'].hash_values() % 4
[[1, 1, 1], [0, 3], [], [0], [2, 0, 0, 0]]
```

**Additional context**
Necessary for extension of [NVTabular HashBucket op](https://github.com/NVIDIA/NVTabular/blob/9f8216a89d565e00d8356ffef62f4437f3e2dee3/nvtabular/ops.py#L498) to multi-hot categorical data
",2020-07-06T13:43:29Z,0,0,Alec Gunny,MIT
17,[ENH] Identify opportunities for making properties cached in cuDF,"Wherever possible, cache properties using [`cached_property`](https://github.com/rapidsai/cudf/blob/branch-0.15/python/cudf/cudf/utils/utils.py#L310) to avoid computing them every time they are needed.",2020-07-15T12:27:36Z,0,0,Ashwin Srinath,Voltron Data
18,[FEA] Rolling slope calculation with groupby,"Hello.

I would like to calculate the rolling slope of y_value over x_value using cuML LinearRegression.

Sample data (cuDF dataframe):
```
| date       | x_value | y_value |
| ------     | ------  |  ----   |
| 2020-01-01 | 900     | 10      |
| 2020-01-01 | 905     | 15      |
| 2020-01-01 | 910     | 15      |
| 2020-01-01 | 915     | 15      |
| 2020-01-02 | 900     | 30      |
| 2020-01-02 | 905     | 40      |
| 2020-01-02 | 910     | 50      |
| ------     | ------  | ------  |
```
A simple function to use LinearRegression:
```
def RollingOLS(x, y):
    lr = LinearRegression(fit_intercept = True, normalize = False, algorithm = 'svd')
    reg = lr.fit(x, y)
    
    return reg.coef_
```

What I would like to do:
```
data.groupby('date').rolling(2).apply(RollingOLS, x=x_value, y=y_value)
```

However, I am getting an error: ```NotImplementedError: Handling UDF with null values is not yet supported```. Is there any way to overcome this error? Thank you.",2020-08-02T16:43:06Z,0,0,,
19,[FEA] Make java test utlities for Lists and nested types user-friendly and less verbose,"**Is your feature request related to a problem? Please describe.**
Add test utilities to make complex type testing simpler and readable.


**Describe the solution you'd like**
We need some modifications to fromLists and getList methods in cudf java to auto detect number of elements, assert when numRows and data size may not line up and make `DataType` more palatable in terms of verbosity.

",2020-08-07T21:20:07Z,0,0,Kuhu Shukla,
20,[FEA] Pass `cudaStreamPerThread` to numba/CuPy kernels,"Memory allocations should already use PTDS since both numba and CuPy allocate memory using RMM. Kernels on the other hand, may explicitly need to be passed the `cudaStreamPerThread` stream handle.

cc: @jakirkham @kkraus14",2020-08-11T13:45:41Z,0,0,Ashwin Srinath,Voltron Data
21,[FEA] Profiling duplicate reading of metadata,"The row-group-level filtered reading for Parquet that is introduced by #5843 creates an issue of duplicate metadata (metadata is stored in the footers of Parquet files) reading in the case when filters are specified. Arrow is used to read metadata and select a subset of data to read given user-provided filters [4] . Information about this subset is then passed to libcudf which reads in the subset [5]. The issue is that metadata gets read twice - first when Arrow reads metadata to do filtering and second when libcudf reads data.

This issue was initially raised here [1].

# What to profile

- [ ] Perf penalty of reading metadata using Arrow for filtering in the same vein as [2] but with datasets of varying # of files
- [ ] Perf penalty of parsing metadata buffer [3] as fraction of total time Arrow spends reading metadata

# What to determine

- [ ] Determine whether or not perf penalty of the additional reading of metadata using Arrow is significant
- [ ] Determine whether the duplicate reading should be resolved by passing metadata struct (steps to implement [6]) or metadata buffer (which is then parsed into metadata struct in libcudf) (steps to implement [7]) from Arrow `Dataset` to libcudf reader functions

# Relevant discussion/code

[1] https://github.com/rapidsai/cudf/pull/5843#discussion_r467191621
[2] https://github.com/rapidsai/cudf/pull/5843#issuecomment-673566456
[3] https://github.com/apache/arrow/blob/2e6009621011d7df43882aa883905b84d1647018/cpp/src/parquet/file_reader.cc#L532
[4] https://github.com/rapidsai/cudf/pull/5843/files#diff-deac873508aaa12ca2e7c0a2c9035230R316
[5] https://github.com/rapidsai/cudf/pull/5843/files#diff-deac873508aaa12ca2e7c0a2c9035230R359-R375
[6] https://github.com/rapidsai/cudf/pull/5843#issuecomment-674437264
[7] https://github.com/rapidsai/cudf/pull/5843#issuecomment-674437709",2020-08-17T19:09:26Z,0,0,Caleb Winston,Stanford
22,[FEA] Filtering/reading statistics of ORC data with legacy TimestampStatistics,"The ORC statistics reading introduced in #6142 and stats-based ORC filtering in #6116 do not support the legacy version of `TimestampStatistics` in the ORC format. This legacy version uses time that is adjusted to the local timezone that the ORC data was written in. Fortunately, the local timezone is contained in ORC metadata so it is possible for us to support this version.

I'm creating this issue mainly to see if there is a need for this (user/workflow). If there is, the necessary changes would involve an interface between cuDF and libcudf for getting `writerTimezone` from each `StripeFooter`. This `writerTimezone` would be used to decode `minimum` and `maximum` into Python datetimes.",2020-09-04T19:15:28Z,0,0,Caleb Winston,Stanford
23,[FEA] Nth element support in dask cudf,"Requesting `nth` support in dask cudf after groupby.
ex. 
```
from cudf import DataFrame
import dask_cudf
df = DataFrame()
df['key'] = [1, 1, 1, 1, 2, 2, 2]
df['val_0']= [13, 15, 20, 27, 60, 17, 90]
df['val_1'] = [5, 1, 4, 9, 2, 7, 8]
meta_format = DataFrame()
ddf = dask_cudf.from_cudf(df, npartitions=1)
groups = ddf.groupby(['key']).nth(0)
```
Currently it fails with :
```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/miniconda3/envs/branch15/lib/python3.8/site-packages/dask/dataframe/groupby.py in __getattr__(self, key)
   1749         try:
-> 1750             return self[key]
   1751         except KeyError as e:

~/miniconda3/envs/branch15/lib/python3.8/site-packages/dask/dataframe/groupby.py in __getitem__(self, key)
   1735         # error is raised from pandas
-> 1736         g._meta = g._meta[key]
   1737         return g

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in __getitem__(self, key)
    623     def __getitem__(self, key):
--> 624         return self.obj[key].groupby(self.grouping, dropna=self._dropna)
    625

~/miniconda3/envs/branch15/lib/python3.8/contextlib.py in inner(*args, **kwds)
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/dataframe.py in __getitem__(self, arg)
    640         if is_scalar(arg) or isinstance(arg, tuple):
--> 641             return self._get_columns_by_label(arg, downcast=True)
    642

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/frame.py in _get_columns_by_label(self, labels, downcast)
    466         """"""
--> 467         new_data = self._data.select_by_label(labels)
    468         if downcast:

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/column_accessor.py in select_by_label(self, key)
    216                     return self._select_by_label_with_wildcard(key)
--> 217             return self._select_by_label_grouped(key)
    218

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/column_accessor.py in _select_by_label_grouped(self, key)
    264     def _select_by_label_grouped(self, key):
--> 265         result = self._grouped_data[key]
    266         if isinstance(result, cudf.core.column.ColumnBase):

KeyError: 'nth'

The above exception was the direct cause of the following exception:

AttributeError                            Traceback (most recent call last)
<ipython-input-2-9e488bd207ec> in <module>
      7 meta_format = DataFrame()
      8 ddf = dask_cudf.from_cudf(df, npartitions=1)
----> 9 groups = ddf.groupby(['key']).nth(1)

~/miniconda3/envs/branch15/lib/python3.8/site-packages/dask/dataframe/groupby.py in __getattr__(self, key)
   1750             return self[key]
   1751         except KeyError as e:
-> 1752             raise AttributeError(e) from e
   1753
   1754     @derived_from(pd.core.groupby.DataFrameGroupBy)

AttributeError: 'nth'
```
Once this functionality is implemented it should return a dask cudf dataframe that would contain the first row of each groupby

```
     val_0  val_1
key
1       13      5
2       60      2

```",2020-09-08T18:19:17Z,0,0,,
24,[FEA] Improve readability of thread id based branching,"Improve readability of thread id based branches by giving them more descriptive names.

#### e.g.
```c++
if (!t) // is actually a t == 0
```
#### and
https://github.com/rapidsai/cudf/blob/57ef76927373d7260b6a0eda781e59a4c563d36e/cpp/src/io/statistics/column_stats.cu#L285
Is actually a `lane_id == 0`
As demonstrated in https://github.com/rapidsai/cudf/issues/6241#issuecomment-693125331, prefer cooperative groups for this.


#### and
https://github.com/rapidsai/cudf/blob/85cd56dfb3449140f18c7cef3a3be01ac976fd14/cpp/src/io/parquet/page_enc.cu#L1256
is actually ~`t < 32`~ `lane_id == 31`. (~I think this might be an oversight,~ ignore as it might be fixed in #6238 ).",2020-09-15T18:12:23Z,1,0,Devavret Makkar,@VoltronData
25,[BUG] Rolling window's apply function throws `TypingError`,"On running the apply function for `rolling` and trying to analyze array or any other variable type other than a single value I get the following error:
`TypingError: Failed in nopython mode pipeline (step: nopython frontend)`

Code to reproduce the error:
```
import cudf
import numpy as np
import math
def groll_sort(x):
    t = x.median() #np.median(x.values)
    return t
df = cudf.DataFrame()
df['a'] = (0.25, 0.3, 0.5,1,3,1,-1,3,-2)
rolling = df.rolling(window=3).apply(groll_sort)
print(rolling)
```
Note: I also tried using `t = np.median(x.values)` in the function
On running the above code i get the following error:
```
---------------------------------------------------------------------------
TypingError                               Traceback (most recent call last)
<ipython-input-6-99e3758f2d02> in <module>
      7 df = cudf.DataFrame()
      8 df['a'] = (0.25, 0.3, 0.5,1,3,1,-1,3,-2)
----> 9 rolling = df.rolling(window=3).apply(groll_sort)
     10 print(rolling)

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/window/rolling.py in apply(self, func, *args, **kwargs)
    276                 ""Handling UDF with null values is not yet supported""
    277             )
--> 278         return self._apply_agg(func)
    279
    280     def _normalize(self):

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/window/rolling.py in _apply_agg(self, agg_name)
    236             return self._apply_agg_series(self.obj, agg_name)
    237         else:
--> 238             return self._apply_agg_dataframe(self.obj, agg_name)
    239
    240     def sum(self):

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/window/rolling.py in _apply_agg_dataframe(self, df, agg_name)
    225         result_df = cudf.DataFrame({})
    226         for i, col_name in enumerate(df.columns):
--> 227             result_col = self._apply_agg_series(df[col_name], agg_name)
    228             result_df.insert(i, col_name, result_col)
    229         result_df.index = df.index

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/window/rolling.py in _apply_agg_series(self, sr, agg_name)
    201     def _apply_agg_series(self, sr, agg_name):
    202         if isinstance(self.window, int):
--> 203             result_col = libcudf.rolling.rolling(
    204                 sr._column,
    205                 None,

cudf/_lib/rolling.pyx in cudf._lib.rolling.rolling()

cudf/_lib/aggregation.pyx in cudf._lib.aggregation.make_aggregation()

cudf/_lib/aggregation.pyx in cudf._lib.aggregation._AggregationFactory.from_udf()

~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/utils/cudautils.py in compile_udf(udf, type_signature)
    287     """"""
    288     decorated_udf = cuda.jit(udf, device=True)
--> 289     compiled = decorated_udf.compile(type_signature)
    290     ptx_code = decorated_udf.inspect_ptx(type_signature).decode(""utf-8"")
    291     output_type = numpy_support.as_dtype(compiled.signature.return_type)

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/cuda/compiler.py in compile(self, args)
    162         """"""
    163         if args not in self._compileinfos:
--> 164             cres = compile_cuda(self.py_func, None, args, debug=self.debug,
    165                                 inline=self.inline)
    166             first_definition = not self._compileinfos

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)
     30         def _acquire_compile_lock(*args, **kwargs):
     31             with self:
---> 32                 return func(*args, **kwargs)
     33         return _acquire_compile_lock
     34

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/cuda/compiler.py in compile_cuda(pyfunc, return_type, args, debug, inline)
     36         flags.set('forceinline')
     37     # Run compilation pipeline
---> 38     cres = compiler.compile_extra(typingctx=typingctx,
     39                                   targetctx=targetctx,
     40                                   func=pyfunc,

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)
    601     pipeline = pipeline_class(typingctx, targetctx, library,
    602                               args, return_type, flags, locals)
--> 603     return pipeline.compile_extra(func)
    604
    605

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func)
    337         self.state.lifted = ()
    338         self.state.lifted_from = None
--> 339         return self._compile_bytecode()
    340
    341     def compile_ir(self, func_ir, lifted=(), lifted_from=None):

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self)
    399         """"""
    400         assert self.state.func_ir is None
--> 401         return self._compile_core()
    402
    403     def _compile_ir(self):

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self)
    379                 self.state.status.fail_reason = e
    380                 if is_final_pipeline:
--> 381                     raise e
    382         else:
    383             raise CompilerError(""All available pipelines exhausted"")

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self)
    370             res = None
    371             try:
--> 372                 pm.run(self.state)
    373                 if self.state.cr is not None:
    374                     break

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state)
    339                     (self.pipeline_name, pass_desc)
    340                 patched_exception = self._patch_error(msg, e)
--> 341                 raise patched_exception
    342
    343     def dependency_analysis(self):

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state)
    330                 pass_inst = _pass_registry.get(pss).pass_inst
    331                 if isinstance(pass_inst, CompilerPass):
--> 332                     self._runPass(idx, pass_inst, state)
    333                 else:
    334                     raise BaseException(""Legacy pass in use"")

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)
     30         def _acquire_compile_lock(*args, **kwargs):
     31             with self:
---> 32                 return func(*args, **kwargs)
     33         return _acquire_compile_lock
     34

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state)
    289             mutated |= check(pss.run_initialization, internal_state)
    290         with SimpleTimer() as pass_time:
--> 291             mutated |= check(pss.run_pass, internal_state)
    292         with SimpleTimer() as finalize_time:
    293             mutated |= check(pss.run_finalizer, internal_state)

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state)
    262
    263         def check(func, compiler_state):
--> 264             mangled = func(compiler_state)
    265             if mangled not in (True, False):
    266                 msg = (""CompilerPass implementations should return True/False. ""

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state)
     90                               % (state.func_id.func_name,)):
     91             # Type inference
---> 92             typemap, return_type, calltypes = type_inference_stage(
     93                 state.typingctx,
     94                 state.func_ir,

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors)
     68
     69         infer.build_constraint()
---> 70         infer.propagate(raise_errors=raise_errors)
     71         typemap, restype, calltypes = infer.unify(raise_errors=raise_errors)
     72

~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors)
    992                                   if isinstance(e, ForceLiteralArg)]
    993                 if not force_lit_args:
--> 994                     raise errors[0]
    995                 else:
    996                     raise reduce(operator.or_, force_lit_args)

TypingError: Failed in nopython mode pipeline (step: nopython frontend)
Unknown attribute 'median' of type array(float64, 1d, A)

File ""<ipython-input-6-99e3758f2d02>"", line 5:
def groll_sort(x):
    t = x.median() #np.median(x.values)
    ^

During: typing of get attribute at <ipython-input-6-99e3758f2d02> (5)

File ""<ipython-input-6-99e3758f2d02>"", line 5:
def groll_sort(x):
    t = x.median() #np.median(x.values)
```

The same code runs on pandas and gives the following output:
I/P:
```
import pandas
import numpy as np
def groll_sort(x):
    t = x.median()
    return t
df = pandas.DataFrame()
df['a'] = (0.25, 0.3, 0.5,1,3,1,-1,3,-2)
rolling = df.rolling(window=3).apply(groll_sort)
print(rolling)
```
O/P:
```
     a
0  NaN
1  NaN
2  0.3
3  0.5
4  1.0
5  1.0
6  1.0
7  1.0
8 -1.0
```",2020-09-18T20:42:53Z,0,0,,
26,[FEA] rolling median(),"Use case: Run a sliding window robust z-score as part of standard EEG preprocessing step. Point is to denoise a non-stationary signal. This is a general outlier detection procedure that could have value outside EEG. 

(There was a previous request last year but seems to have stalled: https://github.com/rapidsai/cudf/issues/2135)

The robust z-score uses the **median** for the first (expectation) and second (variance, standard deviation) moments. This is instead of the average. 

Current operation takes about 30 minutes for 10^7x20 element data frame in pandas. cuDF could bring this down to seconds. 

**Describe the solution you'd like**
Like to have a median() agg added to rolling or UDF for apply. 

For robust z the function is:

$$z_i = \kappa\frac{x_i-median(x)}{median(absolute\{(x_i-median(x))\})}$$
$$\text{where } \kappa\textrm{ := scaling factor}$$
$$x \subseteq X \text{, }X\text{ column vector in DF} $$


So, some possible solution to get the sliding robust z once we have the median working with apply are: 1) run the median twice (once of the original and then again on the median absolute values of the substracted residuals), and 2) right a custom UDF once the median function solution is known. 

**Describe alternatives you've considered**
I have tried writing a UDF but the issue is the **sort()** needed for the median calculation. I tried a numba nopython pandas rolling.apply solution. This works if I copy the windowed array (x2 = x.copy()). It spits out an error when run with cuDF. I believe it's a memory and/or broadcasting issue (I've seen two kinds of errors). If I don't copy then the pandas numba code sorts the original array and propagates this corrupt data back to the original DF.   

**Additional context**
Here is an example of the numba solution that works (this is for example to test on cuDF, of course pandas has a rolling median() agg). 

>code

```
@nb.jit(nopython=True)
def udf_median(x):
  ##version 0
  #mu = np.median(x)
  ##version 1
  x2 = x.copy()
  x2.sort()
  n = len(x2)
  k = int(n/2) 
  if n%2 == 0:
    mu = (x2[k]+x2[k+1])/2
  else:
    mu = x2[k]
  return mu



df = pd.DataFrame()
df['a'] = (-5,-3,-1,0.2,-2)
df['b'] = (5,-3,1,-0.2,-2)
print('original df')
print(df)
rolling = df.rolling(window=3,axis=0)
print(""panda call\nwin=3 rolling median"")
print(rolling.apply(udf_median, engine='numba', raw=True))
print('df after rolling call - if copy is not done, then corrupted original df')
print(df)

print(""\ncuDF call"")
df = cudf.DataFrame()
df['a'] = (-5,-3,-1,0.2,-2)
df['b'] = (5,-3,1,-0.2,-2)
rolling = df.rolling(window=3,axis=0)
print(rolling.apply(udf_median))

```

>output
original df
     a    b
0 -5.0  5.0
1 -3.0 -3.0
2 -1.0  1.0
3  0.2 -0.2
4 -2.0 -2.0
panda call
win=3 rolling median
     a    b
0  NaN  NaN
1  NaN  NaN
2 -3.0  1.0
3 -1.0 -0.2
4 -1.0 -0.2
df after rolling call - if copy is not done, then corrupted original df
(in this case the df is intact due to the copy function, comment that out to see the error)
     a    b
0 -5.0  5.0
1 -3.0 -3.0
2 -1.0  1.0
3  0.2 -0.2
4 -2.0 -2.0

cuDF call

RuntimeError                              Traceback (most recent call last)
/usr/local/lib/python3.6/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs)
    744     try:
--> 745         yield
    746     except NumbaError as e:

40 frames
RuntimeError: NRT required but not enabled

During handling of the above exception, another exception occurred:

LoweringError                             Traceback (most recent call last)
cudf/_lib/rolling.pyx in cudf._lib.rolling.rolling()

cudf/_lib/aggregation.pyx in cudf._lib.aggregation.make_aggregation()

cudf/_lib/aggregation.pyx in cudf._lib.aggregation._AggregationFactory.from_udf()

/usr/local/lib/python3.6/site-packages/numba/core/utils.py in reraise(tp, value, tb)
     79     if value.__traceback__ is not tb:
     80         raise value.with_traceback(tb)
---> 81     raise value
     82 
     83 

LoweringError: Failed in nopython mode pipeline (step: nopython mode backend)
NRT required but not enabled

File ""<ipython-input-16-2c1e7f32fcdd>"", line 6:
def udf_median(x):
    <source elided>
  ##version 1
  x2 = x.copy()
  ^

During: lowering ""$0.3 = call $0.2(func=$0.2, args=[], kws=(), vararg=None)"" at <ipython-input-16-2c1e7f32fcdd> (6)
",2020-09-20T04:50:18Z,0,0,,
27,[FEA] Improve escape character and quotation character parsing in Json and CSV reader.,"**Is your feature request related to a problem? Please describe.**
As of now, csv and json reader are post processing occurrences of escape character and quotation character once it parses complete string.
https://github.com/rapidsai/cudf/blob/76e2e155ce6fe2194a2bb41aeca93b48a39a55c2/cpp/src/io/csv/reader_impl.cu#L375

**Describe the solution you'd like**
We might be able to handle skipping/leaving those character while copying the data.",2020-09-23T14:41:02Z,0,0,Ram (Ramakrishna Prabhu),
28,[BUG] `cudf.read_json` is incorrectly parsing TimeStamp typed columns,"**Describe the bug**
`cudf.read_json` is failing to parse DateTime64 typed columns correctly when expected dtype is provided. 

**Steps/Code to reproduce bug**
```
>>> import cudf
>>> import pandas as pd
>>> pdf = pd.DataFrame({""a"":[45461150050, 55414521000, 4544624522000, 4546345758000, 45445254600]}, dtype='datetime64[ms]')
>>> pdf
                        a
0 1970-01-01 00:00:45.461
1 1970-01-01 00:00:55.414
2 1970-01-01 01:15:44.624
3 1970-01-01 01:15:46.345
4 1970-01-01 00:00:45.445
>>> buffer = pdf.to_json(compression='infer', lines=True, orient=""records"")
>>> buffer
'{""a"":45461}\n{""a"":55414}\n{""a"":4544624}\n{""a"":4546345}\n{""a"":45445}'
>>> df = cudf.read_json(buffer, ompression='infer', lines=True, orient=""records"", dtype=['timestamp[ms]'])
>>> df
                        a
0 1969-12-31 23:59:59.999
1 1969-12-31 23:59:59.999
2 1969-12-31 23:59:59.999
3 1969-12-31 23:59:59.999
4 1969-12-31 23:59:59.999
```
If `dtype` isn't specified, and if we cast the resulting int64 column, we get expected result
```
>>> expected_df = cudf.read_json(buffer, ompression='infer', lines=True, orient=""records"")
>>> expected_df['a'] = expected_df['a'].astype('datetime64[ms]')
>>> expected_df
                        a
0 1970-01-01 00:00:45.461
1 1970-01-01 00:00:55.414
2 1970-01-01 01:15:44.624
3 1970-01-01 01:15:46.345
4 1970-01-01 00:00:45.445
>>> 
```

**Expected behavior**
`cudf.read_json` should handle dtype arguement.
```
>>> df = cudf.read_json(buffer, ompression='infer', lines=True, orient=""records"", dtype=['timestamp[ms]'])
>>> df

                        a
0 1970-01-01 00:00:45.461
1 1970-01-01 00:00:55.414
2 1970-01-01 01:15:44.624
3 1970-01-01 01:15:46.345
4 1970-01-01 00:00:45.445
>>> 
```

**Environment overview (please complete the following information)**
 - Environment location: Bare-metal
 - Method of cuDF install: conda",2020-09-30T22:49:03Z,0,0,Ram (Ramakrishna Prabhu),
29,[FEA] Java host string columns should match list columns,"**Is your feature request related to a problem? Please describe.**
The way we construct and layout strings and lists are different but essentially have similar functionality/usage, adding complexity around host side construction/deconstruction. This should be commonized.

**Describe the solution you'd like**
Strings can be represented as lists maybe.
",2020-10-12T13:08:04Z,0,0,Kuhu Shukla,
30,[BUG] Reading JSON file saved from Series fails,"**Describe the bug**
Reading a JSON file created from a Series `.to_json(path, orient='records', lines=True)` call leads to a `Input data is not a valid JSON file` when trying to read with `.read_json(path, orient='records', lines=True)` (with or without `engine='cudf'` parameter).

**NOTE**: this is only a problem when saving Series in this format -- DataFrame objects are saved properly.

**Steps/Code to reproduce bug**
```
cudf.Series([1,2,3,4,5]).to_json('sample.json', lines=True, orient='records')

cudf.read_json('sample.json', lines=True, orient='records')
```

The output file looks as follows:

```
1
2
3
4
5
```

**Expected behavior**
The file is read back properly and produces a valid `cudf.Series` object. 

**Environment overview (please complete the following information)**
 - Environment location: Docker
 - Method of cuDF install: Docker
   - RAPIDS v 0.16 pull from nightly. ",2020-10-12T22:07:00Z,0,0,Tomek Drabas,Voltron Data
31,[FEA] Add java/JNI support for substring() with non-literals parameters,"**Is your feature request related to a problem? Please describe.**
We currently support only literals as params to substring method, using the newly added `slice_strings` we should be able to support non-literals. 

**Describe the solution you'd like**
Requires jni and java side bindings",2020-10-20T13:26:29Z,0,0,Kuhu Shukla,
32,[FEA] Support objects with default values in Series.map,"**Is your feature request related to a problem? Please describe.**
I'd like for cuDF to support 'defaultdict' like objects in the Series.map method. There is currently a NotImplementedError which contrasts from the Pandas implementation of Series.map

**Describe the solution you'd like**
An implementation of Series.map that converts values that are not found in the dict to a default value, if the dict has a default value (e.g. defaultdict).

**Additional context**
With Pandas an example of this looks like
```
>>>p1 = pd.Series(['cat', 'dog', np.nan, 'rabbit'])
>>>from collections import defaultdict
>>>t = defaultdict(lambda: 'bird')
>>> t['cat'] = 'kitten'
>>> t['dog'] = 'puppy'
>>> p1.map(t)
0    kitten
1     puppy
2      bird
3      bird
dtype: object
```
With cuDF currently we get the following
```
>>> s = cudf.Series(['cat', 'dog', np.nan, 'rabbit'])
>>>s.map(t)

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/nfs/mmhangami/marlene/rapids/cudf/python/cudf/cudf/core/series.py"", line 878, in map
    ""default values in dicts are currently not supported.""
NotImplementedError: default values in dicts are currently not supported.
```

for additional context see [pandas.Series.map](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) and PR #6459
",2020-11-10T11:44:49Z,0,0,Marlene ,Microsoft
33,"[FEA]Coalesce(), find the first non-null value, no equivalent function in RAPIDS","I want to create a new column, which is the first non-null value of several columns, I used the function [coalesce()](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/coalesce) in dplyr to achieve that by simply run ` data %>% mutate(d = coalesce(a, b, c))`, in Dask CPU, I run below code to achieve that
```
d = {'a': [1, 2, 3, None, 5, 1, None, None, None, None, 3, None, 5, 6, 7], \
     'b': [1, 2, 3, 200, 5, 1, 200, None, 400, None, 3, None, 5, 6, 7], \
     'c': [1, 2, 3, None, 5, 1, 300, 300, None, 600, 3, 300, 5, 6, 7]} 

df2 = pd.DataFrame(d)

ddf2 = dd.from_pandas(df2,npartitions=50)
ddf2['d'] = ddf2['a'].copy().fillna(ddf2['b']).fillna(ddf2['c'])
ddf2.compute()
```
However, in dask cuDF, when I am trying to use the fillna() to acheive my intent, I got the error message
```
d = {'id': ['a', 'a','a','a','a','b','b','b','b','b','c','c','c','c','c'], \
     'time': ['1', '2', '4', '3', '5', '1', '2', '3', '4', '5','1', '2', '3', '4', '5'], \
     'a': [1, 2, 3, None, 5, 1, None, None, None, None, 3, None, 5, 6, 7], \
     'b': [1, 2, 3, 200, 5, 1, 200, None, 400, None, 3, None, 5, 6, 7], \
     'c': [1, 2, 3, None, 5, 1, 300, 300, None, 600, 3, 300, 5, 6, 7]} 

df = pd.DataFrame(data=d)
gdf = cudf.DataFrame.from_pandas(df)

ddf = dask_cudf.from_cudf(gdf, npartitions=4)

ddf['d'] = ddf['a'].copy().fillna(ddf['b']).fillna(ddf['c'])
ddf.compute()
```
error message: `RuntimeError: cuDF failure at: /opt/conda/envs/rapids/conda-bld/libcudf_1598487636199/work/cpp/src/replace/replace.cu:804: Column size mismatch`

So I am wondering if there are functions that allows me to get the first non-null value from several columns in cuDF or if we can add that.",2020-11-12T21:16:22Z,0,0,,
34,[BUG] Bools written by cuIO ORC writer don't match when read by pyarrow/pyorc,"When writing a large dataframe with bool column using cuIO ORC writer, the result of reading the file back using pyarrow does not match the input dataframe. However when reading back from cudf's ORC reader it matches.

```python
import pandas as pd
import numpy as np
import pyarrow as pa
import pyorc
import cudf

np.random.seed(0)
from cudf._lib.null_mask import bitmask_allocation_size_bytes

def random_bitmask(size):
    sz = bitmask_allocation_size_bytes(size)
    data = np.random.randint(0, 255, dtype=""u1"", size=sz)
    return data.view(""i1"")

size = 6000000
arr = np.random.randint(low=0, high=2, size=size).astype(np.bool)
s = cudf.Series.from_masked_array(arr, random_bitmask(size))
gdf = cudf.DataFrame({""col_bool"": s})

# write with cuIO
fname = ""brokenbool.orc""
gdf.to_orc(fname)

# read with pyarrow
pdf = pa.orc.ORCFile(fname).read().to_pandas()

# the sum doesn't match
print(gdf.col_bool.sum(), pdf.col_bool.sum())

# read with pyorc
file = open(fname, 'rb')
data = pyorc.Reader(file).read()
pdf = pd.DataFrame(data, columns=[""col_bool""])

# sum matches pyarrow but not original df
print(gdf.col_bool.sum(), pdf.col_bool.sum())

# reading with cuIO gives the correct result
print(gdf.col_bool.sum(), cudf.read_orc(fname).col_bool.sum())
```

Note that this doesn't occur when there are no nulls in the input.",2020-11-13T08:17:43Z,0,0,Devavret Makkar,@VoltronData
35,[FEA] Decimal constructor for boxed unscaled values,"As mentioned in conversation of #6770, it is good to have a decimal constructor for boxed unscaled values, which working with `ColumnVector.build`.",2020-11-18T01:54:43Z,0,0,Alfred Xu,
36,[FEA] Add factory methods for ColumnVector creation in cudf java,"As a follow on to https://github.com/rapidsai/cudf/pull/6751, we plan to move towards factory methods to create ColumnVector instances.",2020-11-18T15:22:04Z,0,0,Kuhu Shukla,
37,[BUG] arrow data: Categorical categories must be unique,"**Describe the bug**

I switched from using csv format to feather format and getting and error for the same dataset. Error is being raised during printing. Sorry for not having minimal example but python is not my native language.

**Steps/Code to reproduce bug**

Generate data in csv and feather
```sh
Rscript -e 'install.packages(c(""data.table"",""arrow""))'
wget https://raw.githubusercontent.com/h2oai/db-benchmark/629755352248c9538fbd924e56356e5592f268be/_data/groupby-datagen.R
Rscript groupby-datagen.R 1e7 1e2 0 0
Rscript -e 'arrow::write_feather(data.table::fread(""G1_1e7_1e2_0_0.csv"", stringsAsFactors=TRUE, data.table=FALSE), ""G1_1e7_1e2_0_0.feather"")'
```

cudf using csv
```py
import cudf as cu
x = cu.read_csv(""G1_1e7_1e2_0_0.csv"", header=0, dtype=['str','str','str','int32','int32','int32','int32','int32','float64'])
x['id1'] = x['id1'].astype('category')
x['id2'] = x['id2'].astype('category')
x['id3'] = x['id3'].astype('category')
ans = x.groupby(['id1'],as_index=False).agg({'v1':'sum'})
print(ans.head(3), flush=True)
```
```
     id1      v1
0  id001  299542
1  id002  300933
2  id003  301968
```

cudf using feather
```py
import cudf as cu
x = cu.io.feather.read_feather(""data/G1_1e7_1e2_0_0.feather"")
#/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/io/feather.py:15: UserWarning: Using CPU via PyArrow to read #feather 
#dataset, this may be GPU accelerated in the future
#  warnings.warn(
ans = x.groupby(['id1'],as_index=False).agg({'v1':'sum'})
print(ans.head(3), flush=True)
```
```
Traceback (most recent call last):
  File ""./cudf/groupby-cudf.py"", line 58, in <module>
    print(ans.head(3), flush=True)
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py"", line 1025, in __str__
    return self.to_string()
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py"", line 1022, in to_string
    return self.__repr__()
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py"", line 1272, in __repr__
    return self._clean_renderable_dataframe(output)
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py"", line 1151, in _clean_renderable_dataframe
    output = output.to_pandas().to_string(
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py"", line 4861, in to_pandas
    out_data[i] = self._data[col_key].to_pandas(index=out_index)
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/column/categorical.py"", line 935, in to_pandas
    data = pd.Categorical.from_codes(
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/arrays/categorical.py"", line 606, in from_codes
    dtype = CategoricalDtype._from_values_or_dtype(
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py"", line 277, in _from_values_or_dtype
    dtype = CategoricalDtype(categories, ordered)
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py"", line 164, in __init__
    self._finalize(categories, ordered, fastpath=False)
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py"", line 318, in _finalize
    categories = self.validate_categories(categories, fastpath=fastpath)
  File ""/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py"", line 495, in validate_categories
    raise ValueError(""Categorical categories must be unique"")
ValueError: Categorical categories must be unique
```

**Expected behavior**

Printing `ans` should not raise error for feather source data, same as it doesn't for csv data.

**Environment overview (please complete the following information)**

bare-metal
cudf installed from conda

**Environment details**

```
cudf/print_env.sh
#Traceback (most recent call last):
#  File ""<stdin>"", line 1, in <module>
#NameError: name 'cudf' is not defined
```

cudf 0.16
arrow 2.0.0
",2020-11-21T09:00:14Z,0,0,Jan Gorecki,
38,"[FEA] Add function ""to_julian_date()""  to cuDF","'DatetimeIndex' object has no attribute 'to_julian_date', would be good if it could do as pandas:
julianday = pd.DatetimeIndex(df['mydatetime']).to_julian_date()",2020-12-06T21:16:16Z,0,0,,
39,[FEA] Support casting operations on nested types,"**Is your feature request related to a problem? Please describe.**
Currently we support `castTo` on primitive data types. This request is to extend this functionality/operator to nested types like lists, structs, and list of structs.

**Describe the solution you'd like**
One should be able to call a cudf function to cast an `array(floats)` for example to an `array(doubles)`. We should also allow other valid casts that we support today to nested type category.
",2021-01-27T14:31:06Z,0,0,Kuhu Shukla,
40,[FEA] Support FIRST_VALUE and LAST_VALUE in grouped_rolling_window,"**Is your feature request related to a problem? Please describe.**
Like ROW_NUMBER, which supported in PR 4881, FIRST_VALUE is widely used window function in sql. So, we want to provide it for BlazingSQL. FIRST_VALUE and LAST_VALUE are fairly trivial where there are no partitions to worry about, but if you have multiple groups or partitions, for the case of `grouped_rolling_window`, then its not so trivial, and we would want native support for that aggregator in cudf.

**Describe the solution you'd like**
Implementation of the aggregation for FIRST_VALUE and LAST_VALUE, especially for `grouped_rolling_window`
",2021-01-27T21:56:45Z,0,0,William Malpica,Voltron Data
41,[BUG] dask_cudf generates files it cannot read back,"**Describe the bug**

Somewhere between `dgdf = dask_cudf.read_csv(..)` and `dgdf.to_parquet()`, the generated files are written in a way that `cudf.read_parquet` and `dask_cudf.read_parquet` will fail to read the data back.

Exception:  `cuDF failure at: /opt/conda/envs/rapids/conda-bld/libcudf_1607621803079/work/cpp/src/io/parquet/reader_impl.cu:371: All sources must have the same schemas`



**Steps/Code to reproduce bug**

May need to fix paths:

Download:

```bash
curl -O /tmp/logs.csv.gz ""https://s3.amazonaws.com/botsdataset/botsv1/csv-by-sourcetype/botsv1.WinEventLog%3ASecurity.csv.gz""
(cd /tmp && gunzip logs.csv.gz)
```

Convert:
```python
with dask.distributed.Client(ADDRESS):
  dgdf = dask_cudf.read_csv('/tmp/logs.csv')
  dgdf.to_parquet(
       '/tmp/logs.parquet',
        compression='snappy',
        write_index=False,
        index=False)
```

Test: Unexpectedly throws exn
```python
cudf.read_parquet('/tmp/logs.parquet')
```

**Expected behavior**
The converted file to read back with matching dtypes... but throws an exn

**Environment overview (please complete the following information)**
RAPIDS 0.18 (conda) in docker (ubuntu); A100's

**Additional context**

* Variants where we set `schema`, `dtypes`,  and `use_pandas_metadata` also fail
* Also seeing failures when doing dask_cudf.read_parquet, and doing an intermediate repartition
",2021-03-15T21:02:56Z,0,0,,Graphistry
42,[FEA][INTERNALS] A `ColumnMeta` type to represent the column metadata of a `Frame`,"When we roundtrip a `Frame` between Python and libcudf, we potentially lose a bunch of metadata:

1. Names of columns
2. Whether the columns have multiple levels (i.e., the Frame has a MultiIndex as its columns(
3. The level names

## The problem

libcudf functions return a `unique_ptr<cudf::table>`, we  convert that `table` into a  `Frame` in the function [from_unique_ptr](https://github.com/rapidsai/cudf/blob/ec5364c2fc0a3c63583e648ec90efa8d3b5675bc/python/cudf/cudf/_lib/table.pyx#L82). Here, we pass the column names (1), but not the multiindex (2) or level_names (3) metadata.

This can lead to surprising behaviour in many situations. For example, consider the `loc` call below where we lose the `multiindex` part of our metadata:

```python
In [10]: df
Out[10]:
    a       b
  sum min max min
a
2   4   2   5   4
1   3   1   3   1

In [11]: df.loc[[2, 2, 1, 1], :]
Out[11]:
   (a, sum)  (a, min)  (b, max)  (b, min)
a
2         4         2         5         4
2         4         2         5         4
1         3         1         3         1
1         3         1         3         1

In [12]: df.to_pandas().loc[[2, 2, 1, 1], :]
Out[12]:
    a       b
  sum min max min
a
2   4   2   5   4
2   4   2   5   4
1   3   1   3   1
1   3   1   3   1
```

## Proposed solution

We could introduce an internal `ColumnMeta` type:

```python
class ColumnMeta:
    names: Tuple[Any]
    multiindex: bool
    level_names: Optional[Tuple[Any]]
```

which could be a property of `Frame` objects for convenience:

```python
class Frame:
    @cached_property
    def _column_meta(self):
         ...
```

Now, instead of passing just the column names and index names to `from_unique_ptr`, we could pass the full metadata for both:

```python
cdef Table from_unique_ptr(
    unique_ptr[table] c_tbl,
    ColumnMeta data_meta,
    ColumnMeta index_meta=None
):
```

and it would construct the resulting `Frame` with the correct column metadata.

--

With this, a typical Python wrapper around a libcudf API would be:

```python
def py_func(Table foo, ...):
    cdef table_view c_input = foo.view()
    cdef unique_ptr[table] c_result
    with nogil:
        c_result = cpp_func(c_input)
    return Table.from_unique_ptr(c_result, foo._column_meta, foo.index._column_meta)
```",2021-03-18T22:07:35Z,0,0,Ashwin Srinath,Voltron Data
43,[FEA] rolling correlation,"**What is your question?**
How to calculate rolling correlation between two cuDF columns?",2021-03-22T14:11:38Z,0,0,,
44,[FEA] Mixed precision Decimal math support in cudf Python,"Using recent cudf nightly conda package (0.19.0a+250.g8632ca0da3):

**Int & Decimal Addition**:
```
import cudf
from cudf.core.dtypes import Decimal64Dtype

df = cudf.DataFrame({'val': [0.01, 0.02, 0.03]})

df['dec_val'] = df['val'].astype(Decimal64Dtype(7,2))
df['dec_val'] + 1
```
**Result**:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-8-d4f1761193b6> in <module>
----> 1 df['val'] + 1

/conda/lib/python3.8/site-packages/cudf/core/series.py in __add__(self, other)
   1600 
   1601     def __add__(self, other):
-> 1602         return self._binaryop(other, ""add"")
   1603 
   1604     def radd(self, other, fill_value=None, axis=0):

/conda/lib/python3.8/contextlib.py in inner(*args, **kwds)
     73         def inner(*args, **kwds):
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner
     77 

/conda/lib/python3.8/site-packages/cudf/core/series.py in _binaryop(self, other, fn, fill_value, reflect, can_reindex)
   1515         else:
   1516             lhs, rhs = self, other
-> 1517         rhs = self._normalize_binop_value(rhs)
   1518 
   1519         if fn == ""truediv"":

/conda/lib/python3.8/site-packages/cudf/core/series.py in _normalize_binop_value(self, other)
   2307             return cudf.Scalar(other, dtype=self.dtype)
   2308         else:
-> 2309             return self._column.normalize_binop_value(other)
   2310 
   2311     def eq(self, other, fill_value=None, axis=0):

AttributeError: 'DecimalColumn' object has no attribute 'normalize_binop_value'
```

**Workaround**:
```
import cudf
from cudf.core.dtypes import Decimal64Dtype

df = cudf.DataFrame({'val': [0.01, 0.02, 0.03]})

df['dec_val'] = df['val'].astype(Decimal64Dtype(7,2))
df['ones'] = 1.00
df['dec_val'] + df['ones'].astype(Decimal64Dtype(7,0))
```
```
0    1.01
1    1.02
2    1.03
dtype: decimal
```

**Decimal & Float Multiplication**:
```
import cudf
from cudf.core.dtypes import Decimal64Dtype

df = cudf.DataFrame({'val': [0.01, 0.02, 0.03]})

df['dec_val'] = df['val'].astype(Decimal64Dtype(7,2))
df['val'] * df['dec_val']
```
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-13-4680a31be74b> in <module>
----> 1 df['val'] * df['dec_val']

/conda/lib/python3.8/site-packages/cudf/core/series.py in __mul__(self, other)
   1799 
   1800     def __mul__(self, other):
-> 1801         return self._binaryop(other, ""mul"")
   1802 
   1803     def rmul(self, other, fill_value=None, axis=0):

/conda/lib/python3.8/contextlib.py in inner(*args, **kwds)
     73         def inner(*args, **kwds):
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner
     77 

/conda/lib/python3.8/site-packages/cudf/core/series.py in _binaryop(self, other, fn, fill_value, reflect, can_reindex)
   1542                     rhs = rhs.fillna(fill_value)
   1543 
-> 1544         outcol = lhs._column.binary_operator(fn, rhs, reflect=reflect)
   1545         result = lhs._copy_construct(data=outcol, name=result_name)
   1546         return result

/conda/lib/python3.8/site-packages/cudf/core/column/numerical.py in binary_operator(self, binop, rhs, reflect)
    108             ):
    109                 msg = ""{!r} operator not supported between {} and {}""
--> 110                 raise TypeError(msg.format(binop, type(self), type(rhs)))
    111             out_dtype = np.result_type(self.dtype, rhs.dtype)
    112             if binop in [""mod"", ""floordiv""]:

TypeError: 'mul' operator not supported between <class 'cudf.core.column.numerical.NumericalColumn'> and <class 'cudf.core.column.decimal.DecimalColumn'
```

**Workaround**:
```
import cudf
from cudf.core.dtypes import Decimal64Dtype

df = cudf.DataFrame({'val': [0.01, 0.02, 0.03]})

df['dec_val'] = df['val'].astype(Decimal64Dtype(7,2))
df['dec_val'] * df['val'].astype(Decimal64Dtype(7, 2))
```
```
0    0.0001
1    0.0004
2    0.0009
dtype: decimal
```",2021-03-23T14:36:45Z,0,0,Randy Gelhausen,
45,"[FEA] Support list types in ""to_csv""","**Example**:
```
import cudf

df = cudf.DataFrame({'id': [0, 1], 'list_col': [[0, 0], [1, 1]]})
df.to_csv('test.csv')
```
**Result**:
```
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
<ipython-input-11-781fe2a14f27> in <module>
      1 df = cudf.DataFrame({'id': [0, 1], 'list_col': [[0, 0], [1, 1]]})
----> 2 df.to_csv('test.csv')

/conda/lib/python3.8/site-packages/cudf/core/dataframe.py in to_csv(self, path_or_buf, sep, na_rep, columns, header, index, line_terminator, chunksize, encoding, compression, **kwargs)
   7366         from cudf.io import csv as csv
   7367 
-> 7368         return csv.to_csv(
   7369             self,
   7370             path_or_buf=path_or_buf,

/conda/lib/python3.8/contextlib.py in inner(*args, **kwds)
     73         def inner(*args, **kwds):
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner
     77 

/conda/lib/python3.8/site-packages/cudf/io/csv.py in to_csv(df, path_or_buf, sep, na_rep, columns, header, index, line_terminator, chunksize, encoding, compression, **kwargs)
    157     for col in df._data.columns:
    158         if isinstance(col, cudf.core.column.ListColumn):
--> 159             raise NotImplementedError(
    160                 ""Writing to csv format is not yet supported with ""
    161                 ""list columns.""

NotImplementedError: Writing to csv format is not yet supported with list columns.
```

Pandas does this by wrapping a stringified representation of each row's list `quotechar`:
```
import pandas as pd

df = pd.DataFrame({'id': [0, 1], 'list_col': [[0, 0], [1, 1]]})
df.to_csv('test.csv')
```
test.csv:
```
,id,list_col
0,0,""[0, 0]""
1,1,""[1, 1]""
```",2021-03-24T15:55:18Z,0,0,Randy Gelhausen,
46,[FEA] dask_cudf cross-partition type coercions,"**Is your feature request related to a problem? Please describe.**

It's been frustrating adapting cudf -> dask_cudf kernels in two basic areas around cross-partition type mismatches:

* ingest: loading json, csv, etc. that vary in column types across partitions: existence, nans, int vs float, etc. When the code writer isn't the user -- so a library, piece of software, a UI, this is common and you can't just workaround by specifying dtypes ahead of time

* compute: when doing data cleaning (ex: date inference) or some algs, it's unclear what `meta` should be ahead of time, only after you actually do the calc. dask will sample the first df... which is often wrong

**Describe the solution you'd like**

dask_cudf ingest operators: an auto-coercion flag (""when columns are in conflict across partitions, coerce to the closest common type, like float or str"")

dask_cudf map, concat, etc: same thing


**Describe alternatives you've considered**

It may also be possible to make each operator smarter via sampling or other tricks. dask core and some cudf io seems to be experimenting here.

I like explicit flags b/c of their predictability/reliability, and uniformity... but ultimately, whatever work :)


**Additional context**

By default, I'm guessing this issue will be ignored & deprioritized ;-)

Before doing that, it may be worth polling dask_cudf users -- not devs -- how they feel about this ;-) my bet is people spend a surprising % of their time on a few issues around here, well before actual perf
",2021-03-26T21:18:23Z,0,0,,Graphistry
47,[FEA] Groupby support with Decimal column as key column,"```
import cudf
from cudf.core.dtypes import Decimal64Dtype

df = cudf.DataFrame({'id': [0, 1, 2]})

df['id_dec'] = df['id'].astype(Decimal64Dtype(7,2))

#works
df.groupby('id').count()

# fails
df.groupby('id_dec').count()
```
```
---------------------------------------------------------------------------
RecursionError                            Traceback (most recent call last)
<ipython-input-6-a16bdd01391b> in <module>
----> 1 df.groupby('id_dec').count()

/conda/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in _agg_func_name_with_args(self, func_name, *args, **kwargs)
    605 
    606     func.__name__ = func_name
--> 607     return self.agg(func)
    608 
    609 

/conda/lib/python3.8/contextlib.py in inner(*args, **kwds)
     73         def inner(*args, **kwds):
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner
     77 

/conda/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in agg(self, func)
    163         # a Float64Index, while Pandas returns an Int64Index
    164         # (GH: 6945)
--> 165         result = self._groupby.aggregate(self.obj, normalized_aggs)
    166 
    167         result = cudf.DataFrame._from_table(result)

/conda/lib/python3.8/site-packages/cudf/utils/utils.py in __get__(self, instance, cls)
    276             return self
    277         else:
--> 278             value = self.func(instance)
    279             setattr(instance, self.func.__name__, value)
    280             return value

/conda/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in _groupby(self)
    102     @cached_property
    103     def _groupby(self):
--> 104         return libgroupby.GroupBy(self.grouping.keys, dropna=self._dropna)
    105 
    106     @annotate(""GROUPBY_AGG"", domain=""cudf_python"")

/conda/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in keys(self)
    887             )
    888         else:
--> 889             return cudf.core.index.as_index(
    890                 self._key_columns[0], name=self.names[0]
    891             )

/conda/lib/python3.8/site-packages/cudf/core/index.py in as_index(arbitrary, **kwargs)
   2866     elif isinstance(arbitrary, range):
   2867         return RangeIndex(arbitrary, **kwargs)
-> 2868     return as_index(
   2869         column.as_column(arbitrary, dtype=kwargs.get(""dtype"", None)), **kwargs
   2870     )

... last 1 frames repeated, from the frame below ...

/conda/lib/python3.8/site-packages/cudf/core/index.py in as_index(arbitrary, **kwargs)
   2866     elif isinstance(arbitrary, range):
   2867         return RangeIndex(arbitrary, **kwargs)
-> 2868     return as_index(
   2869         column.as_column(arbitrary, dtype=kwargs.get(""dtype"", None)), **kwargs
   2870     )

RecursionError: maximum recursion depth exceeded in comparison
```",2021-04-01T22:08:37Z,0,0,Randy Gelhausen,
48,[DOC] Rolling window apply with constant parameters.,"## Report incorrect documentation

**Location of incorrect documentation**
 https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.window.rolling.Rolling.apply.html?highlight=apply#pandas.core.[…]olling.apply

**Describe the problems or issues found in the documentation**
Is the rolling apply fully implemented? `args` and `kwargs` seem to be ignored, or I am doing it wrong. I searched far and wide for examples of how to add a constant parameter for this function (like decay rate) but I have not found it. 

Looking at the implementation in Github https://github.com/rapidsai/cudf/blob/c929ba1fe85c152d6e8b4c868cd36f0802dafa51/python/cudf/cudf/core/window/rolling.py#L254 it also does not become directly clear how to use it. `args` and `kwargs` are not referenced.

**Steps taken to verify documentation is incorrect**
List any steps you have taken:
Looked at the source code and examples.

**Suggested fix for documentation**
Detail proposed changes to fix the documentation if you have any.
Give an example usage of the rolling apply with a constant parameter (for example, decay rate).
---

## Report needed documentation

**Report needed documentation**
A lot of rolling functions will have some kind of configuration parameters that are required. It should be possible to pass them.

**Describe the documentation you'd like**
Either documentation giving examples for this use case should be added, or if the feature is forgotten, the feature should be completed.

**Steps taken to search for needed documentation**
List any steps you have taken:
- Google
- https://pandas.pydata.org/pandas-docs/stable/user_guide/window.html#rolling-window
- https://docs.rapids.ai/api/cudf/stable/api.html?highlight=apply#cudf.core.window.Rolling.apply
",2021-04-04T12:48:14Z,1,0,Disper,
49,[FEA] Support string concatenation of a Series and something array-like into a Series ,"I’d like for cuDF to support concatenating a series and something array-like into a series similarly to how Pandas functions.

# Example:
```
cudfArray = cudf.concat([cudfSeriesB, cudfSeries], axis=1)
cudfSeries
cudfArray
cudfSeries.str.cat(cudfArray, na_rep=""-"")
```

# Result:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/column.py in as_column(arbitrary, nan_as_null, dtype, length)
   1950             data = as_column(
-> 1951                 memoryview(arbitrary), dtype=dtype, nan_as_null=nan_as_null
   1952             )

TypeError: memoryview: a bytes-like object is required, not 'DataFrame'

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/column.py in as_column(arbitrary, nan_as_null, dtype, length)
   1987                         if nan_as_null is None
-> 1988                         else nan_as_null,
   1989                     ),

/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/array.pxi in pyarrow.lib.array()

/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/error.pxi in pyarrow.lib.check_status()

/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/dataframe.py in __arrow_array__(self, type)
   1018         raise TypeError(
-> 1019             ""Implicit conversion to a host PyArrow Table via __arrow_array__ ""
   1020             ""is not allowed, To explicitly construct a PyArrow Table, ""

TypeError: Implicit conversion to a host PyArrow Table via __arrow_array__ is not allowed, To explicitly construct a PyArrow Table, consider using .to_arrow()

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
<ipython-input-64-9046cb089696> in <module>
      2 cudfSeries
      3 cudfArray
----> 4 cudfSeries.str.cat(cudfArray, na_rep=""-"")

/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/string.py in cat(self, others, sep, na_rep)
    441             )
    442         else:
--> 443             other_cols = _get_cols_list(self._parent, others)
    444             all_cols = [self._column] + other_cols
    445             data = cpp_concatenate(

/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/string.py in _get_cols_list(parent_obj, others)
   5198             others = others.reindex(parent_index)
   5199 
-> 5200         return [column.as_column(others, dtype=""str"")]
   5201     else:
   5202         raise TypeError(

/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/column.py in as_column(arbitrary, nan_as_null, dtype, length)
   1996                     data = as_column(sr, nan_as_null=nan_as_null, dtype=dtype)
   1997                 elif np_type == np.str_:
-> 1998                     sr = pd.Series(arbitrary, dtype=""str"")
   1999                     data = as_column(sr, nan_as_null=nan_as_null)
   2000                 else:

/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath)
    325                     data = data.copy()
    326             else:
--> 327                 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)
    328 
    329                 data = SingleBlockManager.from_array(data, index)

/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure)
    461         subarr = construct_1d_arraylike_from_scalar(data, len(index), dtype)
    462     else:
--> 463         subarr = _try_cast(data, dtype, copy, raise_cast_failure)
    464 
    465     # scalar like, GH

/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/construction.py in _try_cast(arr, dtype, copy, raise_cast_failure)
    566             subarr = construct_1d_object_array_from_listlike(subarr)
    567         elif not is_extension_array_dtype(subarr):
--> 568             subarr = construct_1d_ndarray_preserving_na(subarr, dtype, copy=copy)
    569     except OutOfBoundsDatetime:
    570         # in case of out of bound datetime64 -> always raise

/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/dtypes/cast.py in construct_1d_ndarray_preserving_na(values, dtype, copy)
   1621 
   1622     if dtype is not None and dtype.kind == ""U"":
-> 1623         subarr = lib.ensure_string_array(values, convert_na_value=False, copy=copy)
   1624     else:
   1625         subarr = np.array(values, dtype=dtype, copy=copy)

pandas/_libs/lib.pyx in pandas._libs.lib.ensure_string_array()

pandas/_libs/lib.pyx in pandas._libs.lib.ensure_string_array()

/opt/conda/envs/rapids/lib/python3.7/site-packages/numpy/core/_asarray.py in asarray(a, dtype, order)
     81 
     82     """"""
---> 83     return array(a, dtype, copy=False, order=order)
     84 
     85 

/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/dataframe.py in __array__(self, dtype)
   1009     def __array__(self, dtype=None):
   1010         raise TypeError(
-> 1011             ""Implicit conversion to a host NumPy array via __array__ is not ""
   1012             ""allowed, To explicitly construct a GPU matrix, consider using ""
   1013             "".as_gpu_matrix()\nTo explicitly construct a host ""

TypeError: Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .as_gpu_matrix()
To explicitly construct a host matrix, consider using .as_matrix()
```

**Pandas does this by Concatenating a series and something array-like (dataframe) into a series.:**
 
```
pandasArray = pd.concat([pandasSeriesB, pandasSeries], axis=1)
pandasSeries
pandasArray
pandasSeries.str.cat(pandasArray, na_rep=""-"")

```
**A cudf workaround was found doing the following:**

```
cudfArray = cudf.concat([cudfSeriesB, cudfSeries], axis=1)
print(cudfSeries)
print(cudfArray)
print(cudfSeriesB)
#cudfArray = cudfArray.as_matrix()
cudfArray[1].str.cat(cudfArray[0], na_rep=""-"").str.cat(cudfSeries, na_rep=""-"")
```

",2021-04-08T01:26:40Z,0,0,,
50,[FEA] Support an “extractall” method,"I’d like for cuDF to support an “extractall” method similarly to how Pandas functions

# Example:

```
cudfSeries = cudf.Series([""a1a2"", ""b1"", ""c1""], index=[""A"", ""B"", ""C""], dtype=""str"")
cudfSeries
cudf_two_groups = ""(?P<letter>[a-z])(?P<digit>[0-9])""
cudfSeries.str.extract(cudf_two_groups, expand=True)
cudfSeries.str.extractall(cudf_two_groups)
```
 
# Result:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-76-e32113055d25> in <module>
----> 1 cudfSeries.str.extractall(cudf_two_groups)
 
AttributeError: 'StringMethods' object has no attribute 'extractall'
```
 

**Pandas does this by extracting using ‘extractall’ is always a DataFrame with a MultiIndex on its rows. The last level of the MultiIndex is named match and indicates the order in the subject.:**
 
pandasSeries = pd.Series([""a1a2"", ""b1"", ""c1""], index=[""A"", ""B"", ""C""], dtype=""string"")
pandasSeries
pandas_two_groups = ""(?P<letter>[a-z])(?P<digit>[0-9])""
pandasSeries.str.extract(pandas_two_groups, expand=True)
pandasSeries.str.extractall(pandas_two_groups)

# Output

```
	   letter   digit
    match		
_________________________
A	0	a	1
1	a	2
B	0	b	1
C	0	c	1
```

",2021-04-08T07:30:21Z,0,0,,
51,[FEA] Support `cudf::replace_nulls` on structs,"**Is your feature request related to a problem? Please describe.**
I am working on supporting join on StructType in spark-rapids.  And I found an unsupported error while testing FullOuterJoin, which caused by `cudf::replace_nulls` on StructType.  Here is the [link](https://github.com/rapidsai/cudf/blob/branch-0.20/java/src/main/native/src/TableJni.cpp#L1696) of error code piece.",2021-04-13T14:18:04Z,0,0,Alfred Xu,
52,[FEA] Support lists as groupby keys,"I'd like to be able to use lists as keys in a groupby:
```
import cudf

df = cudf.DataFrame({
    'id': [0, 1],
    'id_lst': [[0, 0], [1, 1]],
    'val': [0, 1]
})

df.groupby(['id', 'id_lst']).val.sum()
```
Result:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
~/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath)
    339             try:
--> 340                 codes, categories = factorize(values, sort=True)
    341             except TypeError as err:

~/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/algorithms.py in factorize(values, sort, na_sentinel, size_hint)
    721 
--> 722         codes, uniques = factorize_array(
    723             values, na_sentinel=na_sentinel, size_hint=size_hint, na_value=na_value

~/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/algorithms.py in factorize_array(values, na_sentinel, size_hint, na_value, mask)
    527     table = hash_klass(size_hint or len(values))
--> 528     uniques, codes = table.factorize(
    529         values, na_sentinel=na_sentinel, na_value=na_value, mask=mask

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.factorize()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable._unique()

TypeError: unhashable type: 'numpy.ndarray'
```

One workaround is once [string list concatenation](https://github.com/rapidsai/cudf/pull/7929) merges, converting `id_lst` to a tokenized string and using the string representation as the grouping key.",2021-04-22T18:26:08Z,0,0,Randy Gelhausen,
53,Concatenated rows exceeds size_type range after merge operation[BUG],"**Describe the bug**
Hi Guys,  I got an error about `Total number of concatenated rows exceeds size_type range` after  doing an`inner join` on two `dask_cudf` dfs. It seems that some partitions contains a large number of rows. However, the code works good when I `concat` these two dfs.

**Steps/Code to reproduce bug**
In my understanding, the rows in q2 should be larger than q1 .
```
# setup
c = LocalCUDACluster( device_memory_limit=0.8, rmm_managed_memory=True, jit_unspill=True)
c = Client(c)

# 40G data
a = dask_cudf.read_orc('a/*.orc')
# 4G data
b = dask_cudf.read_orc('b/*.orc')

# Works good
q2 = dask_cudf.concat([a,b])
q2.map_partitions(len).compute()

0        307200
1        291840
2        337920
3        261120
4        256000
          ...  
21529    100525
21530     94142
21531     86762
21532     94782
21533     12502
Length: 21534, dtype: int64

# Errors with concatenated rows exceeds size_type range
q1 = a.merge(b, on=['a'],how='inner' )
length_partition = q1.map_partitions(len)
length_partition.compute()

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-8-efedf1b4ef97> in <module>
      1 length_partition = q1.map_partitions(len)
----> 2 length_partition.compute()

/conda/envs/rapids/lib/python3.7/site-packages/dask/base.py in compute(self, **kwargs)
    282         dask.base.compute
    283         """"""
--> 284         (result,) = compute(self, traverse=False, **kwargs)
    285         return result
    286 

/conda/envs/rapids/lib/python3.7/site-packages/dask/base.py in compute(*args, **kwargs)
    564         postcomputes.append(x.__dask_postcompute__())
    565 
--> 566     results = schedule(dsk, keys, **kwargs)
    567     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])
    568 

/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py in get(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)
   2664                     should_rejoin = False
   2665             try:
-> 2666                 results = self.gather(packed, asynchronous=asynchronous, direct=direct)
   2667             finally:
   2668                 for f in futures.values():

/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py in gather(self, futures, errors, direct, asynchronous)
   1979                 direct=direct,
   1980                 local_worker=local_worker,
-> 1981                 asynchronous=asynchronous,
   1982             )
   1983 

/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py in sync(self, func, asynchronous, callback_timeout, *args, **kwargs)
    842         else:
    843             return sync(
--> 844                 self.loop, func, *args, callback_timeout=callback_timeout, **kwargs
    845             )
    846 

/conda/envs/rapids/lib/python3.7/site-packages/distributed/utils.py in sync(loop, func, callback_timeout, *args, **kwargs)
    351     if error[0]:
    352         typ, exc, tb = error[0]
--> 353         raise exc.with_traceback(tb)
    354     else:
    355         return result[0]

/conda/envs/rapids/lib/python3.7/site-packages/distributed/utils.py in f()
    334             if callback_timeout is not None:
    335                 future = asyncio.wait_for(future, callback_timeout)
--> 336             result[0] = yield future
    337         except Exception as exc:
    338             error[0] = sys.exc_info()

/conda/envs/rapids/lib/python3.7/site-packages/tornado/gen.py in run(self)
    760 
    761                     try:
--> 762                         value = future.result()
    763                     except Exception:
    764                         exc_info = sys.exc_info()

/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py in _gather(self, futures, errors, direct, local_worker)
   1838                             exc = CancelledError(key)
   1839                         else:
-> 1840                             raise exception.with_traceback(traceback)
   1841                         raise exc
   1842                     if errors == ""skip"":

/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/core.py in _concat()
    101         args[0]
    102         if not args2
--> 103         else methods.concat(args2, uniform=True, ignore_index=ignore_index)
    104     )
    105 

/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/methods.py in concat()
    434             filter_warning=filter_warning,
    435             ignore_index=ignore_index,
--> 436             **kwargs
    437         )
    438 

/conda/envs/rapids/lib/python3.7/site-packages/dask_cuda/proxy_object.py in wrapper()
    708         args = [unproxy(d) for d in args]
    709         kwargs = {k: unproxy(v) for k, v in kwargs.items()}
--> 710         return func(*args, **kwargs)
    711 
    712     return wrapper

/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/methods.py in concat()
    434             filter_warning=filter_warning,
    435             ignore_index=ignore_index,
--> 436             **kwargs
    437         )
    438 

/conda/envs/rapids/lib/python3.7/site-packages/dask_cudf/backends.py in concat_cudf()
    223         )
    224 
--> 225     return cudf.concat(dfs, axis=axis, ignore_index=ignore_index)
    226 
    227 

/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/reshape.py in concat()
    370                 ignore_index=ignore_index,
    371                 # Explicitly cast rather than relying on None being falsy.
--> 372                 sort=bool(sort),
    373             )
    374         return result

/conda/envs/rapids/lib/python3.7/contextlib.py in inner()
     72         def inner(*args, **kwds):
     73             with self._recreate_cm():
---> 74                 return func(*args, **kwds)
     75         return inner
     76 

/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/frame.py in _concat()
    454         # Concatenate the Tables
    455         out = cls._from_table(
--> 456             libcudf.concat.concat_tables(tables, ignore_index=ignore_index)
    457         )
    458 

cudf/_lib/concat.pyx in cudf._lib.concat.concat_tables()

cudf/_lib/concat.pyx in cudf._lib.concat.concat_tables()

RuntimeError: cuDF failure at: ../src/copying/concatenate.cu:364: Total number of concatenated rows exceeds size_type range



```


**Environment overview (please complete the following information)**
 - Environment location: Docker
 - Method of cuDF install: conda
",2021-05-07T15:42:19Z,0,0,Cg Lai,
54,[BUG] map_partitions() potentially resulting in unexpected index,"**Describe the bug**
When using map_partitions() on a `dask_cudf` dataframe we can potentially get an unexpected index. This does not affect `.compute()` by default as it reconstructs a global index.

**Steps/Code to reproduce bug**
```
import cudf
import dask_cudf
s = cudf.Series([""ab"", ""cd"", ""ef"", ""gh"", ""ij""])
ds = dask_cudf.from_cudf(s, 2)
print(ds.compute())
print(ds.map_partitions(lambda x: x.str.character_tokenize(), meta=ds._meta).compute())
```
This prints
```
0    ab
1    cd
2    ef
3    gh
4    ij
dtype: object
0    a
1    b
2    c
3    d
4    e
5    f
0    g
1    h
2    i
3    j
dtype: object
```

**Expected behavior**
Would love to discuss what the expected output would be, but below is what I would expect.
```
0    ab
1    cd
2    ef
3    gh
4    ij
dtype: object
0    a
1    b
2    c
3    d
4    e
5    f
6    g
7    h
8    i
9    j
dtype: object
```
**Environment details**
<details><summary>Click here to see environment details</summary><pre>
     
     **git***
     commit 512e485c41f0b9aa2261430ba426fa8c05c98c2a (HEAD -> list-accessor, origin/list-accessor)
     Merge: bf68778b78 5f9dade58a
     Author: Shane Ding <shane200195@gmail.com>
     Date:   Fri May 7 14:33:32 2021 +0000
     
     Merge branch 'branch-0.20' of https://github.com/rapidsai/cudf into list-accessor
     **git submodules***
     
     ***OS Information***
     DGX_NAME=""DGX Server""
     DGX_PRETTY_NAME=""NVIDIA DGX Server""
     DGX_SWBUILD_DATE=""2019-12-02""
     DGX_SWBUILD_VERSION=""4.3.0""
     DGX_COMMIT_ID=""3015363""
     DGX_PLATFORM=""DGX Server for DGX-1""
     DGX_SERIAL_NUMBER=""QTFCOU9270061""
     DISTRIB_ID=Ubuntu
     DISTRIB_RELEASE=18.04
     DISTRIB_CODENAME=bionic
     DISTRIB_DESCRIPTION=""Ubuntu 18.04.3 LTS""
     NAME=""Ubuntu""
     VERSION=""18.04.3 LTS (Bionic Beaver)""
     ID=ubuntu
     ID_LIKE=debian
     PRETTY_NAME=""Ubuntu 18.04.3 LTS""
     VERSION_ID=""18.04""
     HOME_URL=""https://www.ubuntu.com/""
     SUPPORT_URL=""https://help.ubuntu.com/""
     BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
     PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
     VERSION_CODENAME=bionic
     UBUNTU_CODENAME=bionic
     Linux rl-dgx-r11-u30-rapids-dgx103 4.15.0-55-generic #60-Ubuntu SMP Tue Jul 2 18:22:20 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
     
     ***GPU Information***
     Mon May 10 17:20:28 2021
     +-----------------------------------------------------------------------------+
     | NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
     |-------------------------------+----------------------+----------------------+
     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
     |                               |                      |               MIG M. |
     |===============================+======================+======================|
     |   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |
     | N/A   35C    P0    48W / 163W |    718MiB / 32510MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |
     | N/A   33C    P0    42W / 163W |      3MiB / 32510MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |
     | N/A   34C    P0    44W / 163W |      3MiB / 32510MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |
     | N/A   31C    P0    43W / 163W |      3MiB / 32510MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |
     | N/A   36C    P0    43W / 163W |      3MiB / 32510MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |
     | N/A   35C    P0    43W / 163W |      3MiB / 32510MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
     | N/A   37C    P0    41W / 163W |      3MiB / 32510MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
     | N/A   34C    P0    42W / 163W |      3MiB / 32510MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     
     +-----------------------------------------------------------------------------+
     | Processes:                                                                  |
     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
     |        ID   ID                                                   Usage      |
     |=============================================================================|
     |    0   N/A  N/A     44033      C   .../envs/cudf_dev/bin/python      715MiB |
     +-----------------------------------------------------------------------------+
     
     ***CPU***
     Architecture:        x86_64
     CPU op-mode(s):      32-bit, 64-bit
     Byte Order:          Little Endian
     CPU(s):              80
     On-line CPU(s) list: 0-79
     Thread(s) per core:  2
     Core(s) per socket:  20
     Socket(s):           2
     NUMA node(s):        2
     Vendor ID:           GenuineIntel
     CPU family:          6
     Model:               79
     Model name:          Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz
     Stepping:            1
     CPU MHz:             1967.306
     CPU max MHz:         3600.0000
     CPU min MHz:         1200.0000
     BogoMIPS:            4390.35
     Virtualization:      VT-x
     L1d cache:           32K
     L1i cache:           32K
     L2 cache:            256K
     L3 cache:            51200K
     NUMA node0 CPU(s):   0-19,40-59
     NUMA node1 CPU(s):   20-39,60-79
     Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap intel_pt xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts md_clear flush_l1d
     
     ***CMake***
     /raid/sding/miniconda3/envs/cudf_dev/bin/cmake
     cmake version 3.18.5
     
     CMake suite maintained and supported by Kitware (kitware.com/cmake).
     
     ***g++***
     /usr/bin/g++
     g++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
     Copyright (C) 2017 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
     
     
     ***nvcc***
     /usr/local/cuda/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2021 NVIDIA Corporation
     Built on Sun_Feb_14_21:12:58_PST_2021
     Cuda compilation tools, release 11.2, V11.2.152
     Build cuda_11.2.r11.2/compiler.29618528_0
     
     ***Python***
     /raid/sding/miniconda3/envs/cudf_dev/bin/python
     Python 3.8.8
     
     ***Environment Variables***
     PATH                            : /home/u00u97shnnb9gHdDUD357/.vscode-server/bin/3c4e3df9e89829dce27b7b5c24508306b151f30d/bin:/raid/sding/miniconda3/envs/cudf_dev/bin:/raid/sding/miniconda3/condabin:/home/u00u97shnnb9gHdDUD357/.vscode-server/bin/3c4e3df9e89829dce27b7b5c24508306b151f30d/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin:/usr/local/cuda/bin
     LD_LIBRARY_PATH                 :
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /raid/sding/miniconda3/envs/cudf_dev
     PYTHON_PATH                     :
     
     ***conda packages***
     /raid/sding/miniconda3/condabin/conda
     # packages in environment at /raid/sding/miniconda3/envs/cudf_dev:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                       1_gnu    conda-forge
     abseil-cpp                20210324.0           h9c3ff4c_0    conda-forge
     alabaster                 0.7.12                     py_0    conda-forge
     apipkg                    1.5                        py_0    conda-forge
     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
     argon2-cffi               20.1.0           py38h497a2fe_2    conda-forge
     arrow-cpp                 1.0.1           py38h27527b3_37_cuda    conda-forge
     arrow-cpp-proc            3.0.0                      cuda    conda-forge
     async_generator           1.10                       py_0    conda-forge
     attrs                     20.3.0             pyhd3deb0d_0    conda-forge
     aws-c-cal                 0.5.6                hd8e7a0d_1    conda-forge
     aws-c-common              0.5.10               h7f98852_0    conda-forge
     aws-c-event-stream        0.2.7                he3525c2_3    conda-forge
     aws-c-io                  0.9.11               hd6868ff_1    conda-forge
     aws-checksums             0.1.11               h8a473d3_5    conda-forge
     aws-sdk-cpp               1.8.186              h2f913a8_1    conda-forge
     babel                     2.9.1              pyh44b312d_0    conda-forge
     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge
     backports                 1.0                        py_2    conda-forge
     backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge
     black                     19.10b0                    py_4    conda-forge
     bleach                    3.3.0              pyh44b312d_0    conda-forge
     bokeh                     2.3.1            py38h578d9bd_0    conda-forge
     boost-cpp                 1.76.0               hc6e9bd1_0    conda-forge
     brotli                    1.0.9                h9c3ff4c_4    conda-forge
     brotlipy                  0.7.0           py38h497a2fe_1001    conda-forge
     bzip2                     1.0.8                h7f98852_4    conda-forge
     c-ares                    1.17.1               h7f98852_1    conda-forge
     ca-certificates           2020.12.5            ha878542_0    conda-forge
     cachetools                4.2.2              pyhd8ed1ab_0    conda-forge
     certifi                   2020.12.5        py38h578d9bd_1    conda-forge
     cffi                      1.14.5           py38ha65f79e_0    conda-forge
     cfgv                      3.2.0                      py_0    conda-forge
     chardet                   4.0.0            py38h578d9bd_1    conda-forge
     clang                     8.0.1                hc9558a2_2    conda-forge
     clang-tools               8.0.1                hc9558a2_2    conda-forge
     clangxx                   8.0.1                         2    conda-forge
     click                     7.1.2              pyh9f0ad1d_0    conda-forge
     cloudpickle               1.6.0                      py_0    conda-forge
     cmake                     3.18.5               h1f3970d_0    rapidsai-nightly
     cmake_setuptools          0.1.3                      py_0    rapidsai
     colorama                  0.4.4              pyh9f0ad1d_0    conda-forge
     commonmark                0.9.1                      py_0    conda-forge
     cryptography              3.4.7            py38ha5dfef3_0    conda-forge
     cudatoolkit               11.0.221             h6bb024c_0    nvidia
     cudf                      0.20.0a0+260.gd56428abfc          pypi_0    pypi
     cudnn                     8.0.0                cuda11.0_0    nvidia
     cupy                      8.0.0            py38hb7c6141_0    rapidsai
     cython                    0.29.23          py38h709712a_0    conda-forge
     cytoolz                   0.11.0           py38h497a2fe_3    conda-forge
     dask                      2021.4.1+17.gc3993fd9          pypi_0    pypi
     dask-cudf                 0.20.0a0+280.g611cabd5ba.dirty          pypi_0    pypi
     dataclasses               0.8                pyhc8e2a94_1    conda-forge
     decorator                 5.0.7              pyhd8ed1ab_0    conda-forge
     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge
     distlib                   0.3.1              pyh9f0ad1d_0    conda-forge
     distributed               2021.4.1+12.g1ee22c84          pypi_0    pypi
     dlpack                    0.3                  he1b5a44_1    conda-forge
     docutils                  0.16             py38h578d9bd_3    conda-forge
     double-conversion         3.1.5                h9c3ff4c_2    conda-forge
     editdistance-s            1.0.0            py38h1fd1430_1    conda-forge
     entrypoints               0.3             pyhd8ed1ab_1003    conda-forge
     execnet                   1.8.0              pyh44b312d_0    conda-forge
     expat                     2.2.10               h9c3ff4c_0    conda-forge
     fastavro                  1.4.0            py38h497a2fe_0    conda-forge
     fastrlock                 0.6              py38h709712a_0    conda-forge
     filelock                  3.0.12             pyh9f0ad1d_0    conda-forge
     flake8                    3.8.3                      py_1    conda-forge
     flatbuffers               1.12.0               h58526e2_0    conda-forge
     freetype                  2.10.4               h0708190_1    conda-forge
     fsspec                    2021.4.0           pyhd8ed1ab_0    conda-forge
     future                    0.18.2           py38h578d9bd_3    conda-forge
     gflags                    2.2.2             he1b5a44_1004    conda-forge
     glog                      0.4.0                h49b9bf7_3    conda-forge
     gmp                       6.2.1                h58526e2_0    conda-forge
     grpc-cpp                  1.37.1               h36de60a_0    conda-forge
     heapdict                  1.0.1                      py_0    conda-forge
     hypothesis                6.10.1             pyhd8ed1ab_0    conda-forge
     icu                       68.1                 h58526e2_0    conda-forge
     identify                  2.2.4              pyhd8ed1ab_0    conda-forge
     idna                      2.10               pyh9f0ad1d_0    conda-forge
     imagesize                 1.2.0                      py_0    conda-forge
     importlib-metadata        4.0.1            py38h578d9bd_0    conda-forge
     iniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge
     ipykernel                 5.5.3            py38hd0cf306_0    conda-forge
     ipython                   7.23.0           py38hd0cf306_0    conda-forge
     ipython_genutils          0.2.0                      py_1    conda-forge
     isort                     5.0.7            py38h32f6830_0    conda-forge
     jedi                      0.18.0           py38h578d9bd_2    conda-forge
     jinja2                    2.11.3             pyh44b312d_0    conda-forge
     joblib                    1.0.1              pyhd8ed1ab_0    conda-forge
     jpeg                      9d                   h36c2ea0_0    conda-forge
     jsonschema                3.2.0              pyhd8ed1ab_3    conda-forge
     jupyter_client            6.1.12             pyhd8ed1ab_0    conda-forge
     jupyter_core              4.7.1            py38h578d9bd_0    conda-forge
     jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge
     krb5                      1.17.2               h926e7f8_0    conda-forge
     lcms2                     2.12                 hddcbb42_0    conda-forge
     ld_impl_linux-64          2.35.1               hea4e1c9_2    conda-forge
     libblas                   3.9.0                9_openblas    conda-forge
     libcblas                  3.9.0                9_openblas    conda-forge
     libcurl                   7.76.1               hc4aaa36_1    conda-forge
     libedit                   3.1.20191231         he28a2e2_2    conda-forge
     libev                     4.33                 h516909a_1    conda-forge
     libevent                  2.1.10               hcdb4288_3    conda-forge
     libffi                    3.3                  h58526e2_2    conda-forge
     libgcc-ng                 9.3.0               h2828fa1_19    conda-forge
     libgfortran-ng            9.3.0               hff62375_19    conda-forge
     libgfortran5              9.3.0               hff62375_19    conda-forge
     libgomp                   9.3.0               h2828fa1_19    conda-forge
     liblapack                 3.9.0                9_openblas    conda-forge
     libllvm10                 10.0.1               he513fc3_3    conda-forge
     libllvm8                  8.0.1                hc9558a2_0    conda-forge
     libnghttp2                1.43.0               h812cca2_0    conda-forge
     libopenblas               0.3.15          pthreads_h8fe5266_0    conda-forge
     libpng                    1.6.37               h21135ba_2    conda-forge
     libprotobuf               3.15.8               h780b84a_0    conda-forge
     librmm                    0.20.0a210505   cuda11.0_g9aaa7bc_26    rapidsai-nightly
     libsodium                 1.0.18               h36c2ea0_1    conda-forge
     libssh2                   1.9.0                ha56f1ee_6    conda-forge
     libstdcxx-ng              9.3.0               h6de172a_19    conda-forge
     libthrift                 0.14.1               he6d91bd_1    conda-forge
     libtiff                   4.2.0                hdc55705_1    conda-forge
     libutf8proc               2.6.1                h7f98852_0    conda-forge
     libuv                     1.41.0               h7f98852_0    conda-forge
     libwebp-base              1.2.0                h7f98852_2    conda-forge
     llvmlite                  0.36.0           py38h4630a5e_0    conda-forge
     locket                    0.2.0                      py_2    conda-forge
     lz4-c                     1.9.3                h9c3ff4c_0    conda-forge
     markdown                  3.3.4              pyhd8ed1ab_0    conda-forge
     markupsafe                1.1.1            py38h497a2fe_3    conda-forge
     matplotlib-inline         0.1.2              pyhd8ed1ab_2    conda-forge
     mccabe                    0.6.1                      py_1    conda-forge
     mimesis                   4.0.0              pyh9f0ad1d_0    conda-forge
     mistune                   0.8.4           py38h497a2fe_1003    conda-forge
     more-itertools            8.7.0              pyhd8ed1ab_1    conda-forge
     msgpack-python            1.0.2            py38h1fd1430_1    conda-forge
     mypy                      0.782                      py_0    conda-forge
     mypy_extensions           0.4.3            py38h578d9bd_3    conda-forge
     nbclient                  0.5.3              pyhd8ed1ab_0    conda-forge
     nbconvert                 6.0.7            py38h578d9bd_3    conda-forge
     nbformat                  5.1.3              pyhd8ed1ab_0    conda-forge
     nbsphinx                  0.8.4              pyhd8ed1ab_0    conda-forge
     nccl                      2.7.8.1            h4962215_100    nvidia
     ncurses                   6.2                  h58526e2_4    conda-forge
     nest-asyncio              1.5.1              pyhd8ed1ab_0    conda-forge
     nodeenv                   1.6.0              pyhd8ed1ab_0    conda-forge
     notebook                  6.3.0              pyha770c72_1    conda-forge
     numba                     0.53.1           py38h0e12cce_0    conda-forge
     numpy                     1.20.2           py38h9894fe3_0    conda-forge
     numpydoc                  1.1.0                      py_1    conda-forge
     nvtx                      0.2.3            py38h497a2fe_0    conda-forge
     olefile                   0.46               pyh9f0ad1d_1    conda-forge
     openjpeg                  2.4.0                hf7af979_0    conda-forge
     openssl                   1.1.1k               h7f98852_0    conda-forge
     orc                       1.6.7                heec2584_1    conda-forge
     packaging                 20.9               pyh44b312d_0    conda-forge
     pandas                    1.2.4            py38h1abd341_0    conda-forge
     pandoc                    1.19.2                        0    conda-forge
     pandocfilters             1.4.2                      py_1    conda-forge
     parquet-cpp               1.5.1                         2    conda-forge
     parso                     0.8.2              pyhd8ed1ab_0    conda-forge
     partd                     1.2.0              pyhd8ed1ab_0    conda-forge
     pathspec                  0.8.1              pyhd3deb0d_0    conda-forge
     pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge
     pickleshare               0.7.5                   py_1003    conda-forge
     pillow                    8.1.2            py38ha0e1e83_1    conda-forge
     pip                       21.1.1             pyhd8ed1ab_0    conda-forge
     pluggy                    0.13.1           py38h578d9bd_4    conda-forge
     pre-commit                2.12.1           py38h578d9bd_0    conda-forge
     pre_commit                2.12.1               hd8ed1ab_0    conda-forge
     prometheus_client         0.10.1             pyhd8ed1ab_0    conda-forge
     prompt-toolkit            3.0.18             pyha770c72_0    conda-forge
     protobuf                  3.15.8           py38h709712a_0    conda-forge
     psutil                    5.8.0            py38h497a2fe_1    conda-forge
     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge
     py                        1.10.0             pyhd3deb0d_0    conda-forge
     py-cpuinfo                8.0.0              pyhd8ed1ab_0    conda-forge
     pyarrow                   1.0.1           py38hb53058b_37_cuda    conda-forge
     pycodestyle               2.6.0              pyh9f0ad1d_0    conda-forge
     pycparser                 2.20               pyh9f0ad1d_2    conda-forge
     pyflakes                  2.2.0              pyh9f0ad1d_0    conda-forge
     pygments                  2.8.1              pyhd8ed1ab_0    conda-forge
     pyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge
     pyorc                     0.4.0                    pypi_0    pypi
     pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge
     pyrsistent                0.17.3           py38h497a2fe_2    conda-forge
     pysocks                   1.7.1            py38h578d9bd_3    conda-forge
     pytest                    6.2.4            py38h578d9bd_0    conda-forge
     pytest-benchmark          3.4.1              pyhd8ed1ab_0    conda-forge
     pytest-forked             1.3.0              pyhd3deb0d_0    conda-forge
     pytest-xdist              2.2.1              pyhd8ed1ab_0    conda-forge
     python                    3.8.8           hffdb5ce_0_cpython    conda-forge
     python-dateutil           2.8.1                      py_0    conda-forge
     python_abi                3.8                      1_cp38    conda-forge
     pytz                      2021.1             pyhd8ed1ab_0    conda-forge
     pyyaml                    5.4.1            py38h497a2fe_0    conda-forge
     pyzmq                     22.0.3           py38h2035c66_1    conda-forge
     rapidjson                 1.1.0             he1b5a44_1002    conda-forge
     re2                       2021.04.01           h9c3ff4c_0    conda-forge
     readline                  8.1                  h46c0cb4_0    conda-forge
     recommonmark              0.7.1              pyhd8ed1ab_0    conda-forge
     regex                     2021.4.4         py38h497a2fe_0    conda-forge
     requests                  2.25.1             pyhd3deb0d_0    conda-forge
     rhash                     1.4.1                h7f98852_0    conda-forge
     rmm                       0.20.0a210505   cuda_11.0_py38_g9aaa7bc_26    rapidsai-nightly
     s2n                       1.0.5                h9b69904_0    conda-forge
     sacremoses                0.0.43             pyh9f0ad1d_0    conda-forge
     send2trash                1.5.0                      py_0    conda-forge
     setuptools                49.6.0           py38h578d9bd_3    conda-forge
     six                       1.15.0             pyh9f0ad1d_0    conda-forge
     snappy                    1.1.8                he1b5a44_3    conda-forge
     snowballstemmer           2.1.0              pyhd8ed1ab_0    conda-forge
     sortedcontainers          2.3.0              pyhd8ed1ab_0    conda-forge
     spdlog                    1.7.0                hc9558a2_2    conda-forge
     sphinx                    3.5.4              pyh44b312d_0    conda-forge
     sphinx-copybutton         0.3.1              pyhd8ed1ab_0    conda-forge
     sphinx-markdown-tables    0.0.15             pyhd3deb0d_0    conda-forge
     sphinx_rtd_theme          0.5.2              pyhd8ed1ab_1    conda-forge
     sphinxcontrib-applehelp   1.0.2                      py_0    conda-forge
     sphinxcontrib-devhelp     1.0.2                      py_0    conda-forge
     sphinxcontrib-htmlhelp    1.0.3                      py_0    conda-forge
     sphinxcontrib-jsmath      1.0.1                      py_0    conda-forge
     sphinxcontrib-qthelp      1.0.3                      py_0    conda-forge
     sphinxcontrib-serializinghtml 1.1.4                      py_0    conda-forge
     sphinxcontrib-websupport  1.2.4              pyh9f0ad1d_0    conda-forge
     sqlite                    3.35.5               h74cdb3f_0    conda-forge
     streamz                   0.6.2              pyh44b312d_0    conda-forge
     tblib                     1.7.0              pyhd8ed1ab_0    conda-forge
     terminado                 0.9.4            py38h578d9bd_0    conda-forge
     testpath                  0.4.4                      py_0    conda-forge
     tk                        8.6.10               h21135ba_1    conda-forge
     tokenizers                0.10.1           py38hb63a372_0    conda-forge
     toml                      0.10.2             pyhd8ed1ab_0    conda-forge
     toolz                     0.11.1                     py_0    conda-forge
     tornado                   6.1              py38h497a2fe_1    conda-forge
     tqdm                      4.60.0             pyhd8ed1ab_0    conda-forge
     traitlets                 5.0.5                      py_0    conda-forge
     transformers              4.5.1              pyhd8ed1ab_1    conda-forge
     typed-ast                 1.4.3            py38h497a2fe_0    conda-forge
     typing_extensions         3.7.4.3                    py_0    conda-forge
     unknown                   0.0.0                     dev_0    <develop>
     urllib3                   1.26.4             pyhd8ed1ab_0    conda-forge
     virtualenv                20.4.4           py38h578d9bd_0    conda-forge
     wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge
     webencodings              0.5.1                      py_1    conda-forge
     wheel                     0.36.2             pyhd3deb0d_0    conda-forge
     xz                        5.2.5                h516909a_1    conda-forge
     yaml                      0.2.5                h516909a_0    conda-forge
     zeromq                    4.3.4                h9c3ff4c_0    conda-forge
     zict                      2.0.0                      py_0    conda-forge
     zipp                      3.4.1              pyhd8ed1ab_0    conda-forge
     zlib                      1.2.11            h516909a_1010    conda-forge
     zstd                      1.4.9                ha95c52a_0    conda-forge
",2021-05-10T17:27:36Z,0,0,,
55,[FEA] Add support for limit to Series.fillna,"**Is your feature request related to a problem? Please describe.**
It is not currently possible to limit the number of missing values filled consecutively using `fillna`.

**Describe the solution you'd like**
Support for a limit argument similar to how pandas does it.

**Describe alternatives you've considered**
Writing a clunkier version of fillna that keeps track of the number of missing values filled.

**Additional context**
Example:
```python
import cudf
sr = cudf.Series([1, 2, None, None, 5])
sr.fillna(method='pad', limit=1)
```
Should return:
```
0    1
1    2
2    2
3    <NA>
4    5
dtype: int64
```
But throws a NotImplementedError instead",2021-05-20T21:55:04Z,0,0,,
56,[FEA] Add decimal support to Dask cuDF parquet reader,"**Is your feature request related to a problem? Please describe.**
I wish I could use the Dask cuDF parquet reader to read parquet files with decimal columns.

**Describe the solution you'd like**
Currently
```
import cudf
import dask_cudf
from cudf.core.dtypes import Decimal64Dtype
from decimal import Decimal

df = cudf.DataFrame({""val"":[Decimal(""3.5""), Decimal(""4.3"")]}, dtype=Decimal64Dtype(5,2))
df.to_parquet(""test.parquet"")

dask_df = dask_cudf.read_parquet(""test.parquet"")
dask_df.dtypes
```
returns
```
val    object
dtype: object
```
Whereas using cudf
```
df = cudf.read_parquet(""test.parquet"")
df.dtypes
```
returns
```
val    decimal
dtype: object
```

",2021-05-21T04:54:30Z,0,0,,
57,[BUG] MultiIndex loc expects an iterable when passed Timestamp,"**Describe the bug**
cuDF DataFrames indexed by a Timestamp range can be accessed using `.loc[]` without any problem. However, if the cuDF DataFrame is indexed with a MultiIndex with timestamps as the first key, `.loc[]` fails, when doing so causes no issue with pandas.

**Steps/Code to reproduce bug**
The [following gist](https://gist.github.com/pbruneau/689242cf5c79ce9185aa7fa3bb1f2e89) holds a self-contained example. The last line of the code fails with error: `TypeError: 'Timestamp' object is not iterable`

**Expected behavior**
I would expect the pandas and cuDF snippets to behave similarly. 

**Environment overview (please complete the following information)**
 - Environment location: Docker
 - Method of cuDF install: Docker
   - docker pull rapidsai/rapidsai:0.18-cuda10.1-runtime-ubuntu18.04-py3.7
   - docker run -d -p 10000:8888 -p 10001:8787 -p 10002:8786 --privileged=true --gpus all --name test -t test

**Environment details**
<details><summary>Click here to see environment details</summary><pre>
     
     **git***
     commit 2cda39b34197c60614186ec51106d8254e5f7b05 (grafted, HEAD, origin/branch-0.16)
     Author: Ray Douglass <3107146+raydouglass@users.noreply.github.com>
     Date:   Wed Oct 21 10:31:49 2020 -0400
     
     Update CHANGELOG.md
     **git submodules***
     
     ***OS Information***
     DISTRIB_ID=Ubuntu
     DISTRIB_RELEASE=18.04
     DISTRIB_CODENAME=bionic
     DISTRIB_DESCRIPTION=""Ubuntu 18.04.5 LTS""
     NAME=""Ubuntu""
     VERSION=""18.04.5 LTS (Bionic Beaver)""
     ID=ubuntu
     ID_LIKE=debian
     PRETTY_NAME=""Ubuntu 18.04.5 LTS""
     VERSION_ID=""18.04""
     HOME_URL=""https://www.ubuntu.com/""
     SUPPORT_URL=""https://help.ubuntu.com/""
     BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
     PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
     VERSION_CODENAME=bionic
     UBUNTU_CODENAME=bionic
     Linux fe1b5c84b917 4.15.0-143-generic #147-Ubuntu SMP Wed Apr 14 16:10:11 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
     
     ***GPU Information***
     Tue Jun 22 15:01:51 2021
     +-----------------------------------------------------------------------------+
     | NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
     |-------------------------------+----------------------+----------------------+
     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
     |                               |                      |               MIG M. |
     |===============================+======================+======================|
     |   0  GeForce GTX 1080    On   | 00000000:05:00.0 Off |                  N/A |
     | 28%   43C    P8     7W / 180W |   1504MiB /  8114MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     
     +-----------------------------------------------------------------------------+
     | Processes:                                                                  |
     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
     |        ID   ID                                                   Usage      |
     |=============================================================================|
     +-----------------------------------------------------------------------------+
     
     ***CPU***
     Architecture:        x86_64
     CPU op-mode(s):      32-bit, 64-bit
     Byte Order:          Little Endian
     CPU(s):              12
     On-line CPU(s) list: 0-11
     Thread(s) per core:  2
     Core(s) per socket:  6
     Socket(s):           1
     NUMA node(s):        1
     Vendor ID:           GenuineIntel
     CPU family:          6
     Model:               79
     Model name:          Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz
     Stepping:            1
     CPU MHz:             1200.861
     CPU max MHz:         3800.0000
     CPU min MHz:         1200.0000
     BogoMIPS:            6800.53
     Virtualization:      VT-x
     L1d cache:           32K
     L1i cache:           32K
     L2 cache:            256K
     L3 cache:            15360K
     NUMA node0 CPU(s):   0-11
     Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap intel_pt xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts md_clear flush_l1d
     
     ***CMake***
     
     ***g++***
     
     ***nvcc***
     
     ***Python***
     /opt/conda/envs/rapids/bin/python
     Python 3.7.10
     
     ***Environment Variables***
     PATH                            : /opt/conda/envs/rapids/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
     LD_LIBRARY_PATH                 : /usr/local/nvidia/lib:/usr/local/nvidia/lib64
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /opt/conda/envs/rapids
     PYTHON_PATH                     :
     
     ***conda packages***
     /opt/conda/condabin/conda
     # packages in environment at /opt/conda/envs/rapids:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                       1_gnu    conda-forge
     abseil-cpp                20200225.2           he1b5a44_2    conda-forge
     aiobotocore               1.2.1              pyhd8ed1ab_0    conda-forge
     aiohttp                   3.7.4            py37h5e8e339_0    conda-forge
     aioitertools              0.7.1              pyhd8ed1ab_0    conda-forge
     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
     argon2-cffi               20.1.0           py37h5e8e339_2    conda-forge
     arrow-cpp                 1.0.1           py37h2318771_14_cuda    conda-forge
     arrow-cpp-proc            3.0.0                      cuda    conda-forge
     async-timeout             3.0.1                   py_1000    conda-forge
     async_generator           1.10                       py_0    conda-forge
     attrs                     20.3.0             pyhd3deb0d_0    conda-forge
     aws-c-common              0.4.59               h36c2ea0_1    conda-forge
     aws-c-event-stream        0.1.6                had2084c_6    conda-forge
     aws-checksums             0.1.10               h4e93380_0    conda-forge
     aws-sdk-cpp               1.8.63               h9b98462_0    conda-forge
     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge
     backports                 1.0                        py_2    conda-forge
     backports.functools_lru_cache 1.6.1                      py_0    conda-forge
     blas                      2.14                   openblas    conda-forge
     blazingsql                0.18.0                   pypi_0    pypi
     bleach                    3.3.0              pyh44b312d_0    conda-forge
     bokeh                     2.2.3            py37h89c1867_0    conda-forge
     boost                     1.72.0           py37h48f8a5e_1    conda-forge
     boost-cpp                 1.72.0               h9d3c048_4    conda-forge
     botocore                  1.19.52            pyhd8ed1ab_0    conda-forge
     brotli                    1.0.9                h9c3ff4c_4    conda-forge
     brotlipy                  0.7.0           py37h5e8e339_1001    conda-forge
     bzip2                     1.0.8                h7f98852_4    conda-forge
     c-ares                    1.17.1               h36c2ea0_0    conda-forge
     ca-certificates           2020.12.5            ha878542_0    conda-forge
     cairo                     1.16.0            h6cf1ce9_1008    conda-forge
     certifi                   2020.12.5        py37h89c1867_1    conda-forge
     cffi                      1.14.5           py37hc58025e_0    conda-forge
     cfitsio                   3.470                h2e3daa1_7    conda-forge
     cftime                    1.5.0                    pypi_0    pypi
     chardet                   4.0.0            py37h89c1867_1    conda-forge
     click                     7.1.2              pyh9f0ad1d_0    conda-forge
     click-plugins             1.1.1                      py_0    conda-forge
     cligj                     0.7.1              pyhd8ed1ab_0    conda-forge
     cloudpickle               1.6.0                      py_0    conda-forge
     colorcet                  2.0.6              pyhd8ed1ab_0    conda-forge
     convertdate               2.3.2                    pypi_0    pypi
     cryptography              3.4.4            py37hf1a17b8_0    conda-forge
     cudatoolkit               10.1.243             h036e899_8    nvidia
     cudf                      0.18.0          cuda_10.1_py37_g20778e5ddb_0    rapidsai
     cudf_kafka                0.18.0          py37_g20778e5ddb_0    rapidsai
     cudnn                     7.6.0                cuda10.1_0    nvidia
     cugraph                   0.18.0          py37_g65ec965f_0    rapidsai
     cuml                      0.18.0          cuda10.1_py37_gb5f59e005_0    rapidsai
     cupy                      8.0.0            py37h0632833_0    conda-forge
     curl                      7.71.1               he644dc0_8    conda-forge
     cusignal                  0.18.0          py38_g42899d2_0    rapidsai
     cuspatial                 0.18.0a210212   py37_g3045c48_21    rapidsai-nightly
     custreamz                 0.18.0          py37_g20778e5ddb_0    rapidsai
     cuxfilter                 0.18.0          py37_gac6f488_0    rapidsai
     cycler                    0.10.0                     py_2    conda-forge
     cyrus-sasl                2.1.27               h3274739_1    conda-forge
     cython                    0.29.22          py37hcd2ae1e_0    conda-forge
     cytoolz                   0.11.0           py37h5e8e339_3    conda-forge
     dask                      2021.2.0           pyhd8ed1ab_0    conda-forge
     dask-core                 2021.2.0           pyhd8ed1ab_0    conda-forge
     dask-cuda                 0.18.0                   py37_0    rapidsai
     dask-cudf                 0.18.0          py37_g20778e5ddb_0    rapidsai
     dask-glm                  0.2.0                      py_1    conda-forge
     dask-labextension         4.0.1              pyhd8ed1ab_0    conda-forge
     dask-ml                   1.8.0              pyhd8ed1ab_0    conda-forge
     datashader                0.11.1             pyh9f0ad1d_0    conda-forge
     datashape                 0.5.4                      py_1    conda-forge
     decorator                 4.4.2                      py_0    conda-forge
     defusedxml                0.6.0                      py_0    conda-forge
     distlib                   0.3.2                    pypi_0    pypi
     distributed               2021.2.0         py37h89c1867_0    conda-forge
     dlpack                    0.3                  he1b5a44_1    conda-forge
     ecmwf-api-client          1.6.1                    pypi_0    pypi
     entrypoints               0.3             pyhd8ed1ab_1003    conda-forge
     ephem                     4.0.0.2                  pypi_0    pypi
     expat                     2.2.10               h9c3ff4c_0    conda-forge
     fa2                       0.3.5            py37h8f50634_0    conda-forge
     faiss-proc                1.0.0                      cuda    conda-forge
     fastavro                  1.3.4            py37h5e8e339_0    conda-forge
     fastrlock                 0.5              py37hcd2ae1e_2    conda-forge
     filelock                  3.0.12                   pypi_0    pypi
     filterpy                  1.4.5                      py_1    conda-forge
     fiona                     1.8.18           py37h527b4ca_0    conda-forge
     flask                     2.0.1                    pypi_0    pypi
     flask-wtf                 0.15.1                   pypi_0    pypi
     fontconfig                2.13.1            hba837de_1004    conda-forge
     freetype                  2.10.4               h0708190_1    conda-forge
     freexl                    1.0.6                h7f98852_0    conda-forge
     fsspec                    0.8.7              pyhd8ed1ab_0    conda-forge
     future                    0.18.2           py37h89c1867_3    conda-forge
     gdal                      3.1.4            py37h2ec2946_2    conda-forge
     geopandas                 0.8.1                      py_0    conda-forge
     geos                      3.8.1                he1b5a44_0    conda-forge
     geotiff                   1.6.0                h5d11630_3    conda-forge
     gettext                   0.19.8.1          h0b5b191_1005    conda-forge
     gflags                    2.2.2             he1b5a44_1004    conda-forge
     giflib                    5.2.1                h36c2ea0_2    conda-forge
     git                       2.30.1          pl5320h6697202_1    conda-forge
     glog                      0.4.0                h49b9bf7_3    conda-forge
     gluonts                   0.7.6                    pypi_0    pypi
     google-cloud-cpp          1.16.0               he4a878c_2    conda-forge
     google-cloud-cpp-common   0.25.0               he83eced_7    conda-forge
     googleapis-cpp            0.10.0               h6b1abdc_4    conda-forge
     gpuci-tools               0.3.1                         0    gpuci
     greenlet                  1.0.0            py37hcd2ae1e_0    conda-forge
     grpc-cpp                  1.32.0               h7997a97_1    conda-forge
     gunicorn                  20.1.0                   pypi_0    pypi
     hdf4                      4.2.13            h10796ff_1004    conda-forge
     hdf5                      1.10.6          nompi_h7c3c948_1111    conda-forge
     heapdict                  1.0.1                      py_0    conda-forge
     hijri-converter           2.1.2                    pypi_0    pypi
     holidays                  0.11.1                   pypi_0    pypi
     holoviews                 1.14.2             pyhd8ed1ab_0    conda-forge
     icu                       68.1                 h58526e2_0    conda-forge
     idna                      2.10               pyh9f0ad1d_0    conda-forge
     importlib-metadata        3.7.0            py37h89c1867_0    conda-forge
     importlib_metadata        3.7.0                hd8ed1ab_0    conda-forge
     iniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge
     ipykernel                 5.5.0            py37h888b3d9_1    conda-forge
     ipython                   7.15.0           py37hc8dfbb8_0    conda-forge
     ipython_genutils          0.2.0                      py_1    conda-forge
     ipywidgets                7.6.3              pyhd3deb0d_0    conda-forge
     itsdangerous              2.0.1                    pypi_0    pypi
     jedi                      0.17.2           py37h89c1867_1    conda-forge
     jinja2                    3.0.1                    pypi_0    pypi
     jmespath                  0.10.0             pyh9f0ad1d_0    conda-forge
     joblib                    1.0.1              pyhd8ed1ab_0    conda-forge
     jpeg                      9d                   h36c2ea0_0    conda-forge
     jpype1                    1.2.1            py37h2527ec5_0    conda-forge
     json-c                    0.13.1            hbfbb72e_1002    conda-forge
     json5                     0.9.5              pyh9f0ad1d_0    conda-forge
     jsonschema                3.2.0                      py_2    conda-forge
     jupyter-server-proxy      1.6.0              pyhd8ed1ab_0    conda-forge
     jupyter_client            6.1.11             pyhd8ed1ab_1    conda-forge
     jupyter_core              4.7.1            py37h89c1867_0    conda-forge
     jupyterlab                2.1.5                      py_0    conda-forge
     jupyterlab-nvdashboard    0.1.11200212              py_12    rapidsai-nightly
     jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge
     jupyterlab_server         1.2.0                      py_0    conda-forge
     jupyterlab_widgets        1.0.0              pyhd8ed1ab_1    conda-forge
     kealib                    1.4.14               hcc255d8_2    conda-forge
     kiwisolver                1.3.1            py37h2527ec5_1    conda-forge
     korean-lunar-calendar     0.2.1                    pypi_0    pypi
     krb5                      1.17.2               h926e7f8_0    conda-forge
     lcms2                     2.12                 hddcbb42_0    conda-forge
     ld_impl_linux-64          2.35.1               hea4e1c9_2    conda-forge
     libblas                   3.8.0               14_openblas    conda-forge
     libcblas                  3.8.0               14_openblas    conda-forge
     libcrc32c                 1.1.1                h9c3ff4c_2    conda-forge
     libcudf                   0.18.1          cuda10.1_g999be56c80_0    rapidsai
     libcudf_kafka             0.18.0a210226   g1544474166_254    rapidsai-nightly
     libcugraph                0.18.0          cuda10.1_g65ec965f_0    rapidsai
     libcuml                   0.18.0          cuda10.1_gb5f59e005_0    rapidsai
     libcumlprims              0.18.0a210211   cuda10.1_gff080f3_0    rapidsai-nightly
     libcurl                   7.71.1               hcdd3856_8    conda-forge
     libcuspatial              0.18.0          cuda10.1_gf4da460_0    rapidsai
     libdap4                   3.20.6               hd7c4107_1    conda-forge
     libedit                   3.1.20191231         he28a2e2_2    conda-forge
     libev                     4.33                 h516909a_1    conda-forge
     libevent                  2.1.10               hcdb4288_3    conda-forge
     libfaiss                  1.6.3           he68dc02_3_cuda    conda-forge
     libffi                    3.3                  h58526e2_2    conda-forge
     libgcc-ng                 9.3.0               h2828fa1_18    conda-forge
     libgcrypt                 1.9.2                h7f98852_0    conda-forge
     libgdal                   3.1.4                h02eeb80_2    conda-forge
     libgfortran-ng            7.5.0               h14aa051_18    conda-forge
     libgfortran4              7.5.0               h14aa051_18    conda-forge
     libglib                   2.68.0               h3e27bee_2    conda-forge
     libgomp                   9.3.0               h2828fa1_18    conda-forge
     libgpg-error              1.42                 h9c3ff4c_0    conda-forge
     libgsasl                  1.8.0                         2    conda-forge
     libhwloc                  2.3.0                h5e5b7d1_1    conda-forge
     libiconv                  1.16                 h516909a_0    conda-forge
     libkml                    1.3.0             hd79254b_1012    conda-forge
     liblapack                 3.8.0               14_openblas    conda-forge
     liblapacke                3.8.0               14_openblas    conda-forge
     libllvm10                 10.0.1               he513fc3_3    conda-forge
     libnetcdf                 4.7.4           nompi_h56d31a8_107    conda-forge
     libnghttp2                1.43.0               h812cca2_0    conda-forge
     libntlm                   1.4               h7f98852_1002    conda-forge
     libopenblas               0.3.7                h5ec1e0e_6    conda-forge
     libpng                    1.6.37               h21135ba_2    conda-forge
     libpq                     12.3                 h255efa7_3    conda-forge
     libprotobuf               3.13.0.1             h8b12597_0    conda-forge
     librdkafka                1.5.3                h54cafa9_0    conda-forge
     librmm                    0.18.0          cuda10.1_ga4ee6b7_0    rapidsai
     librttopo                 1.1.0                hb271727_4    conda-forge
     libsodium                 1.0.18               h36c2ea0_1    conda-forge
     libspatialindex           1.9.3                h9c3ff4c_3    conda-forge
     libspatialite             5.0.1                h6ec7341_0    conda-forge
     libssh2                   1.9.0                hab1572f_5    conda-forge
     libstdcxx-ng              9.3.0               h6de172a_18    conda-forge
     libthrift                 0.13.0               h5aa387f_6    conda-forge
     libtiff                   4.2.0                hdc55705_0    conda-forge
     libutf8proc               2.6.1                h7f98852_0    conda-forge
     libuuid                   2.32.1            h7f98852_1000    conda-forge
     libuv                     1.41.0               h7f98852_0    conda-forge
     libwebp                   1.2.0                h3452ae3_0    conda-forge
     libwebp-base              1.2.0                h7f98852_0    conda-forge
     libxcb                    1.13              h7f98852_1003    conda-forge
     libxgboost                1.3.3dev.rapidsai0.18      cuda10.1_0    rapidsai-nightly
     libxml2                   2.9.10               h72842e0_3    conda-forge
     line-profiler             3.3.0                    pypi_0    pypi
     llvmlite                  0.35.0           py37h9d7f4d0_1    conda-forge
     locket                    0.2.0                      py_2    conda-forge
     lz4-c                     1.9.2                he1b5a44_3    conda-forge
     markdown                  3.3.4              pyhd8ed1ab_0    conda-forge
     markupsafe                2.0.1                    pypi_0    pypi
     matplotlib-base           3.3.4            py37h0c9df89_0    conda-forge
     mistune                   0.8.4           py37h5e8e339_1003    conda-forge
     more-itertools            8.7.0              pyhd8ed1ab_0    conda-forge
     msgpack-python            1.0.2            py37h2527ec5_1    conda-forge
     multidict                 5.1.0            py37h5e8e339_1    conda-forge
     multipledispatch          0.6.0                      py_0    conda-forge
     munch                     2.5.0                      py_0    conda-forge
     mxnet-cu101               1.8.0                    pypi_0    pypi
     nbclient                  0.5.3              pyhd8ed1ab_0    conda-forge
     nbconvert                 6.0.7            py37h89c1867_3    conda-forge
     nbformat                  5.1.2              pyhd8ed1ab_1    conda-forge
     nccl                      2.8.4.1              h8b44402_3    conda-forge
     ncurses                   6.2                  h58526e2_4    conda-forge
     nest-asyncio              1.4.3              pyhd8ed1ab_0    conda-forge
     netcdf4                   1.5.6                    pypi_0    pypi
     netifaces                 0.10.9          py37h5e8e339_1003    conda-forge
     networkx                  2.5                        py_0    conda-forge
     nodejs                    14.15.4              h92b4a50_1    conda-forge
     notebook                  6.2.0            py37h89c1867_0    conda-forge
     numba                     0.52.0           py37hdc94413_0    conda-forge
     numpy                     1.19.5           py37haa41c4c_1    conda-forge
     nvtx                      0.2.3            py37h5e8e339_0    conda-forge
     olefile                   0.46               pyh9f0ad1d_1    conda-forge
     openjdk                   11.0.1            h516909a_1016    conda-forge
     openjpeg                  2.4.0                hf7af979_0    conda-forge
     openssl                   1.1.1k               h7f98852_0    conda-forge
     orc                       1.6.5                hd3605a7_0    conda-forge
     packaging                 20.9               pyh44b312d_0    conda-forge
     pandas                    1.1.5            py37hdc94413_0    conda-forge
     pandoc                    2.11.4               h7f98852_0    conda-forge
     pandocfilters             1.4.2                      py_1    conda-forge
     panel                     0.10.3             pyhd8ed1ab_0    conda-forge
     param                     1.10.1             pyhd3deb0d_0    conda-forge
     parquet-cpp               1.5.1                         2    conda-forge
     parso                     0.7.1              pyh9f0ad1d_0    conda-forge
     partd                     1.1.0                      py_0    conda-forge
     patsy                     0.5.1                      py_0    conda-forge
     pcre                      8.44                 he1b5a44_0    conda-forge
     perl                      5.32.0               h36c2ea0_0    conda-forge
     pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge
     pickle5                   0.0.11           py37h8f50634_0    conda-forge
     pickleshare               0.7.5                   py_1003    conda-forge
     pillow                    8.1.1            py37h4600e1f_0    conda-forge
     pip                       21.0.1             pyhd8ed1ab_0    conda-forge
     pipenv                    2021.5.29                pypi_0    pypi
     pixman                    0.40.0               h36c2ea0_0    conda-forge
     pluggy                    0.13.1           py37h89c1867_4    conda-forge
     poppler                   0.89.0               h2de54a5_5    conda-forge
     poppler-data              0.4.10                        0    conda-forge
     postgresql                12.3                 hc2f5b80_3    conda-forge
     proj                      7.1.1                h966b41f_3    conda-forge
     prometheus_client         0.9.0              pyhd3deb0d_0    conda-forge
     prompt-toolkit            3.0.16             pyha770c72_0    conda-forge
     protobuf                  3.13.0.1         py37h745909e_1    conda-forge
     psutil                    5.8.0            py37h5e8e339_1    conda-forge
     pthread-stubs             0.4               h36c2ea0_1001    conda-forge
     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge
     pvlib                     0.8.1                    pypi_0    pypi
     py                        1.10.0             pyhd3deb0d_0    conda-forge
     py-xgboost                1.3.3dev.rapidsai0.18  cuda10.1py37_0    rapidsai-nightly
     pyarrow                   1.0.1           py37hbeecfa9_14_cuda    conda-forge
     pycparser                 2.20               pyh9f0ad1d_2    conda-forge
     pyct                      0.4.6                      py_0    conda-forge
     pyct-core                 0.4.6                      py_0    conda-forge
     pydantic                  1.8.2                    pypi_0    pypi
     pydeck                    0.5.0              pyh9f0ad1d_0    conda-forge
     pyee                      7.0.4              pyh9f0ad1d_0    conda-forge
     pyephem                   9.99                     pypi_0    pypi
     pygments                  2.8.0              pyhd8ed1ab_0    conda-forge
     pyhive                    0.6.3              pyhd3deb0d_0    conda-forge
     pymeeus                   0.5.11                   pypi_0    pypi
     pynndescent               0.5.2              pyh44b312d_0    conda-forge
     pynvml                    8.0.4                      py_1    conda-forge
     pyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge
     pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge
     pyppeteer                 0.2.2                      py_1    conda-forge
     pyproj                    2.6.1.post1      py37h6415a23_3    conda-forge
     pyrsistent                0.17.3           py37h5e8e339_2    conda-forge
     pysocks                   1.7.1            py37h89c1867_3    conda-forge
     pytest                    6.2.2            py37h89c1867_0    conda-forge
     python                    3.7.10          hffdb5ce_100_cpython    conda-forge
     python-confluent-kafka    1.5.0            py37h8f50634_0    conda-forge
     python-dateutil           2.8.1                      py_0    conda-forge
     python-graphviz           0.8.4                    pypi_0    pypi
     python_abi                3.7                     1_cp37m    conda-forge
     pytz                      2021.1             pyhd8ed1ab_0    conda-forge
     pyviz_comms               2.0.1              pyhd3deb0d_0    conda-forge
     pyyaml                    5.4.1            py37h5e8e339_0    conda-forge
     pyzmq                     22.0.3           py37h336d617_1    conda-forge
     rapids                    0.18.0a210302   cuda10.1_py37_g58c5d18_220    rapidsai-nightly
     rapids-blazing            0.18.0a210302   cuda10.1_py37_g58c5d18_220    rapidsai-nightly
     rapids-xgboost            0.18.0a210302   cuda10.1_py37_g58c5d18_220    rapidsai-nightly
     re2                       2020.10.01           he1b5a44_0    conda-forge
     readline                  8.0                  he28a2e2_2    conda-forge
     requests                  2.25.1             pyhd3deb0d_0    conda-forge
     rmm                       0.18.0          cuda_10.1_py37_ga4ee6b7_0    rapidsai
     rtree                     0.9.7            py37h0b55af0_1    conda-forge
     s2n                       1.0.0                h9b69904_0    conda-forge
     s3fs                      0.5.2              pyhd8ed1ab_0    conda-forge
     sasl                      0.2.1           py37h3340039_1002    conda-forge
     scikit-learn              0.23.1           py37h8a51577_0    conda-forge
     scipy                     1.5.3            py37h8911b10_0    conda-forge
     seaborn                   0.11.1               hd8ed1ab_1    conda-forge
     seaborn-base              0.11.1             pyhd8ed1ab_1    conda-forge
     send2trash                1.5.0                      py_0    conda-forge
     setuptools                49.6.0           py37h89c1867_3    conda-forge
     shapely                   1.7.1            py37hba0730f_1    conda-forge
     simpervisor               0.4                pyhd8ed1ab_0    conda-forge
     six                       1.15.0             pyh9f0ad1d_0    conda-forge
     snappy                    1.1.8                he1b5a44_3    conda-forge
     sortedcontainers          2.3.0              pyhd8ed1ab_0    conda-forge
     spdlog                    1.7.0                hc9558a2_2    conda-forge
     sqlalchemy                1.4.3            py37h5e8e339_0    conda-forge
     sqlite                    3.34.0               h74cdb3f_0    conda-forge
     statsmodels               0.12.2           py37h902c9e0_0    conda-forge
     streamz                   0.6.2              pyh44b312d_0    conda-forge
     tbb                       2020.2               h4bd325d_3    conda-forge
     tblib                     1.6.0                      py_0    conda-forge
     terminado                 0.9.2            py37h89c1867_0    conda-forge
     testpath                  0.4.4                      py_0    conda-forge
     threadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge
     thrift                    0.13.0           py37hcd2ae1e_2    conda-forge
     thrift_sasl               0.4.2            py37h8f50634_0    conda-forge
     tiledb                    2.1.6                h1022b9d_0    conda-forge
     tk                        8.6.10               h21135ba_1    conda-forge
     toml                      0.10.2             pyhd8ed1ab_0    conda-forge
     toolz                     0.11.1                     py_0    conda-forge
     tornado                   6.1              py37h5e8e339_1    conda-forge
     tqdm                      4.58.0             pyhd8ed1ab_0    conda-forge
     traitlets                 5.0.5                      py_0    conda-forge
     treelite                  1.0.0            py37hc731546_0    conda-forge
     treelite-runtime          1.0.0                    pypi_0    pypi
     typing-extensions         3.7.4.3                       0    conda-forge
     typing_extensions         3.7.4.3                    py_0    conda-forge
     tzcode                    2021a                h7f98852_1    conda-forge
     ucx                       1.9.0+gcd9efd3       cuda10.1_0    rapidsai-nightly
     ucx-proc                  1.0.0                       gpu    rapidsai-nightly
     ucx-py                    0.18.0a210323   py37_gcd9efd3_19    rapidsai-nightly
     umap-learn                0.5.1            py37h89c1867_0    conda-forge
     urllib3                   1.26.3             pyhd8ed1ab_0    conda-forge
     virtualenv                20.4.7                   pypi_0    pypi
     virtualenv-clone          0.5.4                    pypi_0    pypi
     wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge
     webencodings              0.5.1                      py_1    conda-forge
     websockets                8.1              py37h5e8e339_3    conda-forge
     werkzeug                  2.0.1                    pypi_0    pypi
     wheel                     0.36.2             pyhd3deb0d_0    conda-forge
     widgetsnbextension        3.5.1            py37h89c1867_4    conda-forge
     wrapt                     1.12.1           py37h5e8e339_3    conda-forge
     wtforms                   2.3.3                    pypi_0    pypi
     xarray                    0.17.0             pyhd8ed1ab_0    conda-forge
     xerces-c                  3.2.3                h9d8b166_2    conda-forge
     xgboost                   1.3.3dev.rapidsai0.18  cuda10.1py37_0    rapidsai-nightly
     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge
     xorg-libice               1.0.10               h7f98852_0    conda-forge
     xorg-libsm                1.2.3             hd9c2040_1000    conda-forge
     xorg-libx11               1.7.0                h7f98852_0    conda-forge
     xorg-libxau               1.0.9                h7f98852_0    conda-forge
     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge
     xorg-libxext              1.3.4                h7f98852_1    conda-forge
     xorg-libxrender           0.9.10            h7f98852_1003    conda-forge
     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge
     xorg-xextproto            7.3.0             h7f98852_1002    conda-forge
     xorg-xproto               7.0.31            h7f98852_1007    conda-forge
     xz                        5.2.5                h516909a_1    conda-forge
     yaml                      0.2.5                h516909a_0    conda-forge
     yarl                      1.6.3            py37h5e8e339_1    conda-forge
     zeromq                    4.3.4                h9c3ff4c_0    conda-forge
     zict                      2.0.0                      py_0    conda-forge
     zipp                      3.4.0                      py_0    conda-forge
     zlib                      1.2.11            h516909a_1010    conda-forge
     zstd                      1.4.8                hdf46e1d_0    conda-forge
     
</pre></details>",2021-06-22T15:07:25Z,0,0,Pierrick Bruneau,Luxembourg Institute of Science and Technology
58,[FEA] Scalar factory functions do not let you provide a validity bool.,"
Scalars can be null and contain a validity bool.  The constructors for the various scalars take an `is_valid` parameter for this purpose.  But the factory functions themselves don't let you specify one in the call. Seems like an oversight. This applies to all scalar types.
```
struct_scalar(table&& data,
                bool is_valid                       = true,
                rmm::cuda_stream_view stream        = rmm::cuda_stream_default,
                rmm::mr::device_memory_resource* mr = rmm::mr::get_current_device_resource());
```

```
std::unique_ptr<scalar> make_struct_scalar(
  table_view const& data,
  rmm::cuda_stream_view stream        = rmm::cuda_stream_default,
  rmm::mr::device_memory_resource* mr = rmm::mr::get_current_device_resource());
```",2021-06-30T18:32:32Z,0,0,,
59,"[BUG] Missing ""inplace"" argument in ""dask_cudf.DataFrame.drop"" although it exists in documentation","Hi guys,

I tried `gdf.drop(columns=['Churn_Value'], inplace=True)` where `gdf` is a `dask_cudf.DataFrame` and I got this error `TypeError: drop() got an unexpected keyword argument 'inplace'` even though it is listed among the list of parameters in the doc for `dask_cudf.DataFrame.drop` :

```
dask_cudf.DataFrame.drop(
    self,
    labels=None,
    axis=0,
    columns=None,
    errors='raise',
)
Docstring:
Drop specified labels from rows or columns.

This docstring was copied from pandas.core.frame.DataFrame.drop.

Some inconsistencies with the Dask version may exist.

Remove rows or columns by specifying label names and corresponding
axis, or by specifying directly index or column names. When using a
multi-index, labels on different levels can be removed by specifying
the level.

Parameters
----------
labels : single label or list-like
    Index or column labels to drop.
axis : {0 or 'index', 1 or 'columns'}, default 0
    Whether to drop labels from the index (0 or 'index') or
    columns (1 or 'columns').
index : single label or list-like  (Not supported in Dask)
    Alternative to specifying axis (``labels, axis=0``
    is equivalent to ``index=labels``).
columns : single label or list-like
    Alternative to specifying axis (``labels, axis=1``
    is equivalent to ``columns=labels``).
level : int or level name, optional  (Not supported in Dask)
    For MultiIndex, level from which the labels will be removed.
inplace : bool, default False  (Not supported in Dask)
    If False, return a copy. Otherwise, do operation
    inplace and return None.
errors : {'ignore', 'raise'}, default 'raise'
    If 'ignore', suppress error and only existing labels are
    dropped.

Returns
-------
DataFrame or None
    DataFrame without the removed index or column labels or
    None if ``inplace=True``.
```
Can you guys check this out ?
Thanks :)",2021-07-09T07:32:08Z,0,0,Bassem Karoui,
60,[BUG] DataFrame constructor incorrectly loads nested dictionary input,"**What is your question?**
Got different results when trying to convert dictionary to dataframe using pandas and cudf
![image](https://user-images.githubusercontent.com/87376384/125461623-98da6483-d5eb-4278-bdeb-944276949a5e.png)
",2021-07-13T13:38:28Z,0,0,,
61,[BUG] dataframe reindex NaN,"**Describe the bug**
cuDF DataFrame is not reindexed as intented. Using a multiindex, it ends up in NaNs.

**Steps/Code to reproduce bug**
```
data_df = cudf.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0/c439ef22282f412ba39e9137a3fdabac.parquet')
offsets = data_df.groupby(['time_id'], as_index=False).agg({'seconds_in_bucket':'min'}).reset_index(drop=True)
offsets.columns = ['time_id', 'offset']
data_df = cudf.merge(data_df, offsets, on = ['time_id'], how = 'left')
data_df.seconds_in_bucket = data_df.seconds_in_bucket - data_df.offset
# MultiIndex.from_product uses pandas in the background
# That's why we need to transform the data into pd dataframe
data_df = data_df.set_index(['time_id', 'seconds_in_bucket'])
columns = [col for col in data_df.columns.values]
data_df = data_df.reindex(cudf.MultiIndex.from_product([data_df.to_pandas().index.levels[0], np.arange(0,600)], names = ['time_id', 'seconds_in_bucket']), columns=columns).fillna(method='ffill')
data_df = cudf.DataFrame(data_df.reset_index())
```
https://www.kaggle.com/medali1992/optiver-train-dataset?scriptVersionId=68637709

This workaround works:
```
indices = cudf.MultiIndex.from_product([data_df.to_pandas().index.levels[0], np.arange(0,600)], names = ['time_id', 'seconds_in_bucket'])
data_df = cudf.DataFrame().set_index(indices).join(data_df, how=""left"").fillna(method='ffill').reset_index(drop=True)
```

**Expected behavior**
I expect reindex function to get the correct values instead of NaNs as in pandas.

**Environment overview (please complete the following information)**
Kaggle GPU Docker, RAPIDS 21.06

",2021-07-20T18:56:35Z,0,0,Ahmet Erdem,
62,[BUG] Drop function for Multicolumn index doesn't work,"**Describe the bug**
Drop function for Multicolumn index doesn't work as expected
The error I get is: 'One or more values not found in axis'

**Steps/Code to reproduce bug**
```python
import cudf
df=cudf.DataFrame()
df['src_lat']=[-46.0,-46.0,-46.0, -34.0,-34.0,-34.0, 11.5, 11.5, 11.5]; df['src_long']=df['src_lat']+1
df['dst_lat']=[-46.0, -34.0,11.5,-46.0, -34.0,11.5,-46.0, -34.0,11.5];df['dst_long']=df['dst_lat']+1
df['val']=[0.1,0.2,0.1,0.3,0.2,0.1,0.3,0.3,0.1]
df = df.pivot(index=['src_lat', 'src_long'], columns=['dst_lat', 'dst_long'], values=['val'])
df.columns = df.index
df.drop([(11.5, 12.5), (-46.0, -45.0)])
```
",2021-08-06T15:48:46Z,0,0,,
63,[FEA] Support the `min_count` argument in groupby aggregations,"Updated 5/13/2024: `numeric_only` is now supported (as of #10629). `min_count` is not yet supported.

In Pandas,  groupby aggregations (e.g., [`max`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.max.html)) accept the following arguments:

- `min_count`: the minimum number of non-null values required per group in order for the result to be non-null
- `numeric_only`: only aggregate numeric columns

It would be nice for cuDF to support these as well:

```python
In [6]: df = cudf.DataFrame({'a': [1, 1, 1, 2, 2], 'b': ['a', 'b', 'c', 'd', 'e'], 'c': [1, 2, 3, 4, 5]})

In [7]: df
Out[7]:
   a  b  c
0  1  a  1
1  1  b  2
2  1  c  3
3  2  d  4
4  2  e  5

In [8]: df.groupby('a').max(numeric_only=True)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-8-612714d07c42> in <module>
----> 1 df.groupby('a').max(numeric_only=True)

TypeError: max() got an unexpected keyword argument 'numeric_only'

In [9]: df.to_pandas().groupby('a').max(numeric_only=True)
Out[9]:
   c
a
1  3
2  5
```
",2021-08-10T18:17:43Z,0,0,Ashwin Srinath,Voltron Data
64,[BUG] pyorc does not read string column statistics of cuDF generated files,"When reading the statistics for an ORC file written by cuDF, the result for sum is wrong when read using cuDF and absent when using pyorc.

```python
In [1]: import cudf

In [2]: import pyorc

In [3]: gdf = cudf.DataFrame({'b':[1,7], 'a':['Badam khao', 'roz']})

In [4]: gdf.to_orc(""temp.orc"")

In [5]: cudf.io.orc.read_orc_statistics([""temp.orc""])
Out[5]: 
([{'col0': {'number_of_values': 2},
   'b': {'number_of_values': 2, 'minimum': 1, 'maximum': 7, 'sum': 8},
   'a': {'number_of_values': 2,
    'minimum': 'Badam khao',
    'maximum': 'roz',
    'sum': -7}}],
 [{'col0': {'number_of_values': 2},
   'b': {'number_of_values': 2, 'minimum': 1, 'maximum': 7, 'sum': 8},
   'a': {'number_of_values': 2,
    'minimum': 'Badam khao',
    'maximum': 'roz',
    'sum': -7}}])

In [6]: f = open(""temp.orc"", 'rb')

In [7]: r = pyorc.Reader(f)

In [8]: r[1].statistics
Out[8]: 
{'has_null': False,
 'number_of_values': 2,
 'minimum': 1,
 'maximum': 7,
 'sum': 8,
 'kind': <TypeKind.LONG: 4>}

In [9]: r[2].statistics
Out[9]: {'has_null': False, 'number_of_values': 2, 'kind': <TypeKind.STRING: 7>}
```

#### Expected result
Sum statistics contains the sum of lengths of all the strings in the column. We do correctly compute this in libcudf, so it should be present when reading with pyorc and correct when reading with cudf.

There's two issues here:

- [x] String sum statistics are encoded incorrectly (will be fixed by https://github.com/rapidsai/cudf/pull/11740)
- [ ] pyroc does not read cuDF-written ORC string statistics",2021-09-27T11:01:54Z,0,0,Devavret Makkar,@VoltronData
65,"[FEA] Support ""on"" parameter in cudf.DataFrame.join","Version used: cuml==21.8.2

**Steps/Code to reproduce bug**
```
left = cudf.DataFrame([100, 101], columns=[""item_id""])
right = cudf.DataFrame([""a"",""b""], index=[100,101], columns=[""item_name""])

# This will result in having only <NA> in item_name
left.join(right, on=""item_id"")

# This works as expected
left.to_pandas().join(right.to_pandas(), on=""item_id"")

# Workarround
left.merge(right, left_on=""item_id"", right_index=True)
```
",2021-10-25T10:19:46Z,0,0,Nico Kreiling,scieneers
66,[FEA] Supporting `timedelta64` dtypes for ceil/floor operations,"**Is your feature request related to a problem? Please describe.**
This issue is created as a follow-up to #9571  and #9554 where we add support for ceil/floor operations for `datetime64[ns]` data type. In this case, we would like additional support for `timedelta64[ns]` types as well.

**Describe the solution you'd like**
```python
import cudf
tdIndex = cudf.TimedeltaIndex(data =['4 day 8h 20min 35us 45ns', '+17:42:19.999999',
'9 day 3h 08:16:02.000055', '+22:35:25.000075'])
tdIndex.ceil(freq='T'))
```
Output:
```bash
TimedeltaIndex(['4 days 08:21:00', '0 days 17:43:00', '9 days 11:17:00',
'0 days 22:36:00'],
dtype='timedelta64[ns]', freq=None)
```

**Additional context**
Similar [to how pandas supports it](https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html?pandas.TimedeltaIndex.ceil#pandas-timedeltaindex-ceil)",2021-10-29T16:12:50Z,0,0,Mayank Anand,
67,[BUG] Aggregation with NaN not matching Pandas behavior,"Aggregation(mean/sum) on cols NaN result in NaN value. even with dropna as `True`

```
>>> df  = cudf.DataFrame()
>>> df['a'] = [1,2,3,0,4]
>>> df['b'] = [1,1,1,0,1]
>>> df['c'] = df.a/df.b
>>> df['s'] = 0
>>> df
   a  b    c  s
0  1  1  1.0  0
1  2  1  2.0  0
2  3  1  3.0  0
3  0  0  NaN  0
4  4  1  4.0  0
>>> df[['c', 's']].groupby(['s']).mean()
    c
s    
0 NaN
```

**Expected/Pandas behavior**
```
>>> import pandas as pd
>>> df = pd.DataFrame()
>>> df['a'] = [1,2,3,0,4]
>>> df['b'] = [1,1,1,0,1]
>>> df['c'] = df.a/df.b
>>> df['s'] = 0
>>> df
   a  b    c  s
0  1  1  1.0  0
1  2  1  2.0  0
2  3  1  3.0  0
3  0  0  NaN  0
4  4  1  4.0  0
>>> df[['c', 's']].groupby(['s']).mean()
     c
s     
0  2.5
```",2021-11-01T17:48:00Z,0,0,Lahir Marni,
68,[FEA] Improve cudf.read_csv empty file error message,"It's embarrassingly common to accidentally produce empty ""CSV"" files, then for a downstream system to fail on attempting to read them.

If I'm trying to read an empty file with Pandas, I get a helpful error message indicating the problem.

```
import pandas as pd

with open('test.csv', 'w') as fp:
    fp.write('')

pd.read_csv('test.csv')
```
```
---------------------------------------------------------------------------
EmptyDataError                            Traceback (most recent call last)
/tmp/ipykernel_3734411/2382990058.py in <module>
      4     fp.write('')
      5 
----> 6 pd.read_csv('test.csv')

~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs)
    309                     stacklevel=stacklevel,
    310                 )
--> 311             return func(*args, **kwargs)
    312 
    313         return wrapper

~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/readers.py in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)
    584     kwds.update(kwds_defaults)
    585 
--> 586     return _read(filepath_or_buffer, kwds)
    587 
    588 

~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/readers.py in _read(filepath_or_buffer, kwds)
    480 
    481     # Create the parser.
--> 482     parser = TextFileReader(filepath_or_buffer, **kwds)
    483 
    484     if chunksize or iterator:

~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/readers.py in __init__(self, f, engine, **kwds)
    809             self.options[""has_index_names""] = kwds[""has_index_names""]
    810 
--> 811         self._engine = self._make_engine(self.engine)
    812 
    813     def close(self):

~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/readers.py in _make_engine(self, engine)
   1038             )
   1039         # error: Too many arguments for ""ParserBase""
-> 1040         return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
   1041 
   1042     def _failover_to_python(self):

~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py in __init__(self, src, **kwds)
     67         kwds[""dtype""] = ensure_dtype_objs(kwds.get(""dtype"", None))
     68         try:
---> 69             self._reader = parsers.TextReader(self.handles.handle, **kwds)
     70         except Exception:
     71             self.handles.close()

~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader.__cinit__()

EmptyDataError: No columns to parse from file
```

When I try to read an empty CSV file from Dask-cudf (or cudf directly), it's not clear if I perhaps OOMed or some other non-input-file-related problem:
```
~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/cudf-21.12.0a0+254.g84e5a03032-py3.8-linux-x86_64.egg/cudf/io/csv.py in read_csv(filepath_or_buffer, lineterminator, quotechar, quoting, doublequote, header, mangle_dupe_cols, usecols, sep, delimiter, delim_whitespace, skipinitialspace, names, dtype, skipfooter, skiprows, dayfirst, compression, thousands, decimal, true_values, false_values, nrows, byte_range, skip_blank_lines, parse_dates, comment, na_values, keep_default_na, na_filter, prefix, index_col, use_python_file_object, **kwargs)
     78         na_values = [na_values]
     79 
---> 80     return libcudf.csv.read_csv(
     81         filepath_or_buffer,
     82         lineterminator=lineterminator,

cudf/_lib/csv.pyx in cudf._lib.csv.read_csv()

cudf/_lib/csv.pyx in cudf._lib.csv.make_csv_reader_options()

cudf/_lib/io/utils.pyx in cudf._lib.io.utils.make_source_info()

IndexError: Out of bounds on buffer access (axis 0)
```",2021-11-12T22:16:00Z,0,0,Randy Gelhausen,
69,[FEA] `pack`/`unpack` functions to merge/split (multiple) `device_buffer`(s),"**Is your feature request related to a problem? Please describe.**

It would be useful to have a `pack` function to merge multiple `device_buffer`s into a single `device_buffer`. This is helpful in situations where having one large `device_buffer` to read from is more performant. However it ultimately consists of many smaller data segments that would need to be merged together. Example use cases include sending data with UCX and spilling data from device to host.

Similarly it would be useful to have an `unpack` function to split a `device_buffer` into multiple `device_buffer`s. This is helpful in situations where having one large `device_buffer` to write into is more performant. However it ultimately consists of many smaller data segments that may need to be freed at different times. Example use cases include receiving data with UCX and unspilling data from host to device.

**Describe the solution you'd like**

For `pack` it would be nice if it simply takes several `device_buffer`s in `vector` form and return a single one. Additionally it would be nice if `pack` could recognize when `device_buffer`s are contiguous in memory and avoid a copy. Though admittedly this last part is tricky (maybe less so if `unpack` is used regularly?). If we allow `pack` to change the order (to benefit from contiguous memory for example), we may want additional information about where the data segments live in the larger `device_buffer`.

For `unpack` it would be nice if it takes a single `device_buffer` and `size_t`s in `vector` form to split and return a `vector` of multiple `device_buffer`s. Additionally it would be nice if `unpack` did not perform any copies. Hopefully that is straightforward, but there may be things I'm not understanding.

**Describe alternatives you've considered**

One might consider using variadics in C++ for the arguments. While nice at the C++ level, this seems tricky to use from the Cython and Python levels. Hence the suggestion to just use `vector`.

`pack` itself could be implemented by a user simply allocating a larger buffer and copying over. Would be nice to avoid the extra allocation when possible though (which may require knowledge that RMM has about the allocations).

**Additional context**

Having `unpack` in particular would be helpful for aggregated receives. A natural extension of this would be to have `pack` for aggregated sends. All-in-all this should allow transmitting a larger amount of data at once with UCX and thus benefiting from this use case it is more honed for. PR  ( https://github.com/dask/distributed/pull/3453 ) provides a WIP implementation of aggregated receives for context.

Also having `pack` would be useful when spilling several `device_buffer`s from device to host as it would allow us to pack them into one `device_buffer` before transferring ( https://github.com/rapidsai/dask-cuda/issues/250 ). Having `unpack` would help us break up the allocation whenever the object is unspilled.

This need has also come up in downstream contexts ( https://github.com/rapidsai/cudf/issues/3793 ). Maybe they would benefit from an upstream solution as well?",2020-03-01T22:37:33Z,0,0,,
70,[FEA] Improve the performance of sample,"**Is your feature request related to a problem? Please describe.**
The sample without replacement is slower than the CPU.

**Additional context**
With replacement is really fast. 
This indicates that thrust::shuffle_copy is the reason for the slowness.
```
// replacement is true
spark.time(spark.range(Int.MaxValue * 12L).sample(true, 0.01, 0).selectExpr(""SUM(id)"", ""COUNT(id)"").show())
+-------------------+---------+
|            sum(id)|count(id)|
+-------------------+---------+
|3320410258800588221|257697960|
+-------------------+---------+
Time taken: 670 ms

// without replacement
scala> spark.time(spark.range(Int.MaxValue).sample(0.01, 0).agg(functions.sum(""id"")).show())
+-----------------+                                                             
|          sum(id)|
+-----------------+
|23058247476802342|
+-----------------+

Time taken: 1608 ms
```

[Sample code link](https://github.com/rapidsai/cudf/blob/branch-22.02/cpp/include/cudf/copying.hpp#L935)",2021-12-03T09:29:34Z,0,0,Chong Gao,
71,[FEA] Add version of extract_re that takes an index,"**Is your feature request related to a problem? Please describe.**
From Spark, when we call `extract_re` we often are only interested in extracting a single group rather than all the groups in the pattern. We currently call `extract_re` which returns a `Table` and we then get the column we are interested in and discard the others. It would be more efficient if we could pass the column index to cuDF so that only one column needs instantiating.

**Describe the solution you'd like**
I would like a signature something like `extract_re(pattern, index)`.

**Describe alternatives you've considered**
None

**Additional context**
None
",2021-12-07T17:56:51Z,0,0,Andy Grove,@Apple
72,[BUG] dask_cudf from_delayed throws exception when meta is included in the from_delayed,"Exception:

```
Columns: [_col10, _col5, _col0, _col12, visit_date]
Index: [], 'from_delayed')
kwargs:    {}
Exception: ""ValueError('Metadata mismatch found in `from_delayed`.\\n\\nExpected partition of type `pandas.core.frame.DataFrame` but got `cudf.core.dataframe.DataFrame`')""
```

Reproducer:
```
import cudf
import numpy as np
from dask.dataframe import from_delayed
from dask.delayed import delayed
import numpy as np
import cudf
from dask.distributed import Client
from dask_cuda import LocalCUDACluster
import dask_cudf

df = cudf.DataFrame()
for i in range(100):
    df[f'_col{i}'] = np.random.randint(20, size=100)
    
df.to_orc('test1.orc')
df.to_orc('test0.orc')

files = [(('a',), 'test0.orc'), (('a',), 'test1.orc')]
print(files)


def rd(f, cols, meta=None):
    if partitions:
        cols = list(set(cols) - set([x[0] for x in partitions]))
    if type(f).__name__ == 'str':
        f = ((), f)
    df = cudf.read_orc(f[1], columns=cols,  use_index=False)
    if partitions:
        for i, col in enumerate(partitions):
            df[col[0]] = f[0][i]
            df[col[0]] = df[col[0]].astype(col[1])
    if meta:
        return df[list(meta.keys())]
    else:
        return df


partitions =[('visit_date', 'str')]
cols = ['_col0', '_col12', '_col10', '_col5']
meta = dict(rd(files[0], cols, meta=None).dtypes)
for i in partitions:
    meta[i[0]] = i[1]
    
print(meta)

def main():
    c=Client(LocalCUDACluster())
    dfs=[delayed(rd)(f, cols=cols, meta=meta) for f in files[:2]]
    xx = dask_cudf.from_delayed(dfs, meta=meta)
    print(xx.compute())


if __name__ == ""__main__"":
    main()
```

this issue is very similar to issue here: https://github.com/dask/dask/issues/8528

the difference is from_delayed with meta, throws another exception ""The columns in the computed data do not match the columns in the provided metadata"" even though both dfs have same columns and dtypes.
since we provide the meta here, we run into different issue.",2022-01-05T19:52:25Z,0,0,Lahir Marni,
73,[BUG] `DataFrame.merge` does not assign `dtype` as expected in result as pandas does,"The `dtype` in the result of a merge is inconsistent with the equivalent pandas merge for the same inputs:
cuDF:
```
>>> df1=cudf.DataFrame({""a"":[1,2,3,4]})
>>> df2=cudf.DataFrame(columns=[""a""])
>>> r=df2.merge(df1,how=""outer"")
>>> df1[""a""].dtype
dtype('int64')
>>> r[""a""].dtype
dtype('float64')
```
pandas:
```
>>> pdf1=pd.DataFrame({""a"":[1,2,3,4]})
>>> pdf2=pd.DataFrame(columns=[""a""])
>>> pr=pdf2.merge(pdf1,how=""outer"")
>>> pdf1[""a""].dtype
dtype('int64')
>>> pr[""a""].dtype
dtype('int64')
```",2022-01-06T16:01:41Z,0,0,Rick Ratzel,
74,[FEA] Supporting separators with more than 1 character in cudf.read_csv method,"**Is your feature request related to a problem? Please describe.**
When calling the method _cudf.read_csv_, the _sep_ argument only accepts a 1 character string - which was an old issue in pandas. However, they have already included support for multi-character separators and it would be a useful thing to have on cudf.

**Describe the solution you'd like**
Calling the _cudf.read_csv_ method as 

```python
cudf.read_csv(filepath, sep='::')
```

**Describe alternatives you've considered**
Perhaps allowing users to use a regex as a separator definer would provide a more robust solution.

**Additional context**
Python code example

```python
import pandas as pd
import cudf

filepath = './example.csv'
with open(filepath, 'w') as f:
    f.write('column0::column1\n')
    f.write('value00::value01\n')
    f.write('value10::value11\n')

df_pandas = pd.read_csv(filepath, sep='::')
print ('Loaded csv file from pandas')
df_cudf = cudf.read_csv(filepath, sep='::')
print ('Loaded csv file from cudf')
```

Current output: `ValueError: only single character unicode strings can be converted to Py_UCS4, got length 2`",2022-01-06T20:26:21Z,0,0,Joao Felipe Guedes,Globo.com
75,[FEA] Add Localization support to cudf's Datetime capabilities,"**Is your feature request related to a problem? Please describe.**
cuDF does not support UTC offsets, `utc=True` in `cudf.to_datetime()`, `.tz_localize()`, nor external packages localization parameters (like `dateutils.parse` and `pytz`) in its datetime accessor.  We had an issue where a user tried to do that, and got errors

https://stackoverflow.com/questions/70511547/compatibility-of-datetime-with-cudf-and-pandas-for-filter-datetime-in-python/70704931#70704931 (issue code and proposed work around solution is below)


**Describe the solution you'd like**
where `testdata.csv` is 
```
Datetime,Open,High,Low,Close,Adj Close,Volume 
2021-10-22 13:30:00+00:00,149.69,149.75,149.01,149.04,149.04,4032096.0 
2021-10-22 13:40:00+00:00,149.69,150.175,148.845,149.92,149.92,19671400.0
2021-11-22 13:50:00+00:00,149.975,150.18,149.5601,149.75,149.75,11911828.0 
```
pandas works, but cudf doesn't, declaring that the output doesn't looke like it's in datetime format
```
import pandas as pd
#import cudf as pd # uncomment to see cudf error out
import time 
import datetime 
import dateutil

if __name__ == ""__main__"":
    Zeit_start = datetime.datetime.now()
    AGdata_search = pd.read_csv(""testdata.csv"",parse_dates=['Datetime'],infer_datetime_format=True,cache_dates=False)
    AGdata_TEST = AGdata_search.loc[(AGdata_search['Datetime'] >= dateutil.parser.parse(""2021-11-02 13:44:00+00:00""))] 
    AGdata_TEST.to_csv(""output.csv"", encoding='utf-8',index=False)
```
These are the Pandas dtypes
```
Datetime     datetime64[ns, UTC]
Open                     float64
High                     float64
Low                      float64
Close                    float64
Adj Close                float64
Volume                   float64
dtype: object
```

cuDF dtype would only recognize:
```
Datetime     datetime64[ns]
```

Also tried these with obvious, but various errors that would work in Pandas
```
AGdata_search['Datetime'].dt.tz_localize(None)
# AttributeError: Can only use .dt accessor with datetimelike values

AGdata_search['Datetime'].astype('datetime64[ns]')
# not a recognized datetime format

AGdata_search['Datetime'].astype('datetime64[ns, UTC]')
# unrecognized dtype error

AGdata_search['Datetime'] = cudf.to_datetime(AGdata_search['Datetime'], utc=True)
# no affect

import pytz
AGdata_search['Datetime'].tz_localize(pytz.utc)
# AttributeError: 'Series' object has no attribute 'tz_localize'
```

**Describe alternatives you've considered**
The workaround proposed was to explicitly declare the format code 
```
AGdata_search['Datetime'] = cudf.to_datetime(AGdata_search['Datetime'], format='%Y-%m-D %H:%M:%S+%z')
```
and the full solution presented was:
```
import cudf as cudf 
import time 
import datetime 
import dateutil

if __name__ == ""__main__"":
    Zeit_start = datetime.datetime.now()
    AGdata_search = cudf.read_csv(""testdata.csv"")
    AGdata_search['Datetime'] = cudf.to_datetime(AGdata_search['Datetime'], format='%Y-%m-%d %H:%M:%S+%z') # this makes it work)
    AGdata_TEST = AGdata_search.loc[(AGdata_search['Datetime'] >= dateutil.parser.parse(""2021-11-02 13:44:00+00:00""))]
    AGdata_TEST.to_csv(""output.csv"", encoding='utf-8',index=False)
```

**Additional context**
This format seems to be used often in the financial market analysis.

here is some other pandas code that works only in pandas i stumbled on while trying to find a workaround
```
import pandas as pd
import pytz

index = pd.date_range('20140101 21:55', freq='15S', periods=5)
df = pd.DataFrame(1, index=index, columns=['X'])
print(df)
#                      X
# 2014-01-01 21:55:00  1
# 2014-01-01 21:55:15  1
# 2014-01-01 21:55:30  1
# 2014-01-01 21:55:45  1
# 2014-01-01 21:56:00  1

# [5 rows x 1 columns]
print(df.index)
# <class 'pandas.tseries.index.DatetimeIndex'>
# [2014-01-01 21:55:00, ..., 2014-01-01 21:56:00]
# Length: 5, Freq: 15S, Timezone: None

eastern = pytz.timezone('US/Eastern')
df.index = df.index.tz_localize(pytz.utc).tz_convert(eastern)
print(df)
#                            X
# 2014-01-01 16:55:00-05:00  1
# 2014-01-01 16:55:15-05:00  1
# 2014-01-01 16:55:30-05:00  1
# 2014-01-01 16:55:45-05:00  1
# 2014-01-01 16:56:00-05:00  1

# [5 rows x 1 columns]

print(df.index)
# <class 'pandas.tseries.index.DatetimeIndex'>
# [2014-01-01 16:55:00-05:00, ..., 2014-01-01 16:56:00-05:00]
# Length: 5, Freq: 15S, Timezone: US/Eastern
```",2022-01-14T02:13:28Z,1,0,Taurean Dyer,
76,[BUG] ValueError: 'category' column dtypes are currently not supported by the gpu accelerated parquet writer,"The following exception is thrown when a column of type 'int' is written using to_parquet, and read with read_parquet and re-written with to-parquet again.

So, the first to_parquet is changing the `int` col type to catg, but when reading again, and the same file is re-written it fails.

Exception: ValueError: 'category' column dtypes are currently not supported by the gpu accelerated parquet writer

Reproducer Code:
```
import cudf
df = cudf.DataFrame()

df['a'] = [0 , 0 , 0, 1]
df['b'] = [0 , 0 , 0, 1]

df['a']  = df.a.astype('int')
df.to_parquet('test', partition_cols=['a'], partition_file_name=f'0.parquet')
df = cudf.read_parquet('test/a=0/0.parquet')
df.to_parquet('test.pq')
```",2022-01-24T22:45:20Z,0,0,Lahir Marni,
77,"[FEA] Support ""mode"" argument to to_csv","I'm trying to iteratively write (append) to an existing CSV file:
```
import cudf

df = cudf.DataFrame({'id': [0, 1, 2]})
df.to_csv('test.csv', header=False, index=False, mode='a')
```
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Input In [3], in <module>
      1 import cudf
      3 df = cudf.DataFrame({'id': [0, 1, 2]})
----> 4 df.to_csv('test.csv', header=False, index=False, mode=""a"")

File ~/conda/envs/dsql-1-25/lib/python3.8/site-packages/cudf/core/dataframe.py:5749, in DataFrame.to_csv(self, path_or_buf, sep, na_rep, columns, header, index, line_terminator, chunksize, encoding, compression, **kwargs)
   5746 """"""{docstring}""""""
   5747 from cudf.io import csv as csv
-> 5749 return csv.to_csv(
   5750     self,
   5751     path_or_buf=path_or_buf,
   5752     sep=sep,
   5753     na_rep=na_rep,
   5754     columns=columns,
   5755     header=header,
   5756     index=index,
   5757     line_terminator=line_terminator,
   5758     chunksize=chunksize,
   5759     encoding=encoding,
   5760     compression=compression,
   5761     **kwargs,
   5762 )

File ~/conda/envs/dsql-1-25/lib/python3.8/contextlib.py:75, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     72 @wraps(func)
     73 def inner(*args, **kwds):
     74     with self._recreate_cm():
---> 75         return func(*args, **kwds)

File ~/conda/envs/dsql-1-25/lib/python3.8/site-packages/cudf/io/csv.py:148, in to_csv(df, path_or_buf, sep, na_rep, columns, header, index, line_terminator, chunksize, encoding, compression, **kwargs)
    145     path_or_buf = StringIO()
    146     return_as_string = True
--> 148 path_or_buf = ioutils.get_writer_filepath_or_buffer(
    149     path_or_data=path_or_buf, mode=""w"", **kwargs
    150 )
    152 if columns is not None:
    153     try:

TypeError: get_writer_filepath_or_buffer() got multiple values for keyword argument 'mode'
```

As a workaround, I could always write to a new, separate CSV file and concat them together afterwards.",2022-01-25T18:43:02Z,0,0,Randy Gelhausen,
78,[FEA] Support for callable functions in groupby transform,"**What is your question?**
We would to run this code on a dataframe loaded using cudf, but encounter the following error.
if anyone have an answer for this problem, thank you

`df['rmean'] = df.groupby(['outlet', 'product'])['sales'].transform(lambda x: x.rolling(window=win).mean()).astype(np.float32)`

`AttributeError: type object 'cudf._lib.aggregation.GroupbyAggregation' has no attribute 'rolling'`
",2022-02-08T04:02:19Z,0,0,Muhammad Rizky Ferlanda,
79,[FEA] JSON reader: ignores Java/C++ style comment,"This is part of FEA of https://github.com/NVIDIA/spark-rapids/issues/9
We have a JSON file

``` json
{""name"": // name
 ""Reynold Xin""}
```

Spark can parse it when enabling `allowComments` and `multiLine`

or 

``` json
{'name': /* hello */ 'Reynold Xin'}
```

Spark can parse it when enabling `allowComments` 

We expect there is a configure `allowComments` to control this behavior. ",2022-02-10T08:58:50Z,0,0,Bobby Wang,
80,[FEA] JSON reader: support unquoted JSON field names.,"This is part of FEA of https://github.com/NVIDIA/spark-rapids/issues/9
We have a JSON file

``` json
{name: ""Reynold Xin""}
```

Spark can parse it when enabling `allowUnquotedFieldNames`

CUDF parsing will throw exception

We expect there is a configure `allowUnquotedFieldNames` to control this behavior. ",2022-02-10T09:10:57Z,0,0,Bobby Wang,
81,[FEA] JSON reader: support multi-lines,"This is part of FEA of https://github.com/NVIDIA/spark-rapids/issues/9
We have a JSON file

``` json
{""name"":
   ""Reynold Xin""}
```

Spark can parse it when enabling `multiLine`

CUDF parsing will throw an exception

We expect there is a configure `multiLine` to control this behavior. ",2022-02-10T09:18:20Z,0,0,Bobby Wang,
82,"Use ""ranger"" to prevent grid stride loop overflow","(updated Aug 2023)

### Background

We found a kernel indexing overflow issue, first discovered in the `fused_concatenate` kernels (https://github.com/rapidsai/cudf/issues/10333) and this issue is present in a number of our CUDA kernels that take the following form:

```
size_type output_index = threadIdx.x + blockIdx.x * blockDim.x;  
while (output_index < output_size) {
  output_index += blockDim.x * gridDim.x;
}
```

If we have an output_size of say 1.2 billion and a grid size that's the same, the following happens:  Some late thread id, say 1.19 billion attempts to add 1.2 billion (blockDim.x * gridDim.x) and overflows the size_type (signed 32 bits). 

We made a round of fixes in #10448, and then later found another instance of this error in #13838. Our first pass of investigation was not adequate to contain the issue, so we need to take another close look.


### Part 1 - First pass fix kernels with this issue

| Source file | Kernels | Status | 
|---|---|---|
| `copying/concatenate.cu` | `fused_concatenate_kernel` |  #10448 |
| `valid_if.cuh` | `valid_if_kernel` |  #10448 |
| `scatter.cu` | `marking_bitmask_kernel` |  #10448 |
| `replace/nulls.cu` | `replace_nulls_strings` | #10448 |
| `replace/nulls.cu` | `replace_nulls` |  #10448 |
| `rolling/rolling_detail.cuh` | `gpu_rolling` |  #10448 |
| `rolling/jit/kernel.cu` | `gpu_rolling_new` | #10448 |
| `transform/compute_column.cu` | `compute_column_kernel`  | #10448 |
|`copying/concatenate.cu` | `fused_concatenate_string_offset_kernel` |  #13838 |
| `replace/replace.cu` |   `replace_strings_first_pass` <br>   `replace_strings_second_pass` <br>  `replace_kernel` | #13905 |
| `copying/concatenate.cu` |   `concatenate_masks_kernel` <br>   `fused_concatenate_string_offset_kernel` <br>   `fused_concatenate_string_chars_kernel` <br>  `fused_concatenate_kernel` (int64) | #13906 | | 
| `hash/helper_functions.cuh` |   `init_hashtbl` | #13895  |
| `null_mask.cu` |  `set_null_mask_kernel` <br>   `copy_offset_bitmask` <br>   `count_set_bits_kernel` | #13895  | 
| `transform/row_bit_count.cu` |   `compute_row_sizes` | #13895  | 
| `multibyte_split.cu` |   `multibyte_split_init_kernel` <br>   `multibyte_split_seed_kernel` (auto??) <br>   `multibyte_split_kernel`  | #13910 | 
| IO modules: parquet, orc, json | | #13910 | 
| `io/utilities/parsing_utils.cu` |   `count_and_set_positions` (uint64_t)  | #13910 |  
| `conditional_join_kernels.cuh` |   `compute_conditional_join_output_size` <br>   `conditional_join` | #13971 | 
| `merge.cu` |   `materialize_merged_bitmask_kernel`  | #13972 | 
| `partitioning.cu` |   `compute_row_partition_numbers`  <br>  `compute_row_output_locations` <br>   `copy_block_partitions`  | #13973  | 
| `json_path.cu` |  `get_json_object_kernel`  | #13962 | 
 | `tdigest` |   `compute_percentiles_kernel` (int)  | #13962 | 
| `strings/attributes.cu` |   `count_characters_parallel_fn`  | #13968 |  
| `strings/convert/convert_urls.cu` |   `url_decode_char_counter` (int) <br>   `url_decode_char_replacer` (int)  | #13968 |  
| `text/subword/data_normalizer.cu` |   `kernel_data_normalizer` (uint32_t)  |  #13915  | 
| `text/subword/subword_tokenize.cu`  |  `kernel_compute_tensor_metadata` (uint32_t)  |  #13915 | 
| `text/subword/wordpiece_tokenizer.cu` |  `init_data_and_mark_word_start_and_ends` (uint32_t) <br>   `mark_string_start_and_ends` (uint32_t) <br>   `kernel_wordpiece_tokenizer` (uint32_t) | #13915  | 

### Part 2 - Take another pass over more challenging kernels


| Source file | Kernels | Status | 
|---|---|---|
| null_mash.cuh | [subtract_set_bits_range_boundaries_kernel](https://github.com/rapidsai/cudf/blob/b4da39cfbe569e290ae42ca9cf8ff868d5788757/cpp/include/cudf/detail/null_mask.cuh#L215) | |
| valid_if.cuh | [valid_if_n_kernel](https://github.com/rapidsai/cudf/blob/b4da39cfbe569e290ae42ca9cf8ff868d5788757/cpp/include/cudf/detail/valid_if.cuh#L154) | |
|copy_if_else.cuh | [copy_if_else_kernel](https://github.com/rapidsai/cudf/blob/b4da39cfbe569e290ae42ca9cf8ff868d5788757/cpp/include/cudf/detail/copy_if_else.cuh#L41) | |
| gather.cuh | [gather_chars_fn_string_parallel](https://github.com/rapidsai/cudf/blob/b4da39cfbe569e290ae42ca9cf8ff868d5788757/cpp/include/cudf/strings/detail/gather.cuh#L78) | |
| more? | search `gridDim.x` or `blockDim.x` to find more examples | | 




### Part 3 - Use [ranger](https://github.com/harrism/ranger) to prevent grid stride loop overflow
* incorporate the ranger header as a libcudf utility
* use ranger instead of manual indexing in libcudf kernels


### Additional information

There are also a number of kernels that have this pattern but probably don't ever overflow because they are indexing by bitmask words.  ([Example](https://github.com/rapidsai/cudf/blob/4c9ef5161268e2486938546deef00f7fc84c9a95/cpp/include/cudf/detail/copy_range.cuh#L41))
Additional, In this kernel, `source_idx` probably overflows, but harmlessly.

A snippet of code to see this in action:
```
size_type const size = 1200000000;
auto big = cudf::make_fixed_width_column(data_type{type_id::INT32}, size, mask_state::UNALLOCATED);  
auto x = cudf::rolling_window(*big, 1, 1, 1, cudf::detail::sum_aggregation{}); 
```

Note:  rmm may mask out of bounds accesses in some cases, so it's helpful to run with the plain cuda allocator.",2022-02-28T19:30:02Z,0,0,,
83,[FEA] Cleanup of unneeded functions in Python aggregation types.,"
With this PR  https://github.com/rapidsai/cudf/pull/10357 all aggregations in cudf are now represented as algorithm-specific aggregation classes.   There is some followup cleanup work to be done in the python bindings. See:

https://github.com/rapidsai/cudf/pull/10357#issuecomment-1054204554
",2022-03-07T16:28:51Z,0,0,,
84,[FEA] Iterator versions of make_device_uvector_sync() and make_device_uvector_async(),"
Ran into some code in a PR that was staging results into a std::vector just so that it could be passed to a factory function.  Seems like it would be useful to have versions that take (device) iterators directly. ",2022-03-18T15:49:01Z,0,0,,
85,[FEA] Provide a way to specify the maximum allowable precision for integers/floats,"**Is your feature request related to a problem? Please describe.**

GPU memory is a valuable resource, and using int64/float64 columns where int32/float32 would suffice means using 2x as much memory unnecessarily. As opposed to scientific computing, 32-bit data types (or lower) are sufficient for many data science applications.

Even only 32-bit data types as inputs, the resulting output can be a 64-bit type:

```python
>>> cudf.Series([1, 2, 3], dtype=""int32"") + cudf.Scalar(1, dtype=""float32"")
0    2.0
1    3.0
2    4.0
dtype: float64
```

(this is consistent with Pandas and NumPy)

**Describe the solution you'd like**

It would be nice to be able to specify a maximum bitwidth for integer/floating types. If an operation would result in a value greater than could be accommodated, simply overflowing would be acceptable.

This could be another use case for [cudf.config](https://github.com/rapidsai/cudf/issues/5311).

**Describe alternatives you've considered**

The user can carefully cast results back from 64bit to 32bit to reduce memory usage, but this is tedious and does not help with peak memory usage.
",2022-03-31T18:28:33Z,0,0,Ashwin Srinath,Voltron Data
86,[BUG] Parsing string to float is inconsistent between CSV reader and to_numeric,"**Describe the bug**
The parsing of strings to floats has different results in different contexts, as discussed in https://github.com/NVIDIA/spark-rapids/issues/5035.

## Parsing floats from CSV

Given the following input file:

```
0.1
0.2
0.3
```

The following code parses the floats as follows.

``` python
>>> df  = cudf.read_csv(""floats.csv"", names=[""a""], dtype=[""float64""])
>>> df['a'][0]
0.1
>>> df['a'][1]
0.2
>>> df['a'][2]
0.30000000000000004
```

## Parsing floats with to_numeric

Parsing the same values using `to_numeric` produces different results.

``` python
>>> s = cudf.Series(['0.1', '0.2', '0.3'])
>>> x = cudf.to_numeric(s)
>>> x[0]
0.09999999999999999
>>> x[1]
0.19999999999999998
>>> x[2]
0.3
```

**Steps/Code to reproduce bug**
See above code examples.

**Expected behavior**
These two paths should produce consistent results.

**Environment overview (please complete the following information)**
Bare metal (desktop PC).

**Environment details**
<details><summary>Click here to see environment details</summary><pre>
     
     **git***
     commit 9932a03894f12f9c3f83ae635792c7d79eb430a1 (HEAD, sperlingxx/enable_zero_backref)
     Author: sperlingxx <lovedreamf@gmail.com>
     Date:   Wed Mar 30 08:44:00 2022 +0800
     
     update
     **git submodules***
     
     ***OS Information***
     DISTRIB_ID=Ubuntu
     DISTRIB_RELEASE=20.04
     DISTRIB_CODENAME=focal
     DISTRIB_DESCRIPTION=""Ubuntu 20.04.3 LTS""
     NAME=""Ubuntu""
     VERSION=""20.04.3 LTS (Focal Fossa)""
     ID=ubuntu
     ID_LIKE=debian
     PRETTY_NAME=""Ubuntu 20.04.3 LTS""
     VERSION_ID=""20.04""
     HOME_URL=""https://www.ubuntu.com/""
     SUPPORT_URL=""https://help.ubuntu.com/""
     BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
     PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
     VERSION_CODENAME=focal
     UBUNTU_CODENAME=focal
     Linux ripper 5.13.0-39-generic #44~20.04.1-Ubuntu SMP Thu Mar 24 16:43:35 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
     
     ***GPU Information***
     Tue Apr  5 14:53:32 2022
     +-----------------------------------------------------------------------------+
     | NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |
     |-------------------------------+----------------------+----------------------+
     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
     |                               |                      |               MIG M. |
     |===============================+======================+======================|
     |   0  NVIDIA GeForce ...  On   | 00000000:42:00.0  On |                  N/A |
     |  0%   50C    P5    26W / 320W |   1086MiB / 10014MiB |      5%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     
     +-----------------------------------------------------------------------------+
     | Processes:                                                                  |
     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
     |        ID   ID                                                   Usage      |
     |=============================================================================|
     |    0   N/A  N/A      1714      G   /usr/lib/xorg/Xorg                102MiB |
     |    0   N/A  N/A      2459      G   /usr/lib/xorg/Xorg                605MiB |
     |    0   N/A  N/A      2595      G   /usr/bin/gnome-shell              109MiB |
     |    0   N/A  N/A      3028      G   ...AAAAAAAAA= --shared-files        8MiB |
     |    0   N/A  N/A      3409      G   /usr/lib/firefox/firefox          168MiB |
     |    0   N/A  N/A      9759      G   ...veSuggestionsOnlyOnDemand       51MiB |
     |    0   N/A  N/A     39765      G   ..._20525.log --shared-files        4MiB |
     |    0   N/A  N/A    126249      G   ./jetbrains-toolbox                12MiB |
     |    0   N/A  N/A    147354      G   /usr/lib/firefox/firefox            3MiB |
     |    0   N/A  N/A    190794      G   /usr/lib/firefox/firefox            3MiB |
     +-----------------------------------------------------------------------------+
     
     ***CPU***
     Architecture:                    x86_64
     CPU op-mode(s):                  32-bit, 64-bit
     Byte Order:                      Little Endian
     Address sizes:                   43 bits physical, 48 bits virtual
     CPU(s):                          48
     On-line CPU(s) list:             0-47
     Thread(s) per core:              2
     Core(s) per socket:              24
     Socket(s):                       1
     NUMA node(s):                    4
     Vendor ID:                       AuthenticAMD
     CPU family:                      23
     Model:                           8
     Model name:                      AMD Ryzen Threadripper 2970WX 24-Core Processor
     Stepping:                        2
     Frequency boost:                 enabled
     CPU MHz:                         2166.041
     CPU max MHz:                     3000.0000
     CPU min MHz:                     2200.0000
     BogoMIPS:                        5988.02
     Virtualization:                  AMD-V
     L1d cache:                       768 KiB
     L1i cache:                       1.5 MiB
     L2 cache:                        12 MiB
     L3 cache:                        64 MiB
     NUMA node0 CPU(s):               0-5,24-29
     NUMA node1 CPU(s):               12-17,36-41
     NUMA node2 CPU(s):               6-11,30-35
     NUMA node3 CPU(s):               18-23,42-47
     Vulnerability Itlb multihit:     Not affected
     Vulnerability L1tf:              Not affected
     Vulnerability Mds:               Not affected
     Vulnerability Meltdown:          Not affected
     Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
     Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
     Vulnerability Spectre v2:        Mitigation; LFENCE, IBPB conditional, STIBP disabled, RSB filling
     Vulnerability Srbds:             Not affected
     Vulnerability Tsx async abort:   Not affected
     Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid amd_dcm aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb hw_pstate ssbd ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 rdseed adx smap clflushopt sha_ni xsaveopt xsavec xgetbv1 xsaves clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif overflow_recov succor smca sme sev sev_es
     
     ***CMake***
     /usr/bin/cmake
     cmake version 3.16.3
     
     CMake suite maintained and supported by Kitware (kitware.com/cmake).
     
     ***g++***
     /usr/bin/g++
     g++ (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
     Copyright (C) 2019 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
     
     
     ***nvcc***
     /usr/local/cuda/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2021 NVIDIA Corporation
     Built on Thu_Nov_18_09:45:30_PST_2021
     Cuda compilation tools, release 11.5, V11.5.119
     Build cuda_11.5.r11.5/compiler.30672275_0
     
     ***Python***
     /home/andy/miniconda3/envs/rapids-22.04/bin/python
     Python 3.8.13
     
     ***Environment Variables***
     PATH                            : /home/andy/miniconda3/envs/rapids-22.04/bin:/home/andy/miniconda3/condabin:/home/andy/.cargo/bin:/home/andy/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/apache-maven-3.8.4/bin:mvnd-0.5.2-linux-amd64/bin:/usr/local/cuda/bin
     LD_LIBRARY_PATH                 : :/usr/local/cuda/targets/x86_64-linux/lib/:/usr/local/cuda/lib64
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /home/andy/miniconda3/envs/rapids-22.04
     PYTHON_PATH                     :
     
     ***conda packages***
     /home/andy/miniconda3/condabin/conda
     # packages in environment at /home/andy/miniconda3/envs/rapids-22.04:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                       1_gnu    conda-forge
     abseil-cpp                20210324.2           h9c3ff4c_0    conda-forge
     aiohttp                   3.8.1            py38h0a891b7_1    conda-forge
     aiosignal                 1.2.0              pyhd8ed1ab_0    conda-forge
     alsa-lib                  1.2.3                h516909a_0    conda-forge
     anyio                     3.5.0            py38h578d9bd_0    conda-forge
     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
     argon2-cffi               21.3.0             pyhd8ed1ab_0    conda-forge
     argon2-cffi-bindings      21.2.0           py38h497a2fe_1    conda-forge
     arrow-cpp                 6.0.1           py38h4dc56cc_5_cuda    conda-forge
     arrow-cpp-proc            3.0.0                      cuda    conda-forge
     asgiref                   3.5.0              pyhd8ed1ab_0    conda-forge
     asttokens                 2.0.5              pyhd8ed1ab_0    conda-forge
     async-timeout             4.0.2              pyhd8ed1ab_0    conda-forge
     attrs                     21.4.0             pyhd8ed1ab_0    conda-forge
     aws-c-auth                0.6.8                hadad3cd_1    conda-forge
     aws-c-cal                 0.5.12               h70efedd_7    conda-forge
     aws-c-common              0.6.17               h7f98852_0    conda-forge
     aws-c-compression         0.2.14               h7c7754b_7    conda-forge
     aws-c-event-stream        0.2.7               hd2be095_32    conda-forge
     aws-c-http                0.6.10               h416565a_3    conda-forge
     aws-c-io                  0.10.14              he836878_0    conda-forge
     aws-c-mqtt                0.7.10               h885097b_0    conda-forge
     aws-c-s3                  0.1.29               h8d70ed6_0    conda-forge
     aws-c-sdkutils            0.1.1                h7c7754b_4    conda-forge
     aws-checksums             0.1.12               h7c7754b_6    conda-forge
     aws-crt-cpp               0.17.10              h6ab17b9_5    conda-forge
     aws-sdk-cpp               1.9.160              h36ff4c5_0    conda-forge
     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge
     backports                 1.0                        py_2    conda-forge
     backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge
     backports.zoneinfo        0.2.1            py38h497a2fe_4    conda-forge
     beautifulsoup4            4.10.0             pyha770c72_0    conda-forge
     bleach                    4.1.0              pyhd8ed1ab_0    conda-forge
     blosc                     1.21.0               h9c3ff4c_0    conda-forge
     bokeh                     2.4.2            py38h578d9bd_0    conda-forge
     boost                     1.74.0           py38h2b96118_5    conda-forge
     boost-cpp                 1.74.0               h312852a_4    conda-forge
     brotli                    1.0.9                h166bdaf_7    conda-forge
     brotli-bin                1.0.9                h166bdaf_7    conda-forge
     brotlipy                  0.7.0           py38h0a891b7_1004    conda-forge
     brunsli                   0.1                  h9c3ff4c_0    conda-forge
     bzip2                     1.0.8                h7f98852_4    conda-forge
     c-ares                    1.18.1               h7f98852_0    conda-forge
     c-blosc2                  2.0.4                h5f21a17_1    conda-forge
     ca-certificates           2021.10.8            ha878542_0    conda-forge
     cachetools                5.0.0              pyhd8ed1ab_0    conda-forge
     cairo                     1.16.0            h6cf1ce9_1008    conda-forge
     certifi                   2021.10.8        py38h578d9bd_2    conda-forge
     cffi                      1.15.0           py38h3931269_0    conda-forge
     cfitsio                   3.470                hb418390_7    conda-forge
     charls                    2.2.0                h9c3ff4c_0    conda-forge
     charset-normalizer        2.0.12             pyhd8ed1ab_0    conda-forge
     click                     8.0.4            py38h578d9bd_0    conda-forge
     click-plugins             1.1.1                      py_0    conda-forge
     cligj                     0.7.2              pyhd8ed1ab_1    conda-forge
     cloudpickle               2.0.0              pyhd8ed1ab_0    conda-forge
     colorama                  0.4.4              pyh9f0ad1d_0    conda-forge
     colorcet                  3.0.0              pyhd8ed1ab_0    conda-forge
     cryptography              36.0.2           py38h2b5fc30_1    conda-forge
     cucim                     22.04.00a220405 cuda_11_py38_g7602774_34    rapidsai-nightly
     cuda-python               11.6.1           py38h3fd9d12_0    nvidia
     cudatoolkit               11.5.1               hcf5317a_9    nvidia
     cudf                      22.04.00a220405 cuda_11_py38_g4c84184a3f_304    rapidsai-nightly
     cudf_kafka                22.04.00a220405 py38_g4c84184a3f_304    rapidsai-nightly
     cugraph                   22.04.00a220405 cuda11_py38_g38be932f_101    rapidsai-nightly
     cuml                      22.04.00a220405 cuda11_py38_g5feaf7b74_107    rapidsai-nightly
     cupy                      9.6.0            py38h177b0fd_0    conda-forge
     curl                      7.82.0               h7bff187_0    conda-forge
     cusignal                  22.04.00a220405 py39_g8878bf7_15    rapidsai-nightly
     cuspatial                 22.04.00a220405 py38_g7709a43_19    rapidsai-nightly
     custreamz                 22.04.00a220405 py38_g4c84184a3f_304    rapidsai-nightly
     cuxfilter                 22.04.00a220405 py38_gf9a106c_18    rapidsai-nightly
     cycler                    0.11.0             pyhd8ed1ab_0    conda-forge
     cyrus-sasl                2.1.27               h230043b_5    conda-forge
     cytoolz                   0.11.2           py38h497a2fe_1    conda-forge
     dask                      2022.3.0           pyhd8ed1ab_1    conda-forge
     dask-core                 2022.3.0           pyhd8ed1ab_0    conda-forge
     dask-cuda                 22.04.00a220405         py38_29    rapidsai-nightly
     dask-cudf                 22.04.00a220405 cuda_11_py38_g4c84184a3f_304    rapidsai-nightly
     dask-sql                  2022.1.1a220405  py_gab2aa5a_33    dask/label/dev
     datashader                0.13.1a                    py_0    rapidsai-nightly
     datashape                 0.5.4                      py_1    conda-forge
     debugpy                   1.5.1            py38h709712a_0    conda-forge
     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge
     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge
     distributed               2022.3.0           pyhd8ed1ab_0    conda-forge
     dlpack                    0.5                  h9c3ff4c_0    conda-forge
     entrypoints               0.4                pyhd8ed1ab_0    conda-forge
     executing                 0.8.3              pyhd8ed1ab_0    conda-forge
     expat                     2.4.8                h27087fc_0    conda-forge
     faiss-proc                1.0.0                      cuda    conda-forge
     fastapi                   0.75.1             pyhd8ed1ab_0    conda-forge
     fastavro                  1.4.10           py38h0a891b7_0    conda-forge
     fastrlock                 0.8              py38hfa26641_1    conda-forge
     fiona                     1.8.20           py38hbb147eb_2    conda-forge
     flit-core                 3.7.1              pyhd8ed1ab_0    conda-forge
     font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge
     font-ttf-inconsolata      3.000                h77eed37_0    conda-forge
     font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge
     font-ttf-ubuntu           0.83                 hab24e00_0    conda-forge
     fontconfig                2.14.0               h8e229c2_0    conda-forge
     fonts-conda-ecosystem     1                             0    conda-forge
     fonts-conda-forge         1                             0    conda-forge
     fonttools                 4.31.2           py38h0a891b7_0    conda-forge
     freetype                  2.10.4               h0708190_1    conda-forge
     freexl                    1.0.6                h7f98852_0    conda-forge
     frozenlist                1.3.0            py38h0a891b7_1    conda-forge
     fsspec                    2022.3.0           pyhd8ed1ab_0    conda-forge
     gdal                      3.3.2            py38h81a01a0_3    conda-forge
     geopandas                 0.9.0              pyhd8ed1ab_1    conda-forge
     geopandas-base            0.9.0              pyhd8ed1ab_1    conda-forge
     geos                      3.9.1                h9c3ff4c_2    conda-forge
     geotiff                   1.7.0                h08e826d_2    conda-forge
     gettext                   0.19.8.1          h73d1719_1008    conda-forge
     gflags                    2.2.2             he1b5a44_1004    conda-forge
     giflib                    5.2.1                h36c2ea0_2    conda-forge
     glog                      0.5.0                h48cff8f_0    conda-forge
     graphite2                 1.3.13            h58526e2_1001    conda-forge
     grpc-cpp                  1.42.0               ha1441d3_1    conda-forge
     h11                       0.13.0             pyhd8ed1ab_0    conda-forge
     harfbuzz                  2.9.1                h83ec7ef_1    conda-forge
     hdf4                      4.2.15               h10796ff_3    conda-forge
     hdf5                      1.12.1          nompi_h2386368_104    conda-forge
     heapdict                  1.0.1                      py_0    conda-forge
     holoviews                 1.14.6             pyhd8ed1ab_0    conda-forge
     icu                       68.2                 h9c3ff4c_0    conda-forge
     idna                      3.3                pyhd8ed1ab_0    conda-forge
     imagecodecs               2021.8.26        py38hb5ce8f7_1    conda-forge
     imageio                   2.16.1             pyhcf75d05_0    conda-forge
     importlib-metadata        4.11.3           py38h578d9bd_1    conda-forge
     importlib_metadata        4.11.3               hd8ed1ab_1    conda-forge
     importlib_resources       5.6.0              pyhd8ed1ab_0    conda-forge
     ipykernel                 6.12.1           py38h7f3c49e_0    conda-forge
     ipython                   8.2.0            py38h578d9bd_0    conda-forge
     ipython_genutils          0.2.0                      py_1    conda-forge
     ipywidgets                7.7.0              pyhd8ed1ab_0    conda-forge
     jbig                      2.1               h7f98852_2003    conda-forge
     jedi                      0.18.1           py38h578d9bd_1    conda-forge
     jinja2                    3.1.1              pyhd8ed1ab_0    conda-forge
     joblib                    1.1.0              pyhd8ed1ab_0    conda-forge
     jpeg                      9e                   h7f98852_0    conda-forge
     jpype1                    1.3.0            py38h1fd1430_2    conda-forge
     json-c                    0.15                 h98cffda_0    conda-forge
     jsonschema                4.4.0              pyhd8ed1ab_0    conda-forge
     jupyter-server-proxy      3.2.1              pyhd8ed1ab_0    conda-forge
     jupyter_client            7.2.1              pyhd8ed1ab_0    conda-forge
     jupyter_core              4.9.2            py38h578d9bd_0    conda-forge
     jupyter_server            1.16.0             pyhd8ed1ab_1    conda-forge
     jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge
     jupyterlab_widgets        1.1.0              pyhd8ed1ab_0    conda-forge
     jxrlib                    1.1                  h7f98852_2    conda-forge
     kealib                    1.4.14               h87e4c3c_3    conda-forge
     keyutils                  1.6.1                h166bdaf_0    conda-forge
     kiwisolver                1.4.2            py38h43d8883_1    conda-forge
     krb5                      1.19.3               h3790be6_0    conda-forge
     lcms2                     2.12                 hddcbb42_0    conda-forge
     ld_impl_linux-64          2.36.1               hea4e1c9_2    conda-forge
     lerc                      3.0                  h9c3ff4c_0    conda-forge
     libaec                    1.0.6                h9c3ff4c_0    conda-forge
     libblas                   3.9.0           13_linux64_openblas    conda-forge
     libbrotlicommon           1.0.9                h166bdaf_7    conda-forge
     libbrotlidec              1.0.9                h166bdaf_7    conda-forge
     libbrotlienc              1.0.9                h166bdaf_7    conda-forge
     libcblas                  3.9.0           13_linux64_openblas    conda-forge
     libcucim                  22.04.00a220405 cuda11_g7602774_34    rapidsai-nightly
     libcudf                   22.04.00a220405 cuda11_g4c84184a3f_304    rapidsai-nightly
     libcudf_kafka             22.04.00a220405 g4c84184a3f_304    rapidsai-nightly
     libcugraph                22.04.00a220405 cuda11_g38be932f_101    rapidsai-nightly
     libcugraph_etl            22.04.00a220405 cuda11_g38be932f_101    rapidsai-nightly
     libcugraphops             22.04.00a220405 cuda11_ga9f323f_32    rapidsai-nightly
     libcuml                   22.04.00a220405 cuda11_g5feaf7b74_107    rapidsai-nightly
     libcumlprims              22.04.00a220324 cuda11_g99e8d8f_15    rapidsai-nightly
     libcurl                   7.82.0               h7bff187_0    conda-forge
     libcusolver               11.3.4.124           h33c3c4e_0    nvidia
     libcuspatial              22.04.00a220405 cuda11_g7709a43_19    rapidsai-nightly
     libdap4                   3.20.6               hd7c4107_2    conda-forge
     libdeflate                1.8                  h7f98852_0    conda-forge
     libedit                   3.1.20191231         he28a2e2_2    conda-forge
     libev                     4.33                 h516909a_1    conda-forge
     libevent                  2.1.10               h9b69904_4    conda-forge
     libfaiss                  1.7.0           cuda112h5bea7ad_8_cuda    conda-forge
     libffi                    3.4.2                h7f98852_5    conda-forge
     libgcc-ng                 11.2.0              h1d223b6_14    conda-forge
     libgcrypt                 1.10.0               h7f98852_0    conda-forge
     libgdal                   3.3.2                h6acdded_3    conda-forge
     libgfortran-ng            11.2.0              h69a702a_14    conda-forge
     libgfortran5              11.2.0              h5c6108e_14    conda-forge
     libglib                   2.70.2               h174f98d_4    conda-forge
     libgomp                   11.2.0              h1d223b6_14    conda-forge
     libgpg-error              1.44                 h9eb791d_0    conda-forge
     libgsasl                  1.10.0               h5b4c23d_0    conda-forge
     libhwloc                  2.3.0                h5e5b7d1_1    conda-forge
     libiconv                  1.16                 h516909a_0    conda-forge
     libkml                    1.3.0             h238a007_1014    conda-forge
     liblapack                 3.9.0           13_linux64_openblas    conda-forge
     libllvm11                 11.1.0               hf817b99_3    conda-forge
     libnetcdf                 4.8.1           nompi_hb3fd0d9_101    conda-forge
     libnghttp2                1.47.0               h727a467_0    conda-forge
     libnsl                    2.0.0                h7f98852_0    conda-forge
     libntlm                   1.4               h7f98852_1002    conda-forge
     libopenblas               0.3.18          pthreads_h8fe5266_0    conda-forge
     libpng                    1.6.37               h21135ba_2    conda-forge
     libpq                     13.5                 hd57d9b9_1    conda-forge
     libprotobuf               3.19.4               h780b84a_0    conda-forge
     libraft-distance          22.04.00a220405 cuda11_gc509483_112    rapidsai-nightly
     libraft-headers           22.04.00a220405 cuda11_gc509483_112    rapidsai-nightly
     libraft-nn                22.04.00a220405 cuda11_gc509483_112    rapidsai-nightly
     librdkafka                1.7.0                hc49e61c_1    conda-forge
     librmm                    22.04.00a220405 cuda11_g1420689_48    rapidsai-nightly
     librttopo                 1.1.0                h1185371_6    conda-forge
     libsodium                 1.0.18               h36c2ea0_1    conda-forge
     libspatialindex           1.9.3                h9c3ff4c_4    conda-forge
     libspatialite             5.0.1                h5cf074c_8    conda-forge
     libssh2                   1.10.0               ha56f1ee_2    conda-forge
     libstdcxx-ng              11.2.0              he4da1e4_14    conda-forge
     libthrift                 0.15.0               he6d91bd_1    conda-forge
     libtiff                   4.3.0                h6f004c6_2    conda-forge
     libutf8proc               2.7.0                h7f98852_0    conda-forge
     libuuid                   2.32.1            h7f98852_1000    conda-forge
     libuv                     1.43.0               h7f98852_0    conda-forge
     libwebp                   1.2.2                h3452ae3_0    conda-forge
     libwebp-base              1.2.2                h7f98852_1    conda-forge
     libxcb                    1.13              h7f98852_1004    conda-forge
     libxgboost                1.5.2dev.rapidsai22.04       cuda_11_0    rapidsai-nightly
     libxml2                   2.9.12               h72842e0_0    conda-forge
     libzip                    1.8.0                h4de3113_1    conda-forge
     libzlib                   1.2.11            h166bdaf_1014    conda-forge
     libzopfli                 1.0.3                h9c3ff4c_0    conda-forge
     llvmlite                  0.38.0           py38h38d86a4_1    conda-forge
     locket                    0.2.0                      py_2    conda-forge
     lz4                       4.0.0            py38h1bf946c_1    conda-forge
     lz4-c                     1.9.3                h9c3ff4c_1    conda-forge
     mapclassify               2.4.3              pyhd8ed1ab_0    conda-forge
     markdown                  3.3.6              pyhd8ed1ab_0    conda-forge
     markupsafe                2.1.1            py38h0a891b7_1    conda-forge
     matplotlib-base           3.5.1            py38hf4fb855_0    conda-forge
     matplotlib-inline         0.1.3              pyhd8ed1ab_0    conda-forge
     mistune                   0.8.4           py38h497a2fe_1005    conda-forge
     msgpack-python            1.0.3            py38h43d8883_1    conda-forge
     multidict                 6.0.2            py38h0a891b7_1    conda-forge
     multipledispatch          0.6.0                      py_0    conda-forge
     munch                     2.5.0                      py_0    conda-forge
     munkres                   1.1.4              pyh9f0ad1d_0    conda-forge
     nbclient                  0.5.13             pyhd8ed1ab_0    conda-forge
     nbconvert                 6.4.5              pyhd8ed1ab_2    conda-forge
     nbconvert-core            6.4.5              pyhd8ed1ab_2    conda-forge
     nbconvert-pandoc          6.4.5              pyhd8ed1ab_2    conda-forge
     nbformat                  5.3.0              pyhd8ed1ab_0    conda-forge
     nccl                      2.12.7.1             h0800d71_0    conda-forge
     ncurses                   6.3                  h9c3ff4c_0    conda-forge
     nest-asyncio              1.5.5              pyhd8ed1ab_0    conda-forge
     networkx                  2.6.3              pyhd8ed1ab_1    conda-forge
     nodejs                    14.18.3              h92b4a50_1    conda-forge
     notebook                  6.4.10             pyha770c72_0    conda-forge
     nspr                      4.32                 h9c3ff4c_1    conda-forge
     nss                       3.77                 h2350873_0    conda-forge
     numba                     0.55.1           py38h4bf6c61_0    conda-forge
     numpy                     1.21.5           py38h87f13fb_0    conda-forge
     nvtx                      0.2.3            py38h497a2fe_1    conda-forge
     openjdk                   11.0.9.1             h5cc2fde_1    conda-forge
     openjpeg                  2.4.0                hb52868f_1    conda-forge
     openssl                   1.1.1n               h166bdaf_0    conda-forge
     orc                       1.7.1                h1be678f_1    conda-forge
     packaging                 21.3               pyhd8ed1ab_0    conda-forge
     pandas                    1.3.5            py38h43a58ef_0    conda-forge
     pandoc                    2.17.1.1             ha770c72_0    conda-forge
     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge
     panel                     0.12.7             pyhd8ed1ab_0    conda-forge
     param                     1.12.1             pyh6c4a22f_0    conda-forge
     parquet-cpp               1.5.1                         2    conda-forge
     parso                     0.8.3              pyhd8ed1ab_0    conda-forge
     partd                     1.2.0              pyhd8ed1ab_0    conda-forge
     pcre                      8.45                 h9c3ff4c_0    conda-forge
     pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge
     pickleshare               0.7.5                   py_1003    conda-forge
     pillow                    9.1.0            py38h0ee0e06_0    conda-forge
     pip                       22.0.4             pyhd8ed1ab_0    conda-forge
     pixman                    0.40.0               h36c2ea0_0    conda-forge
     poppler                   21.09.0              ha39eefc_3    conda-forge
     poppler-data              0.4.11               hd8ed1ab_0    conda-forge
     postgresql                13.5                 h2510834_1    conda-forge
     proj                      8.1.0                h277dcde_1    conda-forge
     prometheus_client         0.13.1             pyhd8ed1ab_0    conda-forge
     prompt-toolkit            3.0.29             pyha770c72_0    conda-forge
     protobuf                  3.19.4           py38h709712a_0    conda-forge
     psutil                    5.9.0            py38h0a891b7_1    conda-forge
     pthread-stubs             0.4               h36c2ea0_1001    conda-forge
     ptxcompiler               0.2.0            py38h98f4b32_0    rapidsai-nightly
     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge
     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge
     py-xgboost                1.5.2dev.rapidsai22.04  cuda_11_py38_0    rapidsai-nightly
     pyarrow                   6.0.1           py38ha746e9d_5_cuda    conda-forge
     pycparser                 2.21               pyhd8ed1ab_0    conda-forge
     pyct                      0.4.6                      py_0    conda-forge
     pyct-core                 0.4.6                      py_0    conda-forge
     pydantic                  1.9.0            py38h0a891b7_1    conda-forge
     pydeck                    0.5.0              pyh9f0ad1d_0    conda-forge
     pyee                      8.1.0              pyhd8ed1ab_0    conda-forge
     pygments                  2.11.2             pyhd8ed1ab_0    conda-forge
     pylibcugraph              22.04.00a220405 cuda11_py38_g38be932f_101    rapidsai-nightly
     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge
     pyopenssl                 22.0.0             pyhd8ed1ab_0    conda-forge
     pyparsing                 3.0.7              pyhd8ed1ab_0    conda-forge
     pyppeteer                 1.0.2              pyhd8ed1ab_0    conda-forge
     pyproj                    3.1.0            py38h3701b11_4    conda-forge
     pyraft                    22.04.00a220405 cuda11_py38_gc509483_112    rapidsai-nightly
     pyrsistent                0.18.1           py38h0a891b7_1    conda-forge
     pysocks                   1.7.1            py38h578d9bd_5    conda-forge
     python                    3.8.13          h582c2e5_0_cpython    conda-forge
     python-confluent-kafka    1.7.0            py38h497a2fe_2    conda-forge
     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge
     python-fastjsonschema     2.15.3             pyhd8ed1ab_0    conda-forge
     python-tzdata             2022.1             pyhd8ed1ab_0    conda-forge
     python_abi                3.8                      2_cp38    conda-forge
     pytz                      2022.1             pyhd8ed1ab_0    conda-forge
     pytz-deprecation-shim     0.1.0.post0      py38h578d9bd_1    conda-forge
     pyviz_comms               2.2.0              pyhd8ed1ab_0    conda-forge
     pywavelets                1.3.0            py38h3ec907f_0    conda-forge
     pyyaml                    6.0              py38h0a891b7_4    conda-forge
     pyzmq                     22.3.0           py38hfc09fa9_2    conda-forge
     rapids                    22.04.00a220405 cuda11_py38_g5d1fba5_121    rapidsai-nightly
     rapids-xgboost            22.04.00a220405 cuda11_py38_g5d1fba5_121    rapidsai-nightly
     re2                       2021.11.01           h9c3ff4c_0    conda-forge
     readline                  8.1                  h46c0cb4_0    conda-forge
     requests                  2.27.1             pyhd8ed1ab_0    conda-forge
     rmm                       22.04.00a220405 cuda11_py38_g1420689_48    rapidsai-nightly
     rtree                     0.9.7            py38h02d302b_3    conda-forge
     s2n                       1.3.0                h9b69904_0    conda-forge
     scikit-image              0.19.2           py38h43a58ef_0    conda-forge
     scikit-learn              1.0.2            py38h1561384_0    conda-forge
     scipy                     1.8.0            py38h56a6a73_1    conda-forge
     send2trash                1.8.0              pyhd8ed1ab_0    conda-forge
     setuptools                59.8.0           py38h578d9bd_1    conda-forge
     shapely                   1.8.0            py38hb7fe4a8_0    conda-forge
     simpervisor               0.4                pyhd8ed1ab_0    conda-forge
     six                       1.16.0             pyh6c4a22f_0    conda-forge
     snappy                    1.1.8                he1b5a44_3    conda-forge
     sniffio                   1.2.0            py38h578d9bd_3    conda-forge
     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge
     soupsieve                 2.3.1              pyhd8ed1ab_0    conda-forge
     spdlog                    1.8.5                h4bd325d_1    conda-forge
     sqlite                    3.37.1               h4ff8645_0    conda-forge
     stack_data                0.2.0              pyhd8ed1ab_0    conda-forge
     starlette                 0.17.1             pyhd8ed1ab_0    conda-forge
     streamz                   0.6.3              pyh6c4a22f_0    conda-forge
     tabulate                  0.8.9              pyhd8ed1ab_0    conda-forge
     tblib                     1.7.0              pyhd8ed1ab_0    conda-forge
     terminado                 0.13.3           py38h578d9bd_1    conda-forge
     testpath                  0.6.0              pyhd8ed1ab_0    conda-forge
     threadpoolctl             3.1.0              pyh8a188c0_0    conda-forge
     tifffile                  2021.11.2          pyhd8ed1ab_0    conda-forge
     tiledb                    2.3.4                he87e0bf_0    conda-forge
     tk                        8.6.12               h27826a3_0    conda-forge
     toolz                     0.11.2             pyhd8ed1ab_0    conda-forge
     tornado                   6.1              py38h0a891b7_3    conda-forge
     tqdm                      4.64.0             pyhd8ed1ab_0    conda-forge
     traitlets                 5.1.1              pyhd8ed1ab_0    conda-forge
     treelite                  2.3.0            py38hdd725b4_0    conda-forge
     treelite-runtime          2.3.0                    pypi_0    pypi
     typing-extensions         4.1.1                hd8ed1ab_0    conda-forge
     typing_extensions         4.1.1              pyha770c72_0    conda-forge
     tzcode                    2022a                h166bdaf_0    conda-forge
     tzdata                    2022a                h191b570_0    conda-forge
     tzlocal                   4.2              py38h578d9bd_0    conda-forge
     ucx                       1.12.0+gd367332      cuda11.2_0    rapidsai-nightly
     ucx-proc                  1.0.0                       gpu    rapidsai-nightly
     ucx-py                    0.25.00a220405  py38_gd367332_13    rapidsai-nightly
     unicodedata2              14.0.0           py38h0a891b7_1    conda-forge
     urllib3                   1.26.9             pyhd8ed1ab_0    conda-forge
     uvicorn                   0.17.6           py38h578d9bd_0    conda-forge
     wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge
     webencodings              0.5.1                      py_1    conda-forge
     websocket-client          1.3.2              pyhd8ed1ab_0    conda-forge
     websockets                10.2             py38h0a891b7_0    conda-forge
     wheel                     0.37.1             pyhd8ed1ab_0    conda-forge
     widgetsnbextension        3.6.0            py38h578d9bd_0    conda-forge
     xarray                    2022.3.0           pyhd8ed1ab_0    conda-forge
     xerces-c                  3.2.3                h9d8b166_3    conda-forge
     xgboost                   1.5.2dev.rapidsai22.04  cuda_11_py38_0    rapidsai-nightly
     xorg-fixesproto           5.0               h7f98852_1002    conda-forge
     xorg-inputproto           2.3.2             h7f98852_1002    conda-forge
     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge
     xorg-libice               1.0.10               h7f98852_0    conda-forge
     xorg-libsm                1.2.3             hd9c2040_1000    conda-forge
     xorg-libx11               1.7.2                h7f98852_0    conda-forge
     xorg-libxau               1.0.9                h7f98852_0    conda-forge
     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge
     xorg-libxext              1.3.4                h7f98852_1    conda-forge
     xorg-libxfixes            5.0.3             h7f98852_1004    conda-forge
     xorg-libxi                1.7.10               h7f98852_0    conda-forge
     xorg-libxrender           0.9.10            h7f98852_1003    conda-forge
     xorg-libxtst              1.2.3             h7f98852_1002    conda-forge
     xorg-recordproto          1.14.2            h7f98852_1002    conda-forge
     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge
     xorg-xextproto            7.3.0             h7f98852_1002    conda-forge
     xorg-xproto               7.0.31            h7f98852_1007    conda-forge
     xz                        5.2.5                h516909a_1    conda-forge
     yaml                      0.2.5                h7f98852_2    conda-forge
     yarl                      1.7.2            py38h0a891b7_2    conda-forge
     zeromq                    4.3.4                h9c3ff4c_1    conda-forge
     zfp                       0.5.5                h9c3ff4c_8    conda-forge
     zict                      2.1.0              pyhd8ed1ab_0    conda-forge
     zipp                      3.8.0              pyhd8ed1ab_0    conda-forge
     zlib                      1.2.11            h166bdaf_1014    conda-forge
     zstd                      1.5.2                ha95c52a_0    conda-forge
     
</pre></details>

**Additional context**
See https://github.com/NVIDIA/spark-rapids/issues/5035
",2022-04-05T20:54:06Z,0,0,Andy Grove,@Apple
87,"[FEA] Define unary operations like `__neg__`, `__pos__`, `__abs__` and `__invert__` for `Column`.","Currently, invoking Python's builtin unary operators on columns raises:

```python
>>> s = cudf.Series([1, 2, 3])
>>> -s._column  # TypeError
```

This came up in https://github.com/rapidsai/cudf/pull/10564.

A workaround is to do for example, `s._column.unary_operator(""abs"")` or `0 - s._column`, but it would be nice to do this in a more Pythonic way.",2022-04-06T20:23:25Z,0,0,Ashwin Srinath,Voltron Data
88,[FEA] Support for approx_count_distinct,"**Is your feature request related to a problem? Please describe.**
I would like to be able to implement a GPU version of Spark's `approx_count_distinct` function, which uses the [HyperLogLog++](https://en.wikipedia.org/wiki/HyperLogLog) cardinality estimation algorithm. 

cuDF does not appear to provide any features today that would allow me to do this.

**Describe the solution you'd like**
I would like cuDF to implement this capability and expose an API that is likely similar to `approx_percentile` in that there would be methods both for computing and merging the underlying data structure, whether that is based on HyperLogLog++ or some other algorithm.

**Describe alternatives you've considered**
None

**Additional context**
None
",2022-04-13T18:16:08Z,0,0,Andy Grove,@Apple
89,[FEA] Support cudf.DataFrame.corrwith ,"**Is your feature request related to a problem? Please describe.**
Developer request to use 'corrwith' in cudf.DataFrame and it is the basic block for their business. 

**Describe the solution you'd like**
Similar in pandas.DataFrame.corrwith(https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html#pandas.DataFrame.corrwith), understand its realization in pandas and try to make it happen in cudf. ",2022-04-28T13:53:32Z,0,0,,
90,[ENH]: serialization schema cleanup,Followup from #10784. Hyphens and underscores are used inconsistently when separating names in metadata keys in `serialize`; go through and standardise on one choice (hyphens seem more popular).,2022-05-05T16:45:28Z,0,0,Lawrence Mitchell,
91,[BUG] can't set groupby transform output to a new column,"**Describe the bug**
I try to use groupby count transform for frequency encoding of a column. I get an error when I do it:

> ValueError: Cannot align indices with non-unique values


**Steps/Code to reproduce bug**
`df[""a_freq""] = df.groupby([""a""])[""b""].transform(""count"")
`
This throws an error.
Setting the column in advance with zero or using values work as workarounds.
```
df[""a_freq""] = 0
df[""a_freq""] = df.groupby([""a""])[""b""].transform(""count"")
```
`df[""a_freq""] = df.groupby([""a""])[""b""].transform(""count"").values`

**Expected behavior**
I expect it to work as it works in pandas.

**Environment overview (please complete the following information)**
 - Environment location: local
 - Method of cuDF install: conda

**Environment details**
conda environment with RAPIDS 22.02
",2022-05-11T10:01:53Z,0,0,Ahmet Erdem,
92,[ENH] Support more input data layouts in `cudf.from_dlpack`,"Related to #10754, the current implementation of `from_dlpack` requires unit-stride fortran order, and produces appropriate error messages in the unsupported cases

Consider

```python
import cudf
import cupy
a = cupy.arange(10)
b = a[::2]
c = cudf.from_dlpack(b.__dlpack__())
=> RuntimeError: from_dlpack of 1D DLTensor only for unit-stride data
b = cupy.broadcast_to(a[1], (10,)) # b is stride-0
=> RuntimeError: from_dlpack of 1D DLTensor only for unit-stride data

a = cupy.arange(12).reshape(3, 4).copy(order=""F"")
b = a[::2, :]
c = cudf.from_dlpack(b.__dlpack__())
=> RuntimeError: from_dlpack of 2D DLTensor only for column-major unit-stride data
```

Since `from_dlpack` copies in all cases right now, I think that things can be handled like so:

1. Non-fortran-order: useful error
2. unit-stride: current `cudaMemcpyAsync` one column at a time
3. fastest-dimension is stride-0 (broadcasted arrays): `std::fill` for the 1D case, just getting the strides right for the 2D case
4. fastest-dimension is stride-N (sliced arrays): `cudaMemcpy2DAsync` with appropriate choices of pitch and stride for the source array

However, I'm not really sure of the performance implications of these choices, and if the current approach of producing an error and requiring that the caller copy to contiguous fortran-order first before calling `from_dlpack` is not better. For example, for case 4 is it faster to copy to a contiguous buffer first rather than copying column by column?",2022-05-13T13:56:20Z,0,0,Lawrence Mitchell,
93,[FEA] Don't copy data in to/from_dlpack when unnecessary,"To `.to_dlpack()` and `.from_dlpack()` methods in cuDF currently always perform a copy to/from the DLTensor. This is reasonable for DataFrames, as the columns of a dataframe in cuDF are not contiguous in memory, nor are they always of the same data type.

For a Series however, I believe we should be able to zero-copy to and from DLPack. That is not the case today:

```python
>>> import cudf
>>> import cupy as cp
>>> s = cudf.Series([1, 2, 3])
>>> arr = cp.from_dlpack(s.to_dlpack())
>>> s._column.data.ptr
139742968545280
>>> arr.data.ptr
139742968545792
```",2022-05-17T13:03:27Z,0,0,Ashwin Srinath,Voltron Data
94,[FEA]Support for list columns,"**PROBLEM DESCRIPTION**

cudF doesn't support applymap or applying using defined functions to columns containing list as cell values. Also, cudf can not save to_csv when dataframe has list columns. Both of these are supported in Pandas. However, switching back and forth between pandas and cudf is time-consuming for huge amount of datas, and it will be great if we can bring more support for list column dataframe

**SOLUTION**
I want to apply user defined functions to cudF columns with lists. The functions are not simple function with one arguement but more complex operation. Moreover I want to save cudf dataframe to csv or hdf5 without switching to pandas for the same type of dataframe.

**Alternatives**
One alternative is to switch to pandas which is not ideal as I want to do everything in GPU. Another alternate solution I tried is by loading the list columns into numpy array and then apply the user defined function and then write them back to the dataframe which is again time-consuming. It will be way easier if I can just apply the function to the column directly.


",2022-05-31T12:20:12Z,0,0,Arpan Das,The École polytechnique fédérale de Lausanne
95,[BUG] Using `.iloc[]` to set a single value in a Series does not do so in-place,"```python
>>> import  cudf
>>> s = cudf.Series([1, 2, 3])
>>> s2 = s.iloc[:]  # s2 is a view into s
>>> s.iloc[0] = -1  # this line does not behave as expected
>>> s
0   -1
1    2
2    3
dtype: int64
>>> s2
0    1
1    2
2    3
dtype: int64
```

Contrast with Pandas:

```python
>>> import pandas as pd
>>> s = pd.Series([1, 2, 3])
>>> s2 = s.iloc[:]  # s2 is a view into s
>>> s.iloc[0] = -1
>>> s
0   -1
1    2
2    3
dtype: int64
>>> s2
0   -1
1    2
2    3
dtype: int64
```

Note that setting  by slice works as expected:

```python
>>> import cudf
>>> s = cudf.Series([1, 2, 3])
>>> s2 = s.iloc[:]
>>> s.iloc[0:1] = -1
>>> s
0   -1
1    2
2    3
dtype: int64
>>> s2
0   -1
1    2
2    3
dtype: int64
```",2022-06-08T20:02:53Z,0,0,Ashwin Srinath,Voltron Data
96,[BUG] libcudf tests warn when linking when building in a conda environment without conda compiler metapackages,"When building libcudf and tests in a conda environment without having the compiler metapackages installed (`c-compiler`, `cxx-compiler`, etc.), it produces warnings about not finding `libz.so.1` needed by `libcudf.so`:
```
[406/674] Linking CXX executable gtests/COLUMN_TEST
/home/keith/miniconda3/envs/dev/bin/../lib/gcc/x86_64-conda-linux-gnu/10.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: warning: libz.so.1, needed by libcudf.so, not found (try using -rpath or -rpath-link)
```

I believe this is due to both the `conda_env` target (https://github.com/rapidsai/cudf/blob/branch-22.08/cpp/CMakeLists.txt#L628) and the zlib target (https://github.com/rapidsai/cudf/blob/branch-22.08/cpp/CMakeLists.txt#L622) both being private links for the libcudf target. zlib is just one example of this, but this could happen for any other private target of libcudf that comes from the conda environment.

This isn't a problem for the compiler metapackages because they set a slew of compiler CLI flags, notably an `rpath-link` flag into the conda environment. I do not use these metapackages because those CLI flags set will point into the conda environment before pointing into the local build directory, which makes having both an install and a working directory a pain.

I believe the fix is either changing the `conda_env` link to be a `PUBLIC` link of the libcudf target, or adding a `conda_env` link to the tests.",2022-06-17T19:32:26Z,0,0,Keith Kraus,@VoltronData
97,[BUG] cudf.DataFrame.all error on pivot-generated data frame,"**Describe the bug**
Getting an `UnboundLocalError: local variable 'index_class_type' referenced before assignment` when calling the cudf.DataFrame.all function. The data frame was created from comparing two data frames with the same columns and index attributes, one of which is generated from a call to cudf.DataFrame.pivot.

**Steps/Code to reproduce bug**
```Python
import cupy
import cudf

x = cupy.array([[1,2,3],[4,2,5]])
df = cudf.DataFrame(x)
pivot_table = df.pivot(index=[0], columns=[1], values=[2])
df2 = cudf.DataFrame(cupy.broadcast_to(pivot_table.iloc[:,0].values[:,None], pivot_table.shape), index=pivot_table.index, columns=pivot_table.columns)

print((df2 == pivot_table).all())
```

**Expected behavior**
Expected output:
```
2    True
dtype: bool
```

**Environment overview (please complete the following information)**
 - Environment location: Docker
 - Method of cuDF install: Docker
   - `docker run -it --rm --gpus all --ipc=host --network=host -v .`

**Environment details**
Version: 22.4.0a0+306.g0cb75a4913

**Additional context**
This snippet works as expected in cuDF 22.2.0 but does not work on cuDF 22.4.0.
",2022-06-24T20:37:57Z,0,0,Alex Xu,
98,[BUG] Timestamps displayed incorrectly due to Pandas not supporting >ns resolution,"The most minimal reproducer of the type of issues I'm seeing are:

```python
In [13]: cudf.Series([""2499-11-01 01:00:00""], dtype=""datetime64[s]"")
Out[13]:
0   1915-04-14 01:25:26.290448384
dtype: datetime64[s]

# indexing into a single element seems to work
In [14]: cudf.Series([""2499-11-01 01:00:00""], dtype=""datetime64[s]"").iloc[0]
Out[14]: numpy.datetime64('2499-11-01T01:00:00')
```

This is  most likely due to Pandas not being able to represent the timestamp accurately overflow occurring somewhere along the way.

Perhaps we should not rely on conversion to Pandas for displaying timestamps?",2022-06-27T19:15:24Z,1,0,Ashwin Srinath,Voltron Data
99,[BUG] Dask_cudf merge function returns too few rows,"**Describe the bug**
The dask_cudf merge functions returns too few rows when both the dtype of the column being merged on is mismatched (eg: `int64` on the left and `int32` on the right) _and_ when `npartitions>1`
 
**Steps/Code to reproduce bug**
Here's a reproducer showing that when the dtype is mismatched the number of rows returned is dependent on the number of partitions in the dataframes being merged:
```python
import cupy as cp
import cudf
import dask_cudf

dfa = cudf.DataFrame({""a"":cp.random.randint(0,100,100000), ""b"":cp.random.normal(size=100000)})
dfb = cudf.DataFrame({""a"":cp.random.randint(0,100,100000), ""c"":cp.random.normal(size=100000)})

dfa[""a""] = dfa[""a""].astype(""int32"")
dfb[""a""] = dfb[""a""].astype(""int64"")

ddfa = dask_cudf.from_cudf(dfa, npartitions=4)
ddfb = dask_cudf.from_cudf(dfb, npartitions=4)
print(""npartitions:"")
print(""left: {}"".format(ddfa.npartitions))
print(""right: {}"".format(ddfb.npartitions))

print(""Number of rows in merge result:"")
print(len(ddfa.merge(ddfb, how=""inner"", on=""a"")))
print(""*""*30)

ddfa = ddfa.repartition(npartitions=3)
ddfb = ddfb.repartition(npartitions=3)
print(""npartitions:"")
print(""left: {}"".format(ddfa.npartitions))
print(""right: {}"".format(ddfb.npartitions))

print(""Number of rows in merge result:"")
print(len(ddfa.merge(ddfb, how=""inner"", on=""a"")))
print(""*""*30)

ddfa = ddfa.repartition(npartitions=2)
ddfb = ddfb.repartition(npartitions=2)
print(""npartitions:"")
print(""left: {}"".format(ddfa.npartitions))
print(""right: {}"".format(ddfb.npartitions))

print(""Number of rows in merge result:"")
print(len(ddfa.merge(ddfb, how=""inner"", on=""a"")))
print(""*""*30)

ddfa = ddfa.repartition(npartitions=1)
ddfb = ddfb.repartition(npartitions=1)
print(""npartitions:"")
print(""left: {}"".format(ddfa.npartitions))
print(""right: {}"".format(ddfb.npartitions))

print(""Number of rows in merge result:"")
print(len(ddfa.merge(ddfb, how=""inner"", on=""a"")))
print(""*""*30)
```
This returns:
```
npartitions:
left: 4
right: 4
Number of rows in merge result:
16083716
******************************
npartitions:
left: 3
right: 3
Number of rows in merge result:
35342145
******************************
npartitions:
left: 2
right: 2
Number of rows in merge result:
46959990
******************************
npartitions:
left: 1
right: 1
Number of rows in merge result:
100006687
******************************
```

**Expected behavior**
If we perform the same operation with just cudf we can see the expected result:
```python
import cupy as cp
import cudf

dfa = cudf.DataFrame({""a"":cp.random.randint(0,100,100000), ""b"":cp.random.normal(size=100000)})
dfb = cudf.DataFrame({""a"":cp.random.randint(0,100,100000), ""c"":cp.random.normal(size=100000)})

dfa[""a""] = dfa[""a""].astype(""int32"")
dfb[""a""] = dfb[""a""].astype(""int64"")

print(len(ddfa.merge(ddfb, how=""inner"", on=""a"")))
```
which returns:
```
100006687
```
which is the same as the dask_cudf version when `npartitions=1`

**Environment overview (please complete the following information)**
 - Environment location: Bare-metal
 - Method of cuDF install: conda


**Environment details**
```
cudf                      22.08.00a220629 cuda_11_py38_gff63c0a745_173    rapidsai-nightly
dask-cudf                 22.08.00a220629 cuda_11_py38_gff63c0a745_173    rapidsai-nightly
libcudf                   22.08.00a220629 cuda11_gff63c0a745_173    rapidsai-nightly
dask                      2022.6.1           pyhd8ed1ab_0    conda-forge
dask-core                 2022.6.1           pyhd8ed1ab_0    conda-forge
dask-cuda                 22.08.00a220630         py38_21    rapidsai-nightly
distributed               2022.6.1           pyhd8ed1ab_0    conda-forge
```

**Note**
The same thing occurs when `how={""left"", ""right"", ""outer""}`",2022-07-01T17:22:10Z,0,0,,
100,[FEA] Potential missing performance in `partitioning.partition` (compared to `hash.hash_partition`),"A common pattern in dask is to shuffle distributed data around by some hash-based index. For example, this comes up in merging dataframes. Since the determination of index buckets is typically carried out independently from the splitting of the dataframe, this turns into calls to `libcudf.partitioning.partition`. The other option for this particular case would be to call `libcudf.hash.hash_partition`. The latter appears  to be signficantly (~5x) faster for large dataframes (code attached below, which partitions a dataframe with row columns and 100_000_000 rows on the first column into a configurable number of partitions, for the results below I used 10). Typical numbers of partitions for this use case are likely O(10-1000). Although this performance difference is not the order one cost in a distributed shuffle, flipping the switch from partition by index to partition by hash in dask-cuda provides a 10% speedup in some benchmarks (see rapidsai/dask-cuda#952).

```
$ python scatter-test.py
partition-by-indices: 52ms
partition-by-hash: 9.5ms
```

To help the timings for the `partition-by-indices` case, I only compute the indices to partition on once. Profiling with nsight shows this takes ~2.7ms. The `partition` call takes 52 ms (of which `scatter` takes 22ms), in contrast `hash-and-scatter` in one go via `hash_partition` takes 9.5ms. Since `partition` by indices needs to read an extra column (the indices), I might expect things to be a bit slower, but this large difference was a bit surprising.

There's a note in the partitioning code that it might make sense to avoid atomics:

https://github.com/rapidsai/cudf/blob/ec0b32bf73fc725982f62b0932782718d3886125/cpp/src/partitioning/partitioning.cu#L631

Aside: the pathological case of `npartitions == 1` is a factor of 2x slower for the partition-by-indices case, and 10x slower for partition-by-hash (probably worthwhile dispatching into a fast-path copy for that).

```python
import rmm
import cudf
import cudf._lib as libcudf
import cupy
import time


def build_dataframe(nrows):
    return cudf.DataFrame({""key"": cupy.arange(nrows),
                           ""value"": cupy.arange(nrows)})


def partition_by_indices(df, indices, npartitions):
    cols, offsets = libcudf.partitioning.partition(
        list(df._columns),
        indices,
        npartitions
    )
    return cols, offsets


def partition_by_hash(df, key, npartitions):
    cols, offsets = libcudf.hash.hash_partition(
        list(df._columns),
        [df._column_names.index(key)],
        npartitions
    )
    return cols, offsets


def run(*, nrows=10**8, with_pool=True, npartitions=10):
    rmm.reinitialize(pool_allocator=with_pool)
    df = build_dataframe(nrows)
    key = ""key""
    indices = (libcudf.hash.hash([df[key]._column], ""murmur3"") % npartitions)
    start = time.time()
    for _ in range(100):
        _ = partition_by_indices(df, indices, npartitions)
    end = time.time()
    print(f""partition-by-indices: {(end - start)*10:.3g}ms"")
    start = time.time()
    for _ in range(100):
        _ = partition_by_hash(df, key, npartitions)
    end = time.time()
    print(f""partition-by-hash: {(end - start)*10:.3g}ms"")


if __name__ == ""__main__"":
    run(nrows=10**8, with_pool=True, npartitions=10)
```

cc: @bdice, @shwina 

",2022-07-18T11:46:41Z,1,0,Lawrence Mitchell,
101,[BUG] Interchange `Column.get_buffers()` erroneously raises for empty string columns,"When using `get_buffers()` on an [interchange protocol](https://data-apis.org/dataframe-protocol/latest/API.html) string column of size 0, an error raises. <sup>Mind I might be constructing string columns incorrectly?</sup>

```python
>>> df = cudf.DataFrame({""foo"": cudf.Series([], dtype=""U8"")})
>>> interchange_df = df.__dataframe__()
>>> interchange_col = interchange_df.get_column_by_name(""foo"")
>>> interchange_col.get_buffers()
Traceback (most recent call last)

  File .../cudf/lib/python3.9/site-packages/cudf/core/df_protocol.py:390, in _CuDFColumn.get_buffers(self)
      387     buffers[""validity""] = None
      389 try:
  --> 390     buffers[""offsets""] = self._get_offsets_buffer()
      391 except RuntimeError:
      392     buffers[""offsets""] = None

  File .../cudf/lib/python3.9/site-packages/cudf/core/df_protocol.py:453, in _CuDFColumn._get_offsets_buffer(self)
      444 """"""
      445 Return the buffer containing the offset values for
      446 variable-size binary data (e.g., variable-length strings)
    (...)
      450 offsets buffer.
      451 """"""
      452 if self.dtype[0] == _DtypeKind.STRING:
  --> 453     offsets = self._col.children[0]
      454     assert (offsets is not None) and (offsets.data is not None), "" ""
      455     ""offsets(.data) should not be None for string column""

IndexError: tuple index out of range
```

Columns with 1+ elements seem to work just fine. I'm assuming the bug stems from an assumption of non-empty columns?

EDIT: Thinking about it, maybe `get_buffers()` doesn't make sense for 0-sided dataframes? Need to see if there's been any previous discussion on the subject.

**Environment overview**
 - Environment location: locally, Ubuntu 20.04.4
 - Method of cuDF install: conda via `rapidsai-nightly`
 - cudf version: `22.08.00a+213.g002cb1c45b`

<details><summary>Click here to see environment details</summary><pre>
     
     **git***
     commit 8b3ae33c2874025c29c3747de1c3254eac516f9f (HEAD -> main, origin/main)
     Author: Matthew Barber <quitesimplymatt@gmail.com>
     Date:   Tue Jul 12 09:58:38 2022 +0100
     
     `--max-examples` flag, skip specific flaky cases on CI
     **git submodules***
     
     ***OS Information***
     DISTRIB_ID=Ubuntu
     DISTRIB_RELEASE=20.04
     DISTRIB_CODENAME=focal
     DISTRIB_DESCRIPTION=""Ubuntu 20.04.4 LTS""
     NAME=""Ubuntu""
     VERSION=""20.04.4 LTS (Focal Fossa)""
     ID=ubuntu
     ID_LIKE=debian
     PRETTY_NAME=""Ubuntu 20.04.4 LTS""
     VERSION_ID=""20.04""
     HOME_URL=""https://www.ubuntu.com/""
     SUPPORT_URL=""https://help.ubuntu.com/""
     BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
     PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
     VERSION_CODENAME=focal
     UBUNTU_CODENAME=focal
     Linux honno-pc 5.13.0-52-generic #59~20.04.1-Ubuntu SMP Thu Jun 16 21:21:28 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
     
     ***GPU Information***
     Tue Jul 12 14:43:34 2022
     +-----------------------------------------------------------------------------+
     | NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |
     |-------------------------------+----------------------+----------------------+
     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
     |                               |                      |               MIG M. |
     |===============================+======================+======================|
     |   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |
     | 40%   54C    P8    20W / 170W |   1312MiB / 12288MiB |      2%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     
     +-----------------------------------------------------------------------------+
     | Processes:                                                                  |
     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
     |        ID   ID                                                   Usage      |
     |=============================================================================|
     |    0   N/A  N/A      1180      G   /usr/lib/xorg/Xorg                 35MiB |
     |    0   N/A  N/A      1865      G   /usr/lib/xorg/Xorg                135MiB |
     |    0   N/A  N/A      2019      G   /usr/bin/gnome-shell               66MiB |
     |    0   N/A  N/A      2480      G   /usr/lib/firefox/firefox          130MiB |
     |    0   N/A  N/A     10214      G   ...veSuggestionsOnlyOnDemand       68MiB |
     |    0   N/A  N/A     62041      C   ...3/envs/cudf/bin/python3.9      431MiB |
     |    0   N/A  N/A     65091      C   ..._playground/bin/python3.9      431MiB |
     +-----------------------------------------------------------------------------+
     
     ***CPU***
     Architecture:                    x86_64
     CPU op-mode(s):                  32-bit, 64-bit
     Byte Order:                      Little Endian
     Address sizes:                   39 bits physical, 48 bits virtual
     CPU(s):                          12
     On-line CPU(s) list:             0-11
     Thread(s) per core:              2
     Core(s) per socket:              6
     Socket(s):                       1
     NUMA node(s):                    1
     Vendor ID:                       GenuineIntel
     CPU family:                      6
     Model:                           165
     Model name:                      Intel(R) Core(TM) i5-10400F CPU @ 2.90GHz
     Stepping:                        5
     CPU MHz:                         2900.000
     CPU max MHz:                     4300.0000
     CPU min MHz:                     800.0000
     BogoMIPS:                        5799.77
     L1d cache:                       192 KiB
     L1i cache:                       192 KiB
     L2 cache:                        1.5 MiB
     L3 cache:                        12 MiB
     NUMA node0 CPU(s):               0-11
     Vulnerability Itlb multihit:     KVM: Mitigation: VMX unsupported
     Vulnerability L1tf:              Not affected
     Vulnerability Mds:               Not affected
     Vulnerability Meltdown:          Not affected
     Vulnerability Mmio stale data:   Mitigation; Clear CPU buffers; SMT vulnerable
     Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
     Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
     Vulnerability Spectre v2:        Mitigation; Enhanced IBRS, IBPB conditional, RSB filling
     Vulnerability Srbds:             Mitigation; Microcode
     Vulnerability Tsx async abort:   Not affected
     Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp pku ospke md_clear flush_l1d arch_capabilities
     
     ***CMake***
     /snap/bin/cmake
     cmake version 3.23.2
     
     CMake suite maintained and supported by Kitware (kitware.com/cmake).
     
     ***g++***
     /usr/bin/g++
     g++ (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
     Copyright (C) 2019 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
     
     
     ***nvcc***
     /usr/local/cuda-11.7/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2022 NVIDIA Corporation
     Built on Tue_May__3_18:49:52_PDT_2022
     Cuda compilation tools, release 11.7, V11.7.64
     Build cuda_11.7.r11.7/compiler.31294372_0
     
     ***Python***
     /home/honno/anaconda3/envs/cudf_playground/bin/python
     Python 3.9.13
     
     ***Environment Variables***
     PATH                            : /home/honno/anaconda3/envs/cudf_playground/bin:/home/honno/anaconda3/condabin:/usr/local/cuda-11.7/bin:/home/honno/.pyenv/shims:/home/honno/.pyenv/bin:/home/honno/go/bin:/usr/local/go/bin:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/honno/.dotnet/tools
     LD_LIBRARY_PATH                 :
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /home/honno/anaconda3/envs/cudf_playground
     PYTHON_PATH                     :
     
     ***conda packages***
     /home/honno/anaconda3/condabin/conda
     # packages in environment at /home/honno/anaconda3/envs/cudf_playground:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                       2_gnu    conda-forge
     abseil-cpp                20210324.2           h9c3ff4c_0    conda-forge
     arrow-cpp                 8.0.0           py39h2f48f8a_4_cuda    conda-forge
     arrow-cpp-proc            3.0.0                      cuda    conda-forge
     asttokens                 2.0.5                    pypi_0    pypi
     aws-c-cal                 0.5.11               h95a6274_0    conda-forge
     aws-c-common              0.6.2                h7f98852_0    conda-forge
     aws-c-event-stream        0.2.7               h3541f99_13    conda-forge
     aws-c-io                  0.10.5               hfb6a706_0    conda-forge
     aws-checksums             0.1.11               ha31a3da_7    conda-forge
     aws-sdk-cpp               1.8.186              hb4091e7_3    conda-forge
     backcall                  0.2.0                    pypi_0    pypi
     bzip2                     1.0.8                h7f98852_4    conda-forge
     c-ares                    1.18.1               h7f98852_0    conda-forge
     ca-certificates           2022.6.15            ha878542_0    conda-forge
     cachetools                5.0.0              pyhd8ed1ab_0    conda-forge
     cuda-python               11.7.0           py39h5a03fae_0    conda-forge
     cudatoolkit               11.7.0              hd8887f6_10    conda-forge
     cudf                      22.08.00a220712 cuda_11_py39_g002cb1c45b_213    rapidsai-nightly
     cupy                      10.6.0           py39hc3c280e_0    conda-forge
     decorator                 5.1.1                    pypi_0    pypi
     dlpack                    0.5                  h9c3ff4c_0    conda-forge
     executing                 0.8.3                    pypi_0    pypi
     fastavro                  1.5.2            py39hb9d737c_0    conda-forge
     fastrlock                 0.8              py39h5a03fae_2    conda-forge
     fsspec                    2022.5.0           pyhd8ed1ab_0    conda-forge
     gflags                    2.2.2             he1b5a44_1004    conda-forge
     glog                      0.6.0                h6f12383_0    conda-forge
     grpc-cpp                  1.45.2               h3b8df00_4    conda-forge
     ipython                   8.4.0                    pypi_0    pypi
     jedi                      0.18.1                   pypi_0    pypi
     keyutils                  1.6.1                h166bdaf_0    conda-forge
     krb5                      1.19.3               h3790be6_0    conda-forge
     ld_impl_linux-64          2.38                 h1181459_1
     libblas                   3.9.0           15_linux64_openblas    conda-forge
     libbrotlicommon           1.0.9                h166bdaf_7    conda-forge
     libbrotlidec              1.0.9                h166bdaf_7    conda-forge
     libbrotlienc              1.0.9                h166bdaf_7    conda-forge
     libcblas                  3.9.0           15_linux64_openblas    conda-forge
     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge
     libcudf                   22.08.00a220712 cuda11_g002cb1c45b_213    rapidsai-nightly
     libcurl                   7.83.1               h7bff187_0    conda-forge
     libedit                   3.1.20210910         h7f8727e_0
     libev                     4.33                 h516909a_1    conda-forge
     libevent                  2.1.10               h9b69904_4    conda-forge
     libffi                    3.4.2                h7f98852_5    conda-forge
     libgcc-ng                 12.1.0              h8d9b700_16    conda-forge
     libgfortran-ng            12.1.0              h69a702a_16    conda-forge
     libgfortran5              12.1.0              hdcd56e2_16    conda-forge
     libgomp                   12.1.0              h8d9b700_16    conda-forge
     libgoogle-cloud           1.40.2               habd0e3a_0    conda-forge
     liblapack                 3.9.0           15_linux64_openblas    conda-forge
     libllvm11                 11.1.0               hf817b99_3    conda-forge
     libnghttp2                1.47.0               h727a467_0    conda-forge
     libnsl                    2.0.0                h7f98852_0    conda-forge
     libopenblas               0.3.20          pthreads_h78a6416_0    conda-forge
     libprotobuf               3.20.1               h6239696_0    conda-forge
     librmm                    22.08.00a220712 cuda11_g5ac89d17_57    rapidsai-nightly
     libssh2                   1.10.0               ha56f1ee_2    conda-forge
     libstdcxx-ng              12.1.0              ha89aaad_16    conda-forge
     libthrift                 0.16.0               h519c5ea_1    conda-forge
     libutf8proc               2.7.0                h7f98852_0    conda-forge
     libuuid                   2.32.1            h7f98852_1000    conda-forge
     libzlib                   1.2.12               h166bdaf_1    conda-forge
     llvmlite                  0.38.1           py39h7d9a04d_0    conda-forge
     lz4-c                     1.9.3                h9c3ff4c_1    conda-forge
     matplotlib-inline         0.1.3                    pypi_0    pypi
     ncurses                   6.3                  h27087fc_1    conda-forge
     numba                     0.55.2           py39h66db6d7_0    conda-forge
     numpy                     1.22.4           py39hc58783e_0    conda-forge
     nvtx                      0.2.3            py39h3811e60_1    conda-forge
     openssl                   1.1.1q               h166bdaf_0    conda-forge
     orc                       1.7.5                h6c59b99_0    conda-forge
     packaging                 21.3               pyhd8ed1ab_0    conda-forge
     pandas                    1.4.3            py39h1832856_0    conda-forge
     parquet-cpp               1.5.1                         2    conda-forge
     parso                     0.8.3                    pypi_0    pypi
     pexpect                   4.8.0                    pypi_0    pypi
     pickleshare               0.7.5                    pypi_0    pypi
     pip                       22.1.2             pyhd8ed1ab_0    conda-forge
     prompt-toolkit            3.0.30                   pypi_0    pypi
     protobuf                  3.20.1           py39h5a03fae_0    conda-forge
     ptxcompiler               0.4.0            py39h1eff087_0    conda-forge
     ptyprocess                0.7.0                    pypi_0    pypi
     pure-eval                 0.2.2                    pypi_0    pypi
     pyarrow                   8.0.0           py39h1ed2e5d_4_cuda    conda-forge
     pyflakes                  2.4.0                    pypi_0    pypi
     pyflyby                   1.7.7                    pypi_0    pypi
     pygments                  2.12.0                   pypi_0    pypi
     pyparsing                 3.0.9              pyhd8ed1ab_0    conda-forge
     python                    3.9.13          h9a8a25e_0_cpython    conda-forge
     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge
     python_abi                3.9                      2_cp39    conda-forge
     pytz                      2022.1             pyhd8ed1ab_0    conda-forge
     re2                       2022.06.01           h27087fc_0    conda-forge
     readline                  8.1.2                h0f457ee_0    conda-forge
     rmm                       22.08.00a220712 cuda11_py39_g5ac89d17_57    rapidsai-nightly
     s2n                       1.0.10               h9b69904_0    conda-forge
     setuptools                63.1.0           py39hf3d152e_0    conda-forge
     six                       1.16.0             pyh6c4a22f_0    conda-forge
     snappy                    1.1.9                hbd366e4_1    conda-forge
     spdlog                    1.8.5                h4bd325d_1    conda-forge
     sqlite                    3.39.0               h4ff8645_0    conda-forge
     stack-data                0.3.0                    pypi_0    pypi
     tk                        8.6.12               h27826a3_0    conda-forge
     traitlets                 5.3.0                    pypi_0    pypi
     typing_extensions         4.3.0              pyha770c72_0    conda-forge
     tzdata                    2022a                h191b570_0    conda-forge
     wcwidth                   0.2.5                    pypi_0    pypi
     wheel                     0.37.1             pyhd8ed1ab_0    conda-forge
     xz                        5.2.5                h516909a_1    conda-forge
     zlib                      1.2.12               h166bdaf_1    conda-forge
     zstd                      1.5.2                h8a70e8d_2    conda-forge
     
</pre></details>",2022-07-20T12:49:41Z,0,0,Matthew Barber,Hexegic
102,"[BUG] Interchange `Column.describe_categorical` is a tuple, not a dict","In the [interchange protocol](https://data-apis.org/dataframe-protocol/latest/API.html), `describe_categorical` should return a dict, but cuDF returns a tuple

```python
>>> df = cudf.DataFrame({""foo"": cudf.Series([0, 1], dtype=""category"")})
>>> interchange_df = df.__dataframe__()
>>> interchange_col = interchange_df.get_column_by_name(""foo"")
>>> interchange_col.describe_categorical
(False, True, {0: 0, 1: 1})
>>> type(interchange_col.describe_categorical)
tuple  # should be dict
```

Relevant code returning a tuple as opposed to dict

https://github.com/rapidsai/cudf/blob/edc5062bdcc3e12755603b0ad07a4d271fe95261/python/cudf/cudf/core/df_protocol.py#L295

This prevents interchanging dataframes with categorical columns, e.g. with pandas
```python
>>> from pandas.api.exchange import from_dataframe
>>> from_dataframe(df)
.../pandas/core/exchange/from_dataframe.py:184, in categorical_column_to_series(col)
    169 """"""
    170 Convert a column holding categorical data to a pandas Series.
    171 
   (...)
    180     that keeps the memory alive.
    181 """"""
    182 categorical = col.describe_categorical
--> 184 if not categorical[""is_dictionary""]:
    185     raise NotImplementedError(""Non-dictionary categoricals not supported yet"")
    187 mapping = categorical[""mapping""]
TypeError: tuple indices must be integers or slices, not str
```


pandas and modin are compliant here, but interestingly vaex currently returns a tuple too https://github.com/vaexio/vaex/issues/2113",2022-07-22T09:20:25Z,0,0,Matthew Barber,Hexegic
103,[FEA] Ability to write multiple files in `to_orc` in a similar file naming pattern to that of `to_csv`,"**What is your question?**
Hello guys,

I wonder if we can rename the files when we use to_orc in dask_cudf,  such as  `ddf.to_orc('name-*.orc')`? I think we are able to do it in `ddf.to_csv()`. Thanks",2022-07-25T15:31:59Z,0,0,Cg Lai,
104,Constructing `Column` objects from `cudf::column` should always take ownership of the null mask,This came out of discussions in #11354. The current approach that `Column.from_unique_ptr` drops a reference to the `cudf::column`s `null_mask` if `null_count == 0` can result in use-after-free if there are also `column_view`s referencing the `column`. See discussion in https://github.com/rapidsai/cudf/pull/11354#discussion_r930808913,2022-07-28T08:44:43Z,0,0,Lawrence Mitchell,
105,"[BUG] Interchange `Column.dtype` returns format strings in NumPy-style, instead of Arrow-style","In the [interchange protocol](https://data-apis.org/dataframe-protocol/latest/API.html), `Column.dtype` should return an [Arrow-style](https://arrow.apache.org/docs/format/CDataInterface.html#data-type-description-format-strings) format string, but instead a NumPy-styled one is returned

```python
>>> df = cudf.DataFrame({""foo"": cudf.Series([0, 1], dtype=""int8"")})
>>> interchange_df = df.__dataframe__()
>>> interchange_col = interchange_df.get_column_by_name(""foo"")
>>> interchange_col.dtype
(<_DtypeKind.INT: 0>, 8, '|i1', '|')  # 3rd element (format string) should be ""c""
```

It looks like currently the `.str` attribute of the dtype objects (i.e. `np.dtype(...)`) is returned as-is

https://github.com/rapidsai/cudf/blob/edc5062bdcc3e12755603b0ad07a4d271fe95261/python/cudf/cudf/core/df_protocol.py#L260",2022-07-28T13:08:05Z,0,0,Matthew Barber,Hexegic
106,[FEA] Change cudf::io::detail::make_column() to have a more verbose name.,"```
std::unique_ptr<column> make_column(column_buffer& buffer,
                                    column_name_info* schema_info,
                                    rmm::cuda_stream_view stream,
                                    rmm::mr::device_memory_resource* mr)
```

This is kind of a weakly named global function.   Because its name is so generic, it doesn't play nice with users who might want to create their own, more appropriately named `make_column` that does some other work along the way.  Changing this to `column_from_column_buffer()` or `make_column_from_buffer()`, or maybe making it a member of `column_buffer` would clean things up a bit

 Eg.

```
// user function (in parquet code for example)
make_column(column_buffer &b)
{
    // random preprocessing work
    auto x = column_from_column_buffer(b);
    // random postprocessing work
}
```",2022-07-28T16:10:13Z,0,0,,
107,Investigate need for output as binary configuration option,"It is possible that the output as binary options are not necessary as mentioned in this comment. Initial testing in the course of the PR showed list tests failing when using just physical type, so more investigation is needed.

_Originally posted by @vuule in https://github.com/rapidsai/cudf/pull/11328#discussion_r932696159_",2022-07-28T21:58:26Z,0,0,Mike Wilson,
108,`schema_tree_node` needs a constructor.,"Nitpick: Looks like `schema_tree_node` needs a constructor. :]

I would've recommended aggregate initialization, but I'm not sure how appropriate it would be, since it's initializing parent members:
```suggestion
        schema_tree_node col_schema {
          .type            = Type::BYTE_ARRAY,
          .converted_type  = ConvertedType::UNKNOWN,
          .stats_dtype     = statistics_dtype::dtype_byte_array,
          .repetition_type = col_nullable ? OPTIONAL : REQUIRED,
          .name = (schema[parent_idx].name == ""list"") ? ""element"" : col_meta.get_name(),
          .parent_idx  = parent_idx,
          .leaf_column = col
        };
```

My personal preference would be to avoid construct-then-initialize. But this is purely stylistic. Please feel free to ignore.

_Originally posted by @mythrocks in https://github.com/rapidsai/cudf/pull/11328#discussion_r932746165_",2022-07-28T23:26:36Z,0,0,Mike Wilson,
109,The example in the documentation for `get_dremel_data()` seems incorrect at line#1764,"I know this isn't part of the review, but the example in the documentation for `get_dremel_data()` seems incorrect at line#1738 (now [#1764](https://github.com/rapidsai/cudf/pull/11328/files#diff-e3891cd717ca174e53dd11bbf812ad3f13034d4c1a4626ea751f05bbed8470d5R1764)):
```c++
 * Given a LIST column of type `List<List<int>>` like so:
 * ```
 * col = {
 *    [],
 *    [[], [1, 2, 3], [4, 5]],
 *    [[]]
 * }
 * ```
 * We can represent it in cudf format with two level of offsets like this:
 * ```
 * Level 0 offsets = {0, 0, 3, 5, 6}
 * Level 1 offsets = {0, 0, 3, 5, 5}
 * Values          = {1, 2, 3, 4, 5}
 * ```
```
The `Level 0` offset values can't exceed `4`, since `Level 1` has only 4 ranges (i.e. 5 offsets).
I'll try make sense of this at a later date, but I'm not sure I could follow along.

_Originally posted by @mythrocks in https://github.com/rapidsai/cudf/pull/11328#discussion_r932727013_",2022-07-28T23:27:58Z,0,0,Mike Wilson,
110,[QST] Should byte_array_view in parquet reader/writer change,"**What is your question?**
Should [`byte_array_view`](https://github.com/rapidsai/cudf/blob/branch-22.08/cpp/src/io/statistics/byte_array_view.cuh) change to a different implementation method or even go away completely.

### Motivation
When reviewing the `byte_array_view` PR it was brought up in [review comments](https://github.com/rapidsai/cudf/pull/11322#discussion_r928012252) that things could be done differently and possibly better. This issue is an attempt to bring this design out in the light and get some discourse going so we can build it the best way possible. Jake was, rightfully, concerned about the cognitive overload of having another object type that has to be understood, no matter how minimal the type turns out to be.

### Backstory and origin
The original thought was that it would be nice to leverage the existing templates in the statistics code to get elements and compute max/min just like everything else. This meant that `.element` on a column would be able to return a type that represents a `list<uint8>`. This is almost identical to a string column, so the thought was to have something analogous to `string_view` that could be used. This was quickly dismissed due to the issue of not having all list columns comprised of this thing and it felt like we were forcing something. All string columns are lists of chars, but not all list columns are lists of bytes.

### Requirements
The requirements in the statistics code are the ability to get an element from a table, compare elements, and compose an element from a pointer and a length. The statistics code goes to great length to type-erase the statistics blobs so they can be easily consumed at a large scale on the GPU and the reconstructs them later. It also uses `thrust::min` and `cub::reduceBlock` to process them, so comparison operators are needed.

### Slippery issues to understand
We can't use the same statistics types as strings because `string_view::max()` is actually not the same as a max byte or a max `byte_array_view`. The distinction is subtle, but important between all of them.

- The max UTF8 string is actually just 5 bytes long and [defined inside the `string_view` header](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/include/cudf/strings/string_view.cuh#L75). No UTF8 string can have a higher value, so comparisons work even though it isn't an infinitely-long character string as one would initially think.
- Maximum value for an unsigned byte is obviously 255, but this isn't the what is intended when one asks for the max byte array view. Instead, the goal is to know the ""biggest"" one. This includes the length and the internal bytes. `0xff, 0x05` is less than `0xff, 0x15` and `0xff` is less than `0x00, 0x00`.
- Maximum `byte_array_view` is defined conceptually as an infinite array of 0xff. This isn't possible to statically define for comparison like the `string_view` class, so some [magic values](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/statistics/byte_array_view.cuh#L173) were used of a nullptr and max length. These then have to be [explicitly compared](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/statistics/byte_array_view.cuh#L101) later in the comparison function to achieve the proper results.

Lots of places required special handling for `byte_array_view` and potentially get worse with the different possible solutions. The goal of course is to make these areas as clean as possible, so I thought it would be good to point some of them out here.

 - [Here](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/statistics/column_statistics.cuh#L115) is where the code grabs the data from the column. There is conversion in here for types, which is used for things like duration and timestamps. Originally it was thought this could be a good spot to convert from a `list_view`, which can be returned from `.element` calls on a list column. This didn't end up being a great solution, but I can't remember the details.
 - min/max calculations and block reduce happens down in [typed_statistics_chunk](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/statistics/typed_statistics_chunk.cuh#L207). This code is responsible for figuring out min, max, null counts, and aggregations like sum. It has to pick up this new type and operate on it.
 - Actual data writing in parquet looks [something like this](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/parquet/page_enc.cu#L1094) where an element is grabbed and written into place.

### Possible solutions
1. Use `device_span` directly. This requires passing comparison functions to cub and thrust for the calculations, but is completely doable. This was [attempted](https://github.com/hyperbolic2346/cudf/tree/mwilson/test_byte_array_view_removal), potentially poorly, with not great looking results.
2. Composition vs inheritance. This came up multiple times as to why it was built with composition, holding a `device_span` inside, vs inheriting from `device_span` either publicly or privately. There isn't a great answer here to argue against inheritance. I originally thought that this would be a very small subset of `device_span` and I didn't want to muddy the waters with all the accessors and iterators, but after further inspection, I don't see anything that I would want to remove from `device_span`, so this would be a viable path. It does still hold the issue of cognitive overload of yet another type someone encounters.
3. Continues to live on as it is now.
4. Your amazing idea that didn't come up in development or review.",2022-07-29T21:19:39Z,0,0,Mike Wilson,
111,[FEA] ClusterfuzzLite integration,"**Is your feature request related to a problem? Please describe.**
cuDF has an extensive fuzzing suite that could benefit the project by running in the CI.

**Describe the solution you'd like**
In this issue I suggest [ClusterfuzzLite](https://google.github.io/clusterfuzzlite/) integration for cuDF. This would require:

1. Adding a `.github/workflows/cflite.yml` file.
2. Adding a .clusterfuzzlite directory with build files.
3. Rewriting the fuzzers into coverage-guided fuzzers via [Atheris](https://github.com/google/atheris).

**Describe alternatives you've considered**


**Additional context**
ClusterfuzzLite handles the management of running fuzzers in the CI when PRs are made. It has a number of features that are useful for projects with multiple fuzzers:

1. CFL reuses corpus so that the fuzzers don't start from scratch every run.
2. [Batch fuzzing](https://google.github.io/clusterfuzzlite/running-clusterfuzzlite/github-actions/#batch-fuzzing) will run the fuzzers periodically to look for harder-to-find bugs and build of the corpus.
3. Only fuzzers that cover code that is changed in PRs run in the CI.

I will be glad to take the lead on this one if it is of interest to cuDF.
",2022-08-01T11:07:28Z,0,0,,Adam@adalogics.com
112,[BUG] Multiple DataFrame.loc operations gives confusing error message upon compute on Dask-cuDF,"**Describe the bug**
After creating a Dask-cuDF data frame, if I perform multiple .loc operations on it using boolean Dask-cuDF series, then when I compute the data frame, it produces a runtime error with the message `cuDF failure at: ../src/stream_compaction/apply_boolean_mask.cu:73: Column size mismatch`. A similar snippet works as expected on cuDF.

**Steps/Code to reproduce bug**
```python
import dask_cudf
import cudf
ddf1 = dask_cudf.from_cudf(cudf.DataFrame({'a':[1,2,3], 'b':[4,5,6]}), npartitions=2)
f1 = dask_cudf.from_cudf(cudf.Series([False, True, True]), npartitions=2)
f2 = dask_cudf.from_cudf(cudf.Series([True, False]), npartitions=2)
ddf2 = ddf1.loc[f1]
ddf3 = ddf2.loc[f2]
print(ddf2.compute())
print(ddf3.compute())
```
The above code produces the following output:
```
   a  b                        
1  2  5
2  3  6                                                       
Traceback (most recent call last):     
  File ""temp.py"", line 9, in <module>
    print(ddf3.compute())
  File ""/opt/conda/lib/python3.8/site-packages/dask/base.py"", line 292, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File ""/opt/conda/lib/python3.8/site-packages/dask/base.py"", line 575, in compute
    results = schedule(dsk, keys, **kwargs)    
  File ""/opt/conda/lib/python3.8/site-packages/dask/local.py"", line 554, in get_sync
    return get_async(                                         
  File ""/opt/conda/lib/python3.8/site-packages/dask/local.py"", line 497, in get_async                                       
    for key, res_info, failed in queue_get(queue).result():
  File ""/opt/conda/lib/python3.8/concurrent/futures/_base.py"", line 437, in result
    return self.__get_result()
  File ""/opt/conda/lib/python3.8/concurrent/futures/_base.py"", line 389, in __get_result
    raise self._exception
  File ""/opt/conda/lib/python3.8/site-packages/dask/local.py"", line 539, in submit
    fut.set_result(fn(*args, **kwargs))
  File ""/opt/conda/lib/python3.8/site-packages/dask/local.py"", line 235, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File ""/opt/conda/lib/python3.8/site-packages/dask/local.py"", line 235, in <listcomp>
    return [execute_task(*a) for a in it]
  File ""/opt/conda/lib/python3.8/site-packages/dask/local.py"", line 226, in execute_task
    result = pack_exception(e, dumps)
  File ""/opt/conda/lib/python3.8/site-packages/dask/local.py"", line 221, in execute_task
    result = _execute_task(task, data)
  File ""/opt/conda/lib/python3.8/site-packages/dask/core.py"", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File ""/opt/conda/lib/python3.8/site-packages/dask/optimization.py"", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File ""/opt/conda/lib/python3.8/site-packages/dask/core.py"", line 149, in get
    result = _execute_task(task, cache)
  File ""/opt/conda/lib/python3.8/site-packages/dask/core.py"", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File ""/opt/conda/lib/python3.8/site-packages/dask/utils.py"", line 39, in apply
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.8/site-packages/dask/dataframe/core.py"", line 6330, in apply_and_enforce
    df = func(*args, **kwargs)
  File ""/opt/conda/lib/python3.8/site-packages/dask/dataframe/methods.py"", line 37, in loc
    return df.loc[iindexer]
  File ""/opt/conda/lib/python3.8/site-packages/cudf/core/dataframe.py"", line 127, in __getitem__
    return self._getitem_tuple_arg(arg)
  File ""/opt/conda/lib/python3.8/site-packages/nvtx/nvtx.py"", line 101, in inner
    result = func(*args, **kwargs)
  File ""/opt/conda/lib/python3.8/site-packages/cudf/core/dataframe.py"", line 267, in _getitem_tuple_arg
    df = columns_df._apply_boolean_mask(tmp_arg[0])
  File ""/opt/conda/lib/python3.8/site-packages/cudf/core/indexed_frame.py"", line 1696, in _apply_boolean_mask
    libcudf.stream_compaction.apply_boolean_mask(
  File ""cudf/_lib/stream_compaction.pyx"", line 101, in cudf._lib.stream_compaction.apply_boolean_mask
RuntimeError: cuDF failure at: ../src/stream_compaction/apply_boolean_mask.cu:73: Column size mismatch
```

**Expected behavior**
Expected output (verified with cudf instead of dask-cudf):
```
   a  b
1  2  5
2  3  6
   a  b
1  2  5
```

**Environment overview (please complete the following information)**
 - Environment location: Docker
 - Method of cuDF install: Docker
   - `docker run -it --rm --gpus all --ipc=host --network=host -v .`

**Environment details**
cuDF version 22.4.0a0+306.g0cb75a4913",2022-08-02T17:46:45Z,0,0,Alex Xu,
113,Need an address alignment utility function in cudf,"As found in review of code, there are alignment functions scattered around. We should have a single device-accessible alignment function that everything uses instead of doing the bit operations themselves or having a static local function for it.

_Originally posted by @etseidl in https://github.com/rapidsai/cudf/pull/11403#discussion_r938132622_",2022-08-04T18:44:25Z,0,0,Mike Wilson,
114,[FEA] Support nested struct columns in ORC fuzz tests,"**Is your feature request related to a problem? Please describe.**
Fuzz testing support for nested struct columns in Orc is incomplete. Some patches were required as shown in #9395 discussion (https://github.com/rapidsai/cudf/issues/9395#issuecomment-1206776202.)

**Describe the solution you'd like**
Add support for nested struct columns in the Orc fuzz testing

**Describe alternatives you've considered**
Adhoc patches that bring side-effects to other fuzzers and unit tests in cuDF.

**Additional context**
We would benefit from a way to limit the overall depth of the generated struct columns - I propose maximum nesting depth of 256. Setting `max_structs_nesting_depth` in the `IOFuzz` class does not seem sufficient to address this limit. Here is a traceback for the recursion error:
```
  File ""/home/gregorykimball/Repo/cudf/python/cudf/cudf/testing/dataset_generator.py"", line 387, in rand_dataframe
    structDtype = create_nested_struct_type(
...
  File ""/home/gregorykimball/Repo/rapids-compose/etc/conda/cuda_11.5/envs/rapids/lib/python3.8/site-packages/numpy/core/fromnumeric.py"", line 70, in _wrapreduction
    passkwargs = {k: v for k, v in kwargs.items()
RecursionError: maximum recursion depth exceeded while calling a Python object

```
",2022-08-05T19:11:48Z,1,0,Gregory Kimball,
115,[BUG] Some custom dask aggregations fail with dask_cudf dataframes,"**Describe the bug**
Some dask custom aggregations (ex: a custom sum of squares aggregation) fail with dask_cudf.

**Steps/Code to reproduce bug**
```
import cudf
import dask_cudf
import dask.dataframe as dd

df = cudf.DataFrame({""a"":[1,2,3], ""b"":[1,1,2]})
ddf = dask_cudf.from_cudf(df, npartitions=1)

sum_of_squares = dd.Aggregation(
    name='sum_of_squares',
    chunk=lambda s: s.agg(lambda x: (x**2).sum()),
    agg=lambda s0: s0.sum()
)

ddf.groupby(""b"").agg(sum_of_squares).compute()
```
returns:
```
TypeError: unsupported operand type(s) for ** or pow(): 'type' and 'int'
```
however when running with a pandas backed dask dataframe:
```
ddf.to_dask_dataframe().groupby(""b"").agg(sum_of_squares).compute()
```
the expected result is returned:
```
   a
b   
1  5
2  9
​
```

cc: @randerzander 
",2022-08-11T16:04:18Z,0,0,,
116,"[PERF] Improve ""isin"" performance by only sorting once","**Is your feature request related to a problem? Please describe.**
While benchmarking cuDF-python, I noticed that [bench_isin](https://github.com/rapidsai/cudf/blob/65a782112f4b76941483adf17f9a30a6824f6164/python/cudf/benchmarks/API/bench_dataframe.py#L50) has low end-to-end data throughput (<10GB/s). A closer look at the profiles showed that the data is being sorted twice, first with `.sort_values()` and then as part of `drop_duplicates()`. The following profile is for a test dataframe with 1 col and 100K rows, and is uses the `isin` argument `range(1000)` in the `bench_isin` benchmark.

<img width=""851"" alt=""image"" src=""https://user-images.githubusercontent.com/12725111/185016040-8c8b70ab-a8fd-4cc5-8294-2fb9ea5acc5e.png"">

When calling `isin` with a dataframe or dict argument, the profile shows two calls to `Frame.argsort`.

<img width=""841"" alt=""image"" src=""https://user-images.githubusercontent.com/12725111/185018010-a4e5789e-cf0a-4a7f-8291-a9fdd52adbbe.png"">





**Describe the solution you'd like**
For a performance improvement, I'd like to refactor `isin` to only sort the data once. We should prefer the libcudf `unique` function to `drop_duplicates` for pre-sorted data.

**Describe alternatives you've considered**
n/a

**Additional context**
Add any other context, code examples, or references to existing implementations about the feature request here.
",2022-08-17T01:48:17Z,0,0,Gregory Kimball,
117,"[DOC] `.mode()` incorrectly states that axis=1 is supported as it throws ""NotImplementedError"" when you try","## Report incorrect documentation

**Location of incorrect documentation**
https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.mode.html?highlight=mode#cudf.DataFrame.mode

**Describe the problems or issues found in the documentation**
Documentation says that mode can be applied over columns (axis = 0) or rows (axis = 1), but when trying axis = 1, it says `Only axis=0 is currently supported`

**Steps taken to verify documentation is incorrect**

```
import cudf
df = cudf.DataFrame(np.random.randint(0,5,size=(15, 10)), columns=list('ABCDEFGHIJ'))
df.mode(axis=1)
```
Stack trace
```
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
/tmp/ipykernel_2243/3323872345.py in <module>
----> 1 df.mode(axis=1)

/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)
     73         def inner(*args, **kwds):
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner
     77 

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in mode(self, axis, numeric_only, dropna)
   5678         """"""
   5679         if axis not in (0, ""index""):
-> 5680             raise NotImplementedError(""Only axis=0 is currently supported"")
   5681 
   5682         if numeric_only:

NotImplementedError: Only axis=0 is currently supported
```
**Suggested fix for documentation**
Either 
1. state that axis = 1 is not supported
2. remove references for axis = 1 in docs
3. add the functionality
",2022-08-19T15:42:58Z,0,0,Taurean Dyer,
118,[ENH] More type-stubs in the mypy pre-commit environment?,"Following on from #11640 (specifically https://github.com/rapidsai/cudf/pull/11640#discussion_r961551760) a question arises as to how complete we should make the mypy pre-commit environment in terms of supported typestubs.

Status quo:

The version of mypy installed via pre-commit only depends on the stdlib typeshed stubs (and after #11640 `types-cachetools`). We set `ignore_missing_imports = True` which means that mypy doesn't complain if it sees an import for something (say numpy) that it can't find. Consequently, any non-importable modules are typed as `Any` (as are all objects, methods, functions, etc... from that module); this is a type that always satisfies any type constraint.

In the development environment, all cudf modules _are_ importable, and so a type-checking run using that environment will deduce narrower types for many function calls in cudf. Many of these currently do not type-check, being of the following form: https://mypy-play.net/?mypy=latest&python=3.10&gist=8d3ba6046bb8ca39c6d6b71b442b432c
```python
from typing import Any

def foo(x: Any) -> Any:
    if isinstance(x, bool):
        y = x
    elif isinstance(x, int):
        y = (True, x)
    else:
        y = x

    return y
```

mypy complains about the assignment `y = (True, x)` ""error: Incompatible types in assignment (expression has type ""Tuple[bool, int]"", variable has type ""bool"")"" because it deduces the type of `y` from the first assignment as `bool`.

There are various places in the codebase where we do this kind of untagged union dispatch, this could be fixed by explicitly typing all the variables as `Union[a, b, c, ...]` but I am not sure that in the end it would be worth it. If we install `numpy` and the `pandas-stubs` package (which provides type stubs for pandas) then we get about 120 errors of this nature.

I think that fixing these things is rather difficult, the right approach is to use tagged unions, but there's no support for that in python and any workaround would (I think) make the code unnecessarily non-idiomatic.

If we think it's worthwhile pursuing this, I can prepare a draft patch for some of the uncovered typing issues so we can discuss more concretely.",2022-09-07T13:15:29Z,0,0,Lawrence Mitchell,
119,[FEA] `read_csv` context-passing interface for distributed/segmented parsing,"**Is your feature request related to a problem? Please describe.**
To parse files from a regular language like CSV, we can only safely parse data inside a byte range if we know the parsing context from before this range. Without this information, we may accidentally interpret a record delimiter (newline) inside a quoted field as an actual delimiter.

More formally, when starting from a byte range, we don't know what state the DFA of the token language is in, so we need to store the transition vector starting from every possible state, and combine the vectors by function composition in the associative scan operation. This is pretty much identical to what is happening in [the finite state transducer](https://github.com/rapidsai/cudf/pull/11242).

Instead of just running the scan on a full file, we can run it only on a byte range, and combine the resulting transition vectors in an exclusive scan over all byte ranges to establish local parsing context.

**Describe the solution you'd like**
I want to propose a slight extension to the `read_csv` interface to handle this case:

1. add a `class csv_parse_context` that opaquely wraps `packed_rowctx_t`, only exposing the `merge_row_contexts` functionality to combine the parsing context from adjacent byte ranges, and a `finalize` operation that turns the transition vector into its value starting from the initial DFA state.
2. add a `read_csv_context` function that only scans the local byte range to compute its `csv_parse_context` transition vector. It can probably take the same parameters as `read_csv`
3. add a `csv_parse_context initial_parsing_state` parameter to `csv_reader_options` that defaults to the initial state. The `read_csv` function can then use this initial state to determine record offsets and do the actual parsing.

**Describe alternatives you've considered**
Alternatively, we could implement backtracking by reading chunks before the byte range until we figured out an unambiguous parser state (that is not the error state). This could in the worst case lead to reading the entire prefix up to the byte range.

**Additional context**
This is relevant if we want `dask.read_csv` to be able to handle quoted record delimiters (i.e. newlines) where the opening quote occurs before the byte range.

The interface has the advantage that it can be tested in isolation on a single node, without having to rely on dask.

The same kind of pattern could also apply to `read_json`, where on top of the regular parsing state, we also need to pass the stack transition operations from the beginning to the end of the byte range.
",2022-09-21T10:22:51Z,0,0,Tobias Ribizel,
120,[FEA] Support New Median / Median-Approximate in Dask-cuDF,"In https://github.com/dask/dask/pull/9483 Dask now has an implementation of `median` and `median_approximate`.  These should available with dask_cudf.  cuDF currently raise a NotImplementedError with `mean(axis=1)`:


```python
cdf = cudf.datasets.timeseries()
cdf = dd.from_pandas(cdf, npartitions=2)
cdf.median(axis=1).compute()

File /datasets/bzaitlen/miniconda3/envs/tpcds-20220906/lib/python3.9/site-packages/cudf/core/dataframe.py:5225, in DataFrame.quantile(self, q, axis, numeric_only, interpolation, columns, exact)
   5164 """"""
   5165 Return values at the given quantile.
   5166
   (...)
   5222 0.5  2.5  55.0
   5223 """"""  # noqa: E501
   5224 if axis not in (0, None):
-> 5225     raise NotImplementedError(""axis is not implemented yet"")
   5227 data_df = self
   5228 if numeric_only:
```

As for `mean_approximate`, ValueError is thrown unexpectedly:


```python
In [32]: cdf.compute()
Out[32]:
   x    y
0  1  1.1
1  2  2.2
2  3  3.3
3  4  4.4
4  5  5.5

In [33]: cdf.median_approximate().compute()
...
File /datasets/bzaitlen/miniconda3/envs/tpcds-20220906/lib/python3.9/site-packages/cudf/core/frame.py:898, in Frame.fillna(self, value, method, axis, inplace, limit)
    892 should_fill = (
    893     col_name in value
    894     and col.contains_na_entries
    895     and not libcudf.scalar._is_null_host_scalar(replace_val)
    896 ) or method is not None
    897 if should_fill:
--> 898     filled_data[col_name] = col.fillna(replace_val, method)
    899 else:
    900     filled_data[col_name] = col.copy(deep=True)

File /datasets/bzaitlen/miniconda3/envs/tpcds-20220906/lib/python3.9/site-packages/cudf/core/column/numerical.py:503, in NumericalColumn.fillna(self, fill_value, method, dtype, fill_nan)
    499     return super(NumericalColumn, col).fillna(fill_value, method)
    501 if np.isscalar(fill_value):
    502     # cast safely to the same dtype as self
--> 503     fill_value_casted = col.dtype.type(fill_value)
    504     if not np.isnan(fill_value) and (fill_value_casted != fill_value):
    505         raise TypeError(
    506             f""Cannot safely cast non-equivalent ""
    507             f""{type(fill_value).__name__} to {col.dtype.name}""
    508         )

ValueError: cannot convert float NaN to integer
```",2022-09-21T13:47:13Z,0,0,Benjamin Zaitlen,
121,[FEA] Support passing scalar string args to string_udfs,"Using the newly merged strings_udf support, I'm trying to pass scalar arguments to a string UDF:
```
import cudf

df = cudf.DataFrame({""str_col"": [""a"", ""abb"", ""abc""]})

def delim_count(row, delim):
    return row[""str_col""].count(delim)

df.apply(delim_count, args=(""b"",), axis=1)
```

But I get udf compilation failed errors.

Trace:
```
---------------------------------------------------------------------------
NumbaNotImplementedError                  Traceback (most recent call last)
/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in cast(self, builder, val, fromty, toty)
    711         try:
--> 712             impl = self._casts.find((fromty, toty))
    713             return impl(self, builder, fromty, toty, val)

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in find(self, sig)
     48         if out is None:
---> 49             out = self._find(sig)
     50             self._cache[sig] = out

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in _find(self, sig)
     57         else:
---> 58             raise errors.NumbaNotImplementedError(f'{self}, {sig}')
     59 

NumbaNotImplementedError: <numba.core.base.OverloadSelector object at 0x7f2498b3aca0>, (unicode_type, string_view)

During handling of the above exception, another exception occurred:

NumbaNotImplementedError                  Traceback (most recent call last)
/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in cast(self, builder, val, fromty, toty)
    712             impl = self._casts.find((fromty, toty))
--> 713             return impl(self, builder, fromty, toty, val)
    714         except errors.NumbaNotImplementedError:

/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/udf/masked_lowering.py in cast_primitive_to_masked(context, builder, fromty, toty, val)
    336 def cast_primitive_to_masked(context, builder, fromty, toty, val):
--> 337     casted = context.cast(builder, val, fromty, toty.value_type)
    338     ext = cgutils.create_struct_proxy(toty)(context, builder)

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in cast(self, builder, val, fromty, toty)
    714         except errors.NumbaNotImplementedError:
--> 715             raise errors.NumbaNotImplementedError(
    716                 ""Cannot cast %s to %s: %s"" % (fromty, toty, val))

NumbaNotImplementedError: Cannot cast unicode_type to string_view: %""inserted.parent"" = insertvalue {i8*, i64, i32, i32, i64, i8*, i8*} %""inserted.meminfo"", i8* %""arg.delim.6"", 6

During handling of the above exception, another exception occurred:

NumbaNotImplementedError                  Traceback (most recent call last)
/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/indexed_frame.py in _apply(self, func, kernel_getter, *args, **kwargs)
   1817         try:
-> 1818             kernel, retty = _compile_or_get(
   1819                 self, func, args, kernel_getter=kernel_getter

/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)
     78             with self._recreate_cm():
---> 79                 return func(*args, **kwds)
     80         return inner

/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/udf/utils.py in _compile_or_get(frame, func, args, kernel_getter)
    214 
--> 215     kernel, scalar_return_type = kernel_getter(frame, func, args)
    216     np_return_type = numpy_support.as_dtype(scalar_return_type)

/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/udf/row_function.py in _get_row_kernel(frame, func, args)
    132     )
--> 133     scalar_return_type = _get_udf_return_type(row_type, func, args)
    134     # this is the signature for the final full kernel compilation

/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)
     78             with self._recreate_cm():
---> 79                 return func(*args, **kwds)
     80         return inner

/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/udf/utils.py in _get_udf_return_type(argty, func, args)
     55     # needed here.
---> 56     ptx, output_type = cudautils.compile_udf(func, compile_sig)
     57     if not isinstance(output_type, MaskedType):

/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/utils/cudautils.py in compile_udf(udf, type_signature)
    249     # compilation with Numba
--> 250     ptx_code, return_type = cuda.compile_ptx_for_current_device(
    251         udf, type_signature, device=True

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/cuda/compiler.py in compile_ptx_for_current_device(pyfunc, args, debug, lineinfo, device, fastmath, opt)
    289     cc = get_current_device().compute_capability
--> 290     return compile_ptx(pyfunc, args, debug=debug, lineinfo=lineinfo,
    291                        device=device, fastmath=fastmath, cc=cc, opt=True)

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)
     34             with self:
---> 35                 return func(*args, **kwargs)
     36         return _acquire_compile_lock

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/cuda/compiler.py in compile_ptx(pyfunc, args, debug, lineinfo, device, fastmath, cc, opt)
    266 
--> 267     cres = compile_cuda(pyfunc, None, args, debug=debug, lineinfo=lineinfo,
    268                         nvvm_options=nvvm_options)

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)
     34             with self:
---> 35                 return func(*args, **kwargs)
     36         return _acquire_compile_lock

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/cuda/compiler.py in compile_cuda(pyfunc, return_type, args, debug, lineinfo, inline, fastmath, nvvm_options)
    201     # Run compilation pipeline
--> 202     cres = compiler.compile_extra(typingctx=typingctx,
    203                                   targetctx=targetctx,

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)
    692                               args, return_type, flags, locals)
--> 693     return pipeline.compile_extra(func)
    694 

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func)
    428         self.state.lifted_from = None
--> 429         return self._compile_bytecode()
    430 

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self)
    496         assert self.state.func_ir is None
--> 497         return self._compile_core()
    498 

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self)
    475                     if is_final_pipeline:
--> 476                         raise e
    477             else:

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self)
    462                 try:
--> 463                     pm.run(self.state)
    464                     if self.state.cr is not None:

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state)
    352                 patched_exception = self._patch_error(msg, e)
--> 353                 raise patched_exception
    354 

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state)
    340                 if isinstance(pass_inst, CompilerPass):
--> 341                     self._runPass(idx, pass_inst, state)
    342                 else:

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)
     34             with self:
---> 35                 return func(*args, **kwargs)
     36         return _acquire_compile_lock

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state)
    295         with SimpleTimer() as pass_time:
--> 296             mutated |= check(pss.run_pass, internal_state)
    297         with SimpleTimer() as finalize_time:

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state)
    268         def check(func, compiler_state):
--> 269             mangled = func(compiler_state)
    270             if mangled not in (True, False):

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state)
    393                                        metadata=metadata)
--> 394                 lower.lower()
    395                 if not flags.no_cpython_wrapper:

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower(self)
    195             self.genlower = None
--> 196             self.lower_normal_function(self.fndesc)
    197         else:

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc)
    249         self.extract_function_arguments()
--> 250         entry_block_tail = self.lower_function_body()
    251 

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_function_body(self)
    278             self.builder.position_at_end(bb)
--> 279             self.lower_block(block)
    280         self.post_lower()

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_block(self, block)
    292                                    loc=self.loc, errcls_=defaulterrcls):
--> 293                 self.lower_inst(inst)
    294         self.post_block(block)

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_inst(self, inst)
    437             ty = self.typeof(inst.target.name)
--> 438             val = self.lower_assign(ty, inst)
    439             argidx = None

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_assign(self, ty, inst)
    623         elif isinstance(value, ir.Expr):
--> 624             return self.lower_expr(ty, value)
    625 

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_expr(self, resty, expr)
   1158         elif expr.op == 'call':
-> 1159             res = self.lower_call(resty, expr)
   1160             return res

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_call(self, resty, expr)
    888         else:
--> 889             res = self._lower_call_normal(fnty, expr, signature)
    890 

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in _lower_call_normal(self, fnty, expr, signature)
   1111         else:
-> 1112             argvals = self.fold_call_args(
   1113                 fnty, signature, expr.args, expr.vararg, expr.kws,

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in fold_call_args(self, fnty, signature, pos_args, vararg, kw_args)
    810                                           ""when calling %s"" % (fnty,))
--> 811             argvals = [self._cast_var(var, sigty)
    812                        for var, sigty in zip(pos_args, signature.args)]

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in <listcomp>(.0)
    810                                           ""when calling %s"" % (fnty,))
--> 811             argvals = [self._cast_var(var, sigty)
    812                        for var, sigty in zip(pos_args, signature.args)]

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in _cast_var(self, var, ty)
    793             val = self.loadvar(var.name)
--> 794         return self.context.cast(self.builder, val, varty, ty)
    795 

/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in cast(self, builder, val, fromty, toty)
    714         except errors.NumbaNotImplementedError:
--> 715             raise errors.NumbaNotImplementedError(
    716                 ""Cannot cast %s to %s: %s"" % (fromty, toty, val))

NumbaNotImplementedError: Failed in cuda mode pipeline (step: native lowering)
Cannot cast unicode_type to Masked(string_view): %""inserted.parent"" = insertvalue {i8*, i64, i32, i32, i64, i8*, i8*} %""inserted.meminfo"", i8* %""arg.delim.6"", 6
During: lowering ""$12call_method.5 = call $8load_method.3(delim, func=$8load_method.3, args=[Var(delim, 3005899295.py:6)], kws=(), vararg=None, target=None)"" at /tmp/ipykernel_2334/3005899295.py (6)

The above exception was the direct cause of the following exception:

ValueError                                Traceback (most recent call last)
/tmp/ipykernel_2334/3005899295.py in <module>
      6     return row[""str_col""].count(delim)
      7 
----> 8 df.apply(delim_count, args=(""b"",), axis=1)

/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)
     77         def inner(*args, **kwds):
     78             with self._recreate_cm():
---> 79                 return func(*args, **kwds)
     80         return inner
     81 

/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py in apply(self, func, axis, raw, result_type, args, **kwargs)
   4089             raise ValueError(""The `result_type` kwarg is not yet supported."")
   4090 
-> 4091         return self._apply(func, _get_row_kernel, *args, **kwargs)
   4092 
   4093     def applymap(

/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)
     77         def inner(*args, **kwds):
     78             with self._recreate_cm():
---> 79                 return func(*args, **kwds)
     80         return inner
     81 

/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/indexed_frame.py in _apply(self, func, kernel_getter, *args, **kwargs)
   1820             )
   1821         except Exception as e:
-> 1822             raise ValueError(
   1823                 ""user defined function compilation failed.""
   1824             ) from e

ValueError: user defined function compilation failed.
```

numba version: '0.55.2'
cudf version: '22.10.00a+242.g387c5ff96d' (built from source)

cc @brandon-b-miller ",2022-09-21T16:17:00Z,0,0,Randy Gelhausen,
122,[BUG] Grouping by a nonexistent key gives `ValueError` rather than `KeyError`,"I would expect the code below to raise a `KeyError`, but it raises a `ValueError` instead:

```python
>>> import cudf
>>> df = cudf.DataFrame({'a': [1, 1, 2], 'b': [1, 2, 3]})
>>> df.groupby('cd').sum() 
...
ValueError: Grouper and object must have same length
```",2022-09-27T18:15:34Z,0,0,Ashwin Srinath,Voltron Data
123,"[FEA] Parquet reader code cleanup, re:  nested columns vs columns with lists.","In the parquet reader there are two similar-sounding but distinct pieces of terminology:

- Nested columns.  This is the same as in the cudf sense.  Anything involving structs or lists at any level.
- Nested hierarchies.  This only involves columns (or _parts_ of columns) that contain lists (represented via repetition levels).

This causes confusion and bugs for a couple of reasons. A given (cudf) output column can contain both nested and non-nested hierarchies.  For example:
```
         A (struct)
       /   \
      B     C (list)
            |
            D (int)
```
This single output column contains two separate input column hierarchies.  A->B and A->C->D.  A->B does not contain repetition data and therefore is not a nested hierarchy.  A->C->D does contain repetition data and does constitute a nested hierarchy.  However they are _both_ nested in the cudf sense (more than 1 level deep).

We handle these two fundamental situations differently during the decoding process.  So if the two concepts get confused it can easily cause bugs.   

It would be great to do a pass that cleans this up in a comprehensive way.

",2022-09-27T19:07:05Z,0,0,,
124,[BUG] sort_values on categorical column fails in dask_cudf,"**Describe the bug**
`ddf.sort_values(col)` does not work with a `dask_cudf` DataFrame when `col` is categorical.

**Steps/Code to reproduce bug**
```python
import cudf
import dask_cudf
df = cudf.DataFrame({""a"": list(""caba""), ""b"": list(range(4))})
df[""a""] = df[""a""].astype(""category"")
ddf = dask_cudf.from_cudf(df, npartitions=2)
df.sort_values(""a"")  # <-- works as expected
ddf.sort_values(""a"")  # raises
```
<details>
<summary>Traceback</summary>

```python-traceback
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In [7], line 1
----> 1 ddf.sort_values(""a"")

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/dask_cudf/core.py:256, in DataFrame.sort_values(self, by, ignore_index, max_branch, divisions, set_divisions, ascending, na_position, sort_function, sort_function_kwargs, **kwargs)
    251 if kwargs:
    252     raise ValueError(
    253         f""Unsupported input arguments passed : {list(kwargs.keys())}""
    254     )
--> 256 df = sorting.sort_values(
    257     self,
    258     by,
    259     max_branch=max_branch,
    260     divisions=divisions,
    261     set_divisions=set_divisions,
    262     ignore_index=ignore_index,
    263     ascending=ascending,
    264     na_position=na_position,
    265     sort_function=sort_function,
    266     sort_function_kwargs=sort_function_kwargs,
    267 )
    269 if ignore_index:
    270     return df.reset_index(drop=True)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/dask_cudf/sorting.py:266, in sort_values(df, by, max_branch, divisions, set_divisions, ignore_index, ascending, na_position, sort_function, sort_function_kwargs)
    264 # Step 1 - Calculate new divisions (if necessary)
    265 if divisions is None:
--> 266     divisions = quantile_divisions(df, by, npartitions)
    268 # Step 2 - Perform repartitioning shuffle
    269 meta = df._meta._constructor_sliced([0])

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/dask_cudf/sorting.py:213, in quantile_divisions(df, by, npartitions)
    211 dtype = df[col].dtype
    212 if dtype != ""object"":
--> 213     divisions[col] = divisions[col].astype(""int64"")
    214     divisions[col].iloc[-1] += 1
    215     divisions[col] = divisions[col].astype(dtype)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/series.py:1857, in Series.astype(self, dtype, copy, errors, **kwargs)
   1855 else:
   1856     dtype = {self.name: dtype}
-> 1857 return super().astype(dtype, copy, errors, **kwargs)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/indexed_frame.py:3264, in IndexedFrame.astype(self, dtype, copy, errors, **kwargs)
   3262 except Exception as e:
   3263     if errors == ""raise"":
-> 3264         raise e
   3265     return self
   3267 return self._from_data(data, index=self._index)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/indexed_frame.py:3261, in IndexedFrame.astype(self, dtype, copy, errors, **kwargs)
   3258     raise ValueError(""invalid error value specified"")
   3260 try:
-> 3261     data = super().astype(dtype, copy, **kwargs)
   3262 except Exception as e:
   3263     if errors == ""raise"":

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/frame.py:328, in Frame.astype(self, dtype, copy, **kwargs)
    326 dt = dtype.get(col_name, col.dtype)
    327 if not is_dtype_equal(dt, col.dtype):
--> 328     result[col_name] = col.astype(dt, copy=copy, **kwargs)
    329 else:
    330     result[col_name] = col.copy() if copy else col

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/column/column.py:857, in ColumnBase.astype(self, dtype, **kwargs)
    851 dtype = (
    852     pandas_dtypes_alias_to_cudf_alias.get(dtype, dtype)
    853     if isinstance(dtype, str)
    854     else pandas_dtypes_to_np_dtypes.get(dtype, dtype)
    855 )
    856 if _is_non_decimal_numeric_dtype(dtype):
--> 857     return self.as_numerical_column(dtype, **kwargs)
    858 elif is_categorical_dtype(dtype):
    859     return self.as_categorical_column(dtype, **kwargs)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/column/categorical.py:1236, in CategoricalColumn.as_numerical_column(self, dtype, **kwargs)
   1235 def as_numerical_column(self, dtype: Dtype, **kwargs) -> NumericalColumn:
-> 1236     return self._get_decategorized_column().as_numerical_column(dtype)

File ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/column/string.py:5312, in StringColumn.as_numerical_column(self, dtype, **kwargs)
   5310 if out_dtype.kind in {""i"", ""u""}:
   5311     if not libstrings.is_integer(string_col).all():
-> 5312         raise ValueError(
   5313             ""Could not convert strings to integer ""
   5314             ""type due to presence of non-integer values.""
   5315         )
   5316 elif out_dtype.kind == ""f"":
   5317     if not libstrings.is_float(string_col).all():

ValueError: Could not convert strings to integer type due to presence of non-integer values.
```

</details>

**Expected behavior**
I expect it to work--that is, match the result of cudf and dask.dataframe.

**Environment overview (please complete the following information)**
 - Environment location: Bare-metal
 - Method of cuDF install: conda

**Environment details**
<details><summary>Click here to see environment details</summary><pre>

     **git***
     commit 82b9922cc1635f6f0923f633a17a7c12f93ebdbe (HEAD -> pg_set_index_and_categorical, eriknw/pg_set_index_and_categorical)
     Author: Erik Welch <erik.n.welch@gmail.com>
     Date:   Tue Sep 27 11:28:04 2022 -0700

     workaround dask_cudf issue with `sort_values` on categorical column
     **git submodules***

     ***OS Information***
     DGX_NAME=""DGX Server""
     DGX_PRETTY_NAME=""NVIDIA DGX Server""
     DGX_SWBUILD_DATE=""2020-03-04""
     DGX_SWBUILD_VERSION=""4.4.0""
     DGX_COMMIT_ID=""ee09ebc""
     DGX_PLATFORM=""DGX Server for DGX-1""
     DGX_SERIAL_NUMBER=""QTFCOU8220028""

     DGX_R418_REPO_ENABLED=20220727-142458

     DGX_OTA_VERSION=""4.13.0""
     DGX_OTA_DATE=""Wed Jul 27 14:38:05 PDT 2022""
     DISTRIB_ID=Ubuntu
     DISTRIB_RELEASE=18.04
     DISTRIB_CODENAME=bionic
     DISTRIB_DESCRIPTION=""Ubuntu 18.04.6 LTS""
     NAME=""Ubuntu""
     VERSION=""18.04.6 LTS (Bionic Beaver)""
     ID=ubuntu
     ID_LIKE=debian
     PRETTY_NAME=""Ubuntu 18.04.6 LTS""
     VERSION_ID=""18.04""
     HOME_URL=""https://www.ubuntu.com/""
     SUPPORT_URL=""https://help.ubuntu.com/""
     BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
     PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
     VERSION_CODENAME=bionic
     UBUNTU_CODENAME=bionic
     Linux dgx12 4.15.0-189-generic #200-Ubuntu SMP Wed Jun 22 19:53:37 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux

     ***GPU Information***
     Tue Sep 27 12:26:17 2022
     +-----------------------------------------------------------------------------+
     | NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |
     |-------------------------------+----------------------+----------------------+
     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
     |                               |                      |               MIG M. |
     |===============================+======================+======================|
     |   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |
     | N/A   32C    P0    42W / 300W |      3MiB / 32768MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |
     | N/A   30C    P0    42W / 300W |      3MiB / 32768MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |
     | N/A   28C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |
     | N/A   28C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |
     | N/A   30C    P0    42W / 300W |      3MiB / 32768MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |
     | N/A   30C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
     | N/A   33C    P0    43W / 300W |      3MiB / 32768MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
     | N/A   29C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+

     +-----------------------------------------------------------------------------+
     | Processes:                                                                  |
     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
     |        ID   ID                                                   Usage      |
     |=============================================================================|
     |  No running processes found                                                 |
     +-----------------------------------------------------------------------------+

     ***CPU***
     Architecture:        x86_64
     CPU op-mode(s):      32-bit, 64-bit
     Byte Order:          Little Endian
     CPU(s):              80
     On-line CPU(s) list: 0-79
     Thread(s) per core:  2
     Core(s) per socket:  20
     Socket(s):           2
     NUMA node(s):        2
     Vendor ID:           GenuineIntel
     CPU family:          6
     Model:               79
     Model name:          Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz
     Stepping:            1
     CPU MHz:             3343.606
     CPU max MHz:         3600.0000
     CPU min MHz:         1200.0000
     BogoMIPS:            4389.85
     Virtualization:      VT-x
     L1d cache:           32K
     L1i cache:           32K
     L2 cache:            256K
     L3 cache:            51200K
     NUMA node0 CPU(s):   0-19,40-59
     NUMA node1 CPU(s):   20-39,60-79
     Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap intel_pt xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts md_clear flush_l1d

     ***CMake***
     /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin/cmake
     cmake version 3.24.2

     CMake suite maintained and supported by Kitware (kitware.com/cmake).

     ***g++***
     /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin/g++
     g++ (conda-forge gcc 10.4.0-16) 10.4.0
     Copyright (C) 2020 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


     ***nvcc***
     /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2021 NVIDIA Corporation
     Built on Thu_Nov_18_09:45:30_PST_2021
     Cuda compilation tools, release 11.5, V11.5.119
     Build cuda_11.5.r11.5/compiler.30672275_0

     ***Python***
     /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin/python
     Python 3.9.13

     ***Environment Variables***
     PATH                            : /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin:/home/nfs/erwelch/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
     LD_LIBRARY_PATH                 :
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /home/nfs/erwelch/miniconda3/envs/cugraph_dev15
     PYTHON_PATH                     :

     ***conda packages***
     /home/nfs/erwelch/miniconda3/condabin/conda
     # packages in environment at /home/nfs/erwelch/miniconda3/envs/cugraph_dev15:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                       2_gnu    conda-forge
     alabaster                 0.7.12                     py_0    conda-forge
     argon2-cffi               21.3.0             pyhd8ed1ab_0    conda-forge
     argon2-cffi-bindings      21.2.0           py39hb9d737c_2    conda-forge
     arrow-cpp                 9.0.0           py39hd3ccb9b_2_cpu    conda-forge
     asttokens                 2.0.8              pyhd8ed1ab_0    conda-forge
     asvdb                     0.4.2               g90e8f2c_40    rapidsai
     attrs                     22.1.0             pyh71513ae_1    conda-forge
     aws-c-cal                 0.5.11               h95a6274_0    conda-forge
     aws-c-common              0.6.2                h7f98852_0    conda-forge
     aws-c-event-stream        0.2.7               h3541f99_13    conda-forge
     aws-c-io                  0.10.5               hfb6a706_0    conda-forge
     aws-checksums             0.1.11               ha31a3da_7    conda-forge
     aws-sdk-cpp               1.8.186              hb4091e7_3    conda-forge
     babel                     2.10.3             pyhd8ed1ab_0    conda-forge
     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge
     backports                 1.0                        py_2    conda-forge
     backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge
     beautifulsoup4            4.11.1             pyha770c72_0    conda-forge
     binutils                  2.36.1               hdd6e379_2    conda-forge
     binutils_impl_linux-64    2.36.1               h193b22a_2    conda-forge
     binutils_linux-64         2.36                hf3e587d_10    conda-forge
     bleach                    5.0.1              pyhd8ed1ab_0    conda-forge
     bokeh                     2.4.3              pyhd8ed1ab_3    conda-forge
     boost                     1.80.0           py39hac2352c_1    conda-forge
     boost-cpp                 1.80.0               h75c5d50_0    conda-forge
     boto3                     1.24.81            pyhd8ed1ab_0    conda-forge
     botocore                  1.27.81            pyhd8ed1ab_0    conda-forge
     brotlipy                  0.7.0           py39hb9d737c_1004    conda-forge
     bzip2                     1.0.8                h7f98852_4    conda-forge
     c-ares                    1.18.1               h7f98852_0    conda-forge
     c-compiler                1.5.0                h166bdaf_0    conda-forge
     ca-certificates           2022.9.24            ha878542_0    conda-forge
     cachetools                5.2.0              pyhd8ed1ab_0    conda-forge
     certifi                   2022.9.24          pyhd8ed1ab_0    conda-forge
     cffi                      1.15.1           py39he91dace_0    conda-forge
     charset-normalizer        2.1.1              pyhd8ed1ab_0    conda-forge
     clang                     11.1.0               ha770c72_1    conda-forge
     clang-11                  11.1.0          default_ha53f305_1    conda-forge
     clang-tools               11.1.0          default_ha53f305_1    conda-forge
     clangxx                   11.1.0          default_ha53f305_1    conda-forge
     click                     8.1.3            py39hf3d152e_0    conda-forge
     cloudpickle               2.2.0              pyhd8ed1ab_0    conda-forge
     cmake                     3.24.2               h5432695_0    conda-forge
     colorama                  0.4.5              pyhd8ed1ab_0    conda-forge
     commonmark                0.9.1                      py_0    conda-forge
     coverage                  6.4.4            py39hb9d737c_0    conda-forge
     cryptography              37.0.4           py39hd97740a_0    conda-forge
     cuda-python               11.7.0           py39h3fd9d12_0    nvidia
     cudatoolkit               11.5.1               hcf5317a_9    nvidia
     cudf                      22.10.00a220920 cuda_11_py39_g0528b38f2b_241    rapidsai-nightly
     cugraph                   22.10.0a0+84.gc2f983f0          pypi_0    pypi
     cupy                      11.1.0           py39hc3c280e_0    conda-forge
     cxx-compiler              1.5.0                h924138e_0    conda-forge
     cython                    0.29.32          py39h5a03fae_0    conda-forge
     cytoolz                   0.12.0           py39hb9d737c_0    conda-forge
     dask                      2022.9.1           pyhd8ed1ab_0    conda-forge
     dask-core                 2022.9.1           pyhd8ed1ab_0    conda-forge
     dask-cuda                 22.10.00a220927 py39_g8de9ce3_19    rapidsai-nightly
     dask-cudf                 22.10.00a220920 cuda_11_py39_g0528b38f2b_241    rapidsai-nightly
     debugpy                   1.6.3            py39h5a03fae_0    conda-forge
     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge
     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge
     distributed               2022.9.1           pyhd8ed1ab_0    conda-forge
     distro                    1.6.0              pyhd8ed1ab_0    conda-forge
     dlpack                    0.5                  h9c3ff4c_0    conda-forge
     docutils                  0.19             py39hf3d152e_0    conda-forge
     doxygen                   1.9.5                h583eb01_0    conda-forge
     entrypoints               0.4                pyhd8ed1ab_0    conda-forge
     executing                 1.1.0              pyhd8ed1ab_0    conda-forge
     expat                     2.4.9                h27087fc_0    conda-forge
     fastavro                  1.6.1            py39hb9d737c_0    conda-forge
     fastrlock                 0.8              py39h5a03fae_2    conda-forge
     flake8                    5.0.4              pyhd8ed1ab_0    conda-forge
     flit-core                 3.7.1              pyhd8ed1ab_0    conda-forge
     freetype                  2.12.1               hca18f0e_0    conda-forge
     fsspec                    2022.8.2           pyhd8ed1ab_0    conda-forge
     future                    0.18.2           py39hf3d152e_5    conda-forge
     gcc                       10.4.0              hb92f740_10    conda-forge
     gcc_impl_linux-64         10.4.0              h7ee1905_16    conda-forge
     gcc_linux-64              10.4.0              h9215b83_10    conda-forge
     gflags                    2.2.2             he1b5a44_1004    conda-forge
     gh                        2.16.1               ha8f183a_0    conda-forge
     glog                      0.6.0                h6f12383_0    conda-forge
     gmock                     1.10.0               h4bd325d_7    conda-forge
     grpc-cpp                  1.47.1               hbad87ad_6    conda-forge
     gtest                     1.10.0               h4bd325d_7    conda-forge
     gxx                       10.4.0              hb92f740_10    conda-forge
     gxx_impl_linux-64         10.4.0              h7ee1905_16    conda-forge
     gxx_linux-64              10.4.0              h6e491c6_10    conda-forge
     heapdict                  1.0.1                      py_0    conda-forge
     icecream                  2.1.3              pyhd8ed1ab_0    conda-forge
     icu                       70.1                 h27087fc_0    conda-forge
     idna                      3.4                pyhd8ed1ab_0    conda-forge
     imagesize                 1.4.1              pyhd8ed1ab_0    conda-forge
     importlib-metadata        4.11.4           py39hf3d152e_0    conda-forge
     importlib_resources       5.9.0              pyhd8ed1ab_0    conda-forge
     iniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge
     ipykernel                 6.16.0             pyh210e3f2_0    conda-forge
     ipython                   8.5.0              pyh41d4057_1    conda-forge
     ipython_genutils          0.2.0                      py_1    conda-forge
     jedi                      0.18.1             pyhd8ed1ab_2    conda-forge
     jinja2                    3.1.2              pyhd8ed1ab_1    conda-forge
     jmespath                  1.0.1              pyhd8ed1ab_0    conda-forge
     joblib                    1.2.0              pyhd8ed1ab_0    conda-forge
     jpeg                      9e                   h166bdaf_2    conda-forge
     jsonschema                4.16.0             pyhd8ed1ab_0    conda-forge
     jupyter_client            7.3.4              pyhd8ed1ab_0    conda-forge
     jupyter_core              4.11.1           py39hf3d152e_0    conda-forge
     jupyterlab_pygments       0.2.2              pyhd8ed1ab_0    conda-forge
     kernel-headers_linux-64   2.6.32              he073ed8_15    conda-forge
     keyutils                  1.6.1                h166bdaf_0    conda-forge
     krb5                      1.19.3               h3790be6_0    conda-forge
     lcms2                     2.12                 hddcbb42_0    conda-forge
     ld_impl_linux-64          2.36.1               hea4e1c9_2    conda-forge
     lerc                      4.0.0                h27087fc_0    conda-forge
     libabseil                 20220623.0      cxx17_h48a1fff_4    conda-forge
     libblas                   3.9.0           16_linux64_openblas    conda-forge
     libbrotlicommon           1.0.9                h166bdaf_7    conda-forge
     libbrotlidec              1.0.9                h166bdaf_7    conda-forge
     libbrotlienc              1.0.9                h166bdaf_7    conda-forge
     libcblas                  3.9.0           16_linux64_openblas    conda-forge
     libclang-cpp11.1          11.1.0          default_ha53f305_1    conda-forge
     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge
     libcudf                   22.10.00a220920 cuda11_g0528b38f2b_241    rapidsai-nightly
     libcugraphops             22.10.00a220927 cuda11_g553bacf_29    rapidsai-nightly
     libcurl                   7.83.1               h7bff187_0    conda-forge
     libcusolver               11.4.0.1                      0    nvidia
     libcusparse               11.7.4.91                     0    nvidia
     libdeflate                1.14                 h166bdaf_0    conda-forge
     libedit                   3.1.20191231         he28a2e2_2    conda-forge
     libev                     4.33                 h516909a_1    conda-forge
     libevent                  2.1.10               h9b69904_4    conda-forge
     libffi                    3.4.2                h7f98852_5    conda-forge
     libgcc-devel_linux-64     10.4.0              h74af60c_16    conda-forge
     libgcc-ng                 12.1.0              h8d9b700_16    conda-forge
     libgfortran-ng            12.1.0              h69a702a_16    conda-forge
     libgfortran5              12.1.0              hdcd56e2_16    conda-forge
     libgomp                   12.1.0              h8d9b700_16    conda-forge
     libgoogle-cloud           2.1.0                h9ebe8e8_2    conda-forge
     libiconv                  1.17                 h166bdaf_0    conda-forge
     liblapack                 3.9.0           16_linux64_openblas    conda-forge
     libllvm11                 11.1.0               hf817b99_3    conda-forge
     libnghttp2                1.47.0               hdcd2b5c_1    conda-forge
     libnsl                    2.0.0                h7f98852_0    conda-forge
     libopenblas               0.3.21          pthreads_h78a6416_3    conda-forge
     libpng                    1.6.38               h753d276_0    conda-forge
     libprotobuf               3.20.1               h6239696_4    conda-forge
     libraft-distance          22.10.00a220927 cuda11_g1dd2feb1_54    rapidsai-nightly
     libraft-headers           22.10.00a220927 cuda11_g1dd2feb1_54    rapidsai-nightly
     librmm                    22.10.00a220927 cuda11_g6e0d65a9_20    rapidsai-nightly
     libsanitizer              10.4.0              hde28e3b_16    conda-forge
     libsodium                 1.0.18               h36c2ea0_1    conda-forge
     libsqlite                 3.39.3               h753d276_0    conda-forge
     libssh2                   1.10.0               haa6b8db_3    conda-forge
     libstdcxx-devel_linux-64  10.4.0              h74af60c_16    conda-forge
     libstdcxx-ng              12.1.0              ha89aaad_16    conda-forge
     libthrift                 0.16.0               h491838f_2    conda-forge
     libtiff                   4.4.0                h55922b4_4    conda-forge
     libutf8proc               2.7.0                h7f98852_0    conda-forge
     libuuid                   2.32.1            h7f98852_1000    conda-forge
     libuv                     1.44.2               h166bdaf_0    conda-forge
     libwebp-base              1.2.4                h166bdaf_0    conda-forge
     libxcb                    1.13              h7f98852_1004    conda-forge
     libxml2                   2.10.2               h4c7fe37_1    conda-forge
     libxslt                   1.1.35               h8affb1d_0    conda-forge
     libzlib                   1.2.12               h166bdaf_3    conda-forge
     llvmlite                  0.38.1           py39h7d9a04d_0    conda-forge
     locket                    1.0.0              pyhd8ed1ab_0    conda-forge
     lxml                      4.9.1            py39hb9d737c_0    conda-forge
     lz4                       4.0.0            py39h029007f_2    conda-forge
     lz4-c                     1.9.3                h9c3ff4c_1    conda-forge
     make                      4.3                  hd18ef5c_1    conda-forge
     markdown                  3.4.1              pyhd8ed1ab_0    conda-forge
     markupsafe                2.1.1            py39hb9d737c_1    conda-forge
     matplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge
     mccabe                    0.7.0              pyhd8ed1ab_0    conda-forge
     mistune                   2.0.4              pyhd8ed1ab_0    conda-forge
     msgpack-python            1.0.4            py39hf939315_0    conda-forge
     nbclient                  0.6.8              pyhd8ed1ab_0    conda-forge
     nbconvert                 7.0.0              pyhd8ed1ab_0    conda-forge
     nbconvert-core            7.0.0              pyhd8ed1ab_0    conda-forge
     nbconvert-pandoc          7.0.0              pyhd8ed1ab_0    conda-forge
     nbformat                  5.6.1              pyhd8ed1ab_0    conda-forge
     nbsphinx                  0.8.9              pyhd8ed1ab_0    conda-forge
     nccl                      2.14.3.1             h0800d71_0    conda-forge
     ncurses                   6.3                  h27087fc_1    conda-forge
     nest-asyncio              1.5.5              pyhd8ed1ab_0    conda-forge
     networkx                  2.8.6              pyhd8ed1ab_0    conda-forge
     notebook                  6.4.12             pyha770c72_0    conda-forge
     numba                     0.55.2           py39h66db6d7_0    conda-forge
     numpy                     1.22.4           py39hc58783e_0    conda-forge
     numpydoc                  1.4.0              pyhd8ed1ab_1    conda-forge
     nvcc_linux-64             10.1                hcaf9a05_10
     nvtx                      0.2.3            py39h3811e60_1    conda-forge
     openjpeg                  2.5.0                h7d73246_1    conda-forge
     openssl                   1.1.1q               h166bdaf_0    conda-forge
     orc                       1.7.6                h6c59b99_0    conda-forge
     packaging                 21.3               pyhd8ed1ab_0    conda-forge
     pandas                    1.4.4            py39h1832856_0    conda-forge
     pandoc                    2.19.2               ha770c72_0    conda-forge
     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge
     parquet-cpp               1.5.1                         2    conda-forge
     parso                     0.8.3              pyhd8ed1ab_0    conda-forge
     partd                     1.3.0              pyhd8ed1ab_0    conda-forge
     pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge
     pickleshare               0.7.5                   py_1003    conda-forge
     pillow                    9.2.0            py39hd5dbb17_2    conda-forge
     pip                       22.2.2             pyhd8ed1ab_0    conda-forge
     pkgutil-resolve-name      1.3.10             pyhd8ed1ab_0    conda-forge
     pluggy                    1.0.0            py39hf3d152e_3    conda-forge
     prometheus_client         0.14.1             pyhd8ed1ab_0    conda-forge
     prompt-toolkit            3.0.31             pyha770c72_0    conda-forge
     protobuf                  3.20.1           py39h5a03fae_0    conda-forge
     psutil                    5.9.2            py39hb9d737c_0    conda-forge
     pthread-stubs             0.4               h36c2ea0_1001    conda-forge
     ptxcompiler               0.2.0            py39h107f55c_0    rapidsai
     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge
     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge
     py                        1.11.0             pyh6c4a22f_0    conda-forge
     py-cpuinfo                8.0.0              pyhd8ed1ab_0    conda-forge
     pyarrow                   9.0.0           py39hc0775d8_2_cpu    conda-forge
     pycodestyle               2.9.1              pyhd8ed1ab_0    conda-forge
     pycparser                 2.21               pyhd8ed1ab_0    conda-forge
     pydata-sphinx-theme       0.10.1             pyhd8ed1ab_0    conda-forge
     pyflakes                  2.5.0              pyhd8ed1ab_0    conda-forge
     pygal                     2.4.0                      py_0    conda-forge
     pygments                  2.13.0             pyhd8ed1ab_0    conda-forge
     pylibcugraph              22.10.0a0+84.gc2f983f0           dev_0    <develop>
     pylibraft                 22.10.00a220927 cuda11_py39_g1dd2feb1_54    rapidsai-nightly
     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge
     pyopenssl                 22.0.0             pyhd8ed1ab_1    conda-forge
     pyparsing                 3.0.9              pyhd8ed1ab_0    conda-forge
     pyrsistent                0.18.1           py39hb9d737c_1    conda-forge
     pysocks                   1.7.1              pyha2e5f31_6    conda-forge
     pytest                    7.1.3            py39hf3d152e_0    conda-forge
     pytest-benchmark          3.2.3              pyh9f0ad1d_0    conda-forge
     pytest-cov                3.0.0              pyhd8ed1ab_0    conda-forge
     python                    3.9.13          h9a8a25e_0_cpython    conda-forge
     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge
     python-fastjsonschema     2.16.2             pyhd8ed1ab_0    conda-forge
     python_abi                3.9                      2_cp39    conda-forge
     pytz                      2022.2.1           pyhd8ed1ab_0    conda-forge
     pyyaml                    6.0              py39hb9d737c_4    conda-forge
     pyzmq                     24.0.1           py39headdf64_0    conda-forge
     raft-dask                 22.10.00a220927 cuda11_py39_g1dd2feb1_54    rapidsai-nightly
     rapids-pytest-benchmark   0.0.14                     py_0    rapidsai
     re2                       2022.06.01           h27087fc_0    conda-forge
     readline                  8.1.2                h0f457ee_0    conda-forge
     recommonmark              0.7.1              pyhd8ed1ab_0    conda-forge
     requests                  2.28.1             pyhd8ed1ab_1    conda-forge
     rhash                     1.4.3                h166bdaf_0    conda-forge
     rmm                       22.10.00a220927 cuda11_py39_g6e0d65a9_20    rapidsai-nightly
     s2n                       1.0.10               h9b69904_0    conda-forge
     s3transfer                0.6.0              pyhd8ed1ab_0    conda-forge
     scikit-build              0.15.0             pyhb871ab6_0    conda-forge
     scikit-learn              1.1.2            py39he5e8d7e_0    conda-forge
     scipy                     1.9.1            py39h8ba3f38_0    conda-forge
     send2trash                1.8.0              pyhd8ed1ab_0    conda-forge
     setuptools                65.4.0                   pypi_0    pypi
     six                       1.16.0             pyh6c4a22f_0    conda-forge
     snappy                    1.1.9                hbd366e4_1    conda-forge
     snowballstemmer           2.2.0              pyhd8ed1ab_0    conda-forge
     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge
     soupsieve                 2.3.2.post1        pyhd8ed1ab_0    conda-forge
     spdlog                    1.8.5                h4bd325d_1    conda-forge
     sphinx                    5.2.1              pyhd8ed1ab_0    conda-forge
     sphinx-copybutton         0.5.0              pyhd8ed1ab_0    conda-forge
     sphinx-markdown-tables    0.0.17             pyh6c4a22f_0    conda-forge
     sphinxcontrib-applehelp   1.0.2                      py_0    conda-forge
     sphinxcontrib-devhelp     1.0.2                      py_0    conda-forge
     sphinxcontrib-htmlhelp    2.0.0              pyhd8ed1ab_0    conda-forge
     sphinxcontrib-jsmath      1.0.1                      py_0    conda-forge
     sphinxcontrib-qthelp      1.0.3                      py_0    conda-forge
     sphinxcontrib-serializinghtml 1.1.5              pyhd8ed1ab_2    conda-forge
     sphinxcontrib-websupport  1.2.4              pyhd8ed1ab_1    conda-forge
     sqlite                    3.39.3               h4ff8645_0    conda-forge
     stack_data                0.5.1              pyhd8ed1ab_0    conda-forge
     sysroot_linux-64          2.12                he073ed8_15    conda-forge
     tblib                     1.7.0              pyhd8ed1ab_0    conda-forge
     terminado                 0.15.0           py39hf3d152e_0    conda-forge
     threadpoolctl             3.1.0              pyh8a188c0_0    conda-forge
     tinycss2                  1.1.1              pyhd8ed1ab_0    conda-forge
     tk                        8.6.12               h27826a3_0    conda-forge
     toml                      0.10.2             pyhd8ed1ab_0    conda-forge
     tomli                     2.0.1              pyhd8ed1ab_0    conda-forge
     toolz                     0.12.0             pyhd8ed1ab_0    conda-forge
     tornado                   6.1              py39hb9d737c_3    conda-forge
     traitlets                 5.4.0              pyhd8ed1ab_0    conda-forge
     typing_extensions         4.3.0              pyha770c72_0    conda-forge
     tzdata                    2022d                h191b570_0    conda-forge
     ucx                       1.13.1               h538f049_0    conda-forge
     ucx-proc                  1.0.0                       gpu    rapidsai
     ucx-py                    0.28.00a220926  py39_g8e07f67_25    rapidsai-nightly
     urllib3                   1.26.11            pyhd8ed1ab_0    conda-forge
     wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge
     webencodings              0.5.1                      py_1    conda-forge
     wheel                     0.37.1             pyhd8ed1ab_0    conda-forge
     xorg-libxau               1.0.9                h7f98852_0    conda-forge
     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge
     xz                        5.2.6                h166bdaf_0    conda-forge
     yaml                      0.2.5                h7f98852_2    conda-forge
     zeromq                    4.3.4                h9c3ff4c_1    conda-forge
     zict                      2.2.0              pyhd8ed1ab_0    conda-forge
     zipp                      3.8.1              pyhd8ed1ab_0    conda-forge
     zlib                      1.2.12               h166bdaf_3    conda-forge
     zstd                      1.5.2                h6239696_4    conda-forge

</pre></details>
**Additional context**
Encountered in ProperterGraph in cugraph.",2022-09-27T19:29:34Z,0,0,Erik Welch,
125,[QST] OOM issue while loading the 26GB twitter dataset into 128GB GPU memory,"Hey I try to load the twitter graph in a AWS `p3.16xlarge` instance, which has 8 16GB memory GPUs, in total 128GB. However, it is OOM. Could you please take a look if I missed anything? Thanks so much!

```python
import dask
from dask_cuda import LocalCUDACluster
from dask.distributed import Client
import dask_cudf
import cugraph
import cugraph.dask as dask_cugraph
from cugraph.dask.common.mg_utils import get_visible_devices
from cugraph.dask.comms import comms as Comms
import time

csv_file_name = ""twitter-2010.csv""

with dask.config.set(jit_unspill=True):
    with LocalCUDACluster(n_workers=8, device_memory_limit=""16GB"") as cluster:
        with Client(cluster) as client:
            client.wait_for_workers(len(get_visible_devices()))
            Comms.initialize(p2p=True)
            chunksize = dask_cugraph.get_chunksize(csv_file_name)
            ddf = dask_cudf.read_csv(csv_file_name, chunksize=chunksize, delimiter=' ', names=['src', 'dst'], dtype=['int32', 'int32'])
            ddf.compute()
            # G = cugraph.Graph(directed=True)
            # G.from_dask_cudf_edgelist(ddf, source='src', destination='dst')
```

I can't find similar issues,  this [one](https://github.com/rapidsai/cudf/issues/6087) got similar errors but it is because LocalCUDACluster is not used.

I used the docker approach to install the rapid frameworks:

```cmd
docker pull rapidsai/rapidsai-dev:22.08-cuda11.5-devel-ubuntu20.04-py3.9
docker run --gpus all --rm -it \
    --shm-size=10g --ulimit memlock=-1 \
    -p 8888:8888 -p 8787:8787 -p 8786:8786 \
    rapidsai/rapidsai-dev:22.08-cuda11.5-devel-ubuntu20.04-py3.9
```

The error log:

```
2022-09-27 13:03:21,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-09-27 13:03:21,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-09-27 13:03:21,524 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-09-27 13:03:21,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-09-27 13:03:21,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-09-27 13:03:21,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-09-27 13:03:21,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-09-27 13:03:21,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-09-27 13:03:21,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-09-27 13:03:21,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-09-27 13:03:21,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-09-27 13:03:21,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-09-27 13:03:21,597 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-09-27 13:03:21,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-09-27 13:03:21,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-09-27 13:03:21,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
---------------------------------------------------------------------------
MemoryError                               Traceback (most recent call last)
/tmp/ipykernel_5947/1798640855.py in <module>
      9             chunksize = dask_cugraph.get_chunksize(csv_file_name)
     10             ddf = dask_cudf.read_csv(csv_file_name, chunksize=chunksize, delimiter=' ', names=['src', 'dst'], dtype=['int32', 'int32'])
---> 11             ddf.compute()
     12             # G = cugraph.Graph(directed=True)
     13             # G.from_dask_cudf_edgelist(ddf, source='src', destination='dst')

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/base.py in compute(self, **kwargs)
    313         dask.base.compute
    314         """"""
--> 315         (result,) = compute(self, traverse=False, **kwargs)
    316         return result
    317 

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/base.py in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)
    597 
    598     results = schedule(dsk, keys, **kwargs)
--> 599     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])
    600 
    601 

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/base.py in <listcomp>(.0)
    597 
    598     results = schedule(dsk, keys, **kwargs)
--> 599     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])
    600 
    601 

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/core.py in finalize(results)
    136 
    137 def finalize(results):
--> 138     return _concat(results)
    139 
    140 

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask_cuda-22.8.0-py3.9.egg/dask_cuda/proxify_device_objects.py in wrapper(*args, **kwargs)
    167     @functools.wraps(func)
    168     def wrapper(*args, **kwargs):
--> 169         ret = func(*args, **kwargs)
    170         if dask.config.get(""jit-unspill-compatibility-mode"", default=False):
    171             ret = unproxify_device_objects(ret, skip_explicit_proxies=False)

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/core.py in _concat(args, ignore_index)
    131         args[0]
    132         if not args2
--> 133         else methods.concat(args2, uniform=True, ignore_index=ignore_index)
    134     )
    135 

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/dispatch.py in concat(dfs, axis, join, uniform, filter_warning, ignore_index, **kwargs)
     60     else:
     61         func = concat_dispatch.dispatch(type(dfs[0]))
---> 62         return func(
     63             dfs,
     64             axis=axis,

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask_cuda-22.8.0-py3.9.egg/dask_cuda/proxy_object.py in wrapper(*args, **kwargs)
    900         args = [unproxy(d) for d in args]
    901         kwargs = {k: unproxy(v) for k, v in kwargs.items()}
--> 902         return func(*args, **kwargs)
    903 
    904     return wrapper

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/dispatch.py in concat(dfs, axis, join, uniform, filter_warning, ignore_index, **kwargs)
     60     else:
     61         func = concat_dispatch.dispatch(type(dfs[0]))
---> 62         return func(
     63             dfs,
     64             axis=axis,

/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)
     77         def inner(*args, **kwds):
     78             with self._recreate_cm():
---> 79                 return func(*args, **kwds)
     80         return inner
     81 

/opt/conda/envs/rapids/lib/python3.9/site-packages/dask_cudf/backends.py in concat_cudf(dfs, axis, join, uniform, filter_warning, sort, ignore_index, **kwargs)
    273         )
    274 
--> 275     return cudf.concat(dfs, axis=axis, ignore_index=ignore_index)
    276 
    277 

/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/reshape.py in concat(objs, axis, join, ignore_index, sort)
    397                 # don't filter out empty df's
    398                 objs = old_objs
--> 399             result = cudf.DataFrame._concat(
    400                 objs,
    401                 axis=axis,

/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)
     77         def inner(*args, **kwds):
     78             with self._recreate_cm():
---> 79                 return func(*args, **kwds)
     80         return inner
     81 

/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py in _concat(cls, objs, axis, join, ignore_index, sort)
   1674         # Concatenate the Tables
   1675         out = cls._from_data(
-> 1676             *libcudf.concat.concat_tables(
   1677                 tables, ignore_index=ignore_index or are_all_range_index
   1678             )

concat.pyx in cudf._lib.concat.concat_tables()

concat.pyx in cudf._lib.concat.concat_tables()
```
",2022-09-27T20:05:54Z,0,0,zhao feng,
126,"[FEA] dataframe.corr() missing ""kendall"" method","**Is your feature request related to a problem? Please describe.**
Pandas has 4 options for the methods parameter in the corr() function: ""pearson"", ""spearman"", ""kendall"", and ""callable"" which accepts a callable object instead of a predetermined algorithm: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html

 CuDF currently only supports ""pearson"" and ""spearman"": https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.corr.html

**Describe the solution you'd like**
Can we evaluate cudf and dask+cudf to implement the ""kendall"" correlation method?

**Context**
NVIDIA Solutions Architect, filing on behalf of customer

Related request for ""callable"" method: https://github.com/rapidsai/cudf/issues/11926
",2022-10-14T18:00:17Z,1,0,,
127,[FEA] dataframe.mode() axis parameter not supported,"**Is your feature request related to a problem? Please describe.**
The cudf documentation lists the mode function's {axis=0,1} parameter, but then has an additional note that ""axis parameter is currently not supported."":  https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.mode.html 

**Describe the solution you'd like**
Is this feature possible to be implemented? Or is there an underlying challenge with replicating this pandas functionality in cudf?

**Additional context**
NVIDIA Solutions Architect, filing on behalf of customer
",2022-10-14T18:08:52Z,0,0,,
128,"[FEA] dataframe.corr() missing ""callable"" method","Is your feature request related to a problem? Please describe.
Pandas has 4 options for the methods parameter in the corr() function: ""pearson"", ""spearman"", ""kendall"", and ""callable"" which accepts a callable object instead of a predetermined algorithm: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html

CuDF currently only supports ""pearson"" and ""spearman"": https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.corr.html

Describe the solution you'd like
Is it feasible to implement ""callable"" methods in cudf and dask+cudf?

Context
NVIDIA Solutions Architect, filing on behalf of customer

related request for ""kendall"" method: https://github.com/rapidsai/cudf/issues/11924 
",2022-10-14T18:52:08Z,0,0,,
129,[BUG] Assignment of string list to column doesn't work,"**Describe the bug**

This does not work:

df.loc[df['column'] =='value', 'column2'] = ['0','1']

TypeError: Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()
To explicitly construct a host matrix, consider using .to_numpy().

Integers do work:
df.loc[df['column']=='value', 'column2'] = [0,1]

Both work in pandas.

Rapids 22.08
Ubuntu 20
",2022-10-19T06:53:58Z,0,0,Üllar Kask,
130,[FEA] cudf.DataFrame.filter,"**Is your feature request related to a problem? Please describe.**
rewriting code from pandas into cudf, trying to use `import cudf as pd`

**Describe the solution you'd like**
`cudf.DataFrame.filter` matching https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html",2022-10-21T13:55:58Z,0,0,Matthew Farrellee,
131,[BUG] semantic mismatch for Int64 and int64,"**Describe the bug**
rewriting code from pandas to cudf, using `import cudf as pd`

**Steps/Code to reproduce bug**

```
$ python
Python 3.9.13 (main, May 18 2022, 00:00:00) 
[GCC 11.3.1 20220421 (Red Hat 11.3.1-2)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import pandas, cudf

>>> pandas.__version__
'1.5.1'

>>> cudf.__version__
'22.10.00a+392.g1558403753'

>>> pandas.Series([1, None], dtype=""Int64"")
0       1
1    <NA>
dtype: Int64

>>> pandas.Series([1, None], dtype=""int64"")
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".../python3.9/site-packages/pandas/core/series.py"", line 470, in __init__
    data = sanitize_array(data, index, dtype, copy)
  File "".../python3.9/site-packages/pandas/core/construction.py"", line 622, in sanitize_array
    subarr = _try_cast(data, dtype, copy, raise_cast_failure)
  File "".../python3.9/site-packages/pandas/core/construction.py"", line 835, in _try_cast
    subarr = maybe_cast_to_integer_array(arr, dtype)
  File "".../python3.9/site-packages/pandas/core/dtypes/cast.py"", line 1834, in maybe_cast_to_integer_array
    casted = np.array(arr, dtype=dtype, copy=copy)
TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'

>>> cudf.Series([1, None], dtype=""Int64"")
Traceback (most recent call last):
  File "".../python3.9/site-packages/cudf/core/column/column.py"", line 2038, in as_column
    memoryview(arbitrary), dtype=dtype, nan_as_null=nan_as_null
TypeError: memoryview: a bytes-like object is required, not 'list'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "".../python3.9/site-packages/cudf/core/column/column.py"", line 2127, in as_column
    np_type = np.dtype(dtype).type
TypeError: data type 'Int64' not understood
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "".../python3.9/site-packages/cudf/core/column/column.py"", line 2199, in _construct_array
    arbitrary = cupy.asarray(arbitrary, dtype=dtype)
  File "".../python3.9/site-packages/cupy/_creation/from_data.py"", line 76, in asarray
    return _core.array(a, dtype, False, order)
  File ""cupy/_core/core.pyx"", line 2266, in cupy._core.core.array
  File ""cupy/_core/core.pyx"", line 2290, in cupy._core.core.array
  File ""cupy/_core/core.pyx"", line 2415, in cupy._core.core._array_default
TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".../python3.9/site-packages/nvtx/nvtx.py"", line 101, in inner
    result = func(*args, **kwargs)
  File "".../python3.9/site-packages/cudf/core/series.py"", line 536, in __init__
    data = column.as_column(data, nan_as_null=nan_as_null, dtype=dtype)
  File "".../python3.9/site-packages/cudf/core/column/column.py"", line 2184, in as_column
    _construct_array(arbitrary, dtype),
  File "".../python3.9/site-packages/cudf/core/column/column.py"", line 2212, in _construct_array
    arbitrary = np.asarray(
TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'

>>> cudf.Series([1, None], dtype=""int64"")
0       1
1    <NA>
dtype: int64

```



**Expected behavior**
matching behavior for `Int64` and `int64`

ref https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html and https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes",2022-10-24T11:25:25Z,0,0,Matthew Farrellee,
132,[FEA] Support imaginary numbers in cuDF dataframes,"Hello, I am trying to store some imaginary numbers as a cudf dataframe column. Each column cell is a list of imaginary numbers. I am wondering what would be the most efficient way to do it as cudf dataframe doesn't support imaginary numbers? Seperating the real and imaginary part is what I am doing now but this is a huge dataset and it is taking a lot of time.",2022-10-25T09:33:07Z,0,0,Arpan Das,The École polytechnique fédérale de Lausanne
133,[ENH/QST] actually inplace updates in `__setitem__` and friends,"## Context

As noted in #11085, in many cases (though inconsistently right now), obtaining a view on `Series` (probably a `DataFrame` as well) using `iloc[:]` _inadvertently_ behaves with pseudo-copy-on-write semantics

```python
import cudf
import numpy as np
s = cudf.Series([1, 2, 3])
sview = s.iloc[:]
s.iloc[[1, 2]] = [4, 5]
assert np.allclose(s.values, sview.values) # => False

sview = s.iloc[:]
s.iloc[0:2] = 3
assert np.allclose(s.values, sview.values) # => True
```

Note: pandas is moving towards _all_ indexing [behaving with copy semantics](https://docs.google.com/document/d/1ZCQ9mx3LBMy-nhwRl33_jgcvWo9IWdEfxDNQ2thyTb0), so for some of these cases we've already skated to the right answer :)

## Why does this happen?

Most (but not all) of the `__setitem__`-like calls into (e.g. `copy_range`, `scatter`) `libcudf` do not operate in place, but instead return a new `cudf::column` that must be wrapped up. As a consequence, to pretend like the operation was in place, we call `_mimic_inplace(...)` to switch out the backing data of the `Column` object we're doing `__setitem__` on:

```python
import cudf
s = cudf.Series([1, 2, 3])
old_data = s._column.data
s.iloc[1:3] = [4, 5]
new_data = s._column.data
assert old_data is new_data # => False
```

This is kind of fine as long as there's only one object holding on to the column data, but this breaks down as soon as we have views.

## Why is the status quo problematic?

1. The current inconsistencies make implementing copy-on-write rather delicate (and in many cases provoke more copies than needed).
2. Operations that to the user do not provoke a copy can overflow GPU memory:
     ```python
      # on a system with 32 GB gpu memory
      import cudf
      import cupy as cp
      import numpy as np
      df = cudf.DataFrame({f""{i}"": cp.ones(10**9, dtype=np.uint8) for i in range(20)}) # about 20GB
      # expectation: this behaves in place, so the operation should fit in memory.
      df.iloc[[0, 2]] = list(range(20)) # => MemoryError: std::bad_alloc: out_of_memory: CUDA error at: rmm/mr/device/cuda_memory_resource.hpp
    ````
3. If the scatter/copy_foo operations in libcudf had an in place then we would have lower memory pressure (as point 2) and in the (common) case where we have a target table view, could avoid a memcopy of the whole table.

## Possible solutions

I don't know the history as to why the libcudf generally tends to offer ""return a copy"" rather than ""modify in place"", but one could make an effort to offer in place versions of most functions. If these operations were available, then the Cython layer could switch to calling into them. In those cases where we really want a copy, we would allocate and copy into an empty table before calling into libcudf.

Edit: modification in place only works at the libcudf level for fixed-width column types (so no strings, lists), and having in- and out-of-place modification for every operation is too much work without some significant motivating use case.

Since we need a work-around that works for string/list columns that cannot by modified in-place _anyway_, I don't think this issue is a sufficiently motivating use case.

The above solution is a no-go, so what else could we do?

- Given that we're trying to move to copy-on-write, we could go the other way and audit all places where `__setitem__` really is in place, and break that connection. ~Note that this is not actually copy-on-write, but copy-on-read so it's not a great option.~ Something close to this probably is copy-on-write, so looks perhaps reasonable.
- ~Change the way `_mimic_inplace(self, other, inplace=True)` works: rather than rewriting where `self.data` points to, we could instead `memcopy` from `other.data` back into `self.data` and then drop `other`. This maintains the same memory footprint right now, at the cost of (another) full `memcopy`, and makes `__setitem__` really behave in place (even for views).~ As pointed out below, this doesn't work for non-fixed-width column dtypes.",2022-10-25T17:17:48Z,0,0,Lawrence Mitchell,
134,Refactor groupby to rely less on storing keys as `Index` objects,"https://github.com/rapidsai/cudf/pull/11792 introduces the ability to group on list columns. In the future, we can expect grouping by, e.g., structs and other types that are not supported by Pandas.

In https://github.com/rapidsai/cudf/issues/6932, we made the decision not to support creating an `Index` with elements of type `list`. 

Unfortunately, our groupby internals rely heavily on being able to store the key columns of a groupby as an `Index`. In particular, the internal [`_Grouping.keys`](https://github.com/rapidsai/cudf/blob/991c86b13acdbc28ab60609bee6eba2f9eac1ecc/python/cudf/cudf/core/groupby/groupby.py#L1836) method is heavily used.

We should rely less on storing keys as `Index` objects, which will make it much easier to support grouping by lists and structs. ",2022-11-01T14:51:06Z,0,0,Ashwin Srinath,Voltron Data
135,[ENH/QST]: Behaviour of type promotion in `__setitem__`,"# Summary

CUDF is not consistent with Pandas (under a bunch of circumstances) in
its behaviour when upcasting during `__setitem__`. In some cases, we
might want to mimic pandas behaviour (though they are very keen to use
value-based type promotion). In others, where we have more structured
dtypes than pandas, we need to decide what to do (current behaviour is
internally inconsistent and buggy in a bunch of cases).

I summarise what I think the current state is (by way of experiment),
and then discuss some options. Opinions welcome!

cc: @vyasr, @mroeschke, @shwina
# Pandas behaviour

Pandas version 1.5.1, MacOS (Apple Silicon)

Edit: updated code for generating more tables.

I should note that these tables are for single index `__setitem__` (`s.iloc[i] = value`). I should check if the same behaviour also occurs for:
- [x] slice-based `__setitem__` with single value `s.iloc[:1] = [value]`
- [x] slice-based `__setitem__` with list of values `s.iloc[:2] = [value for _ in range(2)]`
- [x] mask-based `__setitem__` with singleton value `s.iloc[[True, False]] = [value]`
- [x] mask-based `__setitem__` with multiple values `s.iloc[[True, False, True]] = [value, value]`
- [x] index-based `__setitem__` with single value `s.iloc[[1]] = value`
- [x] index-based `__setitem__` with multiple values `s.iloc[[1, 2]] = [value, value]`

<details>
<summary>Code to generate tables</summary>

```python
from __future__ import annotations

import os
from enum import Enum, IntEnum, auto
from itertools import filterfalse, repeat
from operator import not_
from pathlib import Path

import numpy as np
import pandas as pd
import typer

try:
    import cudf
    import cupy

    class Backend(str, Enum):
        PANDAS = ""pandas""
        CUDF = ""cudf""

except ImportError:

    class Backend(str, Enum):
        PANDAS = ""pandas""


def numeric_series(values, dtype, *, pandas):
    if pandas:
        return pd.Series(values, dtype=dtype)
    else:
        return cudf.Series(values, dtype=dtype)


def format_val(v):
    try:
        dt = v.dtype
        return f""np.{dt.type.__name__}({v})""
    except AttributeError:
        return f""{v}""


class IndexType(IntEnum):
    SINGLE_INT = auto()
    SINGLETON_SLICE = auto()
    CONTIG_SLICE = auto()
    STRIDED_SLICE = auto()
    SINGLETON_MASK = auto()
    GENERAL_MASK = auto()
    SINGLETON_SCATTER = auto()
    GENERAL_SCATTER = auto()


def indexing(index_type: IndexType, n: int) -> tuple[int | slice | list, slice | list]:
    assert n >= 3
    if index_type == IndexType.SINGLE_INT:
        return n - 1, slice(0, n - 1, None)
    elif index_type == IndexType.SINGLETON_SLICE:
        return slice(1, 2, 1), [0, *range(2, n)]
    elif index_type == IndexType.CONTIG_SLICE:
        return slice(1, n - 2, 1), [0, *range(n - 2, n)]
    elif index_type == IndexType.STRIDED_SLICE:
        return slice(0, n, 2), slice(1, n, 2)
    elif index_type == IndexType.SINGLETON_MASK:
        yes = [False, True, *repeat(False, n - 2)]
        no = list(map(not_, yes))
        return yes, no
    elif index_type == IndexType.GENERAL_MASK:
        yes = [True, False, True, *repeat(False, n - 3)]
        no = list(map(not_, yes))
        return yes, no
    elif index_type == IndexType.SINGLETON_SCATTER:
        yes = [1]
        # Oh for Haskell-esque sections
        no = list(filterfalse(yes.__contains__, range(n)))
        return yes, no
    elif index_type == IndexType.GENERAL_SCATTER:
        yes = [0, 2]
        no = list(filterfalse(yes.__contains__, range(n)))
        return yes, no
    else:
        raise ValueError(""Unhandled case"")


def generate_table(f, initial_values, values_to_try, dtype, *, index_type, pandas):
    initial_values = np.asarray(initial_values, dtype=object)
    f.write(""| Initial dtype | New value | Final dtype | Lossy? |\n"")
    f.write(""|---------------|-----------|-------------|--------|\n"")

    yes, no = indexing(index_type, len(initial_values))
    for value in values_to_try:
        s = numeric_series(initial_values, dtype=dtype, pandas=pandas)
        otype = f""np.{type(s.dtype).__name__}""
        try:
            if index_type == IndexType.SINGLETON_SLICE:
                value = cupy.asarray([value])
            s.iloc[yes] = value
        except BaseException as e:
            f.write(f""| `{otype}` | `{format_val(value)}` | N/A | {e} |\n"")
            continue
        ntype = f""np.{type(s.dtype).__name__}""
        expect = (np.asarray if pandas else cupy.asarray)(
            initial_values[no], dtype=dtype
        )
        original_lost_info = (s.iloc[no].astype(dtype) != expect).any()
        try:
            new_vals = s.iloc[yes].astype(value.dtype)
        except AttributeError:
            if pandas:
                new_vals = np.asarray(s.iloc[yes])
            else:
                new_vals = cupy.asarray(s.iloc[yes])
        new_lost_info = (new_vals != value).any()
        lossy = ""Yes"" if original_lost_info or new_lost_info else ""No""
        f.write(f""| `{otype}` | `{format_val(value)}` | `{ntype}` | {lossy} |\n"")


def generate_tables(output_directory: Path, backend: Backend, index_type: IndexType):
    integer_column_values_to_try = [
        10,
        np.int64(10),
        2**40,
        np.int64(2**40),
        2**80,
        10.5,
        np.float64(10),
        np.float64(10.5),
        np.float32(10),
        np.float32(10.5),
    ]
    float_column_values_to_try = [
        10,
        np.int64(10),
        2**40,
        np.int64(2**40),
        np.int32(2**31 - 100),
        np.int64(2**63 - 100),
        2**80 - 100,
        10.5,
        np.float64(10),
        np.float64(10.5),
        np.float64(np.finfo(np.float32).max.astype(np.float64) * 10),
        np.float32(10),
        np.float32(10.5),
    ]

    pandas = backend == Backend.PANDAS
    filename = f""{backend}-setitem-{index_type.name}.md""
    with open(output_directory / filename, ""w"") as f:
        if pandas:
            f.write(f""Pandas {pd.__version__} behaviour for {index_type!r}\n\n"")
        else:
            f.write(f""CUDF {cudf.__version__} behaviour for {index_type!r}\n\n"")

        generate_table(
            f,
            [2**31 - 10, 2**31 - 100, 3, 4, 5],
            integer_column_values_to_try,
            np.int32,
            index_type=index_type,
            pandas=pandas,
        )
        f.write(""\n"")
        generate_table(
            f,
            [2**63 - 10, 2**63 - 100, 3, 4, 5],
            integer_column_values_to_try,
            np.int64,
            index_type=index_type,
            pandas=pandas,
        )
        f.write(""\n"")
        generate_table(
            f,
            [np.finfo(np.float32).max, np.float32(np.inf), 3, 4, 5],
            float_column_values_to_try,
            np.float32,
            index_type=index_type,
            pandas=pandas,
        )
        f.write(""\n"")
        generate_table(
            f,
            [np.finfo(np.float64).max, np.float64(np.inf), 3, 4, 5],
            float_column_values_to_try,
            np.float64,
            index_type=index_type,
            pandas=pandas,
        )


def main(
    output_directory: Path = typer.Argument(Path("".""), help=""Output directory for results""),
    backend: Backend = typer.Option(""pandas"", help=""Dataframe backend to test""),
):
    os.makedirs(output_directory, exist_ok=True)
    for index_type in IndexType.__members__.values():
        generate_tables(output_directory, backend, index_type)


if __name__ == ""__main__"":
    typer.run(main)
```

</details>

## Numeric columns

### Integer column dtypes

#### dtype width < max integer width

Initial values `[2**31 - 10, 2**31 - 100, 3]`. `np.int32` is
representative of any integer type that is smaller than the max width.

| Initial dtype     | New value                   | Final dtype          | Lossy? |
|-------------------|-----------------------------|----------------------|--------|
| `np.dtype[int32]` | `10`                        | `np.dtype[int32]`    | No[^1] |
| `np.dtype[int32]` | `np.int64(10)`              | `np.dtype[int32]`    | No[^1] |
| `np.dtype[int32]` | `1099511627776`             | `np.dtype[longlong]` | No[^2] |
| `np.dtype[int32]` | `np.int64(1099511627776)`   | `np.dtype[longlong]` | No[^2] |
| `np.dtype[int32]` | `1208925819614629174706176` | `np.dtype[object_]`  | No[^3] |
| `np.dtype[int32]` | `10.5`                      | `np.dtype[float64]`  | No[^4] |
| `np.dtype[int32]` | `np.float64(10.0)`          | `np.dtype[int32]`    | No[^1] |
| `np.dtype[int32]` | `np.float64(10.5)`          | `np.dtype[float64]`  | No[^2] |
| `np.dtype[int32]` | `np.float32(10.0)`          | `np.dtype[int32]`    | No[^1] |
| `np.dtype[int32]` | `np.float32(10.5)`          | `np.dtype[float64]`  | No[^5] |

[^1]: value is exact in the initial dtype
[^2]: next largest numpy type that contains the value
[^3]: not representable in a numpy type, so coercion to object column
[^4]: default float type is float64
[^5]: `np.int32` is losslessly convertible to `np.float64`

#### dtype width == max integer width

Initial values `[2 ** 63 - 10, 2 ** 63 - 100, 3]`. These provoke edge
cases in upcasting because:
```python
import numpy as np
np.find_common_type([], [np.int64, np.float64])
# => np.float64 Noooooo! Hates it
# Yes, I know this is the same as the integer to float promotion in
# C/C++, I'm allowed to hate that too.
```

| Initial dtype     | New value                   | Final dtype         | Lossy?  |
|-------------------|-----------------------------|---------------------|---------|
| `np.dtype[int64]` | `10`                        | `np.dtype[int64]`   | No[^1]  |
| `np.dtype[int64]` | `np.int64(10)`              | `np.dtype[int64]`   | No[^1]  |
| `np.dtype[int64]` | `1099511627776`             | `np.dtype[int64]`   | No[^1]  |
| `np.dtype[int64]` | `np.int64(1099511627776)`   | `np.dtype[int64]`   | No[^1]  |
| `np.dtype[int64]` | `1208925819614629174706176` | `np.dtype[object_]` | No[^3]  |
| `np.dtype[int64]` | `10.5`                      | `np.dtype[float64]` | Yes[^6] |
| `np.dtype[int64]` | `np.float64(10.0)`          | `np.dtype[int64]`   | No[^1]  |
| `np.dtype[int64]` | `np.float64(10.5)`          | `np.dtype[float64]` | Yes[^6] |
| `np.dtype[int64]` | `np.float32(10.0)`          | `np.dtype[int64]`   | No[^1]  |
| `np.dtype[int64]` | `np.float32(10.5)`          | `np.dtype[float64]` | Yes[^6] |

[^6]: `np.int64` is _not_ losslessly convertible `np.float64`

### Float column dtypes

#### dtype width < max float width

Initial values `[np.finfo(np.float32).max, np.float32(np.inf), 3]`

| Initial dtype       | New value                            | Final dtype         | Lossy?   |
|---------------------|--------------------------------------|---------------------|----------|
| `np.dtype[float32]` | `10`                                 | `np.dtype[float32]` | No[^1]   |
| `np.dtype[float32]` | `np.int64(10)`                       | `np.dtype[float32]` | No[^1]   |
| `np.dtype[float32]` | `1099511627776`                      | `np.dtype[float32]` | No[^1]   |
| `np.dtype[float32]` | `np.int64(1099511627776)`            | `np.dtype[float32]` | No[^1]   |
| `np.dtype[float32]` | `np.int32(2147483548)`               | `np.dtype[float64]` | No[^1]   |
| `np.dtype[float32]` | `np.int64(9223372036854775708)`      | `np.dtype[float32]` | Yes[^7] |
| `np.dtype[float32]` | `1208925819614629174706076`          | `np.dtype[object_]` | No[^3]  |
| `np.dtype[float32]` | `10.5`                               | `np.dtype[float32]` | No[^1]   |
| `np.dtype[float32]` | `np.float64(10.0)`                   | `np.dtype[float32]` | No[^1]   |
| `np.dtype[float32]` | `np.float64(10.5)`                   | `np.dtype[float32]` | No[^1]   |
| `np.dtype[float32]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float64]` | No[^2]  |
| `np.dtype[float32]` | `np.float32(10.0)`                   | `np.dtype[float32]` | No[^1]   |
| `np.dtype[float32]` | `np.float32(10.5)`                   | `np.dtype[float32]` | No[^1]   |

[^7]: value is not losslessly representable, but also, expecting
    `np.float64`!

#### dtype width == max float width

Initial values `[np.finfo(np.float64).max, np.float64(np.inf), 3]`

| Initial dtype       | New value                            | Final dtype         | Lossy?   |
|---------------------|--------------------------------------|---------------------|----------|
| `np.dtype[float64]` | `10`                                 | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `np.int64(10)`                       | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `1099511627776`                      | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `np.int64(1099511627776)`            | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `np.int32(2147483548)`               | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `np.int64(9223372036854775708)`      | `np.dtype[float64]` | Yes[^6] |
| `np.dtype[float64]` | `1208925819614629174706076`          | `np.dtype[object_]` | No[^3]  |
| `np.dtype[float64]` | `10.5`                               | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `np.float64(10.0)`                   | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `np.float64(10.5)`                   | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `np.float32(10.0)`                   | `np.dtype[float64]` | No[^1]  |
| `np.dtype[float64]` | `np.float32(10.5)`                   | `np.dtype[float64]` | No[^1]  |

## Everything else

Basically, you can put anything in a column and you get an object out,
but numpy types are converted to `object` first.

# CUDF behaviour

CUDF trunk, and state in #11904.

## Numeric columns

### Integer column dtypes

#### dtype width < max integer width

Initial values `[2**31 - 10, 2**31 - 100, 3]`. `np.int32` is
representative of any integer type that is smaller than the max width.

| Initial dtype     | New value                   | Final dtype (trunk)   | Final dtype (#11904)    | Lossy? (trunk) | Lossy? (#11904) |
|-------------------|-----------------------------|-----------------------|-------------------------|----------------|-----------------|
| `np.dtype[int32]` | `10`                        | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |
| `np.dtype[int32]` | `np.int64(10)`              | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |
| `np.dtype[int32]` | `1099511627776`             | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | Yes            | No              |
| `np.dtype[int32]` | `np.int64(1099511627776)`   | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | Yes            | No              |
| `np.dtype[int32]` | `1208925819614629174706176` | OverflowError         | OverflowError           | N/A            | N/A             |
| `np.dtype[int32]` | `10.5`                      | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | Yes            | No              |
| `np.dtype[int32]` | `np.float64(10.0)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |
| `np.dtype[int32]` | `np.float64(10.5)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | Yes            | No              |
| `np.dtype[int32]` | `np.float32(10.0)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |
| `np.dtype[int32]` | `np.float32(10.5)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | Yes            | No              |

[^8]: Bug fixed by #11904
[^9]: CUDF doesn't inspect values, so type-based promotion (difference
    from pandas)

#### dtype width == max integer width

Initial values `[2 ** 63 - 10, 2 ** 63 - 100, 3]`.

| Initial dtype     | New value                   | Final dtype (trunk)   | Final dtype (#11904)    | Lossy? (trunk) | Lossy? (#11904) |
|-------------------|-----------------------------|-----------------------|-------------------------|----------------|-----------------|
| `np.dtype[int64]` | `10`                        | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |
| `np.dtype[int64]` | `np.int64(10)`              | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |
| `np.dtype[int64]` | `1099511627776`             | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |
| `np.dtype[int64]` | `np.int64(1099511627776)`   | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |
| `np.dtype[int64]` | `1208925819614629174706176` | OverflowError         | OverflowError           | N/A            | N/A             |
| `np.dtype[int64]` | `10.5`                      | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | Yes            | Yes[^6]         |
| `np.dtype[int64]` | `np.float64(10.0)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | No             | Yes[^6]         |
| `np.dtype[int64]` | `np.float64(10.5)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | Yes            | Yes[^6]         |
| `np.dtype[int64]` | `np.float32(10.0)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | No             | Yes[^6]         |
| `np.dtype[int64]` | `np.float32(10.5)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | Yes            | Yes[^6]         |

### Float column dtypes

#### dtype width < max float width

Initial values `[np.finfo(np.float32).max, np.float32(np.inf), 3]`

| Initial dtype       | New value                            | Final dtype (trunk)     | Final dtype (#11904)    | Lossy? (trunk) | Lossy? (#11904) |
|---------------------|--------------------------------------|-------------------------|-------------------------|----------------|-----------------|
| `np.dtype[float32]` | `10`                                 | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |
| `np.dtype[float32]` | `np.int64(10)`                       | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |
| `np.dtype[float32]` | `1099511627776`                      | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |
| `np.dtype[float32]` | `np.int64(1099511627776)`            | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |
| `np.dtype[float32]` | `np.int32(2147483548)`               | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | Yes[^10]       | No              |
| `np.dtype[float32]` | `np.int64(9223372036854775708)`      | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | Yes[^10]       | Yes[^6]         |
| `np.dtype[float32]` | `1208925819614629174706076`          | OverflowError           | OverflowError           | N/A            | N/A             |
| `np.dtype[float32]` | `10.5`                               | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |
| `np.dtype[float32]` | `np.float64(10.0)`                   | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |
| `np.dtype[float32]` | `np.float64(10.5)`                   | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |
| `np.dtype[float32]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | Yes[^8]        | No              |
| `np.dtype[float32]` | `np.float32(10.0)`                   | `np.dtype[float32]`[^8] | `np.dtype[float32]`[^9] | No             | No              |
| `np.dtype[float32]` | `np.float32(10.5)`                   | `np.dtype[float32]`[^8] | `np.dtype[float32]`[^9] | No             | No              |

[^10]: As for [^6], but promotion from `np.int32` to `np.float32` is
    also not lossless.

#### dtype width == max float width

Initial values `[np.finfo(np.float64).max, np.float64(np.inf), 3]`

| Initial dtype       | New value                            | Final dtype (trunk) | Final dtype (#11904) | Lossy? (trunk) | Lossy? (#11904) |
|---------------------|--------------------------------------|---------------------|----------------------|----------------|-----------------|
| `np.dtype[float64]` | `10`                                 | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `np.int64(10)`                       | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `1099511627776`                      | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `np.int64(1099511627776)`            | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `np.int32(2147483548)`               | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `np.int64(9223372036854775708)`      | `np.dtype[float64]` | `np.dtype[float64]`  | Yes[^6]        | Yes[^6]         |
| `np.dtype[float64]` | `1208925819614629174706076`          | OverflowError       | OverflowError        | N/A            | N/A             |
| `np.dtype[float64]` | `10.5`                               | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `np.float64(10.0)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `np.float64(10.5)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `np.float32(10.0)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |
| `np.dtype[float64]` | `np.float32(10.5)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |

## Everything else

This is where it starts to get _really_ messy. This section is a work
in progress. We should decide what we _want_ the semantics to be,
because in most cases pandas doesn't have the same dtypes that CUDF does.

### Inserting strings into numerical columns

This ""works"", for some value of ""works"" on #11904 if the string value
is parseable as the target dtype.

So

```python
s = cudf.Series([1, 2, 3], dtype=int)
s.iloc[2] = ""4"" # works
s.iloc[2] = ""0xf"" # => ValueError: invalid literal for int() with base 10: '0xf'
```

And similarly for float strings and float dtypes.

This is probably a nice feature.

### Inserting things into string columns

Works if the the ""thing"" is convertible to a string (so numbers work),
but Scalars with list or struct dtypes don't work.

I would argue that explicit casting from the user here is probably
better.

### List columns

The new value must have an identical dtype to that of the target column.

### Struct columns

The new value must have leaf dtypes that are considered compatible in
some sense, but then the leaves are downcast to the leaf dtypes of the
target column. So this is lossy and likely a bug:

```python
 sr = cudf.Series([{""a"": 1, ""b"": 2}])
 sr.iloc[0] = {""a"": 10.5, ""b"": 2}
 sr[0] # => {""a"": 10, ""b"": 2} (lost data in ""a"")
```
## What I think we want (for composite columns)

For composite columns, if the dtype shapes match, I think the casting
rule should be to traverse to the leaf dtypes and promote using the
rules for non-composite columns. If shapes don't match, `__setitem__`
should not be allowed.

This, to me, exhibits principle of least surprise.
",2022-11-01T18:01:16Z,0,0,Lawrence Mitchell,
136,[BUG] cudf astype('int32') behavior does not match pandas,"**Steps/Code to reproduce bug**
```
$ python3.9 -m IPython
Python 3.9.14 (main, Sep  7 2022, 23:43:48) 
Type 'copyright', 'credits' or 'license' for more information
IPython 8.5.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import pandas as pd, cudf

In [2]: pd.__version__, cudf.__version__
Out[2]: ('1.4.4', '22.10.00a+392.g1558403753')

In [3]: pdf = pd.DataFrame({'a': ['123_1']})

In [4]: pdf.a.astype('int32')
Out[4]: 
0    1231
Name: a, dtype: int32

In [5]: cdf = cudf.DataFrame({'a': ['123_1']})

In [6]: cdf.a.astype('int32')
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In [6], line 1
----> 1 cdf.a.astype('int32')

...

File ~/.local/lib/python3.9/site-packages/cudf/core/column/string.py:5314, in StringColumn.as_numerical_column(self, dtype, **kwargs)
   5312 if out_dtype.kind in {""i"", ""u""}:
   5313     if not libstrings.is_integer(string_col).all():
-> 5314         raise ValueError(
   5315             ""Could not convert strings to integer ""
   5316             ""type due to presence of non-integer values.""
   5317         )
   5318 elif out_dtype.kind == ""f"":
   5319     if not libstrings.is_float(string_col).all():

ValueError: Could not convert strings to integer type due to presence of non-integer values.
```

**Expected behavior**
`cudf` to produce the same result as `pandas`


**Environment overview**
```
$ nvidia-smi 
Wed Nov  2 16:48:53 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   56C    P8    15W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```",2022-11-02T16:53:58Z,0,0,Matthew Farrellee,
137,[FEA] cudf.Timestamp,"**Is your feature request related to a problem? Please describe.**
rewriting code from pandas into cudf, using `import cudf as pd`

**Describe the solution you'd like**
`cudf.Timestamp` matching https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html",2022-11-03T12:49:31Z,0,0,Matthew Farrellee,
138,[FEA] cudf::column needs a set_stream() function.,"
`cudf::column` uses `rmm::device_buffer` for internal storage. `rmm::device_buffer` internally stores the stream it was created on.  This can create issues when creating columns on temporary worker-style streams and then returning them to a primary stream.  When the column gets destroyed, rmm throws exceptions about invalid device contexts.

A `set_stream(rmm::cuda_stream_view)` function that recurses through all children would make it easier to hand off columns between streams. 

We initially encountered this issue with `cudf::io::column_buffer` which has a similar problem but it will also be an issue for columns themselves.",2022-11-08T17:39:15Z,0,0,,
139,dataframe.drop not working for multindex[QST],"I have a cudf dataframe which looks like this  
![Screen Shot 2022-11-09 at 3 24 26 PM](https://user-images.githubusercontent.com/23120837/200855560-cdf38efd-c095-42c2-9c8d-269dcac2515d.png)

I want to drop all the rows corresponding to some multiindex. For example I want to drop 

`index_to_drop= cudf.MultiIndex.from_tuples(zip([0,0], [1,2]), names=(""B_0"", ""B_1""))`

`df.drop(index=index_to_drop)` 

I am getting a NotImplementedError, however same thing is working in Pandas",2022-11-09T14:38:27Z,0,0,Arpan Das,The École polytechnique fédérale de Lausanne
140,[BUG] off-by-one errors in `cudf.date_range`,"**Describe the bug**

[As part of attempting to get to XPASS-zero in the test suite]

If the date range is long enough, and for some frequencies, `cudf.date_range` has a fencepost error in the number of dates it produces.

**Steps/Code to reproduce bug**
```python
import cudf
import pandas as pd
start = ""1831-05-08 15:23:21""
end = ""1996-11-21 04:05:30""
freq = ""110546789L""

cr = cudf.date_range(start=start, end=end, freq=freq)
pr = pd.date_range(start=start, end=end, freq=freq)

assert len(cr) == len(pr) # => False, len(cr) == len(pr) + 1
print(cr[-1])
# => 1996-11-21T14:14:21.984000000
# Which is _after_ the specified end
```

**Expected behavior**

No fencepost error.",2022-11-11T18:47:11Z,0,0,Lawrence Mitchell,
141,Behaviour of inplace for `copy_range` when range is empty.,"In `copying.copy_range` we have an `inplace=False/True` argument.

If `inplace` is `True`, then the column is modified in place, if `inplace` is False, a new (copied) column is created and then modified. If the case that the range we are copying is empty, at present `inplace=False` _still_ returns a new copy (even though `copy_range` is a no-op in this situation).

Should it be allowed that

```
copy_range(source, target, empty_range, inplace=False)
```

Can return `target` (rather than a copy of `target`)?

See discussion where this came p: https://github.com/rapidsai/cudf/pull/12075#discussion_r1015307155
      

",2022-11-14T11:17:05Z,0,0,Lawrence Mitchell,
142,[FEA] Follow up on refactoring possibility from parquet chunked reader PR,"There is a small refactoring that can be done to de-duplicate some code in the parquet decoder which needs to be done as a followup.

https://github.com/rapidsai/cudf/pull/11867#discussion_r1022137500

<img width=""770"" alt=""image"" src=""https://github.com/rapidsai/cudf/assets/12725111/e10d9380-c7bf-4c37-9dfc-c1c6d301b211"">


",2022-11-15T02:44:37Z,0,0,,
143,[BUG/pandas-compat]: Handling of type promotion and division/mod by zero for boolean columns ,"After #12074, most type promotions between columns of mixed types (and non-mixed types) match pandas. The exception is columns with boolean dtypes.

Pandas have taken the decision to disallow division and exponentiation on boolean types when both operands are booleans (https://github.com/pandas-dev/pandas/blob/d13c9e034ce8a1d738766c4b1cec80c76f5523be/pandas/core/ops/array_ops.py#L503).

Aside: I kind of disagree with this since this is all perfectly well defined (excepting the usual caveat of division by zero).

When only one of the operands is `bool`, the status quo depends on the dtype of the other operand:

## Pandas behaviour:

For `a % b`, with `a == 1`, `b == 0` for various dtypes

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | int8(0) (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |
| int | int64(0) (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |
| float | float64(NaN) (or ZeroDivisionError[^1])| float64(NaN) | float64(NaN) |

For `a / b` (or `a // b`) with `a == 1`, `b = 0`

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | NotImplemented (or ZeroDivisionError[^1]) | float64(inf) | float64(inf) |
| int | float64(inf)(or ZeroDivisionError[^1]) | float64(inf) | float64(inf) |
| float | float64(inf) (or ZeroDivisionError[^1])| float64(inf) | float64(inf) |

For `a % b`, with `a == 0`, `b == 0` for various dtypes

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | int8(0)(or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |
| int | int64(0) (or ZeroDivisionError[^1])| float64(NaN) | float64(NaN) |
| float | float64(NaN) (or ZeroDivisionError[^1])| float64(NaN) | float64(NaN) |

For `a / b` (or `a // b`) with `a == 0`, `b = 0`

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | NotImplemented (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |
| int | float64(NaN) (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |
| float | float64(NaN) (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |

[^1]: If the operands are different lengths, we get a ZeroDivisionError (see https://github.com/pandas-dev/pandas/issues/49699)

## cuDF behaviour:

For `a % b`, with `a == 1`, `b == 0` for various dtypes

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | bool(0) | float64(NaN) | float64(NaN) |
| int | int64(2**32 - 1) | float64(NaN) | float64(NaN) |
| float | float64(NaN) | float64(NaN) | float64(NaN) |

For `a // b` with `a == 1`, `b = 0`

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | bool(1) | float64(inf) | float64(inf) |
| int | int64(2**32 - 1) | float64(inf) | float64(inf) |
| float | float64(inf) | float64(inf) | float64(inf) |

For `a / b` with `a == 1`, `b = 0`

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | float32(inf) | float64(inf) | float64(inf) |
| int | float64(inf) | float64(inf) | float64(inf) |
| float | float64(inf) | float64(inf) | float64(inf) |

For `a % b`, with `a == 0`, `b == 0` for various dtypes

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | bool(0) | float64(NaN) | float64(NaN) |
| int | int64(2**32 - 1) | float64(NaN) | float64(NaN) |
| float | float64(NaN) | float64(NaN) | float64(NaN) |

For `a // b` with `a == 0`, `b = 0`

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | bool(False) | float64(NaN) | float64(NaN) |
| int | int64(2**32 - 1) | float64(NaN) | float64(NaN) |
| float | float64(NaN) | float64(NaN) | float64(NaN) |

For `a / b` with `a == 0`, `b = 0`

|  dtype-a \ dtype-b  | bool | int | float |
|----------|------|------|-|
| bool | float32(NaN) | float64(NaN) | float64(NaN) |
| int | float64(NaN) | float64(NaN) | float64(NaN) |
| float | float64(NaN) | float64(NaN) | float64(NaN) |",2022-11-16T11:31:10Z,0,0,Lawrence Mitchell,
144,[FEA] Use RMM memory pool by default,"We should move to using an RMM managed memory pool by default.

This was brought up before in https://github.com/rapidsai/cudf/issues/2676. In response to that issue, we implemented `set_allocator`, https://github.com/rapidsai/cudf/pull/2682, but we chose not to enable the RMM pool by default (likely because we didn't want to monopolize GPU memory away from other libraries). 

Since then, CuPy, Numba (and soon [PyTorch](https://github.com/pytorch/pytorch/pull/86786)) all can be configured to use RMM, and therefore share the same memory pool as cuDF.

## Proposal

Concretely, the proposal is that `import cudf` will:

* Set RMM's default memory resource to a [pool memory resource](https://docs.rapids.ai/api/rmm/stable/api.html#rmm.mr.PoolMemoryResource)
* Configure CuPy, Numba, (and PyTorch?) to all use RMM's default memory resource

## What should the initial and maximum pool size be? 

An RMM pool can be configured with an initial and maximum pool size. The pool grows according to an implementation-defined strategy (see [here](https://github.com/rapidsai/rmm/blob/d132e5236b444d2dcdae25e846c4fe4d5651ee79/include/rmm/mr/device/pool_memory_resource.hpp#L246-L249) for the current strategy).

- As we cannot assume that all (or any) GPU memory is available when cuDF is imported, the initial pool size should be 0 bytes.
- The only reasonable maximum pool size I can think of is the maximum available GPU memory. If the pool cannot expand to this size because of allocations made outside of RMM, so be it: we will OOM. 

## What happens if `import cudf` appears in the middle of the program?

All this works well if `import cudf` appears at the beginning of the program, i.e., before any device memory is actually allocated by any library). However, if it appears _after_ some device objects have already been allocated, it can lead to early out-of-memory errors. As an example, consider some code that uses both PyTorch and cuDF in the following way:

```python
import torch
 
# this part of the code uses PyTorch

import cudf

# this part of the code uses cudf
```

Because PyTorch [uses a caching allocator](https://pytorch.org/docs/stable/notes/cuda.html#memory-management), a memory pool already exists by the time we import cuDF. Importing cuDF initializes a second pool that all libraries (including PyTorch) will use going forward. The first pool essentially becomes a kind of dead space: no new device objects are ever allocated within the pool, and no device memory is ever freed from it. 

There's no perfect solution I can think of to this particular problem, but it's probably a good idea to call [`empty_cache()`](https://pytorch.org/docs/stable/generated/torch.cuda.empty_cache.html#torch.cuda.empty_cache) before resetting the PyTorch allocator to minimize the amount of wasted memory.

---

That's just one example of the kind of issues that can arise if `import cudf` appears later. I think it's fine to assume this will be less common than importing it at the beginning.",2022-11-23T16:49:48Z,2,0,Ashwin Srinath,Voltron Data
145,[BUG] libcudf tests of binary operations (in `binop-compiled-test.cpp`) mostly do not test against a ground truth,"**Describe the bug**

Binary operations between columns are implemented by runtime typed dispatch to device functors in [`cpp/src/binaryop/compiled/operation.cuh`](https://github.com/rapidsai/cudf/blob/7426a06a4510280650df4cf54b76504d690c80b2/cpp/src/binaryop/compiled/operation.cuh).

Tests of this functionality compare to host-based compute, with an implementation of the functors in [`cpp/tests/binaryop/util/operation.h`](https://github.com/rapidsai/cudf/blob/7426a06a4510280650df4cf54b76504d690c80b2/cpp/tests/binaryop/util/operation.h)

This is a very weak test of correctness that really is testing:

1. Can the author of the test copy the device functor implementation into the host implementation?
2. Can the device and host compilers emit correct code for these cases?

These tests should more properly test against a ground truth (either manually constructed, or automatically).",2022-11-24T18:40:03Z,0,0,Lawrence Mitchell,
146,[FEA] Support device-side de/compression of CSV files,"I have a lot of gzip compressed CSV files. When I use cudf to read them, the host handles decompression before copying decompressed data to device.

For cudf, that's not a problem, since it'll at worst be no slower than CPU.

But when I read w/ dask_cudf, compared to CPU dask.dataframe, I will usually have <=8 workers in a LocalCUDACluster. If I'm reading a large number of compressed files, those 8 workers will be highly bottlenecked by decompression.

**Describe the solution you'd like**
Ideally, we could have fast device side decompression for gzip compressed CSVs.

**Describe alternatives you've considered**
Another solution for dask_cudf could be some logic to make more parallel use of host CPUs for decompression, which should increase throughput t device.

**Additional context**
Per file compression level can be high, such that doing device side decompression, even if faster than CPU, could easily lead to OOM scenarios.

An illustrative dataset for use in exploring this problem is NOAA's daily weather observations:
```
import urllib, os

data_dir = '/raid/weather/csv/'

# download weather observations
base_url = 'ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/'
years = list(range(1763, 2020))
for year in years:
    fn = str(year) + '.csv.gz'
    if not os.path.isfile(data_dir+fn):
        print(f'Downloading {base_url+fn} to {data_dir+fn}')
        urllib.request.urlretrieve(base_url+fn, data_dir+fn) 
```

cc @GregoryKimball ",2022-11-29T17:34:28Z,0,0,Randy Gelhausen,
147,[FEA] automatic construction of MultiIndex DataFrame,"**Is your feature request related to a problem? Please describe.**
rewriting code from pandas into cudf, using `import cudf as pd`

**Describe the solution you'd like**
```
>>> import pandas as pd
>>> import cudf
>>> cudf.__version__
'22.12.00a+281.gcc4b4dd27c'
>>> df = pd.DataFrame([[1],[2]], index=[['a', 'a'],['b','c']])
>>> df
     0
a b  1
  c  2
>>> cudf.DataFrame([[1],[2]], index=[['a', 'a'],['b','c']])
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/opt/conda/envs/rapids/lib/python3.9/contextlib.py"", line 79, in inner
    return func(*args, **kwds)
  File ""/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py"", line 710, in __init__
    self._init_from_list_like(
  File ""/opt/conda/envs/rapids/lib/python3.9/contextlib.py"", line 79, in inner
    return func(*args, **kwds)
  File ""/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py"", line 838, in _init_from_list_like
    index = as_index(index)
  File ""/opt/conda/envs/rapids/lib/python3.9/contextlib.py"", line 79, in inner
    return func(*args, **kwds)
  File ""/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/index.py"", line 3019, in as_index
    return as_index(
  File ""/opt/conda/envs/rapids/lib/python3.9/contextlib.py"", line 79, in inner
    return func(*args, **kwds)
  File ""/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/index.py"", line 3005, in as_index
    return _index_from_data({kwargs.get(""name"", None): arbitrary})
  File ""/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/index.py"", line 122, in _index_from_data
    raise NotImplementedError(
NotImplementedError: Unsupported column type passed to create an Index: <class 'cudf.core.column.lists.ListColumn'>
```
i would like the same functionality in `cudf` as is present in `pandas` (see https://pandas.pydata.org/docs/user_guide/advanced.html#hierarchical-indexing-multiindex)",2022-11-29T23:08:04Z,0,0,Matthew Farrellee,
148,[FEA] cudf.DataFrame.xs,"**Is your feature request related to a problem? Please describe.**
rewriting code from pandas to cudf, using `import cudf as pd`


**Describe the solution you'd like**
`cudf.DataFrame.xs` matching https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.xs.html",2022-11-29T23:18:59Z,0,0,Matthew Farrellee,
149,[BUG] DataFrame.groupby.describe differs between cudf and pandas,"**Describe the bug**
```
>>> import pandas as pd
>>> import cudf
>>> cudf.__version__
'22.12.00a+281.gcc4b4dd27c'
>>> data = {'a': ['b'], 'p': ['q'], 'n': [0]}
>>> pd.DataFrame(data).groupby('a').describe()
      n                                  
  count mean std  min  25%  50%  75%  max
a                                        
b   1.0  0.0 NaN  0.0  0.0  0.0  0.0  0.0
>>> cudf.DataFrame(data).groupby('a').describe()
      p             n                                  
  count min max count mean   std min  25%  50%  75% max
a                                                      
b     1   q   q     1  0.0  <NA>   0  0.0  0.0  0.0   0
```

**Environment overview (please complete the following information)**
rapidsai/rapidsai-nightly:22.12-cuda11.5-runtime-rockylinux8-py3.9 on 29 nov 2022",2022-11-30T00:51:25Z,0,0,Matthew Farrellee,
150,"[FEA] For cuDF `bench_merge`, make output size scale with input size","**Is your feature request related to a problem? Please describe.**
The benchmark [bench_merge](https://github.com/rapidsai/cudf/blob/ff3b64325d3ac48fc0e8e0e9e1cf6246dd4aa075/python/cudf/benchmarks/API/bench_dataframe.py#L32) in [bench_dataframe.py](https://github.com/rapidsai/cudf/blob/branch-23.02/python/cudf/benchmarks/API/bench_dataframe.py) yields geometrically-increasing output size when `num_key_cols=2` . As a result, this particular benchmark runs into out-of-memory failures long before any other in the benchmarking suite. 

**Describe the solution you'd like**
I would like to add a data generator with characteristics that make the output row count a roughly constant multiple of the input row count. 

**Describe alternatives you've considered**
One alternative is to disable this benchmark for row counts >1M. However, cuDF join performance is one of its strongest features and we don't want to restrict our benchmarking to smaller tables.

**Additional context**
Here is a code snippet that demonstrates the problem as well as a potential solution.
```
import string
import cupy
import cudf

random_state = cupy.random.RandomState(42)
column_generators = {
    ""int"": (lambda nr: random_state.randint(low=0, high=100, size=nr)),
    ""inthc"": (lambda nr: random_state.randint(low=0, high=nr ** 0.5, size=nr)),
}

for gen in ['int', 'inthc']:       
    print(f'using column generator key {gen}')
    for nr in [100, 10_000, 100_000, 1_000_000]:               
        df = cudf.DataFrame({f""{string.ascii_lowercase[i]}"": column_generators[gen](nr)  for i in range(6)})
        m = df.merge(df, on=['a', 'b'])
        print('for input size {}, output size is {} (the ratio is {:.2f})'.format(nr, len(m), len(m)/nr))
```

```
using column generator key int
for input size 100, output size is 100 (the ratio is 1.00)
for input size 10000, output size is 20234 (the ratio is 2.02)
for input size 100000, output size is 1100538 (the ratio is 11.01)
for input size 1000000, output size is 101002012 (the ratio is 101.00)
using column generator key inthc
for input size 100, output size is 214 (the ratio is 2.14)
for input size 10000, output size is 19868 (the ratio is 1.99)
for input size 100000, output size is 199970 (the ratio is 2.00)
for input size 1000000, output size is 2000782 (the ratio is 2.00)
```
",2022-12-01T05:43:36Z,0,0,Gregory Kimball,
151,Poor scaling for larger query/loc with cudf Dataframe[QST],"I am trying to extract the some columns of a cudf dataframe 

```
%%time
cudf_file = ""/work/ska/cudfoutput/lofar30MHz1_t201806301100_SBL153.parquet""
df = cudf.read_parquet(cudf_file, columns =['TIME','ANTENNA1','ANTENNA2','FLAG','DATA'])
df3 = df.loc[df['TIME'].isin(unique_time)]
for t in unique_time:   
    df2 = df3[df3.TIME == t]
    beam_id_0_cp = cp.asarray(df2['ANTENNA1'])
    beam_id_1_cp = cp.asarray(df2['ANTENNA2'])
    dfflag = df2['FLAG']
    data_flag_cp = cp.asarray(dfflag.list.leaves).reshape(len(dfflag),len(dfflag.iloc[0]),len(dfflag.iloc[0][0]))
    dfdata = df2['DATA']
    data_cp = cp.asarray(dfdata.list.leaves, dtype=np.float64).reshape(len(dfdata),len(dfdata.iloc[0]),len(dfdata.iloc[0][0])).view(np.complex128)
   ```

The scaling becomes worse if we have a bigger loop (>1000 steps), for smaller timesteps it is the faster but as we go higher the scaling is becoming an issue. However, I am wondering why as I am not reading the dataframe inside the loop. Is there a better way to do this? I have tried groupby as well and the results are similar",2022-12-02T11:13:41Z,0,0,Arpan Das,The École polytechnique fédérale de Lausanne
152,[FEA] Support segmented reductions (MIN/MAX/COUNT DISTINCT) in cuDF `list` accessor,"**Is your feature request related to a problem? Please describe.**

Currently, we use cuDF to implement distributed group aggregation operations. That is, GROUP BY + DISTINCT is performed on the local node, and GROUP BY + MIN/MAX/COUNT DISTINCT are performed on the merge node. The LIST is transferred as an intermediate format, but the aggregation operation cannot be implemented.

**Describe the solution you'd like**

Group +  Aggregation supports the list format.

![捕获2](https://user-images.githubusercontent.com/43532055/205540928-0359139e-03ea-4c71-bd8d-0daaf0d5f875.PNG)

**Describe alternatives you've considered**

Aggregation operators are supported in the list format. For example, the current list supports only `len`, and aggregation operators such as `count`, `min`, `max`, and `avg` are expected to be added.

![捕获](https://user-images.githubusercontent.com/43532055/205540951-3d8b4f09-7227-4cb1-836e-49e79c428e31.PNG)
",2022-12-05T03:11:31Z,0,0,Liu,
153,[FEA] AST expression was provided non-matching operand types,"**Is your feature request related to a problem? Please describe.**
rewriting `pandas` code with `import cudf as pd`

**Describe the solution you'd like**
```
>>> import pandas as pd
>>> import cudf
>>> cudf.__version__
'22.10.01+2.gca9a422da9' <- rapidsai/rapidsai-nightly:cuda11.5-runtime-centos7-py3.9 (3b7d5d24867a) on 6 dec 2022
>>> df = cudf.DataFrame({'a': [1,2,3], 'b': [3.0,2.0,1.0]})
>>> df.to_pandas().eval('a + b')
0    4.0
1    4.0
2    4.0
dtype: float64
>>> df.eval('a + b')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/opt/conda/envs/rapids/lib/python3.9/contextlib.py"", line 79, in inner
    return func(*args, **kwds)
  File ""/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py"", line 6766, in eval
    None: libcudf.transform.compute_column(
  File ""transform.pyx"", line 190, in cudf._lib.transform.compute_column
RuntimeError: cuDF failure at: /workspace/.conda-bld/work/cpp/src/ast/expression_parser.cpp:149: An AST expression was provided non-matching operand types.
```

same behavior as `pandas`
",2022-12-06T18:09:14Z,0,0,Matthew Farrellee,
154,[FEA] Support inferring column names when using the `byte_range=` parameter in `read_csv`  ,"I cannot use the `byte_range` parameter with `read_csv` if the column names need to be inferred.

```python
>>> cudf.read_csv(StringIO(""1,2,3\n4,5,6""), dtype=int, byte_range=(3, 6))
RuntimeError: cuDF failure at: cudf/cpp/src/io/csv/reader_impl.cu:438: byte_range offset with header not supported
```

But this works:

```python
>>> cudf.read_csv(StringIO(""1,2,3\n4,5,6""), dtype=int, byte_range=(3, 6), names=['x', 'y', 'z'])
   x  y  z
0  4  5  6
```

And this works:

```python
>>> cudf.read_csv(StringIO(""1,2,3\n4,5,6""), dtype=int, byte_range=(3, 6), header=None)
   0  1  2
0  4  5  6
```
",2022-12-07T12:53:06Z,0,0,Ashwin Srinath,Voltron Data
155,[BUG] Random sampling with cupy does not support these inputs,"Weighted sampling with cudf series is documented as supported but throws the following error

Repro:
```
a = cudf.Series(range(100))
a.sample(n=10, weights=a.values_host, random_state=0)

or

a = cudf.Series(range(100))
a.sample(n=10, weights=a.values_host, random_state=0)

```

Exception:
```
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
File /conda/envs/rapids-22.12/lib/python3.9/site-packages/cudf/core/indexed_frame.py:2952, in IndexedFrame._sample_axis_0(self, n, weights, replace, random_state, ignore_index)
   2951 try:
-> 2952     gather_map_array = random_state.choice(
   2953         len(self), size=n, replace=replace, p=weights
   2954     )
   2955 except NotImplementedError as e:

File /conda/envs/rapids-22.12/lib/python3.9/site-packages/cupy/random/_generator.py:1066, in RandomState.choice(self, a, size, replace, p)
   1065 if not replace:
-> 1066     raise NotImplementedError
   1068 if p is not None:

NotImplementedError: 

The above exception was the direct cause of the following exception:

NotImplementedError                       Traceback (most recent call last)
Cell In [25], line 2
      1 a = cudf.Series(range(100))
----> 2 a.sample(n=10, weights=a, random_state=0)

File /conda/envs/rapids-22.12/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File /conda/envs/rapids-22.12/lib/python3.9/site-packages/cudf/core/indexed_frame.py:2930, in IndexedFrame.sample(self, n, frac, replace, weights, random_state, axis, ignore_index)
   2927     weights = weights / weights.sum()
   2929 if axis == 0:
-> 2930     return self._sample_axis_0(
   2931         n, weights, replace, random_state, ignore_index
   2932     )
   2933 else:
   2934     if isinstance(random_state, cp.random.RandomState):

File /conda/envs/rapids-22.12/lib/python3.9/site-packages/cudf/core/indexed_frame.py:2956, in IndexedFrame._sample_axis_0(self, n, weights, replace, random_state, ignore_index)
   2952     gather_map_array = random_state.choice(
   2953         len(self), size=n, replace=replace, p=weights
   2954     )
   2955 except NotImplementedError as e:
-> 2956     raise NotImplementedError(
   2957         ""Random sampling with cupy does not support these inputs.""
   2958     ) from e
   2960 return self._gather(
   2961     cudf.core.column.as_column(gather_map_array),
   2962     keep_index=not ignore_index,
   2963     check_bounds=False,
   2964 )

NotImplementedError: Random sampling with cupy does not support these inputs.
```",2022-12-08T17:08:17Z,0,0,Lahir Marni,
156,[FEA] support type float16,"**Is your feature request related to a problem? Please describe.**
rewriting code from pandas with `import cudf as pd` and managing memory usage

**Describe the solution you'd like**
```
df['src'] = df['src'].astype('float16')

cudf/core/dtypes.py:51, in dtype(arbitrary)
...
TypeError: Unsupported type float16
```",2022-12-12T16:29:14Z,0,0,Matthew Farrellee,
157,Turn on `xfail_strict=true` in all subpackages,"Followup to #12244.

Can we do the same for other packages in the repo? I would expect that dask-cudf / custreamz / cudf-kafka / strings_udf won't have as many problems as cudf.

_Originally posted by @bdice in https://github.com/rapidsai/cudf/pull/12244#discussion_r1048803383_
      ",2022-12-15T11:11:31Z,0,0,Lawrence Mitchell,
158,Split out exceptional cases in heavily parametrized array ufunc tests,"Followup to #12244; A number of the parametrized array ufunc tests need to xfail (or skip) a large subsection of their parameters since the behaviour varies.

In many cases, this is not really a bug that we're intending to fix, and so the ""xfail""s pollute test output and hide what is really problematic from what is not.

_Originally posted by @vyasr in https://github.com/rapidsai/cudf/pull/12244#discussion_r1049220334_",2022-12-15T11:21:25Z,0,0,Lawrence Mitchell,
159,[FEA] DatetimeProperties day_name matching pandas,"**Is your feature request related to a problem? Please describe.**
converting code with `import cudf as pd`

```
>>> import cudf as pd
>>> pd.__version__
'22.12.01'
>>> df = pd.Series(pd.date_range(""1984"", freq='s', periods=6))
>>> df.to_pandas().dt.day_name()
0    Sunday
1    Sunday
2    Sunday
3    Sunday
4    Sunday
5    Sunday
dtype: object
>>> df.dt.day_name()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'DatetimeProperties' object has no attribute 'day_name'
>>> type(df.dt)
<class 'cudf.core.series.DatetimeProperties'>
```

**Describe the solution you'd like**
implementation of `day_name()` matching https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_name.html

",2022-12-17T15:01:49Z,0,0,Matthew Farrellee,
160,[BUG] cannot pass numpy funcs to groupby().agg(),"**Describe the bug**
converting code with `import cudf as pd`

**Steps/Code to reproduce bug**
```
>>> import cudf as pd
>>> pd.__version__
'22.12.01'
>>> df = pd.DataFrame({'a': [1,2,3]*10})

>>> df.to_pandas().groupby('a').agg({'a': np.sum})
    a
a    
1  10
2  20
3  30

>>> df.groupby('a').agg({'a': np.sum})
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".../python3.8/contextlib.py"", line 75, in inner
    return func(*args, **kwds)
  File "".../python3.8/site-packages/cudf/core/groupby/groupby.py"", line 460, in agg
    ) = self._groupby.aggregate(columns, normalized_aggs)
  File ""groupby.pyx"", line 309, in cudf._lib.groupby.GroupBy.aggregate
  File ""groupby.pyx"", line 184, in cudf._lib.groupby.GroupBy.aggregate_internal
  File ""aggregation.pyx"", line 866, in cudf._lib.aggregation.make_groupby_aggregation
  File ""<__array_function__ internals>"", line 180, in sum
  File "".../python3.8/site-packages/numpy/core/fromnumeric.py"", line 2298, in sum
    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,
  File "".../python3.8/site-packages/numpy/core/fromnumeric.py"", line 84, in _wrapreduction
    return reduction(axis=axis, out=out, **passkwargs)
TypeError: sum() got an unexpected keyword argument 'out'
```
",2022-12-17T15:10:18Z,0,0,Matthew Farrellee,
161,[BUG] pivot_table does not accept single index / columns,"**Describe the bug**
cannot use `import cudf as pd`

**Steps/Code to reproduce bug**
```
>>> import cudf as pd
>>> pd.__version__
'22.12.01'

>>> df = pd.DataFrame({""A"": [""foo"", ""foo"", ""foo"", ""foo"", ""foo"",
...                          ""bar"", ""bar"", ""bar"", ""bar""],
...                    ""B"": [""one"", ""one"", ""one"", ""two"", ""two"",
...                          ""one"", ""one"", ""two"", ""two""],
...                    ""C"": [""small"", ""large"", ""large"", ""small"",
...                          ""small"", ""large"", ""small"", ""small"",
...                          ""large""],
...                    ""D"": [1, 2, 2, 3, 3, 4, 5, 6, 7],
...                    ""E"": [2, 4, 5, 5, 6, 6, 8, 9, 9]})
>>> df
     A    B      C  D  E
0  foo  one  small  1  2
1  foo  one  large  2  4
2  foo  one  large  2  5
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9


>>> df.to_pandas().pivot_table(values='D', index='A', columns='C', aggfunc='sum')
C    large  small
A                
bar     11     11
foo      4      7

>>> df.pivot_table(values='D', index='A', columns='C', aggfunc='sum')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".../python3.8/contextlib.py"", line 75, in inner
    return func(*args, **kwds)
  File "".../python3.8/site-packages/cudf/core/dataframe.py"", line 6749, in pivot_table
    return cudf.core.reshape.pivot_table(
  File "".../python3.8/site-packages/cudf/core/reshape.py"", line 1382, in pivot_table
    for x in keys + values:
TypeError: can only concatenate str (not ""list"") to str
```",2022-12-17T17:20:57Z,0,0,Matthew Farrellee,
162,[BUG] pivot_table columns type differs from pandas,"**Describe the bug**
rewriting code with `import cudf as pd`

**Steps/Code to reproduce bug**
```
>>> import cudf as pd
>>> pd.__version__
'22.12.01'
>>> df = pd.DataFrame({""A"": [""foo"", ""foo"", ""foo"", ""foo"", ""foo"",
...                          ""bar"", ""bar"", ""bar"", ""bar""],
...                    ""B"": [""one"", ""one"", ""one"", ""two"", ""two"",
...                          ""one"", ""one"", ""two"", ""two""],
...                    ""C"": [""small"", ""large"", ""large"", ""small"",
...                          ""small"", ""large"", ""small"", ""small"",
...                          ""large""],
...                    ""D"": [1, 2, 2, 3, 3, 4, 5, 6, 7],
...                    ""E"": [2, 4, 5, 5, 6, 6, 8, 9, 9]})
>>> df.pivot_table(index=['A'], columns=['B'], values='D')
B         one  two
A                 
bar  4.500000  6.5
foo  1.666667  3.0
>>> df.to_pandas().pivot_table(index=['A'], columns=['B'], values='D')
B         one  two
A                 
bar  4.500000  6.5
foo  1.666667  3.0
>>> df.to_pandas().pivot_table(index=['A'], columns=['B'], values='D').columns
Index(['one', 'two'], dtype='object', name='B')
>>> df.pivot_table(index=['A'], columns=['B'], values='D').columns
MultiIndex([('one',),
            ('two',)],
           names=['B'])
```

**Expected behavior**
an `Index` when only aggregating across one column",2022-12-17T19:27:20Z,0,0,Matthew Farrellee,
163,[FEA] groupby.agg() support for controlling output columns,"**Is your feature request related to a problem? Please describe.**
rewriting code with `import cudf as pd`

**Describe the solution you'd like**
```
>>> import cudf as pd
>>> pd.__version__
'22.12.01'

>>> df = pd.DataFrame({'kind': ['cat', 'dog', 'cat', 'dog'], 'height': [9.1, 6.0, 9.5, 34.0], 'weight': [7.9, 7.5, 9.9, 198.0]})
>>> df
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

>>> df.to_pandas().groupby('kind').agg(min_height=('height', 'min'), max_weight=('weight', 'max'))
      min_height  max_weight
kind                        
cat          9.1         9.9
dog          6.0       198.0

>>> df.groupby('kind').agg(min_height=('height', 'min'), max_weight=('weight', 'max'))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".../python3.8/contextlib.py"", line 75, in inner
    return func(*args, **kwds)
TypeError: agg() got an unexpected keyword argument 'min_height'
```

references:
- https://github.com/pandas-dev/pandas/pull/26399
- https://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.20.0.html#deprecate-groupby-agg-with-a-dictionary-when-renaming",2022-12-17T22:38:18Z,0,0,Matthew Farrellee,
164,[BUG] read_csv() got an unexpected keyword argument 'encoding',"**Is your feature request related to a problem? Please describe.**
rewriting code using `import cudf as pd`

**Describe the solution you'd like**
implementation of `encoding` parameter that matches https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas-read-csv
",2022-12-17T23:59:13Z,0,0,Matthew Farrellee,
165,[BUG] support index functions in cudf.DataFrame.rename,"**Is your feature request related to a problem? Please describe.**
rewriting code with `import cudf as pd`

**Describe the solution you'd like**
```
>>> import cudf as pd
>>> pd.__version__
'22.12.01'
>>> df = pd.DataFrame({'a': range(10)})
>>> df = df.rename(index=str, columns={'a': 'b'})
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".../python3.8/contextlib.py"", line 75, in inner
    return func(*args, **kwds)
  File "".../python3.8/site-packages/cudf/core/dataframe.py"", line 3365, in rename
    any(type(item) == str for item in index.values())
AttributeError: type object 'str' has no attribute 'values'
```",2022-12-18T12:24:38Z,0,0,Matthew Farrellee,
166,[FEA] support tuple construction in apply with axis=1,"**Is your feature request related to a problem? Please describe.**
rewriting code with `import cudf as pd`

**Describe the solution you'd like**
```
>>> import cudf as pd
>>> df = pd.DataFrame({'a': range(10, 20), 'b': range(110, 120)})
>>> pd.__version__
'22.12.01'

>>> df.apply(lambda row: (row[0], row[1]), axis=1)
...
numba.core.errors.NumbaNotImplementedError: UniTuple(Masked(int64) x 2) cannot be represented as a NumPy dtype
```",2022-12-18T12:39:53Z,0,0,Matthew Farrellee,
167,[BUG] Series.clip does not work with numpy/cupy clip,"**Describe the bug**
rewriting code with `import cudf as pd`

**Steps/Code to reproduce bug**
```
>>> import cudf as pd
>>> import cupy as np
>>> pd.__version__
'22.12.01'
>>> np.__version__
'11.4.0'

>>> df = pd.DataFrame({'a': range(10, 30)})

>>> np.clip(df.to_pandas().a, a_min=15, a_max=25)
0     15
1     15
2     15
3     15
4     15
5     15
6     16
7     17
8     18
9     19
10    20
11    21
12    22
13    23
14    24
15    25
16    25
17    25
18    25
19    25
Name: a, dtype: int64

>>> np.clip(df.a, a_min=15, a_max=25)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".../python3.8/site-packages/cupy/_math/misc.py"", line 172, in clip
    return a.clip(a_min, a_max, out=out)
  File "".../python3.8/contextlib.py"", line 75, in inner
    return func(*args, **kwds)
TypeError: clip() got an unexpected keyword argument 'out'
```

**Additional context**
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.clip.html
```
*args, **kwargs
    Additional keywords have no effect but might be accepted for compatibility with numpy.
```
",2022-12-18T13:19:47Z,0,0,Matthew Farrellee,
168,[BUG] date_range support for computed parameters,"**Is your feature request related to a problem? Please describe.**
rewriting code with `import cudf as pd`

**Describe the solution you'd like**
implementation of `cudf.date_range` that matches https://pandas.pydata.org/docs/reference/api/pandas.date_range.html

specifically the ability to compute missing parameters

```
>>> import cudf as pd
>>> pd.__version__
'22.12.01'
>>> pd.date_range(100, periods=42)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".../python3.8/site-packages/cudf/core/tools/datetimes.py"", line 820, in date_range
    raise ValueError(
ValueError: Of the four parameters: start, end, periods, and freq, exactly three must be specified
>>> import pandas
>>> pandas.date_range(100, periods=42)
DatetimeIndex(['1970-01-01 00:00:00.000000100',
               '1970-01-02 00:00:00.000000100',
               '1970-01-03 00:00:00.000000100',
               '1970-01-04 00:00:00.000000100',
               '1970-01-05 00:00:00.000000100',
               '1970-01-06 00:00:00.000000100',
               '1970-01-07 00:00:00.000000100',
               '1970-01-08 00:00:00.000000100',
               '1970-01-09 00:00:00.000000100',
               '1970-01-10 00:00:00.000000100',
               '1970-01-11 00:00:00.000000100',
               '1970-01-12 00:00:00.000000100',
               '1970-01-13 00:00:00.000000100',
               '1970-01-14 00:00:00.000000100',
               '1970-01-15 00:00:00.000000100',
               '1970-01-16 00:00:00.000000100',
               '1970-01-17 00:00:00.000000100',
               '1970-01-18 00:00:00.000000100',
               '1970-01-19 00:00:00.000000100',
               '1970-01-20 00:00:00.000000100',
               '1970-01-21 00:00:00.000000100',
               '1970-01-22 00:00:00.000000100',
               '1970-01-23 00:00:00.000000100',
               '1970-01-24 00:00:00.000000100',
               '1970-01-25 00:00:00.000000100',
               '1970-01-26 00:00:00.000000100',
               '1970-01-27 00:00:00.000000100',
               '1970-01-28 00:00:00.000000100',
               '1970-01-29 00:00:00.000000100',
               '1970-01-30 00:00:00.000000100',
               '1970-01-31 00:00:00.000000100',
               '1970-02-01 00:00:00.000000100',
               '1970-02-02 00:00:00.000000100',
               '1970-02-03 00:00:00.000000100',
               '1970-02-04 00:00:00.000000100',
               '1970-02-05 00:00:00.000000100',
               '1970-02-06 00:00:00.000000100',
               '1970-02-07 00:00:00.000000100',
               '1970-02-08 00:00:00.000000100',
               '1970-02-09 00:00:00.000000100',
               '1970-02-10 00:00:00.000000100',
               '1970-02-11 00:00:00.000000100'],
              dtype='datetime64[ns]', freq='D')
```

**Additional context**
gooooooaaaaaallllll!",2022-12-18T15:38:13Z,0,0,Matthew Farrellee,
169,[BUG] date_range support for anchored offsets,"**Is your feature request related to a problem? Please describe.**
updating code to use `import cudf as pd`

**Describe the solution you'd like**
`cudf.date_range` support matching `pandas.date_range`

see https://pandas.pydata.org/docs/reference/api/pandas.date_range.html
see https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases

```
>>> import cudf as pd
>>> pd.__version__
'22.12.01'
>>> import pandas
>>> pandas.__version__
'1.2.2'
>>> pd.date_range('2011-12-31T00:00:00.000000000', periods=52, freq='W-FRI')
DatetimeIndex(['2011-12-31', '2012-01-07', '2012-01-14', '2012-01-21',
               '2012-01-28', '2012-02-04', '2012-02-11', '2012-02-18',
               '2012-02-25', '2012-03-03', '2012-03-10', '2012-03-17',
               '2012-03-24', '2012-03-31', '2012-04-07', '2012-04-14',
               '2012-04-21', '2012-04-28', '2012-05-05', '2012-05-12',
               '2012-05-19', '2012-05-26', '2012-06-02', '2012-06-09',
               '2012-06-16', '2012-06-23', '2012-06-30', '2012-07-07',
               '2012-07-14', '2012-07-21', '2012-07-28', '2012-08-04',
               '2012-08-11', '2012-08-18', '2012-08-25', '2012-09-01',
               '2012-09-08', '2012-09-15', '2012-09-22', '2012-09-29',
               '2012-10-06', '2012-10-13', '2012-10-20', '2012-10-27',
               '2012-11-03', '2012-11-10', '2012-11-17', '2012-11-24',
               '2012-12-01', '2012-12-08', '2012-12-15', '2012-12-22'],
              dtype='datetime64[ns]')
>>> pandas.date_range('2011-12-31T00:00:00.000000000', periods=52, freq='W-FRI')
DatetimeIndex(['2012-01-06', '2012-01-13', '2012-01-20', '2012-01-27',
               '2012-02-03', '2012-02-10', '2012-02-17', '2012-02-24',
               '2012-03-02', '2012-03-09', '2012-03-16', '2012-03-23',
               '2012-03-30', '2012-04-06', '2012-04-13', '2012-04-20',
               '2012-04-27', '2012-05-04', '2012-05-11', '2012-05-18',
               '2012-05-25', '2012-06-01', '2012-06-08', '2012-06-15',
               '2012-06-22', '2012-06-29', '2012-07-06', '2012-07-13',
               '2012-07-20', '2012-07-27', '2012-08-03', '2012-08-10',
               '2012-08-17', '2012-08-24', '2012-08-31', '2012-09-07',
               '2012-09-14', '2012-09-21', '2012-09-28', '2012-10-05',
               '2012-10-12', '2012-10-19', '2012-10-26', '2012-11-02',
               '2012-11-09', '2012-11-16', '2012-11-23', '2012-11-30',
               '2012-12-07', '2012-12-14', '2012-12-21', '2012-12-28'],
              dtype='datetime64[ns]', freq='W-FRI')
```
",2022-12-18T16:14:11Z,0,0,Matthew Farrellee,
170,[FEA] Support for min_periods in DataFrame correlation,"Hi. Pip installation on Google Colab with `!pip install cudf-cu11 --extra-index-url=https://pypi.ngc.nvidia.com` seems to work but results in missing functionality. For example, trying to compute column correlations in a dataframe with a `min_periods` argument specified raises `NotImplementedError: Unsupported argument 'min_periods'`. Other general functionality seems to be missing as well with various errors raised. Interestingly, everything seemed to be working yesterday. Any thoughts on what could be going on? Having a working pip installation on colab would be a game changer!",2023-01-01T12:08:14Z,0,0,,
171,[FEA] category dtype support in parquet writer,"**Is your feature request related to a problem? Please describe.**
writing code with `import cudf as pd`

**Describe the solution you'd like**
same behavior as `import pandas as pd`

```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.01'

In [3]: df = pd.DataFrame({'a': ['one','two','three'] * 10})

In [4]: df.info()
<class 'cudf.core.dataframe.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   a       30 non-null     object
dtypes: object(1)
memory usage: 234.0+ bytes

In [5]: df.a = df.astype('category')

In [6]: df.info()
<class 'cudf.core.dataframe.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   a       30 non-null     category
dtypes: category(1)
memory usage: 57.0 bytes

In [7]: df.to_parquet('df.parquet')
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[7], line 1
----> 1 df.to_parquet('df.parquet')

File .../lib/python3.8/site-packages/cudf/core/dataframe.py:6287, in DataFrame.to_parquet(self, path, engine, compression, index, partition_cols, partition_file_name, partition_offsets, statistics, metadata_file_path, int96_timestamps, row_group_size_bytes, row_group_size_rows, max_page_size_bytes, max_page_size_rows, storage_options, return_metadata, *args, **kwargs)
   6284 """"""{docstring}""""""
   6285 from cudf.io import parquet
-> 6287 return parquet.to_parquet(
   6288     self,
   6289     path=path,
   6290     engine=engine,
   6291     compression=compression,
   6292     index=index,
   6293     partition_cols=partition_cols,
   6294     partition_file_name=partition_file_name,
   6295     partition_offsets=partition_offsets,
   6296     statistics=statistics,
   6297     metadata_file_path=metadata_file_path,
   6298     int96_timestamps=int96_timestamps,
   6299     row_group_size_bytes=row_group_size_bytes,
   6300     row_group_size_rows=row_group_size_rows,
   6301     max_page_size_bytes=max_page_size_bytes,
   6302     max_page_size_rows=max_page_size_rows,
   6303     storage_options=storage_options,
   6304     return_metadata=return_metadata,
   6305     *args,
   6306     **kwargs,
   6307 )

File .../lib/python3.8/contextlib.py:75, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     72 @wraps(func)
     73 def inner(*args, **kwds):
     74     with self._recreate_cm():
---> 75         return func(*args, **kwds)

File .../lib/python3.8/site-packages/cudf/io/parquet.py:700, in to_parquet(df, path, engine, compression, index, partition_cols, partition_file_name, partition_offsets, statistics, metadata_file_path, int96_timestamps, row_group_size_bytes, row_group_size_rows, max_page_size_bytes, max_page_size_rows, storage_options, return_metadata, *args, **kwargs)
    698     if partition_cols is None or col not in partition_cols:
    699         if df[col].dtype.name == ""category"":
--> 700             raise ValueError(
    701                 ""'category' column dtypes are currently not ""
    702                 + ""supported by the gpu accelerated parquet writer""
    703             )
    705 if partition_cols:
    706     if metadata_file_path is not None:

ValueError: 'category' column dtypes are currently not supported by the gpu accelerated parquet writer

In [8]: df.to_pandas().to_parquet('df.parquet')

In [9]: %ls df.parquet
df.parquet
```",2023-01-07T13:39:50Z,0,0,Matthew Farrellee,
172,[FEA] category dtype support in parquet reader,"**Is your feature request related to a problem? Please describe.**
writing code with `import cudf as pd`

**Describe the solution you'd like**
same behavior as `import pandas as pd`
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.01'

In [3]: df = pd.DataFrame({'a': ['one','two','three'] * 10})

In [4]: df.info()
<class 'cudf.core.dataframe.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   a       30 non-null     object
dtypes: object(1)
memory usage: 234.0+ bytes

In [5]: df.a = df.astype('category')

In [6]: df.info()
<class 'cudf.core.dataframe.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   a       30 non-null     category
dtypes: category(1)
memory usage: 57.0 bytes

In [7]: %ls df.parquet
ls: cannot access 'df.parquet': No such file or directory

In [8]: df.to_pandas().to_parquet('df.parquet')

In [9]: %ls df.parquet
df.parquet

In [10]: pd.read_parquet('df.parquet').info()
<class 'cudf.core.dataframe.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   a       30 non-null     object
dtypes: object(1)
memory usage: 234.0+ bytes

In [11]: import pandas

In [12]: pandas.read_parquet('df.parquet').info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype   
---  ------  --------------  -----   
 0   a       30 non-null     category
dtypes: category(1)
memory usage: 290.0 bytes

In [13]: pd.DataFrame(pandas.read_parquet('df.parquet')).info()
<class 'cudf.core.dataframe.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   a       30 non-null     category
dtypes: category(1)
memory usage: 57.0 bytes
```

the parquet reader turns the column into dtype=object
```
In [10]: pd.read_parquet('df.parquet').info()
<class 'cudf.core.dataframe.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   a       30 non-null     object
dtypes: object(1)
memory usage: 234.0+ bytes
```",2023-01-07T13:45:35Z,0,0,Matthew Farrellee,
173,[QST] CPU memory spike during cudf dataframe conversion,"Hi all, I have a dataframe that is ~19K Rows, ~11.4 MB (Profiled using ```df.info(memory_usage = ""deep"")```). We are currently running into CPU out of memory issues and so profiling our memory using this sample dataset. As you can see in the screenshot attached, there is a jump in mem usage, from 840MiB -> 4148MiB, during the type conversion of ```df```. Image below shows the dataframe memory usage after conversion. 

My question is: Why is there a jump in the memory usage when converting a dataframe from pandas to cudf? Furthermore, this memory is not released after, and so increases from this point in following processing steps.

<img width=""508"" alt=""Screenshot 2023-01-09 at 6 08 11 PM"" src=""https://user-images.githubusercontent.com/58301316/211284128-f093d906-cdb5-42b9-9ea8-79d4ff237f95.png"">
<img width=""1179"" alt=""Screenshot 2023-01-10 at 11 16 09 AM"" src=""https://user-images.githubusercontent.com/58301316/211454005-c39e9bf0-393c-4bbc-83ad-9e9f23783991.png"">
",2023-01-09T10:09:07Z,0,0,Yi Kuang,
174,"[QST]The group by collect performance is insufficient, and the performance deteriorates with the increase of the group by column length.","**What is your question?**
The group by collect performance is insufficient, and the performance deteriorates with the increase of the group by column length.

```
>>> import cudf
>>> import time
>>>
>>> import pandas
>>> import pyarrow
>>> import numpy as np
>>>
>>> def create_table(n_rows, n_cols, n_range):
...     table = pyarrow.Table.from_pydict(
...         {f'col_{c}': np.random.randint(0, n_range, size=[n_rows]) for c in range(n_cols)})
...     return table
...
>>>
>>> def create_table_with_str(n_rows, n_cols, n_strs, n_strs_cols, n_range):
...     prefix = 'xxxx_' * ((n_strs - 10) // 5)
...     cdf = create_table(n_rows, n_cols, n_range).to_pandas()
...     for i in range(n_strs_cols):
...         cdf[f'col_{i}'] = cdf[f'col_{i}'].apply(lambda x: f'{prefix}{x:010}')
    return pyarrow.Table.from_pandas(cdf)...     return pyarrow.Table.from_pandas(cdf)
...
>>>
>>> def stat_cost(str_len):
...     tbl = create_table_with_str(2000 * 10000, 2, str_len, 1, 1500 * 10000)
...     start = time.time()
...     df = cudf.DataFrame.from_arrow(tbl)
...     print(f'from arrow cost: {time.time() - start} s, '
...           f'bandwidth: {df.shape[0] / 10000 / (time.time() - start)} WRows/s')
...     print(df)
...     start = time.time()
...     result = df.groupby(['col_0']).collect()
...     print(f'group by collect cost: {time.time() - start} s, '
...           f'bandwidth: {df.shape[0] / 10000 / (time.time() - start)} WRows/s')
...
>>>
>>> stat_cost(10)
from arrow cost: 0.09801530838012695 s, bandwidth: 20401.15471699949 WRows/s
               col_0     col_1
0         0009882104   3942519
1         0009170270   7183154
2         0000346561  14059698
3         0009672848   6882498
4         0011532285  12876681
...              ...       ...
19999995  0000388357    579814
19999996  0009951171  14008663
19999997  0002681040    318695
19999998  0003139531   5608877
19999999  0007299816  12547343

[20000000 rows x 2 columns]
group by collect cost: 1.317047119140625 s, bandwidth: 1518.522440661447 WRows/s
>>> stat_cost(20)
from arrow cost: 0.14093589782714844 s, bandwidth: 14187.992497213516 WRows/s
                         col_0     col_1
0         xxxx_xxxx_0011097676   6734961
1         xxxx_xxxx_0005386896  13758023
2         xxxx_xxxx_0012936583  12093805
3         xxxx_xxxx_0014685588    977351
4         xxxx_xxxx_0002394173   4422859
...                        ...       ...
19999995  xxxx_xxxx_0008602092   1174373
19999996  xxxx_xxxx_0006179928   9909283
19999997  xxxx_xxxx_0004578043   4414022
19999998  xxxx_xxxx_0004295524   9151066
19999999  xxxx_xxxx_0009383727   5630830

[20000000 rows x 2 columns]
group by collect cost: 3.6019299030303955 s, bandwidth: 555.254619538489 WRows/s
>>> stat_cost(30)
from arrow cost: 0.1838366985321045 s, bandwidth: 10878.289477949978 WRows/s
                                   col_0     col_1
0         xxxx_xxxx_xxxx_xxxx_0012107927  11093137
1         xxxx_xxxx_xxxx_xxxx_0008415030   6082935
2         xxxx_xxxx_xxxx_xxxx_0001637082   5181973
3         xxxx_xxxx_xxxx_xxxx_0014907884  13010547
4         xxxx_xxxx_xxxx_xxxx_0011395415   8406699
...                                  ...       ...
19999995  xxxx_xxxx_xxxx_xxxx_0013393283   9371961
19999996  xxxx_xxxx_xxxx_xxxx_0012288828   3685424
19999997  xxxx_xxxx_xxxx_xxxx_0011403282  11832112
19999998  xxxx_xxxx_xxxx_xxxx_0014808359  12467674
19999999  xxxx_xxxx_xxxx_xxxx_0007966548   3177904

[20000000 rows x 2 columns]
group by collect cost: 6.546090126037598 s, bandwidth: 305.5246419013939 WRows/s

```
![捕获](https://user-images.githubusercontent.com/43532055/211317106-522eec4e-6bc4-439f-8eda-4dd889379a24.PNG)

How to improve performance?


",2023-01-09T13:18:58Z,0,0,Liu,
175,[BUG] IndexError during assignment through loc[],"**Describe the bug**
rewriting code with `import cudf as pd`

**Steps/Code to reproduce bug**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame(columns=['a'])

In [4]: df.loc[0] = [1]
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
Cell In [4], line 1
----> 1 df.loc[0] = [1]

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:149, in _DataFrameIndexer.__setitem__(self, key, value)
    147 if not isinstance(key, tuple):
    148     key = (key, slice(None))
--> 149 return self._setitem_tuple_arg(key, value)

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:393, in _DataFrameLocIndexer._setitem_tuple_arg(self, key, value)
    386 # Otherwise, there are two situations. The key on row axis
    387 # can be a scalar or 1d. In either of the situation, the
    388 # ith element in value corresponds to the ith row in
    389 # the indexed object.
    390 # If the key is 1d, a broadcast will happen.
    391 else:
    392     for i, col in enumerate(columns_df._column_names):
--> 393         self._frame[col].loc[key[0]] = value[i]

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/series.py:285, in _SeriesLocIndexer.__setitem__(self, key, value)
    283     value = cudf.Series(value)
    284     value = value._align_to_index(self._frame.index, how=""right"")
--> 285 self._frame.iloc[key] = value

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/series.py:236, in _SeriesIlocIndexer.__setitem__(self, key, value)
    231     if to_dtype != self._frame._column.dtype:
    232         self._frame._column._mimic_inplace(
    233             self._frame._column.astype(to_dtype), inplace=True
    234         )
--> 236 self._frame._column[key] = value

File ~/.local/lib/python3.9/site-packages/cudf/core/column/column.py:496, in ColumnBase.__setitem__(self, key, value)
    494     if not isinstance(key, cudf.core.column.NumericalColumn):
    495         raise ValueError(f""Invalid scatter map type {key.dtype}."")
--> 496     out = self._scatter_by_column(key, value_normalized)
    498 if out:
    499     self._mimic_inplace(out, inplace=True)

File ~/.local/lib/python3.9/site-packages/cudf/core/column/column.py:580, in ColumnBase._scatter_by_column(self, key, value)
    576     return libcudf.copying.boolean_mask_scatter([value], [self], key)[
    577         0
    578     ]._with_type_metadata(self.dtype)
    579 else:
--> 580     return libcudf.copying.scatter([value], key, [self])[
    581         0
    582     ]._with_type_metadata(self.dtype)

File /usr/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File copying.pyx:265, in cudf._lib.copying.scatter()

IndexError: index out of bounds for column of size 0

In [5]: pdf = df.to_pandas()

In [6]: pdf
Out[6]: 
Empty DataFrame
Columns: [a]
Index: []

In [7]: pdf.loc[0] = [1]

In [8]: pdf
Out[8]: 
   a
0  1
```


**Expected behavior**
same behavior as `import pandas as pd`
",2023-01-09T21:16:15Z,0,0,Matthew Farrellee,
176,[BUG] assignment through loc[] breaks DataFrame,"**Describe the bug**
rewriting code with `import cudf as pd`

**Steps/Code to reproduce bug**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame({'a':0})

In [4]: df
Out[4]: 
   a
0  0

In [5]: df.loc[1] = 2

In [6]: df
Out[6]: ---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
File ~/.local/lib/python3.9/site-packages/IPython/core/formatters.py:707, in PlainTextFormatter.__call__(self, obj)
    700 stream = StringIO()
    701 printer = pretty.RepresentationPrinter(stream, self.verbose,
    702     self.max_width, self.newline,
    703     max_seq_length=self.max_seq_length,
    704     singleton_pprinters=self.singleton_printers,
    705     type_pprinters=self.type_printers,
    706     deferred_pprinters=self.deferred_printers)
--> 707 printer.pretty(obj)
    708 printer.flush()
    709 return stream.getvalue()

File ~/.local/lib/python3.9/site-packages/IPython/lib/pretty.py:410, in RepresentationPrinter.pretty(self, obj)
    407                         return meth(obj, self, cycle)
    408                 if cls is not object \
    409                         and callable(cls.__dict__.get('__repr__')):
--> 410                     return _repr_pprint(obj, self, cycle)
    412     return _default_pprint(obj, self, cycle)
    413 finally:

File ~/.local/lib/python3.9/site-packages/IPython/lib/pretty.py:778, in _repr_pprint(obj, p, cycle)
    776 """"""A pprint that just redirects to the normal repr function.""""""
    777 # Find newlines and replace them with p.break_()
--> 778 output = repr(obj)
    779 lines = output.splitlines()
    780 with p.group():

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:1863, in DataFrame.__repr__(self)
   1860 @_cudf_nvtx_annotate
   1861 def __repr__(self):
   1862     output = self._get_renderable_dataframe()
-> 1863     return self._clean_renderable_dataframe(output)

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:1741, in DataFrame._clean_renderable_dataframe(self, output)
   1738 else:
   1739     width = None
-> 1741 output = output.to_pandas().to_string(
   1742     max_rows=max_rows,
   1743     min_rows=min_rows,
   1744     max_cols=max_cols,
   1745     line_width=width,
   1746     max_colwidth=max_colwidth,
   1747     show_dimensions=show_dimensions,
   1748 )
   1750 lines = output.split(""\n"")
   1752 if lines[-1].startswith(""[""):

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:5037, in DataFrame.to_pandas(self, nullable, **kwargs)
   5034 out_index = self.index.to_pandas()
   5036 for i, col_key in enumerate(self._data):
-> 5037     out_data[i] = self._data[col_key].to_pandas(
   5038         index=out_index, nullable=nullable
   5039     )
   5041 out_df = pd.DataFrame(out_data, index=out_index)
   5042 out_df.columns = self._data.to_pandas_index()

File ~/.local/lib/python3.9/site-packages/cudf/core/column/numerical.py:732, in NumericalColumn.to_pandas(self, index, nullable, **kwargs)
    729     pd_series = self.to_arrow().to_pandas(**kwargs)
    731 if index is not None:
--> 732     pd_series.index = index
    733 return pd_series

File ~/.local/lib/python3.9/site-packages/pandas/core/generic.py:5588, in NDFrame.__setattr__(self, name, value)
   5586 try:
   5587     object.__getattribute__(self, name)
-> 5588     return object.__setattr__(self, name, value)
   5589 except AttributeError:
   5590     pass

File ~/.local/lib/python3.9/site-packages/pandas/_libs/properties.pyx:70, in pandas._libs.properties.AxisProperty.__set__()

File ~/.local/lib/python3.9/site-packages/pandas/core/series.py:572, in Series._set_axis(self, axis, labels, fastpath)
    568             pass
    570 if not fastpath:
    571     # The ensure_index call above ensures we have an Index object
--> 572     self._mgr.set_axis(axis, labels)

File ~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py:214, in BaseBlockManager.set_axis(self, axis, new_labels)
    212 def set_axis(self, axis: int, new_labels: Index) -> None:
    213     # Caller is responsible for ensuring we have an Index object.
--> 214     self._validate_set_axis(axis, new_labels)
    215     self.axes[axis] = new_labels

File ~/.local/lib/python3.9/site-packages/pandas/core/internals/base.py:69, in DataManager._validate_set_axis(self, axis, new_labels)
     66     pass
     68 elif new_len != old_len:
---> 69     raise ValueError(
     70         f""Length mismatch: Expected axis has {old_len} elements, new ""
     71         f""values have {new_len} elements""
     72     )

ValueError: Length mismatch: Expected axis has 2 elements, new values have 1 elements

In [7]: pdf = pd.DataFrame({'a':0}).to_pandas()

In [8]: pdf
Out[8]: 
   a
0  0

In [9]: pdf.loc[1] = 2

In [10]: pdf
Out[10]: 
   a
0  0
1  2

In [11]: df.loc[0]
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
Cell In [13], line 1
----> 1 df.loc[0]

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:144, in _DataFrameIndexer.__getitem__(self, arg)
    142 if not isinstance(arg, tuple):
    143     arg = (arg, slice(None))
--> 144 return self._getitem_tuple_arg(arg)

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:291, in _DataFrameLocIndexer._getitem_tuple_arg(self, arg)
    286 tmp_col_name = str(uuid4())
    287 other_df = DataFrame(
    288     {tmp_col_name: column.arange(len(tmp_arg[0]))},
    289     index=as_index(tmp_arg[0]),
    290 )
--> 291 df = other_df.join(columns_df, how=""inner"")
    292 # as join is not assigning any names to index,
    293 # update it over here
    294 df.index.name = columns_df.index.name

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:4038, in DataFrame.join(self, other, on, how, lsuffix, rsuffix, sort)
   4035 if on is not None:
   4036     raise NotImplementedError(""The on parameter is not yet supported"")
-> 4038 df = self.merge(
   4039     other,
   4040     left_index=True,
   4041     right_index=True,
   4042     how=how,
   4043     suffixes=(lsuffix, rsuffix),
   4044     sort=sort,
   4045 )
   4046 df.index.name = (
   4047     None if self.index.name != other.index.name else self.index.name
   4048 )
   4049 return df

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:3987, in DataFrame.merge(self, right, on, left_on, right_on, left_index, right_index, how, sort, lsuffix, rsuffix, indicator, suffixes)
   3984 elif how in {""leftsemi"", ""leftanti""}:
   3985     merge_cls = MergeSemi
-> 3987 return merge_cls(
   3988     lhs,
   3989     rhs,
   3990     on=on,
   3991     left_on=left_on,
   3992     right_on=right_on,
   3993     left_index=left_index,
   3994     right_index=right_index,
   3995     how=how,
   3996     sort=sort,
   3997     indicator=indicator,
   3998     suffixes=suffixes,
   3999 ).perform_merge()

File ~/.local/lib/python3.9/site-packages/cudf/core/join/join.py:200, in Merge.perform_merge(self)
    189 gather_kwargs = {
    190     ""nullify"": True,
    191     ""check_bounds"": False,
    192     ""keep_index"": self._using_left_index or self._using_right_index,
    193 }
    194 left_result = (
    195     self.lhs._gather(gather_map=left_rows, **gather_kwargs)
    196     if left_rows is not None
    197     else cudf.DataFrame._from_data({})
    198 )
    199 right_result = (
--> 200     self.rhs._gather(gather_map=right_rows, **gather_kwargs)
    201     if right_rows is not None
    202     else cudf.DataFrame._from_data({})
    203 )
    205 result = cudf.DataFrame._from_data(
    206     *self._merge_results(left_result, right_result)
    207 )
    209 if self.sort:

File ~/.local/lib/python3.9/site-packages/cudf/core/indexed_frame.py:1722, in IndexedFrame._gather(self, gather_map, keep_index, nullify, check_bounds)
   1716 if not libcudf.copying._gather_map_is_valid(
   1717     gather_map, len(self), check_bounds, nullify
   1718 ):
   1719     raise IndexError(""Gather map index is out of bounds."")
   1721 return self._from_columns_like_self(
-> 1722     libcudf.copying.gather(
   1723         list(self._index._columns + self._columns)
   1724         if keep_index
   1725         else list(self._columns),
   1726         gather_map,
   1727         nullify=nullify,
   1728     ),
   1729     self._column_names,
   1730     self._index.names if keep_index else None,
   1731 )

File /usr/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File copying.pyx:178, in cudf._lib.copying.gather()

File utils.pyx:46, in cudf._lib.utils.table_view_from_columns()

RuntimeError: cuDF failure at: /project/cpp/src/table/table_view.cpp:35: Column size mismatch.
```

**Expected behavior**
same behavior as `import pandas as pd`",2023-01-09T21:22:09Z,0,0,Matthew Farrellee,
177,[FEA] replace(): regex parameter is not implemented yet,"**Is your feature request related to a problem? Please describe.**
writing code with `import cudf as pd`

**Describe the solution you'd like**
```
In [1]: import cudf as pd

In [2]: df = pd.DataFrame({'a': ['abc','bcd','cde']})

In [3]: df.replace('c', 'C', regex=True)
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
Cell In [3], line 1
----> 1 df.replace('c', 'C', regex=True)

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/indexed_frame.py:744, in IndexedFrame.replace(self, to_replace, value, inplace, limit, regex, method)
    741     raise NotImplementedError(""limit parameter is not implemented yet"")
    743 if regex:
--> 744     raise NotImplementedError(""regex parameter is not implemented yet"")
    746 if method not in (""pad"", None):
    747     raise NotImplementedError(
    748         ""method parameter is not implemented yet""
    749     )

NotImplementedError: regex parameter is not implemented yet

In [4]: df.to_pandas().replace('c', 'C', regex=True)
Out[4]: 
     a
0  abC
1  bCd
2  Cde

In [5]: pd.__version__
Out[5]: '22.12.0'
```",2023-01-09T21:30:39Z,0,0,Matthew Farrellee,
178,[FEA] DataFrame.query support for strings,"**Is your feature request related to a problem? Please describe.**
working with code using `import cudf as pd`

**Describe the solution you'd like**
functionality matching `import pandas as pd`
```
In [1]: import cudf as pd

In [2]: df = pd.DataFrame({'a': ['one', 'two', 'three']})

In [3]: df.query('a == ""one""')
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In [3], line 1
----> 1 df.query('a == ""one""')

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:4174, in DataFrame.query(self, expr, local_dict)
   4168 callenv = {
   4169     ""locals"": callframe.f_locals,
   4170     ""globals"": callframe.f_globals,
   4171     ""local_dict"": local_dict,
   4172 }
   4173 # Run query
-> 4174 boolmask = queryutils.query_execute(self, expr, callenv)
   4175 return self._apply_boolean_mask(boolmask)

File ~/.local/lib/python3.9/site-packages/cudf/utils/queryutils.py:218, in query_execute(df, expr, callenv)
    216 # wait to check the types until we know which cols are used
    217 if any(col.dtype not in SUPPORTED_QUERY_TYPES for col in colarrays):
--> 218     raise TypeError(
    219         ""query only supports numeric, datetime, timedelta, ""
    220         ""or bool dtypes.""
    221     )
    223 colarrays = [col.data_array_view for col in colarrays]
    225 kernel = compiled[""kernel""]

TypeError: query only supports numeric, datetime, timedelta, or bool dtypes.

In [4]: pd.__version__
Out[4]: '22.12.0'

In [5]: df.to_pandas().query('a == ""one""')
Out[5]: 
     a
0  one
``` ",2023-01-09T23:25:35Z,0,0,Matthew Farrellee,
179,[FEA] DataFrame.query support for math ops,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
support for math ops matching `pandas`

```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame({'a': [1**2, 2**2, 3**2]})

In [4]: df.query('sqrt(a) >= 2')
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:7559, in extract_col(df, col)
   7558 try:
-> 7559     return df._data[col]
   7560 except KeyError:

File ~/.local/lib/python3.9/site-packages/cudf/core/column_accessor.py:155, in ColumnAccessor.__getitem__(self, key)
    154 def __getitem__(self, key: Any) -> ColumnBase:
--> 155     return self._data[key]

KeyError: 'sqrt'

During handling of the above exception, another exception occurred:

KeyError                                  Traceback (most recent call last)
Cell In [4], line 1
----> 1 df.query('sqrt(a) >= 2')

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:4174, in DataFrame.query(self, expr, local_dict)
   4168 callenv = {
   4169     ""locals"": callframe.f_locals,
   4170     ""globals"": callframe.f_globals,
   4171     ""local_dict"": local_dict,
   4172 }
   4173 # Run query
-> 4174 boolmask = queryutils.query_execute(self, expr, callenv)
   4175 return self._apply_boolean_mask(boolmask)

File ~/.local/lib/python3.9/site-packages/cudf/utils/queryutils.py:214, in query_execute(df, expr, callenv)
    211 columns = compiled[""colnames""]
    213 # prepare col args
--> 214 colarrays = [cudf.core.dataframe.extract_col(df, col) for col in columns]
    216 # wait to check the types until we know which cols are used
    217 if any(col.dtype not in SUPPORTED_QUERY_TYPES for col in colarrays):

File ~/.local/lib/python3.9/site-packages/cudf/utils/queryutils.py:214, in <listcomp>(.0)
    211 columns = compiled[""colnames""]
    213 # prepare col args
--> 214 colarrays = [cudf.core.dataframe.extract_col(df, col) for col in columns]
    216 # wait to check the types until we know which cols are used
    217 if any(col.dtype not in SUPPORTED_QUERY_TYPES for col in colarrays):

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:7567, in extract_col(df, col)
   7561 if (
   7562     col == ""index""
   7563     and col not in df.index._data
   7564     and not isinstance(df.index, MultiIndex)
   7565 ):
   7566     return df.index._data.columns[0]
-> 7567 return df.index._data[col]

File ~/.local/lib/python3.9/site-packages/cudf/core/column_accessor.py:155, in ColumnAccessor.__getitem__(self, key)
    154 def __getitem__(self, key: Any) -> ColumnBase:
--> 155     return self._data[key]

KeyError: 'sqrt'

In [5]: df.to_pandas().query('sqrt(a) >= 2')
Out[5]: 
   a
1  4
2  9
```

**Additional context**
https://github.com/pandas-dev/pandas/blob/v1.5.2/pandas/core/computation/ops.py#L39-L60",2023-01-10T00:45:18Z,0,0,Matthew Farrellee,
180,[FEA] Allow keep='all' for nlargest/nsmallest,"**Is your feature request related to a problem? Please describe.**
writing code with `import cudf as pd`

**Describe the solution you'd like**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame({'a': [1, 2, 3] * 2, 'b': list('abcdef')})

In [4]: df.nlargest(1, 'a', keep='all')
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In [4], line 1
----> 1 df.nlargest(1, 'a', keep='all')

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:3624, in DataFrame.nlargest(self, n, columns, keep)
   3558 @_cudf_nvtx_annotate
   3559 def nlargest(self, n, columns, keep=""first""):
   3560     """"""Return the first *n* rows ordered by *columns* in descending order.
   3561 
   3562     Return the first *n* rows with the largest values in *columns*, in
   (...)
   3622     Brunei      434000    12128      BN
   3623     """"""
-> 3624     return self._n_largest_or_smallest(True, n, columns, keep)

File ~/.local/lib/python3.9/site-packages/cudf/core/indexed_frame.py:2156, in IndexedFrame._n_largest_or_smallest(self, largest, n, columns, keep)
   2154     return self._gather(indices, keep_index=True, check_bounds=False)
   2155 else:
-> 2156     raise ValueError('keep must be either ""first"", ""last""')

ValueError: keep must be either ""first"", ""last""

In [5]: df.to_pandas().nlargest(1, 'a', keep='all')
Out[5]: 
   a  b
2  3  c
5  3  f
```

**Additional context**
https://github.com/pandas-dev/pandas/pull/21650",2023-01-10T13:33:01Z,0,0,Matthew Farrellee,
181,[FEA] support for read_html,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
functionality matching https://pandas.pydata.org/docs/reference/api/pandas.read_html.html
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: pd.read_html(""https://docs.rapids.ai/maintainers"")
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Cell In [3], line 1
----> 1 pd.read_html(""https://docs.rapids.ai/maintainers"")

AttributeError: module 'cudf' has no attribute 'read_html'

In [4]: import pandas

In [5]: pandas.read_html(""https://docs.rapids.ai/maintainers"")
Out[5]: 
[                                         Phase        Start          End Duration
 0          Development (cuDF/RMM/rapids-cmake)  Thu, Nov 10  Wed, Jan 18  42 days
 1                         Development (others)  Thu, Nov 17  Wed, Jan 25  43 days
 2             Burn Down(cuDF/RMM/rapids-cmake)  Thu, Jan 19  Wed, Jan 25   5 days
 3                           Burn Down (others)  Thu, Jan 26   Wed, Feb 1   5 days
 4  Code Freeze/Testing (cuDF/RMM/rapids-cmake)  Thu, Jan 26  Tue, Jan 31   4 days
 5               Code Freeze/Testing (others) 1   Thu, Feb 2   Tue, Feb 7   4 days
 6                                      Release   Wed, Feb 8   Thu, Feb 9   2 days,
                                          Phase        Start          End Duration
 0          Development (cuDF/RMM/rapids-cmake)  Thu, Jan 19  Wed, Mar 22  42 days
 1                         Development (others)  Thu, Jan 26  Wed, Mar 29  42 days
 2             Burn Down(cuDF/RMM/rapids-cmake)  Thu, Mar 23  Wed, Mar 29   5 days
 3                           Burn Down (others)  Thu, Mar 30   Wed, Apr 5   5 days
 4  Code Freeze/Testing (cuDF/RMM/rapids-cmake)  Thu, Mar 30   Tue, Apr 4   4 days
 5               Code Freeze/Testing (others) 1   Thu, Apr 6  Tue, Apr 11   4 days
 6                                      Release  Wed, Apr 12  Thu, Apr 13   2 days]
```",2023-01-10T14:58:23Z,0,0,Matthew Farrellee,
182,[FEA] Series.str.contains support for case,"**Is your feature request related to a problem? Please describe.**
writing code with `import cudf as pd`

**Describe the solution you'd like**
same behavior as `import pandas as pd`
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame({'a': ['one', 'One', 'onE']})

In [4]: df.a.str.contains('one', case=False)
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
Cell In [4], line 1
----> 1 df.a.str.contains('one', case=False)

File ~/.local/lib/python3.9/site-packages/cudf/core/column/string.py:759, in StringMethods.contains(self, pat, case, flags, na, regex)
    650 r""""""
    651 Test if pattern or regex is contained within a string of a Series or
    652 Index.
   (...)
    756 dtype: bool
    757 """"""  # noqa W605
    758 if case is not True:
--> 759     raise NotImplementedError(""`case` parameter is not yet supported"")
    760 if na is not np.nan:
    761     raise NotImplementedError(""`na` parameter is not yet supported"")

NotImplementedError: `case` parameter is not yet supported

In [5]: df.to_pandas().a.str.contains('one', case=False)
Out[5]: 
0    True
1    True
2    True
Name: a, dtype: bool
```

**Additional context**
https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html",2023-01-10T15:05:46Z,0,0,Matthew Farrellee,
183,[FEA] DataFrame.to_markdown support,"**Is your feature request related to a problem? Please describe.**
rewriting code with `import cudf as pd`

**Describe the solution you'd like**
support for `to_markdown` matching https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html
",2023-01-10T15:47:29Z,0,0,Matthew Farrellee,
184,[BUG] groupby().agg() with list() expansion: TypeError: 'type' object is not iterable,"**Describe the bug**
rewriting code with `import cudf as pd`

**Steps/Code to reproduce bug**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame({
   ...:     ""col1"": [1, 2, 3, 4, 3],
   ...:     ""col2"": [""a"", ""a"", ""b"", ""b"", ""c""],
   ...:     ""col3"": [""d"", ""e"", ""f"", ""g"", ""h""]
   ...: })

In [4]: df.groupby([""col2""]).agg({""col1"": ""mean"", ""col3"": lambda x: list(x)})
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In [4], line 1
----> 1 df.groupby([""col2""]).agg({""col1"": ""mean"", ""col3"": lambda x: list(x)})

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:460, in GroupBy.agg(self, func)
    451 column_names, columns, normalized_aggs = self._normalize_aggs(func)
    453 # Note: When there are no key columns, the below produces
    454 # a Float64Index, while Pandas returns an Int64Index
    455 # (GH: 6945)
    456 (
    457     result_columns,
    458     grouped_key_cols,
    459     included_aggregations,
--> 460 ) = self._groupby.aggregate(columns, normalized_aggs)
    462 result_index = self.grouping.keys._from_columns_like_self(
    463     grouped_key_cols,
    464 )
    466 multilevel = _is_multi_agg(func)

File groupby.pyx:309, in cudf._lib.groupby.GroupBy.aggregate()

File groupby.pyx:184, in cudf._lib.groupby.GroupBy.aggregate_internal()

File aggregation.pyx:866, in cudf._lib.aggregation.make_groupby_aggregation()

Cell In [4], line 1, in <lambda>(x)
----> 1 df.groupby([""col2""]).agg({""col1"": ""mean"", ""col3"": lambda x: list(x)})

TypeError: 'type' object is not iterable

In [5]: df.to_pandas().groupby([""col2""]).agg({""col1"": ""mean"", ""col3"": lambda x: list(x)})
Out[5]: 
      col1    col3
col2              
a      1.5  [d, e]
b      3.5  [f, g]
c      3.0     [h]
```
",2023-01-10T15:56:31Z,0,0,Matthew Farrellee,
185,"[FEA] cudf.to_datetime support locale-specific formatting (%a, %A, %b, %B, %c, %x, %X, %p)","**Is your feature request related to a problem? Please describe.**
writing code with `import cudf as pd`

**Describe the solution you'd like**
`cudf.to_datetime(..., format=...)` support matching https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html and https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes

related: https://github.com/rapidsai/cudf/issues/12419",2023-01-10T19:22:58Z,0,0,Matthew Farrellee,
186,[FEA] support for groupby named aggregates,"**Is your feature request related to a problem? Please describe.**
writing code with `import cudf as pd`

**Describe the solution you'd like**
`groupby().agg()` matching `pandas`

https://pandas.pydata.org/docs/user_guide/groupby.html#groupby-aggregate-named

e.g.
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame({""size"": [""S"", ""S"", ""M"", ""L""], ""price"": [44, 29.99, 10, 19]})

In [4]: df.groupby('size').agg({'price': 'mean'})
Out[4]: 
       price
size        
L     19.000
M     10.000
S     36.995

In [5]: df.groupby('size').agg(mean_price=('price', 'mean'))
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In [5], line 1
----> 1 df.groupby('size').agg(mean_price=('price', 'mean'))

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

TypeError: agg() got an unexpected keyword argument 'mean_price'

In [6]: df.to_pandas().groupby('size').agg(mean_price=('price', 'mean'))
Out[6]: 
      mean_price
size            
L         19.000
M         10.000
S         36.995

```",2023-01-10T19:57:06Z,0,0,Matthew Farrellee,
187,[FEA] support month (M) frequency for date_range and resample,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
https://pandas.pydata.org/docs/reference/api/pandas.date_range.html
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html

frequencies - https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases
",2023-01-10T23:32:38Z,0,0,Matthew Farrellee,
188,[BUG] cudf.pivot_table behavior does not match pandas.pivor_table - mismatched index structure,"**Describe the bug**
working with `import cudf as pd`

**Steps/Code to reproduce bug**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.00'

In [3]: df = pd.DataFrame({""A"": [""foo"", ""foo"", ""foo"", ""foo"", ""foo"",
   ...:                          ""bar"", ""bar"", ""bar"", ""bar""],
   ...:                    ""B"": [""one"", ""one"", ""one"", ""two"", ""two"",
   ...:                          ""one"", ""one"", ""two"", ""two""],
   ...:                    ""C"": [""small"", ""large"", ""large"", ""small"",
   ...:                          ""small"", ""large"", ""small"", ""small"",
   ...:                          ""large""],
   ...:                    ""D"": [1, 2, 2, 3, 3, 4, 5, 6, 7],
   ...:                    ""E"": [2, 4, 5, 5, 6, 6, 8, 9, 9]})

In [4]: df
Out[4]: 
     A    B      C  D  E
0  foo  one  small  1  2
1  foo  one  large  2  4
2  foo  one  large  2  5
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9

In [5]: pd.pivot_table(df, index=[""A""], columns=[""B""], aggfunc=""size"", fill_value=0)
Out[5]: 
      C       D       E    
B   one two one two one two
A                          
bar   2   2   2   2   2   2
foo   3   2   3   2   3   2

In [6]: import pandas

In [7]: pandas.__version__
Out[7]: '1.5.2'

In [8]: pandas.pivot_table(df.to_pandas(), index=[""A""], columns=[""B""], aggfunc=""size"", fill_value=0)
Out[8]: 
B    one  two
A            
bar    2    2
foo    3    2
```",2023-01-18T14:45:09Z,0,0,Matthew Farrellee,
189,[FEA] cudf.crosstab support for margins parameter,"**Is your feature request related to a problem? Please describe.**
writing code with `import cudf as pd`

**Describe the solution you'd like**
matching behavior with [`pandas.crosstab`](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html)
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.00'

In [3]: df = pd.DataFrame({""A"": [""foo"", ""foo"", ""foo"", ""foo"", ""foo"",
   ...:                          ""bar"", ""bar"", ""bar"", ""bar""],
   ...:                    ""B"": [""one"", ""one"", ""one"", ""two"", ""two"",
   ...:                          ""one"", ""one"", ""two"", ""two""],
   ...:                    ""C"": [""small"", ""large"", ""large"", ""small"",
   ...:                          ""small"", ""large"", ""small"", ""small"",
   ...:                          ""large""],
   ...:                    ""D"": [1, 2, 2, 3, 3, 4, 5, 6, 7],
   ...:                    ""E"": [2, 4, 5, 5, 6, 6, 8, 9, 9]})

In [4]: pd.crosstab(df.A, df.B, margins=True)
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
Cell In[4], line 1
----> 1 pd.crosstab(df.A, df.B, margins=True)

File /usr/local/lib/python3.8/dist-packages/cudf/core/reshape.py:1296, in crosstab(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)
   1293     df[""__dummy__""] = values
   1294     kwargs = {""aggfunc"": aggfunc}
-> 1296 table = pivot_table(
   1297     data=df,
   1298     index=rownames,
   1299     columns=colnames,
   1300     values=""__dummy__"",
   1301     margins=margins,
   1302     margins_name=margins_name,
   1303     dropna=dropna,
   1304     **kwargs,
   1305 )
   1307 return table

File /usr/local/lib/python3.8/dist-packages/cudf/core/reshape.py:1352, in pivot_table(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)
   1323 """"""
   1324 Create a spreadsheet-style pivot table as a DataFrame.
   1325 
   (...)
   1349     An Excel style pivot table.
   1350 """"""
   1351 if margins is not False:
-> 1352     raise NotImplementedError(""margins is not supported yet"")
   1354 if margins_name != ""All"":
   1355     raise NotImplementedError(""margins_name is not supported yet"")

NotImplementedError: margins is not supported yet
```",2023-01-18T14:51:08Z,0,0,Matthew Farrellee,
190,[FEA] support passing label to value_counts(),"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
matching behavior with `pandas`
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.00'

In [3]: df = pd.DataFrame({""XYZ"": [""foo"", ""foo"", ""foo"", ""foo"", ""foo""]})

In [4]: df.value_counts(""XYZ"")
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
Cell In[4], line 1
----> 1 df.value_counts(""XYZ"")

File /usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:7188, in DataFrame.value_counts(self, subset, normalize, sort, ascending, dropna)
   7186     diff = set(subset) - set(self._data)
   7187     if len(diff) != 0:
-> 7188         raise KeyError(f""columns {diff} do not exist"")
   7189 columns = list(self._data.names) if subset is None else subset
   7190 result = (
   7191     self.groupby(
   7192         by=columns,
   (...)
   7196     .astype(""int64"")
   7197 )

KeyError: ""columns {'Y', 'X', 'Z'} do not exist""

In [5]: df.to_pandas().value_counts(""XYZ"")
Out[5]: 
XYZ
foo    5
dtype: int64
```

**Additional context**
[`pandas.DataFrame.value_counts`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html) declares support for `list-like` input, but is [implemented](https://github.com/pandas-dev/pandas/blob/v1.5.2/pandas/core/frame.py#L7215) with [`pandas.DataFrame.groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html), which accepts `mapping, function, label, or list of labels`",2023-01-18T15:48:29Z,0,0,Matthew Farrellee,
191,[FEA] DataFrame.query support for datetime,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.00'

In [3]: df = pd.DataFrame({'A': pd.date_range(start=""2023-01-01"", periods=8, freq=""D"")})

In [4]: df.info()
<class 'cudf.core.dataframe.DataFrame'>
RangeIndex: 8 entries, 0 to 7
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   A       8 non-null      datetime64[ns]
dtypes: datetime64[ns](1)
memory usage: 64.0 bytes

In [5]: df.query('A >= ""2023-01-02""')
---------------------------------------------------------------------------
TypingError                               Traceback (most recent call last)
Cell In[5], line 1
----> 1 df.query('A >= ""2023-01-02""')

File /usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:4174, in DataFrame.query(self, expr, local_dict)
   4168 callenv = {
   4169     ""locals"": callframe.f_locals,
   4170     ""globals"": callframe.f_globals,
   4171     ""local_dict"": local_dict,
   4172 }
   4173 # Run query
-> 4174 boolmask = queryutils.query_execute(self, expr, callenv)
   4175 return self._apply_boolean_mask(boolmask)

File /usr/local/lib/python3.8/dist-packages/cudf/utils/queryutils.py:248, in query_execute(df, expr, callenv)
    246 # run kernel
    247 args = [out] + colarrays + envargs
--> 248 kernel.forall(nrows)(*args)
    249 out_mask = applyutils.make_aggregate_nullmask(df, columns=columns)
    250 return out.set_mask(out_mask).fillna(False)

File /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:438, in ForAll.__call__(self, *args)
    436     specialized = self.dispatcher
    437 else:
--> 438     specialized = self.dispatcher.specialize(*args)
    439 blockdim = self._compute_thread_per_block(specialized)
    440 griddim = (self.ntasks + blockdim - 1) // blockdim

File /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:667, in CUDADispatcher.specialize(self, *args)
    664 targetoptions = self.targetoptions
    665 specialization = CUDADispatcher(self.py_func,
    666                                 targetoptions=targetoptions)
--> 667 specialization.compile(argtypes)
    668 specialization.disable_compile()
    669 specialization._specialized = True

File /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:794, in CUDADispatcher.compile(self, sig)
    791 if not self._can_compile:
    792     raise RuntimeError(""Compilation disabled"")
--> 794 kernel = _Kernel(self.py_func, argtypes, **self.targetoptions)
    795 # We call bind to force codegen, so that there is a cubin to cache
    796 kernel.bind()

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)
     32 @functools.wraps(func)
     33 def _acquire_compile_lock(*args, **kwargs):
     34     with self:
---> 35         return func(*args, **kwargs)

File /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:75, in _Kernel.__init__(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)
     66 self.extensions = extensions or []
     68 nvvm_options = {
     69     'debug': self.debug,
     70     'lineinfo': self.lineinfo,
     71     'fastmath': fastmath,
     72     'opt': 3 if opt else 0
     73 }
---> 75 cres = compile_cuda(self.py_func, types.void, self.argtypes,
     76                     debug=self.debug,
     77                     lineinfo=self.lineinfo,
     78                     inline=inline,
     79                     fastmath=fastmath,
     80                     nvvm_options=nvvm_options)
     81 tgt_ctx = cres.target_context
     82 code = self.py_func.__code__

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)
     32 @functools.wraps(func)
     33 def _acquire_compile_lock(*args, **kwargs):
     34     with self:
---> 35         return func(*args, **kwargs)

File /usr/local/lib/python3.8/dist-packages/numba/cuda/compiler.py:212, in compile_cuda(pyfunc, return_type, args, debug, lineinfo, inline, fastmath, nvvm_options)
    210 from numba.core.target_extension import target_override
    211 with target_override('cuda'):
--> 212     cres = compiler.compile_extra(typingctx=typingctx,
    213                                   targetctx=targetctx,
    214                                   func=pyfunc,
    215                                   args=args,
    216                                   return_type=return_type,
    217                                   flags=flags,
    218                                   locals={},
    219                                   pipeline_class=CUDACompiler)
    221 library = cres.library
    222 library.finalize()

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:716, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)
    692 """"""Compiler entry point
    693 
    694 Parameter
   (...)
    712     compiler pipeline
    713 """"""
    714 pipeline = pipeline_class(typingctx, targetctx, library,
    715                           args, return_type, flags, locals)
--> 716 return pipeline.compile_extra(func)

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:452, in CompilerBase.compile_extra(self, func)
    450 self.state.lifted = ()
    451 self.state.lifted_from = None
--> 452 return self._compile_bytecode()

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:520, in CompilerBase._compile_bytecode(self)
    516 """"""
    517 Populate and run pipeline for bytecode input
    518 """"""
    519 assert self.state.func_ir is None
--> 520 return self._compile_core()

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:499, in CompilerBase._compile_core(self)
    497         self.state.status.fail_reason = e
    498         if is_final_pipeline:
--> 499             raise e
    500 else:
    501     raise CompilerError(""All available pipelines exhausted"")

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:486, in CompilerBase._compile_core(self)
    484 res = None
    485 try:
--> 486     pm.run(self.state)
    487     if self.state.cr is not None:
    488         break

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:368, in PassManager.run(self, state)
    365 msg = ""Failed in %s mode pipeline (step: %s)"" % \
    366     (self.pipeline_name, pass_desc)
    367 patched_exception = self._patch_error(msg, e)
--> 368 raise patched_exception

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:356, in PassManager.run(self, state)
    354 pass_inst = _pass_registry.get(pss).pass_inst
    355 if isinstance(pass_inst, CompilerPass):
--> 356     self._runPass(idx, pass_inst, state)
    357 else:
    358     raise BaseException(""Legacy pass in use"")

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)
     32 @functools.wraps(func)
     33 def _acquire_compile_lock(*args, **kwargs):
     34     with self:
---> 35         return func(*args, **kwargs)

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:311, in PassManager._runPass(self, index, pss, internal_state)
    309     mutated |= check(pss.run_initialization, internal_state)
    310 with SimpleTimer() as pass_time:
--> 311     mutated |= check(pss.run_pass, internal_state)
    312 with SimpleTimer() as finalize_time:
    313     mutated |= check(pss.run_finalizer, internal_state)

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:273, in PassManager._runPass.<locals>.check(func, compiler_state)
    272 def check(func, compiler_state):
--> 273     mangled = func(compiler_state)
    274     if mangled not in (True, False):
    275         msg = (""CompilerPass implementations should return True/False. ""
    276                ""CompilerPass with name '%s' did not."")

File /usr/local/lib/python3.8/dist-packages/numba/core/typed_passes.py:105, in BaseTypeInference.run_pass(self, state)
     99 """"""
    100 Type inference and legalization
    101 """"""
    102 with fallback_context(state, 'Function ""%s"" failed type inference'
    103                       % (state.func_id.func_name,)):
    104     # Type inference
--> 105     typemap, return_type, calltypes, errs = type_inference_stage(
    106         state.typingctx,
    107         state.targetctx,
    108         state.func_ir,
    109         state.args,
    110         state.return_type,
    111         state.locals,
    112         raise_errors=self._raise_errors)
    113     state.typemap = typemap
    114     # save errors in case of partial typing

File /usr/local/lib/python3.8/dist-packages/numba/core/typed_passes.py:83, in type_inference_stage(typingctx, targetctx, interp, args, return_type, locals, raise_errors)
     81     infer.build_constraint()
     82     # return errors in case of partial typing
---> 83     errs = infer.propagate(raise_errors=raise_errors)
     84     typemap, restype, calltypes = infer.unify(raise_errors=raise_errors)
     86 # Output all Numba warnings

File /usr/local/lib/python3.8/dist-packages/numba/core/typeinfer.py:1086, in TypeInferer.propagate(self, raise_errors)
   1083 force_lit_args = [e for e in errors
   1084                   if isinstance(e, ForceLiteralArg)]
   1085 if not force_lit_args:
-> 1086     raise errors[0]
   1087 else:
   1088     raise reduce(operator.or_, force_lit_args)

TypingError: Failed in cuda mode pipeline (step: nopython frontend)
Failed in cuda mode pipeline (step: nopython frontend)
No implementation of function Function(<built-in function ge>) found for signature:
 
 >>> ge(datetime64[ns], Literal[str](2023-01-02))
 
There are 26 candidate implementations:
    - Of which 24 did not match due to:
    Overload of function 'ge': File: <numerous>: Line N/A.
      With argument(s): '(datetime64[ns], unicode_type)':
     No match.
    - Of which 2 did not match due to:
    Operator Overload in function 'ge': File: unknown: Line unknown.
      With argument(s): '(datetime64[ns], unicode_type)':
     No match for registered cases:
      * (bool, bool) -> bool
      * (int8, int8) -> bool
      * (int16, int16) -> bool
      * (int32, int32) -> bool
      * (int64, int64) -> bool
      * (uint8, uint8) -> bool
      * (uint16, uint16) -> bool
      * (uint32, uint32) -> bool
      * (uint64, uint64) -> bool
      * (float32, float32) -> bool
      * (float64, float64) -> bool

During: typing of intrinsic-call at <string> (2)

File ""<string>"", line 2:
<source missing, REPL/exec in use?>

During: resolving callee type: type(CUDADispatcher(<function queryexpr_5817a7cbdce0865b at 0x7f0618ab7f70>))
During: typing of call at <string> (6)


File ""<string>"", line 6:
<source missing, REPL/exec in use?>


In [6]: df.to_pandas().query('A >= ""2023-01-02""')
Out[6]: 
           A
1 2023-01-02
2 2023-01-03
3 2023-01-04
4 2023-01-05
5 2023-01-06
6 2023-01-07
7 2023-01-08
```",2023-01-18T17:39:46Z,0,0,Matthew Farrellee,
192,[BUG] DataFrame.query binary-ops do not match pandas,"**Describe the bug**
using `import cudf as pd`

**Steps/Code to reproduce bug**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.00'

In [3]: df = pd.DataFrame({""A"": [""foo"", ""foo"", ""foo"", ""foo"", ""foo"",
   ...:                          ""bar"", ""bar"", ""bar"", ""bar""],
   ...:                    ""B"": [""one"", ""one"", ""one"", ""two"", ""two"",
   ...:                          ""one"", ""one"", ""two"", ""two""],
   ...:                    ""C"": [""small"", ""large"", ""large"", ""small"",
   ...:                          ""small"", ""large"", ""small"", ""small"",
   ...:                          ""large""],
   ...:                    ""D"": [1, 2, 2, 3, 3, 4, 5, 6, 7],
   ...:                    ""E"": [2, 4, 5, 5, 6, 6, 8, 9, 9]})

In [4]: df.query(""D > 5 & E > 5"")
Out[4]: 
Empty DataFrame
Columns: [A, B, C, D, E]
Index: []

In [5]: df.to_pandas().query(""D > 5 & E > 5"")
Out[5]: 
     A    B      C  D  E
7  bar  two  small  6  9
8  bar  two  large  7  9

In [6]: df.query(""D > 5 | E > 5"")
Out[6]: 
Empty DataFrame
Columns: [A, B, C, D, E]
Index: []

In [7]: df.to_pandas().query(""D > 5 | E > 5"")
Out[7]: 
     A    B      C  D  E
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9
```",2023-01-18T17:50:38Z,0,0,Matthew Farrellee,
193,[FEA] support datetime property in DataFrame.query,"**Is your feature request related to a problem? Please describe.**
writing code with `import cudf as pd`

**Describe the solution you'd like**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.00'

In [3]: df = pd.DataFrame({'A': pd.date_range(start=""2023-01-01"", periods=8, freq=""D"")})

In [4]: df.query(""A.dt.month == 1"")
---------------------------------------------------------------------------
TypingError                               Traceback (most recent call last)
Cell In[4], line 1
----> 1 df.query(""A.dt.month == 1"")

File /usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:4174, in DataFrame.query(self, expr, local_dict)
   4168 callenv = {
   4169     ""locals"": callframe.f_locals,
   4170     ""globals"": callframe.f_globals,
   4171     ""local_dict"": local_dict,
   4172 }
   4173 # Run query
-> 4174 boolmask = queryutils.query_execute(self, expr, callenv)
   4175 return self._apply_boolean_mask(boolmask)

File /usr/local/lib/python3.8/dist-packages/cudf/utils/queryutils.py:248, in query_execute(df, expr, callenv)
    246 # run kernel
    247 args = [out] + colarrays + envargs
--> 248 kernel.forall(nrows)(*args)
    249 out_mask = applyutils.make_aggregate_nullmask(df, columns=columns)
    250 return out.set_mask(out_mask).fillna(False)

File /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:438, in ForAll.__call__(self, *args)
    436     specialized = self.dispatcher
    437 else:
--> 438     specialized = self.dispatcher.specialize(*args)
    439 blockdim = self._compute_thread_per_block(specialized)
    440 griddim = (self.ntasks + blockdim - 1) // blockdim

File /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:667, in CUDADispatcher.specialize(self, *args)
    664 targetoptions = self.targetoptions
    665 specialization = CUDADispatcher(self.py_func,
    666                                 targetoptions=targetoptions)
--> 667 specialization.compile(argtypes)
    668 specialization.disable_compile()
    669 specialization._specialized = True

File /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:794, in CUDADispatcher.compile(self, sig)
    791 if not self._can_compile:
    792     raise RuntimeError(""Compilation disabled"")
--> 794 kernel = _Kernel(self.py_func, argtypes, **self.targetoptions)
    795 # We call bind to force codegen, so that there is a cubin to cache
    796 kernel.bind()

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)
     32 @functools.wraps(func)
     33 def _acquire_compile_lock(*args, **kwargs):
     34     with self:
---> 35         return func(*args, **kwargs)

File /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:75, in _Kernel.__init__(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)
     66 self.extensions = extensions or []
     68 nvvm_options = {
     69     'debug': self.debug,
     70     'lineinfo': self.lineinfo,
     71     'fastmath': fastmath,
     72     'opt': 3 if opt else 0
     73 }
---> 75 cres = compile_cuda(self.py_func, types.void, self.argtypes,
     76                     debug=self.debug,
     77                     lineinfo=self.lineinfo,
     78                     inline=inline,
     79                     fastmath=fastmath,
     80                     nvvm_options=nvvm_options)
     81 tgt_ctx = cres.target_context
     82 code = self.py_func.__code__

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)
     32 @functools.wraps(func)
     33 def _acquire_compile_lock(*args, **kwargs):
     34     with self:
---> 35         return func(*args, **kwargs)

File /usr/local/lib/python3.8/dist-packages/numba/cuda/compiler.py:212, in compile_cuda(pyfunc, return_type, args, debug, lineinfo, inline, fastmath, nvvm_options)
    210 from numba.core.target_extension import target_override
    211 with target_override('cuda'):
--> 212     cres = compiler.compile_extra(typingctx=typingctx,
    213                                   targetctx=targetctx,
    214                                   func=pyfunc,
    215                                   args=args,
    216                                   return_type=return_type,
    217                                   flags=flags,
    218                                   locals={},
    219                                   pipeline_class=CUDACompiler)
    221 library = cres.library
    222 library.finalize()

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:716, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)
    692 """"""Compiler entry point
    693 
    694 Parameter
   (...)
    712     compiler pipeline
    713 """"""
    714 pipeline = pipeline_class(typingctx, targetctx, library,
    715                           args, return_type, flags, locals)
--> 716 return pipeline.compile_extra(func)

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:452, in CompilerBase.compile_extra(self, func)
    450 self.state.lifted = ()
    451 self.state.lifted_from = None
--> 452 return self._compile_bytecode()

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:520, in CompilerBase._compile_bytecode(self)
    516 """"""
    517 Populate and run pipeline for bytecode input
    518 """"""
    519 assert self.state.func_ir is None
--> 520 return self._compile_core()

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:499, in CompilerBase._compile_core(self)
    497         self.state.status.fail_reason = e
    498         if is_final_pipeline:
--> 499             raise e
    500 else:
    501     raise CompilerError(""All available pipelines exhausted"")

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:486, in CompilerBase._compile_core(self)
    484 res = None
    485 try:
--> 486     pm.run(self.state)
    487     if self.state.cr is not None:
    488         break

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:368, in PassManager.run(self, state)
    365 msg = ""Failed in %s mode pipeline (step: %s)"" % \
    366     (self.pipeline_name, pass_desc)
    367 patched_exception = self._patch_error(msg, e)
--> 368 raise patched_exception

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:356, in PassManager.run(self, state)
    354 pass_inst = _pass_registry.get(pss).pass_inst
    355 if isinstance(pass_inst, CompilerPass):
--> 356     self._runPass(idx, pass_inst, state)
    357 else:
    358     raise BaseException(""Legacy pass in use"")

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)
     32 @functools.wraps(func)
     33 def _acquire_compile_lock(*args, **kwargs):
     34     with self:
---> 35         return func(*args, **kwargs)

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:311, in PassManager._runPass(self, index, pss, internal_state)
    309     mutated |= check(pss.run_initialization, internal_state)
    310 with SimpleTimer() as pass_time:
--> 311     mutated |= check(pss.run_pass, internal_state)
    312 with SimpleTimer() as finalize_time:
    313     mutated |= check(pss.run_finalizer, internal_state)

File /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:273, in PassManager._runPass.<locals>.check(func, compiler_state)
    272 def check(func, compiler_state):
--> 273     mangled = func(compiler_state)
    274     if mangled not in (True, False):
    275         msg = (""CompilerPass implementations should return True/False. ""
    276                ""CompilerPass with name '%s' did not."")

File /usr/local/lib/python3.8/dist-packages/numba/core/typed_passes.py:105, in BaseTypeInference.run_pass(self, state)
     99 """"""
    100 Type inference and legalization
    101 """"""
    102 with fallback_context(state, 'Function ""%s"" failed type inference'
    103                       % (state.func_id.func_name,)):
    104     # Type inference
--> 105     typemap, return_type, calltypes, errs = type_inference_stage(
    106         state.typingctx,
    107         state.targetctx,
    108         state.func_ir,
    109         state.args,
    110         state.return_type,
    111         state.locals,
    112         raise_errors=self._raise_errors)
    113     state.typemap = typemap
    114     # save errors in case of partial typing

File /usr/local/lib/python3.8/dist-packages/numba/core/typed_passes.py:83, in type_inference_stage(typingctx, targetctx, interp, args, return_type, locals, raise_errors)
     81     infer.build_constraint()
     82     # return errors in case of partial typing
---> 83     errs = infer.propagate(raise_errors=raise_errors)
     84     typemap, restype, calltypes = infer.unify(raise_errors=raise_errors)
     86 # Output all Numba warnings

File /usr/local/lib/python3.8/dist-packages/numba/core/typeinfer.py:1086, in TypeInferer.propagate(self, raise_errors)
   1083 force_lit_args = [e for e in errors
   1084                   if isinstance(e, ForceLiteralArg)]
   1085 if not force_lit_args:
-> 1086     raise errors[0]
   1087 else:
   1088     raise reduce(operator.or_, force_lit_args)

TypingError: Failed in cuda mode pipeline (step: nopython frontend)
Failed in cuda mode pipeline (step: nopython frontend)
Unknown attribute 'dt' of type datetime64[ns]

File ""<string>"", line 2:
<source missing, REPL/exec in use?>

During: typing of get attribute at <string> (2)

File ""<string>"", line 2:
<source missing, REPL/exec in use?>

During: resolving callee type: type(CUDADispatcher(<function queryexpr_a1b175044f595522 at 0x7f61a8bade50>))
During: typing of call at <string> (6)


File ""<string>"", line 6:
<source missing, REPL/exec in use?>


In [5]: df.to_pandas().query(""A.dt.month == 1"")
Out[5]: 
           A
0 2023-01-01
1 2023-01-02
2 2023-01-03
3 2023-01-04
4 2023-01-05
5 2023-01-06
6 2023-01-07
7 2023-01-08
```",2023-01-18T17:54:09Z,0,0,Matthew Farrellee,
194,[FEA] support inplace for DataFrame.query,"**Is your feature request related to a problem? Please describe.**
using `import cudf as pd`

**Describe the solution you'd like**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.00'

In [3]: df = pd.DataFrame({""A"": [""foo"", ""foo"", ""foo"", ""foo"", ""foo"",
   ...:                          ""bar"", ""bar"", ""bar"", ""bar""],
   ...:                    ""B"": [""one"", ""one"", ""one"", ""two"", ""two"",
   ...:                          ""one"", ""one"", ""two"", ""two""],
   ...:                    ""C"": [""small"", ""large"", ""large"", ""small"",
   ...:                          ""small"", ""large"", ""small"", ""small"",
   ...:                          ""large""],
   ...:                    ""D"": [1, 2, 2, 3, 3, 4, 5, 6, 7],
   ...:                    ""E"": [2, 4, 5, 5, 6, 6, 8, 9, 9]})

In [4]: df
Out[4]: 
     A    B      C  D  E
0  foo  one  small  1  2
1  foo  one  large  2  4
2  foo  one  large  2  5
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9

In [5]: df.query(""D ** 2 > 8"")
Out[5]: 
     A    B      C  D  E
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9

In [6]: df.query(""D ** 2 > 8"", inplace=True)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[6], line 1
----> 1 df.query(""D ** 2 > 8"", inplace=True)

TypeError: query() got an unexpected keyword argument 'inplace'

In [7]: pdf = df.to_pandas()

In [8]: pdf
Out[8]: 
     A    B      C  D  E
0  foo  one  small  1  2
1  foo  one  large  2  4
2  foo  one  large  2  5
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9

In [9]: pdf.query(""D ** 2 > 8"", inplace=True)

In [10]: pdf
Out[10]: 
     A    B      C  D  E
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9
```
",2023-01-18T17:58:38Z,0,0,Matthew Farrellee,
195,[BUG] read_csv always reads values in quotes as strings,"A CSV file containing quoted values:

```python
In [15]: !cat test.csv
""1"",""2""
""3"",""4""
```

has the data type of the quoted values inferred by Pandas:

```python
In [20]: df = pd.read_csv(""test.csv"", index_col=False, header=None)

In [21]: df
Out[21]: 
   0  1
0  1  2
1  3  4

In [22]: df.dtypes
Out[22]: 
0    int64
1    int64
dtype: object
```

but cuDF reads them as strings (""object"" data type):

```python
In [23]: df = cudf.read_csv(""test.csv"", index_col=False, header=None)

In [24]: df
Out[24]: 
   0  1
0  1  2
1  3  4

In [25]: df.dtypes
Out[25]: 
0    object
1    object
dtype: object
```",2023-01-20T16:45:24Z,0,0,Ashwin Srinath,Voltron Data
196,[FEA] Refactor `experimental/row_operators.cuh` and make it default,"**Is your feature request related to a problem? Please describe.**
libcudf contains two sets of row operators: [legacy row operators](https://github.com/rapidsai/cudf/blob/branch-23.02/cpp/include/cudf/table/row_operators.cuh) for simple types and [experimental row operators](https://github.com/rapidsai/cudf/blob/branch-23.02/cpp/include/cudf/table/experimental/row_operators.cuh) for complex types. When we have completed ""Part 1"" of #11844, then we can safely refactor the experimental row operators to be the default, and drop the `table::experimental` namespace

**Describe the solution you'd like**
Ultimately we will deprecate the legacy row operators and move the experimental row operators out of the experimental namespace. Please note that the new equality and lexicographic comparators will include ""fast paths"" for simple types (see #11330 and #11129), so the legacy row operators will continue to play a role.

Merge plan for completing the deprecation
- [x] Implement ""fast path"" for equality comparison (closed by #12676)
- [ ] Breakup the row_comparator.cu (#11012)
- [ ] Update all algorithms on new comparator, (complete Part 1 of #11844)
- [ ] Drop the experimental namespace and remove legacy comparator

**Describe alternatives you've considered**
n/a

**Additional context**
See #10186 and follow-on issue #11844 for more information about the nested type comparator project.",2023-01-23T17:56:35Z,0,0,Gregory Kimball,
197,[FEA] support DataFrameGroupBy.shift,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**

https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.shift.html

```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame({'salary': [30000,40000,50000,85000,75000], 'gender': list('MFMFM')})

In [9]: df.groupby('gender')['salary'].transform(lambda x: x.shift(-1))
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Cell In [9], line 1
----> 1 df.groupby('gender')['salary'].transform(lambda x: x.shift(-1))

File ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:1070, in GroupBy.transform(self, function)
   1036 """"""Apply an aggregation, then broadcast the result to the group size.
   1037 
   1038 Parameters
   (...)
   1067 agg
   1068 """"""
   1069 try:
-> 1070     result = self.agg(function)
   1071 except TypeError as e:
   1072     raise NotImplementedError(
   1073         ""Currently, `transform()` supports only aggregations.""
   1074     ) from e

File ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:1749, in SeriesGroupBy.agg(self, func)
   1748 def agg(self, func):
-> 1749     result = super().agg(func)
   1751     # downcast the result to a Series:
   1752     if len(result._data):

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:460, in GroupBy.agg(self, func)
    451 column_names, columns, normalized_aggs = self._normalize_aggs(func)
    453 # Note: When there are no key columns, the below produces
    454 # a Float64Index, while Pandas returns an Int64Index
    455 # (GH: 6945)
    456 (
    457     result_columns,
    458     grouped_key_cols,
    459     included_aggregations,
--> 460 ) = self._groupby.aggregate(columns, normalized_aggs)
    462 result_index = self.grouping.keys._from_columns_like_self(
    463     grouped_key_cols,
    464 )
    466 multilevel = _is_multi_agg(func)

File groupby.pyx:309, in cudf._lib.groupby.GroupBy.aggregate()

File groupby.pyx:184, in cudf._lib.groupby.GroupBy.aggregate_internal()

File aggregation.pyx:866, in cudf._lib.aggregation.make_groupby_aggregation()

Cell In [9], line 1, in <lambda>(x)
----> 1 df.groupby('gender')['salary'].transform(lambda x: x.shift(-1))

AttributeError: type object 'cudf._lib.aggregation.GroupbyAggregation' has no attribute 'shift'

In [10]: df.to_pandas().groupby('gender')['salary'].transform(lambda x: x.shift(-1))
Out[10]: 
0    50000.0
1    85000.0
2    75000.0
3        NaN
4        NaN
Name: salary, dtype: float64
```",2023-01-26T19:37:09Z,0,0,Matthew Farrellee,
198,[FEA] support PEP 249 – Python Database API Specification v2.0,"**Is your feature request related to a problem? Please describe.**
connecting a database to a DataFrame

**Describe the solution you'd like**
https://peps.python.org/pep-0249/

- [ ] https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html
- [ ] https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html
- [ ] https://pandas.pydata.org/docs/reference/api/pandas.read_sql_table.html
- [ ] https://pandas.pydata.org/docs/reference/api/pandas.read_sql_query.html",2023-01-26T19:49:50Z,0,0,Matthew Farrellee,
199,[FEA] support numeric_only parameter for groupby.mean(),"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
`pandas`  has deprecated dropping invalid columns during aggregation, e.g. `mean(numeric_only=None)`

`cudf` does not support automatic dropping and does not support `numeric_only`

```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame({'a': ['apple', 'orange'], 'b': [['one', 'two', 'three'], ['four', 'five']]})

In [4]: df.to_pandas().explode('b').groupby('a').mean()
<ipython-input-4-b1604cfc90a4>:1: FutureWarning: Dropping invalid columns in DataFrameGroupBy.mean is deprecated. In a future version, a TypeError will be raised. Before calling .mean, select only columns which should be valid for the function.
  df.to_pandas().explode('b').groupby('a').mean()
Out[4]: 
Empty DataFrame
Columns: []
Index: [apple, orange]

In [5]: df.explode('b').groupby('a').mean()
---------------------------------------------------------------------------
DataError                                 Traceback (most recent call last)
Cell In [5], line 1
----> 1 df.explode('b').groupby('a').mean()

File ~/.local/lib/python3.9/site-packages/cudf/core/mixins/mixin_factory.py:11, in _partialmethod.<locals>.wrapper(self, *args2, **kwargs2)
     10 def wrapper(self, *args2, **kwargs2):
---> 11     return method(self, *args1, *args2, **kwargs1, **kwargs2)

File ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:532, in GroupBy._reduce(self, op, numeric_only, min_count, *args, **kwargs)
    528 if min_count != 0:
    529     raise NotImplementedError(
    530         ""min_count parameter is not implemented yet""
    531     )
--> 532 return self.agg(op)

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:460, in GroupBy.agg(self, func)
    451 column_names, columns, normalized_aggs = self._normalize_aggs(func)
    453 # Note: When there are no key columns, the below produces
    454 # a Float64Index, while Pandas returns an Int64Index
    455 # (GH: 6945)
    456 (
    457     result_columns,
    458     grouped_key_cols,
    459     included_aggregations,
--> 460 ) = self._groupby.aggregate(columns, normalized_aggs)
    462 result_index = self.grouping.keys._from_columns_like_self(
    463     grouped_key_cols,
    464 )
    466 multilevel = _is_multi_agg(func)

File groupby.pyx:309, in cudf._lib.groupby.GroupBy.aggregate()

File groupby.pyx:199, in cudf._lib.groupby.GroupBy.aggregate_internal()

DataError: All requested aggregations are unsupported.

In [6]: df.explode('b').groupby('a').mean(numeric_only=True)
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
Cell In [6], line 1
----> 1 df.explode('b').groupby('a').mean(numeric_only=True)

File ~/.local/lib/python3.9/site-packages/cudf/core/mixins/mixin_factory.py:11, in _partialmethod.<locals>.wrapper(self, *args2, **kwargs2)
     10 def wrapper(self, *args2, **kwargs2):
---> 11     return method(self, *args1, *args2, **kwargs1, **kwargs2)

File ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:525, in GroupBy._reduce(self, op, numeric_only, min_count, *args, **kwargs)
    502 """"""Compute {op} of group values.
    503 
    504 Parameters
   (...)
    522     * Not supporting: numeric_only, min_count
    523 """"""
    524 if numeric_only:
--> 525     raise NotImplementedError(
    526         ""numeric_only parameter is not implemented yet""
    527     )
    528 if min_count != 0:
    529     raise NotImplementedError(
    530         ""min_count parameter is not implemented yet""
    531     )

NotImplementedError: numeric_only parameter is not implemented yet
```",2023-01-26T20:20:28Z,0,0,Matthew Farrellee,
200,[FEA] support numeric_only for DataFrame.corr,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
`cudf.DataFrame.corr` matching `pandas.DataFrame.corr` behavior

1. addition of `numeric_only` parameter 
2. default `numeric_only=None` with deprecation warning and lifecycle similar to `pandas`

```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '22.12.0'

In [3]: df = pd.DataFrame({'a': range(10), 'b': range(10,20), 'c': list('zyxwvutsrq')})

In [4]: df.corr()
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
Cell In [4], line 1
----> 1 df.corr()

File ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:6490, in DataFrame.corr(self, method, min_periods)
   6470 """"""Compute the correlation matrix of a DataFrame.
   6471 
   6472 Parameters
   (...)
   6487     The requested correlation matrix.
   6488 """"""
   6489 if method == ""pearson"":
-> 6490     values = self.values
   6491 elif method == ""spearman"":
   6492     values = self.rank().values

File ~/.local/lib/python3.9/site-packages/cudf/core/frame.py:433, in Frame.values(self)
    420 @property
    421 def values(self):
    422     """"""
    423     Return a CuPy representation of the DataFrame.
    424 
   (...)
    431         The values of the DataFrame.
    432     """"""
--> 433     return self.to_cupy()

File ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)
     98 @wraps(func)
     99 def inner(*args, **kwargs):
    100     libnvtx_push_range(self.attributes, self.domain.handle)
--> 101     result = func(*args, **kwargs)
    102     libnvtx_pop_range(self.domain.handle)
    103     return result

File ~/.local/lib/python3.9/site-packages/cudf/core/frame.py:533, in Frame.to_cupy(self, dtype, copy, na_value)
    507 @_cudf_nvtx_annotate
    508 def to_cupy(
    509     self,
   (...)
    512     na_value=None,
    513 ) -> cupy.ndarray:
    514     """"""Convert the Frame to a CuPy array.
    515 
    516     Parameters
   (...)
    531     cupy.ndarray
    532     """"""
--> 533     return self._to_array(
    534         (lambda col: col.values.copy())
    535         if copy
    536         else (lambda col: col.values),
    537         cupy.empty,
    538         dtype,
    539         na_value,
    540     )

File ~/.local/lib/python3.9/site-packages/cudf/core/frame.py:498, in Frame._to_array(self, get_column_values, make_empty_matrix, dtype, na_value)
    491 matrix = make_empty_matrix(
    492     shape=(len(self), ncol), dtype=dtype, order=""F""
    493 )
    494 for i, col in enumerate(self._data.values()):
    495     # TODO: col.values may fail if there is nullable data or an
    496     # unsupported dtype. We may want to catch and provide a more
    497     # suitable error.
--> 498     matrix[:, i] = get_column_values_na(col)
    499 return matrix

File cupy/_core/core.pyx:1508, in cupy._core.core.ndarray.__setitem__()

File cupy/_core/_routines_indexing.pyx:51, in cupy._core._routines_indexing._ndarray_setitem()

File cupy/_core/_routines_indexing.pyx:997, in cupy._core._routines_indexing._scatter_op()

File cupy/_core/_kernel.pyx:1292, in cupy._core._kernel.ufunc.__call__()

File cupy/_core/_kernel.pyx:1319, in cupy._core._kernel.ufunc._get_ufunc_kernel()

File cupy/_core/_kernel.pyx:1025, in cupy._core._kernel._get_ufunc_kernel()

File cupy/_core/_kernel.pyx:66, in cupy._core._kernel._get_simple_elementwise_kernel()

File cupy/_core/_kernel.pyx:322, in cupy._core._kernel._get_kernel_params()

File cupy/_core/_kernel.pyx:298, in cupy._core._kernel._ArgInfo.get_param_c_type()

File cupy/_core/_kernel.pyx:285, in cupy._core._kernel._ArgInfo.get_c_type()

File cupy/_core/_scalar.pyx:68, in cupy._core._scalar.get_typename()

File cupy/_core/_scalar.pyx:73, in cupy._core._scalar.get_typename()

KeyError: <class 'numpy.object_'>

In [5]: df.to_pandas().corr()
<ipython-input-5-98783459b7d9>:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  df.to_pandas().corr()
Out[5]: 
     a    b
a  1.0  1.0
b  1.0  1.0
```

[`pandas` introduced a `numeric_only` parameter](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)

```
In [6]: df.to_pandas().corr(numeric_only=True)
Out[6]: 
     a    b
a  1.0  1.0
b  1.0  1.0

In [7]: df.corr(numeric_only=True)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In [7], line 1
----> 1 df.corr(numeric_only=True)

TypeError: corr() got an unexpected keyword argument 'numeric_only'
```
```",2023-01-26T22:41:43Z,0,0,Matthew Farrellee,
201,"[DOC] Fix and/or remove cuda.h ""File Not Found"" warning in our 10 Minutes docs.","## Report incorrect documentation

**Describe the problems or issues found in the documentation**
`../../thread/thread_load.cuh(36): warning: cuda.h: [jitify] File not found` warning is in our stable and nightly docs on the site on 10mins.ipynb.  

**Location of incorrect documentation**
https://docs.rapids.ai/api/cudf/stable/user_guide/10min.html#object-creation
https://docs.rapids.ai/api/cudf/nightly/user_guide/10min.html#object-creation

Could we remove this from our docs and/or fix the underlying issue?



",2023-01-27T12:30:41Z,0,0,Taurean Dyer,
202,[BUG] DataFrame.dropna does not support axis='index' results in mismatch w/ pandas,"**Describe the bug**
using `import cudf as pd`

**Steps/Code to reproduce bug**
```
>>> import cudf as pd
>>> import numpy as np

>>> df = pd.DataFrame({'a': ['one', 'two', 'three', 'four', np.nan, None, 'NA'], 'b': ['this', 'that', 'the', 'other', np.nan, np.nan, 'Missing'], 'c': ['something', 'or', 'other', None, np.nan, 'hmm', 'NA'], 'd': ['00', '01', '02', '03', None, None, 'Missing']})
>>> df
       a        b          c        d
0    one     this  something       00
1    two     that         or       01
2  three      the      other       02
3   four    other       <NA>       03
4   <NA>     <NA>       <NA>     <NA>
5   <NA>     <NA>        hmm     <NA>
6     NA  Missing         NA  Missing

>>> df.dropna(axis='index')
/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py:1165: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.
  mask = pd.Series(mask)
Empty DataFrame
Columns: []
Index: [0, 1, 2, 3, 4, 5, 6]
>>> df.to_pandas().dropna(axis='index')
       a        b          c        d
0    one     this  something       00
1    two     that         or       01
2  three      the      other       02
6     NA  Missing         NA  Missing
```

**Environment overview (please complete the following information)**
 - rapidsai/rapidsai-nightly:cuda11.5-runtime-ubuntu20.04-py3.8
 - sha256:4a69370ad40f47a71404805fe2b1dd0a5cf28d7f6a5d4dd1cad419f8a3c8ce5f
 - 30 jan 2023

![Screenshot from 2023-01-30 14-12-11](https://user-images.githubusercontent.com/112653/215572351-96fdd5bc-b96a-47ed-a55b-f84e5cbd9603.png)
![Screenshot from 2023-01-30 14-12-02](https://user-images.githubusercontent.com/112653/215572362-8705fc0a-9ae8-4e94-a62f-5f99a32ff235.png)

",2023-01-30T19:13:24Z,0,0,Matthew Farrellee,
203,[FEA] add DataFrame.interpolate methods supported by cupyx,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
[cudf.DataFrame.interpolate](https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.dataframe.interpolate) supports `method=""linear""`

[pandas.DataFrame.interpolate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html) supports a number of methods, including
- [ ] time
- [ ] krogh
- [ ] piecewise_polynomial
- [ ] spline
- [ ] pchip
- [ ] akima
- [ ] cubicspline

[cupyx.scipy.interpolate](https://docs.cupy.dev/en/latest/reference/scipy_interpolate.html) provides implementations for most of these

extend the supported methods by those available in `cupyx`

",2023-01-31T00:23:42Z,0,0,Matthew Farrellee,
204,[FEA] support cudf.Series.at,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
functionality matching https://pandas.pydata.org/docs/reference/api/pandas.Series.at.html
![image](https://user-images.githubusercontent.com/112653/215628566-44bab64b-d4b3-4250-a97a-ce28082f9c7f.png)
",2023-01-31T00:37:27Z,0,0,Matthew Farrellee,
205,[BUG] `cudf::strings::from_integers` does not appear to be `compute-sanitizer --tool initcheck` clean,"Conversion from (at least) integer to string columns (done a lot for printing on the cudf-python side of things) appears to have uninitialized device memory accesses. Related #8873.

Consider the following:
```c++
#include <algorithm>
#include <cstdint>
#include <vector>

#include <cudf/column/column.hpp>
#include <cudf/column/column_view.hpp>
#include <cudf/strings/convert/convert_integers.hpp>
#include <cudf/types.hpp>

int main(int argc, char **argv) {
  using T = int64_t;
  using size_type = cudf::size_type;
  size_type size;
  if (argc > 1) {
    size = std::stoi(argv[1]);
  } else {
    size = 1;
  }
  std::vector<T> data{size};
  std::generate(data.begin(), data.end(), []() { return 1; });
  auto column = cudf::column{cudf::data_type{cudf::type_to_id<T>()}, size,
                             rmm::device_buffer{data.data(), size * sizeof(T),
                                                cudf::get_default_stream()}};
  cudf::get_default_stream().synchronize();
  auto string_col = cudf::strings::from_integers(
      column.view(), rmm::mr::get_current_device_resource());
  cudf::get_default_stream().synchronize();
  return 0;
}
```

When run as:
```
$ compute-sanitizer --tool initcheck ./test
========= COMPUTE-SANITIZER
========= Uninitialized __global__ memory read of size 4 bytes
=========     at 0x1c0 in void cub::CUB_101702_860_NS::DeviceScanKernel<cub::CUB_101702_860_NS::DeviceScanPolicy<long>::Policy600, int *, cudf::detail::sizes_to_offsets_iterator<int *, long>, cub::CUB_101702_860_NS::ScanTileState<long, (bool)1>, thrust::plus<void>, cub::CUB_101702_860_NS::detail::InputValue<long, long *>, int>(T2, T3, T4, int, T5, T6, T7)
=========     by thread (1,0,0) in block (0,0,0)
=========     Address 0x7f26c3e00204
=========     Saved host backtrace up to driver entry point at kernel launch time
=========     Host Frame: [0x304e32]
=========                in /usr/lib/x86_64-linux-gnu/libcuda.so.1
=========     Host Frame: [0x1488c]
=========                in /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/lib/libcudart.so.11.0
=========     Host Frame:cudaLaunchKernel [0x6c318]
=========                in /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/lib/libcudart.so.11.0
=========     Host Frame:cudf::detail::sizes_to_offsets_iterator<int*, long> thrust::cuda_cub::detail::exclusive_scan_n_impl<thrust::detail::execute_with_allocator<rmm::mr::thrust_allocator<char>, thrust::cuda_cub::execute_on_stream_base>, int*, long, cudf::detail::sizes_to_offsets_iterator<int*, long>, long, thrust::plus<void> >(thrust::cuda_cub::execution_policy<thrust::detail::execute_with_allocator<rmm::mr::thrust_allocator<char>, thrust::cuda_cub::execute_on_stream_base> >&, int*, long, cudf::detail::sizes_to_offsets_iterator<int*, long>, long, thrust::plus<void>) [0x161bf95]
=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so
=========     Host Frame:auto cudf::detail::sizes_to_offsets<int*, int*>(int*, int*, int*, rmm::cuda_stream_view) [0x161c612]
=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so
=========     Host Frame:auto cudf::strings::detail::make_strings_children<cudf::strings::detail::(anonymous namespace)::from_integers_fn<long> >(cudf::strings::detail::(anonymous namespace)::from_integers_fn<long>, int, int, rmm::cuda_stream_view, rmm::mr::device_memory_resource*) [0x264fb1f]
=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so
=========     Host Frame:std::unique_ptr<cudf::column, std::default_delete<cudf::column> > cudf::strings::detail::(anonymous namespace)::dispatch_from_integers_fn::operator()<long, (void*)0>(cudf::column_view const&, rmm::cuda_stream_view, rmm::mr::device_memory_resource*) const [0x264feb1]
=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so
=========     Host Frame:cudf::strings::detail::from_integers(cudf::column_view const&, rmm::cuda_stream_view, rmm::mr::device_memory_resource*) [0x264a1e9]
=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so
=========     Host Frame:cudf::strings::from_integers(cudf::column_view const&, rmm::mr::device_memory_resource*) [0x264a2c7]
=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so
=========     Host Frame:/home/wence/Documents/src/rapids/doodles/c++/test_from_integers.cpp:26:main [0x1ae5e]
=========                in /home/wence/Documents/src/rapids/doodles/c++/./test
=========     Host Frame:__libc_start_main [0x24083]
=========                in /usr/lib/x86_64-linux-gnu/libc.so.6
=========     Host Frame: [0x13079]
=========                in /home/wence/Documents/src/rapids/doodles/c++/./test
=========
========= ERROR SUMMARY: 1 error
```

This _looks_ like an off-by-one, but my tracking through the libcudf side of things didn't spot anything, so perhaps it is a bug in thrust or CUB.

**Environment overview (please complete the following information)**
 - Environment location: [Bare-metal, Docker, Cloud(specify cloud provider)]
 - Method of cuDF install: [conda, Docker, or from source]
   - If method of install is [Docker], provide `docker pull` & `docker run` commands used

**Environment details**

<details><summary>Click here to see environment details</summary><pre>

     **git***
     commit 55ef6018ed92bfd6d3cbb67d9736c72aadaa2668 (HEAD -> branch-23.02)
     Author: Karthikeyan <6488848+karthikeyann@users.noreply.github.com>
     Date:   Sat Jan 28 07:09:29 2023 +0530

     Add JSON Writer (#12474)

     Adds JSON writer with nested support.
     It supports numeric, datetime, duration, strings,  nested types such as struct and list types.
     `orient='records'` is only supported now, with `lines=True/False`.
     Usage: `df.to_json(engine='cudf')`

     closes https://github.com/rapidsai/cudf/issues/11165

     Authors:
     - Karthikeyan (https://github.com/karthikeyann)

     Approvers:
     - Vukasin Milovanovic (https://github.com/vuule)
     - GALI PREM SAGAR (https://github.com/galipremsagar)
     - David Wendt (https://github.com/davidwendt)
     - Michael Wang (https://github.com/isVoid)
     - Robert Maynard (https://github.com/robertmaynard)

     URL: https://github.com/rapidsai/cudf/pull/12474
     **git submodules***

     ***OS Information***
     DISTRIB_ID=Ubuntu
     DISTRIB_RELEASE=20.04
     DISTRIB_CODENAME=focal
     DISTRIB_DESCRIPTION=""Ubuntu 20.04.5 LTS""
     NAME=""Ubuntu""
     VERSION=""20.04.5 LTS (Focal Fossa)""
     ID=ubuntu
     ID_LIKE=debian
     PRETTY_NAME=""Ubuntu 20.04.5 LTS""
     VERSION_ID=""20.04""
     HOME_URL=""https://www.ubuntu.com/""
     SUPPORT_URL=""https://help.ubuntu.com/""
     BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
     PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
     VERSION_CODENAME=focal
     UBUNTU_CODENAME=focal
     Linux shallot 5.15.0-58-generic NVIDIA/cub#64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux

     ***GPU Information***
     Wed Feb  1 16:01:12 2023
     +-----------------------------------------------------------------------------+
     | NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
     |-------------------------------+----------------------+----------------------+
     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
     |                               |                      |               MIG M. |
     |===============================+======================+======================|
     |   0  NVIDIA RTX A6000    On   | 00000000:17:00.0 Off |                  Off |
     | 30%   31C    P8    21W / 300W |      6MiB / 49140MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     |   1  NVIDIA RTX A6000    On   | 00000000:B3:00.0  On |                  Off |
     | 30%   43C    P3    49W / 300W |   1343MiB / 49140MiB |     13%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+

     +-----------------------------------------------------------------------------+
     | Processes:                                                                  |
     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
     |        ID   ID                                                   Usage      |
     |=============================================================================|
     |    0   N/A  N/A      3089      G   /usr/lib/xorg/Xorg                  4MiB |
     |    1   N/A  N/A      3089      G   /usr/lib/xorg/Xorg                738MiB |
     |    1   N/A  N/A      3267      G   /usr/bin/gnome-shell              185MiB |
     |    1   N/A  N/A     44652      G   ...veSuggestionsOnlyOnDemand      154MiB |
     |    1   N/A  N/A     45338      G   /usr/bin/wezterm-gui               11MiB |
     +-----------------------------------------------------------------------------+

     ***CPU***
     Architecture:                    x86_64
     CPU op-mode(s):                  32-bit, 64-bit
     Byte Order:                      Little Endian
     Address sizes:                   46 bits physical, 48 bits virtual
     CPU(s):                          32
     On-line CPU(s) list:             0-31
     Thread(s) per core:              2
     Core(s) per socket:              16
     Socket(s):                       1
     NUMA node(s):                    1
     Vendor ID:                       GenuineIntel
     CPU family:                      6
     Model:                           85
     Model name:                      Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz
     Stepping:                        7
     CPU MHz:                         2900.000
     CPU max MHz:                     3900.0000
     CPU min MHz:                     1200.0000
     BogoMIPS:                        5800.00
     Virtualization:                  VT-x
     L1d cache:                       512 KiB
     L1i cache:                       512 KiB
     L2 cache:                        16 MiB
     L3 cache:                        22 MiB
     NUMA node0 CPU(s):               0-31
     Vulnerability Itlb multihit:     KVM: Mitigation: VMX disabled
     Vulnerability L1tf:              Not affected
     Vulnerability Mds:               Not affected
     Vulnerability Meltdown:          Not affected
     Vulnerability Mmio stale data:   Mitigation; Clear CPU buffers; SMT vulnerable
     Vulnerability Retbleed:          Mitigation; Enhanced IBRS
     Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
     Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
     Vulnerability Spectre v2:        Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence
     Vulnerability Srbds:             Not affected
     Vulnerability Tsx async abort:   Mitigation; TSX disabled
     Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni md_clear flush_l1d arch_capabilities

     ***CMake***
     /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/bin/cmake
     cmake version 3.25.2

     CMake suite maintained and supported by Kitware (kitware.com/cmake).

     ***g++***
     /usr/local/sbin/g++
     g++ (conda-forge gcc 9.5.0-19) 9.5.0
     Copyright (C) 2019 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


     ***nvcc***
     /usr/local/sbin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2022 NVIDIA Corporation
     Built on Wed_Sep_21_10:33:58_PDT_2022
     Cuda compilation tools, release 11.8, V11.8.89
     Build cuda_11.8.r11.8/compiler.31833905_0

     ***Python***
     /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/bin/python
     Python 3.8.15

     ***Environment Variables***
     PATH                            : /usr/local/sbin:/usr/local/bin:/home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/bin:/home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/cuda/bin
     LD_LIBRARY_PATH                 : /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/lib:/home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/lib:/home/wence/Documents/src/rapids/rmm/build/release:/home/wence/Documents/src/rapids/cudf/cpp/build/release:/home/wence/Documents/src/rapids/raft/cpp/build/release:/home/wence/Documents/src/rapids/cuml/cpp/build/release:/home/wence/Documents/src/rapids/cugraph/cpp/build/release:/home/wence/Documents/src/rapids/cuspatial/cpp/build/release
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids
     PYTHON_PATH                     :

     ***conda packages***
     /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/bin/conda

     # packages in environment at /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                  2_kmp_llvm    conda-forge
     _sysroot_linux-64_curr_repodata_hack 3                   h5bd9786_13    conda-forge
     aiobotocore               2.4.2              pyhd8ed1ab_0    conda-forge
     aiohttp                   3.8.3            py38h0a891b7_1    conda-forge
     aioitertools              0.11.0             pyhd8ed1ab_0    conda-forge
     aiosignal                 1.3.1              pyhd8ed1ab_0    conda-forge
     alabaster                 0.7.13             pyhd8ed1ab_0    conda-forge
     anyio                     3.6.2              pyhd8ed1ab_0    conda-forge
     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
     argon2-cffi               21.3.0             pyhd8ed1ab_0    conda-forge
     argon2-cffi-bindings      21.2.0           py38h0a891b7_3    conda-forge
     arrow-cpp                 10.0.1           ha770c72_6_cpu    conda-forge
     asttokens                 2.2.1              pyhd8ed1ab_0    conda-forge
     async-timeout             4.0.2              pyhd8ed1ab_0    conda-forge
     attrs                     22.2.0             pyh71513ae_0    conda-forge
     aws-c-auth                0.6.21               hd93a3ba_3    conda-forge
     aws-c-cal                 0.5.20               hff2c3d7_3    conda-forge
     aws-c-common              0.8.5                h166bdaf_0    conda-forge
     aws-c-compression         0.2.16               hf5f93bc_0    conda-forge
     aws-c-event-stream        0.2.18               h57874a7_0    conda-forge
     aws-c-http                0.7.0                h96ef541_0    conda-forge
     aws-c-io                  0.13.12              h57ca295_1    conda-forge
     aws-c-mqtt                0.7.13              h0b5698f_12    conda-forge
     aws-c-s3                  0.2.3                h82cbbf9_0    conda-forge
     aws-c-sdkutils            0.1.7                hf5f93bc_0    conda-forge
     aws-checksums             0.1.14               h6027aba_0    conda-forge
     aws-crt-cpp               0.18.16             hf80f573_10    conda-forge
     aws-sam-translator        1.58.1             pyhd8ed1ab_0    conda-forge
     aws-sdk-cpp               1.10.57              ha834a50_1    conda-forge
     aws-xray-sdk              2.11.0             pyhd8ed1ab_0    conda-forge
     babel                     2.11.0             pyhd8ed1ab_0    conda-forge
     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge
     backports                 1.0                pyhd8ed1ab_3    conda-forge
     backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge
     backports.zoneinfo        0.2.1            py38h0a891b7_7    conda-forge
     bcrypt                    3.2.2            py38h0a891b7_1    conda-forge
     beautifulsoup4            4.11.1             pyha770c72_0    conda-forge
     binutils                  2.39                 hdd6e379_1    conda-forge
     binutils_impl_linux-64    2.39                 he00db2b_1    conda-forge
     binutils_linux-64         2.39                h5fc0e48_11    conda-forge
     blas                      1.0                         mkl    conda-forge
     bleach                    6.0.0              pyhd8ed1ab_0    conda-forge
     blosc                     1.21.3               hafa529b_0    conda-forge
     bokeh                     2.4.3              pyhd8ed1ab_3    conda-forge
     boost-cpp                 1.78.0               h75c5d50_1    conda-forge
     boto3                     1.24.59            pyhd8ed1ab_0    conda-forge
     botocore                  1.27.59            pyhd8ed1ab_0    conda-forge
     branca                    0.6.0              pyhd8ed1ab_0    conda-forge
     breathe                   4.34.0             pyhd8ed1ab_0    conda-forge
     brotli                    1.0.9                h166bdaf_8    conda-forge
     brotli-bin                1.0.9                h166bdaf_8    conda-forge
     brotlipy                  0.7.0           py38h0a891b7_1005    conda-forge
     bzip2                     1.0.8                h7f98852_4    conda-forge
     c-ares                    1.18.1               h7f98852_0    conda-forge
     c-compiler                1.3.0                h7f98852_0    conda-forge
     ca-certificates           2022.12.7            ha878542_0    conda-forge
     cachetools                5.3.0              pyhd8ed1ab_0    conda-forge
     cairo                     1.16.0            ha61ee94_1014    conda-forge
     certifi                   2022.12.7          pyhd8ed1ab_0    conda-forge
     cffi                      1.15.1           py38h4a40e3a_3    conda-forge
     cfgv                      3.3.1              pyhd8ed1ab_0    conda-forge
     cfitsio                   4.2.0                hd9d235c_0    conda-forge
     cfn-lint                  0.24.8                   py38_0    conda-forge
     charset-normalizer        2.1.1              pyhd8ed1ab_0    conda-forge
     clang                     11.1.0               ha770c72_1    conda-forge
     clang-11                  11.1.0          default_ha53f305_1    conda-forge
     clang-tools               11.1.0          default_ha53f305_1    conda-forge
     clangxx                   11.1.0          default_ha53f305_1    conda-forge
     click                     8.1.3           unix_pyhd8ed1ab_2    conda-forge
     click-plugins             1.1.1                      py_0    conda-forge
     cligj                     0.7.2              pyhd8ed1ab_1    conda-forge
     cloudpickle               2.2.1              pyhd8ed1ab_0    conda-forge
     cmake                     3.25.2               h077f3f9_0    conda-forge
     cmake_setuptools          0.1.3                      py_0    rapidsai
     colorama                  0.4.6              pyhd8ed1ab_0    conda-forge
     comm                      0.1.2              pyhd8ed1ab_0    conda-forge
     commonmark                0.9.1                      py_0    conda-forge
     contourpy                 1.0.7            py38hfbd4bf9_0    conda-forge
     coverage                  7.1.0            py38h1de0b5d_0    conda-forge
     cryptography              39.0.0           py38h3d167d9_0    conda-forge
     cubinlinker               0.2.2            py38h7144610_0    rapidsai
     cuda-profiler-api         11.8.86                       0    nvidia
     cuda-python               11.8.1           py38h241159d_2    conda-forge
     cudatoolkit               11.8.0              h37601d7_11    conda-forge
     cupy                      11.5.0           py38h405e1b6_0    conda-forge
     curl                      7.87.0               hdc1c0ab_0    conda-forge
     cxx-compiler              1.3.0                h4bd325d_0    conda-forge
     cycler                    0.11.0             pyhd8ed1ab_0    conda-forge
     cyrus-sasl                2.1.27               h9033bb2_6    conda-forge
     cython                    0.29.33          py38h8dc9893_0    conda-forge
     cytoolz                   0.12.0           py38h0a891b7_1    conda-forge
     dask                      2023.1.0+17.g2a2b9d3c           dev_0    <develop>
     dask-core                 2023.1.1a230127 py_g185eed2c9_23    dask/label/dev
     dask-cuda                 23.2.0a0+41.g66a6a46.dirty          pypi_0    pypi
     dask-glm                  0.2.1.dev52+g1daf4c5          pypi_0    pypi
     dask-ml                   2022.5.27          pyhd8ed1ab_0    conda-forge
     dataclasses               0.8                pyhc8e2a94_3    conda-forge
     datasets                  1.18.3             pyhd8ed1ab_0    conda-forge
     debugpy                   1.6.6            py38h8dc9893_0    conda-forge
     decopatch                 1.4.10             pyhd8ed1ab_0    conda-forge
     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge
     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge
     dill                      0.3.6              pyhd8ed1ab_1    conda-forge
     distlib                   0.3.6              pyhd8ed1ab_0    conda-forge
     distributed               2023.1.0+9.g0161991f.dirty           dev_0    <develop>
     distro                    1.8.0              pyhd8ed1ab_0    conda-forge
     dlpack                    0.5                  h9c3ff4c_0    conda-forge
     docker-py                 6.0.0              pyhd8ed1ab_0    conda-forge
     docutils                  0.19             py38h578d9bd_1    conda-forge
     doxygen                   1.8.20               had0d8f1_0    conda-forge
     ecdsa                     0.18.0             pyhd8ed1ab_1    conda-forge
     entrypoints               0.4                pyhd8ed1ab_0    conda-forge
     exceptiongroup            1.1.0              pyhd8ed1ab_0    conda-forge
     execnet                   1.9.0              pyhd8ed1ab_0    conda-forge
     executing                 1.2.0              pyhd8ed1ab_0    conda-forge
     expat                     2.5.0                h27087fc_0    conda-forge
     faiss-proc                1.0.0                      cuda    rapidsai
     fastavro                  1.7.1            py38h1de0b5d_0    conda-forge
     fastrlock                 0.8              py38hfa26641_3    conda-forge
     filelock                  3.9.0              pyhd8ed1ab_0    conda-forge
     fiona                     1.8.22           py38hc72d8cd_2    conda-forge
     flask                     2.1.3              pyhd8ed1ab_0    conda-forge
     flask_cors                3.0.10             pyhd3deb0d_0    conda-forge
     flit-core                 3.8.0              pyhd8ed1ab_0    conda-forge
     folium                    0.14.0             pyhd8ed1ab_0    conda-forge
     font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge
     font-ttf-inconsolata      3.000                h77eed37_0    conda-forge
     font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge
     font-ttf-ubuntu           0.83                 hab24e00_0    conda-forge
     fontconfig                2.14.2               h14ed4e7_0    conda-forge
     fonts-conda-ecosystem     1                             0    conda-forge
     fonts-conda-forge         1                             0    conda-forge
     fonttools                 4.38.0           py38h0a891b7_1    conda-forge
     freetype                  2.12.1               hca18f0e_1    conda-forge
     freexl                    1.0.6                h166bdaf_1    conda-forge
     frozenlist                1.3.3            py38h0a891b7_0    conda-forge
     fsspec                    2023.1.0           pyhd8ed1ab_0    conda-forge
     future                    0.18.3             pyhd8ed1ab_0    conda-forge
     gcc                       9.5.0               h1fea6ba_11    conda-forge
     gcc_impl_linux-64         9.5.0               h99780fb_19    conda-forge
     gcc_linux-64              9.5.0               h4258300_11    conda-forge
     gcovr                     5.1                pyhd8ed1ab_0    conda-forge
     gdal                      3.5.3           py38h58634bd_15    conda-forge
     geopandas                 0.12.2             pyhd8ed1ab_0    conda-forge
     geopandas-base            0.12.2             pyha770c72_0    conda-forge
     geos                      3.11.1               h27087fc_0    conda-forge
     geotiff                   1.7.1                h7a142b4_6    conda-forge
     gettext                   0.21.1               h27087fc_0    conda-forge
     gflags                    2.2.2             he1b5a44_1004    conda-forge
     giflib                    5.2.1                h36c2ea0_2    conda-forge
     glog                      0.6.0                h6f12383_0    conda-forge
     gmock                     1.10.0               h4bd325d_7    conda-forge
     gmp                       6.2.1                h58526e2_0    conda-forge
     gmpy2                     2.1.2            py38h793c122_1    conda-forge
     graphql-core              3.2.3              pyhd8ed1ab_0    conda-forge
     greenlet                  2.0.2            py38h8dc9893_0    conda-forge
     gtest                     1.10.0               h4bd325d_7    conda-forge
     gxx                       9.5.0               h1fea6ba_11    conda-forge
     gxx_impl_linux-64         9.5.0               h99780fb_19    conda-forge
     gxx_linux-64              9.5.0               h43f449f_11    conda-forge
     hdbscan                   0.8.29           py38h26c90d9_1    conda-forge
     hdf4                      4.2.15               h9772cbc_5    conda-forge
     hdf5                      1.12.2          nompi_h4df4325_101    conda-forge
     heapdict                  1.0.1                      py_0    conda-forge
     huggingface_hub           0.12.0             pyhd8ed1ab_0    conda-forge
     hypothesis                6.65.2             pyha770c72_0    conda-forge
     icu                       70.1                 h27087fc_0    conda-forge
     identify                  2.5.17             pyhd8ed1ab_0    conda-forge
     idna                      3.4                pyhd8ed1ab_0    conda-forge
     imagesize                 1.4.1              pyhd8ed1ab_0    conda-forge
     importlib-metadata        6.0.0              pyha770c72_0    conda-forge
     importlib_metadata        6.0.0                hd8ed1ab_0    conda-forge
     iniconfig                 2.0.0              pyhd8ed1ab_0    conda-forge
     ipykernel                 6.21.0             pyh210e3f2_0    conda-forge
     ipython                   8.9.0              pyh41d4057_0    conda-forge
     ipython_genutils          0.2.0                      py_1    conda-forge
     itsdangerous              2.1.2              pyhd8ed1ab_0    conda-forge
     jedi                      0.18.2             pyhd8ed1ab_0    conda-forge
     jinja2                    3.1.2              pyhd8ed1ab_1    conda-forge
     jmespath                  1.0.1              pyhd8ed1ab_0    conda-forge
     joblib                    1.2.0              pyhd8ed1ab_0    conda-forge
     jpeg                      9e                   h166bdaf_2    conda-forge
     json-c                    0.16                 hc379101_0    conda-forge
     jsondiff                  2.0.0              pyhd8ed1ab_0    conda-forge
     jsonpatch                 1.32               pyhd8ed1ab_0    conda-forge
     jsonpointer               2.0                        py_0    conda-forge
     jsonschema                3.2.0              pyhd8ed1ab_3    conda-forge
     jupyter-cache             0.5.0              pyhd8ed1ab_0    conda-forge
     jupyter_client            8.0.1              pyhd8ed1ab_0    conda-forge
     jupyter_core              5.2.0            py38h578d9bd_0    conda-forge
     jupyter_events            0.6.3              pyhd8ed1ab_0    conda-forge
     jupyter_server            2.1.0              pyhd8ed1ab_0    conda-forge
     jupyter_server_terminals  0.4.4              pyhd8ed1ab_1    conda-forge
     jupyterlab_pygments       0.2.2              pyhd8ed1ab_0    conda-forge
     kealib                    1.5.0                ha7026e8_0    conda-forge
     kernel-headers_linux-64   3.10.0              h4a8ded7_13    conda-forge
     keyutils                  1.6.1                h166bdaf_0    conda-forge
     kiwisolver                1.4.4            py38h43d8883_1    conda-forge
     krb5                      1.20.1               h81ceb04_0    conda-forge
     lcms2                     2.14                 hfd0df8a_1    conda-forge
     ld_impl_linux-64          2.39                 hcc3a1bd_1    conda-forge
     lerc                      4.0.0                h27087fc_0    conda-forge
     libabseil                 20220623.0      cxx17_h05df665_6    conda-forge
     libaec                    1.0.6                hcb278e6_1    conda-forge
     libarrow                  10.0.1           hf9c26a6_6_cpu    conda-forge
     libblas                   3.9.0            16_linux64_mkl    conda-forge
     libbrotlicommon           1.0.9                h166bdaf_8    conda-forge
     libbrotlidec              1.0.9                h166bdaf_8    conda-forge
     libbrotlienc              1.0.9                h166bdaf_8    conda-forge
     libcblas                  3.9.0            16_linux64_mkl    conda-forge
     libclang-cpp11.1          11.1.0          default_ha53f305_1    conda-forge
     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge
     libcublas                 11.11.3.6                     0    nvidia
     libcublas-dev             11.11.3.6                     0    nvidia
     libcufft                  10.9.0.58                     0    nvidia
     libcufft-dev              10.9.0.58                     0    nvidia
     libcumlprims              23.02.00a230126 cuda11_ge28945f_11    rapidsai-nightly
     libcurand                 10.3.0.86                     0    nvidia
     libcurand-dev             10.3.0.86                     0    nvidia
     libcurl                   7.87.0               hdc1c0ab_0    conda-forge
     libcusolver               11.4.1.48                     0    nvidia
     libcusolver-dev           11.4.1.48                     0    nvidia
     libcusparse               11.7.5.86                     0    nvidia
     libcusparse-dev           11.7.5.86                     0    nvidia
     libdap4                   3.20.6               hd7c4107_2    conda-forge
     libdeflate                1.17                 h0b41bf4_0    conda-forge
     libedit                   3.1.20191231         he28a2e2_2    conda-forge
     libev                     4.33                 h516909a_1    conda-forge
     libevent                  2.1.10               h28343ad_4    conda-forge
     libfaiss                  1.7.2           cuda118h2d43ea4_4_cuda    rapidsai
     libffi                    3.4.2                h7f98852_5    conda-forge
     libgcc-devel_linux-64     9.5.0               h0a57e50_19    conda-forge
     libgcc-ng                 12.2.0              h65d4601_19    conda-forge
     libgcrypt                 1.10.1               h166bdaf_0    conda-forge
     libgdal                   3.5.3               h084b287_15    conda-forge
     libgfortran-ng            12.2.0              h69a702a_19    conda-forge
     libgfortran5              12.2.0              h337968e_19    conda-forge
     libglib                   2.74.1               h606061b_1    conda-forge
     libgomp                   12.2.0              h65d4601_19    conda-forge
     libgoogle-cloud           2.5.0                h21dfe5b_1    conda-forge
     libgpg-error              1.46                 h620e276_0    conda-forge
     libgrpc                   1.51.1               h30feacc_0    conda-forge
     libgsasl                  1.8.0                         2    conda-forge
     libhwloc                  2.8.0                h32351e8_1    conda-forge
     libiconv                  1.17                 h166bdaf_0    conda-forge
     libjpeg-turbo             2.1.4                h166bdaf_0    conda-forge
     libkml                    1.3.0             h37653c0_1015    conda-forge
     liblapack                 3.9.0            16_linux64_mkl    conda-forge
     libllvm11                 11.1.0               he0ac6c6_5    conda-forge
     libnetcdf                 4.8.1           nompi_h261ec11_106    conda-forge
     libnghttp2                1.51.0               hff17c54_0    conda-forge
     libnsl                    2.0.0                h7f98852_0    conda-forge
     libntlm                   1.4               h7f98852_1002    conda-forge
     libpng                    1.6.39               h753d276_0    conda-forge
     libpq                     15.1                 hb675445_3    conda-forge
     libprotobuf               3.21.12              h3eb15da_0    conda-forge
     librdkafka                1.7.0                hb1989a6_1    conda-forge
     librttopo                 1.1.0               ha49c73b_12    conda-forge
     libsanitizer              9.5.0               h2f262e1_19    conda-forge
     libsodium                 1.0.18               h36c2ea0_1    conda-forge
     libspatialindex           1.9.3                h9c3ff4c_4    conda-forge
     libspatialite             5.0.1               h221c8f1_23    conda-forge
     libsqlite                 3.40.0               h753d276_0    conda-forge
     libssh2                   1.10.0               hf14f497_3    conda-forge
     libstdcxx-devel_linux-64  9.5.0               h0a57e50_19    conda-forge
     libstdcxx-ng              12.2.0              h46fd767_19    conda-forge
     libthrift                 0.16.0               he500d00_2    conda-forge
     libtiff                   4.5.0                h6adf6a1_2    conda-forge
     libutf8proc               2.8.0                h166bdaf_0    conda-forge
     libuuid                   2.32.1            h7f98852_1000    conda-forge
     libuv                     1.44.2               h166bdaf_0    conda-forge
     libwebp-base              1.2.4                h166bdaf_0    conda-forge
     libxcb                    1.13              h7f98852_1004    conda-forge
     libxml2                   2.10.3               h7463322_0    conda-forge
     libxslt                   1.1.37               h873f0b0_0    conda-forge
     libzip                    1.9.2                hc929e4a_1    conda-forge
     libzlib                   1.2.13               h166bdaf_4    conda-forge
     littleutils               0.2.2                      py_0    conda-forge
     livereload                2.6.3              pyh9f0ad1d_0    conda-forge
     llvm-openmp               15.0.7               h0cdce71_0    conda-forge
     llvmlite                  0.39.1           py38h38d86a4_1    conda-forge
     locket                    1.0.0              pyhd8ed1ab_0    conda-forge
     lxml                      4.9.2            py38h215a2d7_0    conda-forge
     lz4                       4.2.0            py38hd012fdc_0    conda-forge
     lz4-c                     1.9.3                h9c3ff4c_1    conda-forge
     make                      4.3                  hd18ef5c_1    conda-forge
     makefun                   1.15.0             pyhd8ed1ab_0    conda-forge
     mapclassify               2.5.0              pyhd8ed1ab_1    conda-forge
     markdown                  3.4.1              pyhd8ed1ab_0    conda-forge
     markdown-it-py            2.1.0              pyhd8ed1ab_0    conda-forge
     markupsafe                2.1.2            py38h1de0b5d_0    conda-forge
     matplotlib-base           3.6.3            py38hd6c3c57_0    conda-forge
     matplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge
     mdit-py-plugins           0.3.3              pyhd8ed1ab_0    conda-forge
     mdurl                     0.1.0              pyhd8ed1ab_0    conda-forge
     mimesis                   7.0.0              pyhd8ed1ab_0    conda-forge
     mistune                   2.0.4              pyhd8ed1ab_0    conda-forge
     mkl                       2022.2.1         h84fe81f_16997    conda-forge
     moto                      4.1.1              pyhd8ed1ab_0    conda-forge
     mpc                       1.3.1                hfe3b2da_0    conda-forge
     mpfr                      4.1.0                h9202a9a_1    conda-forge
     mpi                       1.0                     openmpi    conda-forge
     mpi4py                    3.1.4                    pypi_0    pypi
     msgpack-python            1.0.4            py38h43d8883_1    conda-forge
     multidict                 6.0.4            py38h1de0b5d_0    conda-forge
     multipledispatch          0.6.0                      py_0    conda-forge
     multiprocess              0.70.14          py38h0a891b7_3    conda-forge
     munch                     2.5.0                      py_0    conda-forge
     munkres                   1.1.4              pyh9f0ad1d_0    conda-forge
     myst-nb                   0.17.1             pyhd8ed1ab_0    conda-forge
     myst-parser               0.18.1             pyhd8ed1ab_0    conda-forge
     nbclassic                 0.4.8              pyhd8ed1ab_0    conda-forge
     nbclient                  0.5.13             pyhd8ed1ab_0    conda-forge
     nbconvert                 7.2.9              pyhd8ed1ab_0    conda-forge
     nbconvert-core            7.2.9              pyhd8ed1ab_0    conda-forge
     nbconvert-pandoc          7.2.9              pyhd8ed1ab_0    conda-forge
     nbformat                  5.7.3              pyhd8ed1ab_0    conda-forge
     nbsphinx                  0.8.12             pyhd8ed1ab_0    conda-forge
     nccl                      2.14.3.1             h0800d71_0    conda-forge
     ncurses                   6.3                  h27087fc_1    conda-forge
     nest-asyncio              1.5.6              pyhd8ed1ab_0    conda-forge
     networkx                  3.0                pyhd8ed1ab_0    conda-forge
     ninja                     1.11.0               h924138e_0    conda-forge
     nltk                      3.8.1              pyhd8ed1ab_0    conda-forge
     nodeenv                   1.7.0              pyhd8ed1ab_0    conda-forge
     notebook                  6.5.2              pyha770c72_1    conda-forge
     notebook-shim             0.2.2              pyhd8ed1ab_0    conda-forge
     nspr                      4.35                 h27087fc_0    conda-forge
     nss                       3.82                 he02c5a1_0    conda-forge
     numba                     0.56.4           py38h9a4aae9_0    conda-forge
     numpy                     1.23.5           py38h7042d01_0    conda-forge
     numpydoc                  1.5.0              pyhd8ed1ab_0    conda-forge
     nvcc_linux-64             11.8                ha67cc55_22    conda-forge
     nvtx                      0.2.3            py38h0a891b7_2    conda-forge
     ogb                       1.3.5              pyhd8ed1ab_0    conda-forge
     openapi-schema-validator  0.2.3              pyhd8ed1ab_0    conda-forge
     openapi-spec-validator    0.4.0              pyhd8ed1ab_1    conda-forge
     openjpeg                  2.5.0                hfec8fc6_2    conda-forge
     openmpi                   4.1.4              ha1ae619_102    conda-forge
     openssl                   3.0.7                h0b41bf4_2    conda-forge
     orc                       1.8.2                hfdbbad2_0    conda-forge
     outdated                  0.2.2              pyhd8ed1ab_0    conda-forge
     packaging                 23.0               pyhd8ed1ab_0    conda-forge
     pandas                    1.5.3            py38hdc8b05c_0    conda-forge
     pandoc                    1.19.2                        0    conda-forge
     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge
     paramiko                  3.0.0              pyhd8ed1ab_0    conda-forge
     parquet-cpp               1.5.1                         2    conda-forge
     parso                     0.8.3              pyhd8ed1ab_0    conda-forge
     partd                     1.3.0              pyhd8ed1ab_0    conda-forge
     patsy                     0.5.3              pyhd8ed1ab_0    conda-forge
     pcre2                     10.40                hc3806b6_0    conda-forge
     pexpect                   4.8.0              pyh1a96a4e_2    conda-forge
     pickleshare               0.7.5                   py_1003    conda-forge
     pillow                    9.4.0            py38hb32c036_0    conda-forge
     pip                       23.0               pyhd8ed1ab_0    conda-forge
     pixman                    0.40.0               h36c2ea0_0    conda-forge
     platformdirs              2.6.2              pyhd8ed1ab_0    conda-forge
     pluggy                    1.0.0              pyhd8ed1ab_5    conda-forge
     pooch                     1.6.0              pyhd8ed1ab_0    conda-forge
     poppler                   23.01.0              h091648b_0    conda-forge
     poppler-data              0.4.11               hd8ed1ab_0    conda-forge
     postgresql                15.1                 h3248436_3    conda-forge
     pre-commit                3.0.2            py38h578d9bd_0    conda-forge
     proj                      9.1.1                h8ffa02c_2    conda-forge
     prometheus_client         0.16.0             pyhd8ed1ab_0    conda-forge
     prompt-toolkit            3.0.36             pyha770c72_0    conda-forge
     protobuf                  4.21.12          py38h8dc9893_0    conda-forge
     psutil                    5.9.4            py38h0a891b7_0    conda-forge
     pthread-stubs             0.4               h36c2ea0_1001    conda-forge
     ptxcompiler               0.7.0            py38h241159d_3    conda-forge
     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge
     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge
     py                        1.11.0             pyh6c4a22f_0    conda-forge
     py-cpuinfo                9.0.0              pyhd8ed1ab_0    conda-forge
     pyarrow                   10.0.1          py38hf05218d_6_cpu    conda-forge
     pyasn1                    0.4.8                      py_0    conda-forge
     pycparser                 2.21               pyhd8ed1ab_0    conda-forge
     pydantic                  1.10.4           py38h1de0b5d_1    conda-forge
     pydata-sphinx-theme       0.12.0             pyhd8ed1ab_0    conda-forge
     pygments                  2.14.0             pyhd8ed1ab_0    conda-forge
     pynacl                    1.5.0            py38h0a891b7_2    conda-forge
     pynndescent               0.5.8              pyh1a96a4e_0    conda-forge
     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge
     pyopenssl                 23.0.0             pyhd8ed1ab_0    conda-forge
     pyorc                     0.8.0            py38h4492b77_2    conda-forge
     pyparsing                 3.0.9              pyhd8ed1ab_0    conda-forge
     pyproj                    3.4.1            py38h58d5fe2_1    conda-forge
     pyrsistent                0.19.3           py38h1de0b5d_0    conda-forge
     pysocks                   1.7.1              pyha2e5f31_6    conda-forge
     pytest                    7.2.1              pyhd8ed1ab_0    conda-forge
     pytest-benchmark          4.0.0              pyhd8ed1ab_0    conda-forge
     pytest-cases              3.6.13             pyhd8ed1ab_0    conda-forge
     pytest-cov                4.0.0              pyhd8ed1ab_0    conda-forge
     pytest-xdist              3.1.0              pyhd8ed1ab_0    conda-forge
     python                    3.8.15          he550d4f_1_cpython    conda-forge
     python-confluent-kafka    1.7.0            py38h497a2fe_2    conda-forge
     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge
     python-fastjsonschema     2.16.2             pyhd8ed1ab_0    conda-forge
     python-jose               3.3.0              pyh6c4a22f_1    conda-forge
     python-json-logger        2.0.4              pyhd8ed1ab_0    conda-forge
     python-louvain            0.16               pyhd8ed1ab_0    conda-forge
     python-snappy             0.6.1            py38h1ddbb56_0    conda-forge
     python-xxhash             3.2.0            py38h1de0b5d_0    conda-forge
     python_abi                3.8                      3_cp38    conda-forge
     pytorch                   1.11.0              py3.8_cpu_0    pytorch
     pytorch-mutex             1.0                         cpu    pytorch
     pytz                      2022.7.1           pyhd8ed1ab_0    conda-forge
     pywin32-on-windows        0.1.0              pyh1179c8e_3    conda-forge
     pyyaml                    6.0              py38h0a891b7_5    conda-forge
     pyzmq                     25.0.0           py38he24dcef_0    conda-forge
     re2                       2022.06.01           h27087fc_1    conda-forge
     readline                  8.1.2                h0f457ee_0    conda-forge
     recommonmark              0.7.1              pyhd8ed1ab_0    conda-forge
     regex                     2022.10.31       py38h0a891b7_0    conda-forge
     requests                  2.28.2             pyhd8ed1ab_0    conda-forge
     responses                 0.21.0             pyhd8ed1ab_0    conda-forge
     rfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge
     rfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge
     rhash                     1.4.3                h166bdaf_0    conda-forge
     rsa                       4.9                pyhd8ed1ab_0    conda-forge
     rtree                     1.0.1            py38h02d302b_1    conda-forge
     s2n                       1.3.31               h3358134_0    conda-forge
     s3fs                      2023.1.0           pyhd8ed1ab_0    conda-forge
     s3transfer                0.6.0              pyhd8ed1ab_0    conda-forge
     sacremoses                0.0.53             pyhd8ed1ab_0    conda-forge
     scikit-build              0.16.6             pyh56297ac_0    conda-forge
     scikit-learn              1.2.1            py38h1e1a916_0    conda-forge
     scipy                     1.10.0           py38h10c12cc_0    conda-forge
     seaborn                   0.12.2               hd8ed1ab_0    conda-forge
     seaborn-base              0.12.2             pyhd8ed1ab_0    conda-forge
     sed                       4.8                  he412f7d_0    conda-forge
     send2trash                1.8.0              pyhd8ed1ab_0    conda-forge
     setuptools                67.0.0                   pypi_0    pypi
     shapely                   2.0.1            py38hd07e089_0    conda-forge
     six                       1.16.0             pyh6c4a22f_0    conda-forge
     snappy                    1.1.9                hbd366e4_2    conda-forge
     sniffio                   1.3.0              pyhd8ed1ab_0    conda-forge
     snowballstemmer           2.2.0              pyhd8ed1ab_0    conda-forge
     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge
     soupsieve                 2.3.2.post1        pyhd8ed1ab_0    conda-forge
     sparse                    0.13.0             pyhd8ed1ab_0    conda-forge
     spdlog                    1.8.5                h4bd325d_1    conda-forge
     sphinx                    5.3.0              pyhd8ed1ab_0    conda-forge
     sphinx-autobuild          2021.3.14          pyhd8ed1ab_0    conda-forge
     sphinx-copybutton         0.5.0              pyhd8ed1ab_0    conda-forge
     sphinx-markdown-tables    0.0.17             pyh6c4a22f_0    conda-forge
     sphinxcontrib-applehelp   1.0.4              pyhd8ed1ab_0    conda-forge
     sphinxcontrib-devhelp     1.0.2                      py_0    conda-forge
     sphinxcontrib-htmlhelp    2.0.0              pyhd8ed1ab_0    conda-forge
     sphinxcontrib-jsmath      1.0.1                      py_0    conda-forge
     sphinxcontrib-qthelp      1.0.3                      py_0    conda-forge
     sphinxcontrib-serializinghtml 1.1.5              pyhd8ed1ab_2    conda-forge
     sphinxcontrib-websupport  1.2.4              pyhd8ed1ab_1    conda-forge
     sqlalchemy                1.4.46           py38h1de0b5d_0    conda-forge
     sqlite                    3.40.0               h4ff8645_0    conda-forge
     sshpubkeys                3.3.1              pyhd8ed1ab_0    conda-forge
     stack_data                0.6.2              pyhd8ed1ab_0    conda-forge
     statsmodels               0.13.5           py38h26c90d9_2    conda-forge
     streamz                   0.6.4              pyh6c4a22f_0    conda-forge
     sysroot_linux-64          2.17                h4a8ded7_13    conda-forge
     tabulate                  0.9.0              pyhd8ed1ab_1    conda-forge
     tbb                       2021.7.0             h924138e_1    conda-forge
     tblib                     1.7.0              pyhd8ed1ab_0    conda-forge
     terminado                 0.17.1             pyh41d4057_0    conda-forge
     threadpoolctl             3.1.0              pyh8a188c0_0    conda-forge
     tiledb                    2.13.2               hd532e3d_0    conda-forge
     tinycss2                  1.2.1              pyhd8ed1ab_0    conda-forge
     tk                        8.6.12               h27826a3_0    conda-forge
     tokenizers                0.13.1           py38h8bed557_2    conda-forge
     toml                      0.10.2             pyhd8ed1ab_0    conda-forge
     tomli                     2.0.1              pyhd8ed1ab_0    conda-forge
     toolz                     0.12.0             pyhd8ed1ab_0    conda-forge
     tornado                   6.2              py38h0a891b7_1    conda-forge
     tqdm                      4.64.1             pyhd8ed1ab_0    conda-forge
     traitlets                 5.9.0              pyhd8ed1ab_0    conda-forge
     transformers              4.24.0             pyhd8ed1ab_0    conda-forge
     treelite                  3.1.0            py38h2820b77_0    conda-forge
     treelite-runtime          3.1.0                    pypi_0    pypi
     typing-extensions         4.4.0                hd8ed1ab_0    conda-forge
     typing_extensions         4.4.0              pyha770c72_0    conda-forge
     tzcode                    2022g                h166bdaf_0    conda-forge
     tzdata                    2022g                h191b570_0    conda-forge
     ucx                       1.13.1               h538f049_1    conda-forge
     ucx-proc                  1.0.0                       gpu    rapidsai
     ucx-py                    0.30.00a230131  py38_ga21f62a_17    rapidsai-nightly
     ukkonen                   1.0.1            py38h43d8883_3    conda-forge
     umap-learn                0.5.3            py38h578d9bd_0    conda-forge
     unicodedata2              15.0.0           py38h0a891b7_0    conda-forge
     urllib3                   1.26.14            pyhd8ed1ab_0    conda-forge
     virtualenv                20.17.1          py38h578d9bd_0    conda-forge
     wcwidth                   0.2.6              pyhd8ed1ab_0    conda-forge
     webencodings              0.5.1                      py_1    conda-forge
     websocket-client          1.5.0              pyhd8ed1ab_0    conda-forge
     werkzeug                  2.1.2              pyhd8ed1ab_1    conda-forge
     wheel                     0.38.4             pyhd8ed1ab_0    conda-forge
     wrapt                     1.14.1           py38h0a891b7_1    conda-forge
     xerces-c                  3.2.4                h55805fa_1    conda-forge
     xmltodict                 0.13.0             pyhd8ed1ab_0    conda-forge
     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge
     xorg-libice               1.0.10               h7f98852_0    conda-forge
     xorg-libsm                1.2.3             hd9c2040_1000    conda-forge
     xorg-libx11               1.7.2                h7f98852_0    conda-forge
     xorg-libxau               1.0.9                h7f98852_0    conda-forge
     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge
     xorg-libxext              1.3.4                h7f98852_1    conda-forge
     xorg-libxrender           0.9.10            h7f98852_1003    conda-forge
     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge
     xorg-xextproto            7.3.0             h7f98852_1002    conda-forge
     xorg-xproto               7.0.31            h7f98852_1007    conda-forge
     xxhash                    0.8.1                h0b41bf4_0    conda-forge
     xyzservices               2022.9.0           pyhd8ed1ab_0    conda-forge
     xz                        5.2.6                h166bdaf_0    conda-forge
     yaml                      0.2.5                h7f98852_2    conda-forge
     yarl                      1.8.2            py38h0a891b7_0    conda-forge
     zeromq                    4.3.4                h9c3ff4c_1    conda-forge
     zict                      2.2.0              pyhd8ed1ab_0    conda-forge
     zipp                      3.12.0             pyhd8ed1ab_0    conda-forge
     zlib                      1.2.13               h166bdaf_4    conda-forge
     zstd                      1.5.2                h3eb15da_6    conda-forge

</pre></details>
",2023-02-01T16:02:50Z,0,0,Lawrence Mitchell,
206,[BUG] `IndexedFrame._split` is inconsistent for empty dataframes,"This came up while reviewing #12704.

Quoth the documentation:

> Split a frame with split points in ``splits``. Returns a list of Frames of length `len(splits) + 1`.

Which is true, except if the input dataframe is empty:

```python
import cudf
df = cudf.DataFrame({""a"": []})
print(df._split([0])) # => []
```

This makes writing generic code difficult, since we're expecting to get back a list of N+1 things to iterate over, but in this case we don't.

Slicing empty dataframes works fine (and reproduces semantically what you ""expect"" from slicing empty python lists):

```python
df[:0], df[0:] # => (Empty DataFrame, Empty DataFrame)
```

(Arguably slicing with an out of bounds index should raise an `IndexError`, but that ship has sailed.)

What I would like:

```python
splits = [...]

assert df._split(splits) == [df[s:e] for s, e in zip([None] + splits, splits + [None])]
```

",2023-02-07T10:42:25Z,0,0,Lawrence Mitchell,
207,[FEA] cudf.Series.agg support,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
`cudf.Series.agg` matching https://pandas.pydata.org/docs/reference/api/pandas.Series.agg.html

```
>>> import cudf, pandas
>>> cudf.__version__
'23.02.00a+310.g58e0fde346'
>>> pandas.__version__
'1.5.3'
>>> cudf.Series([1, 1, 42, 1984]).agg('mean')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'Series' object has no attribute 'agg'
>>> pandas.Series([1, 1, 42, 1984]).agg('mean')
507.0
```",2023-02-07T13:02:41Z,0,0,Matthew Farrellee,
208,[FEA] cudf.Series.add support for NaN,"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
```
>>> import cudf, pandas
>>> cudf.__version__
'23.02.00a+310.g58e0fde346'
>>> pandas.__version__
'1.5.3'
>>> import numpy as np
>>> cudf.Series([1,1, np.NaN, 9]).add([0, 1, 1, np.NaN])
NotImplemented
>>> pandas.Series([1,1, np.NaN, 9]).add([0, 1, 1, np.NaN])
0    1.0
1    2.0
2    NaN
3    NaN
dtype: float64
```",2023-02-07T13:05:33Z,0,0,Matthew Farrellee,
209,[BUG] NA handling inconsistent in DataFrame/Series.replace,"**Describe the bug**
working with `import cudf as pd`

**Steps/Code to reproduce bug**
```
>>> import cudf, pandas, numpy
>>> cudf.__version__
'23.02.00a+310.g58e0fde346'
>>> pandas.__version__
'1.5.3'

>>> cudf.Series([1, 2, numpy.nan]).replace(numpy.nan, -1)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/opt/conda/envs/rapids/lib/python3.8/contextlib.py"", line 75, in inner
    return func(*args, **kwds)
  File ""/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/series.py"", line 2180, in replace
    return super().replace(to_replace, value, *args, **kwargs)
  File ""/opt/conda/envs/rapids/lib/python3.8/contextlib.py"", line 75, in inner
    return func(*args, **kwds)
  File ""/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/indexed_frame.py"", line 765, in replace
    copy_data[name] = col.find_and_replace(
  File ""/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column/numerical.py"", line 483, in find_and_replace
    to_replace_col = _normalize_find_and_replace_input(
  File ""/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column/numerical.py"", line 771, in _normalize_find_and_replace_input
    col_to_normalize_casted = input_column_dtype.type(
ValueError: cannot convert float NaN to integer
>>> pandas.Series([1, 2, numpy.nan]).replace(numpy.nan, -1)
0    1.0
1    2.0
2   -1.0
dtype: float64
```",2023-02-07T13:40:55Z,0,0,Matthew Farrellee,
210,[FEA] Update IO benchmarks for consistency between formats,"**Is your feature request related to a problem? Please describe.**
- [x] #12678
- [x] #12675 
- [x] add device buffer data source to CSV reader benchmark ([code pointer](https://github.com/rapidsai/cudf/blob/c20c8b42215e38bee207b49dad6e28ea04ccbd8c/cpp/benchmarks/io/csv/csv_reader_input.cpp#L102))
- [x] migrate CSV writer to nvbench. Currently using gbench.
- [x] add JSON writer benchmark. This benchmark could be modeled after CSV writer.
- [x] add JSON reader benchmark with file data source ([NESTED_JSON](https://github.com/rapidsai/cudf/blob/branch-23.04/cpp/benchmarks/io/json/nested_json.cpp) only does parsing and only on device buffers). This benchmark could be modeled after `BM_csv_read_io`
- [x] ~#12700~
- [x] ~#12674 -> add compression to `BM_csv_read_io` (?)~
- [x] add benchmark coverage for parquet chunked reader. Perhaps modeled after [parquet_read_io_compression](https://github.com/rapidsai/cudf/blob/c20c8b42215e38bee207b49dad6e28ea04ccbd8c/cpp/benchmarks/io/parquet/parquet_reader_input.cpp#L143)
- [x] for reader benchmarks, verify that the roundtripped table matches the starting table
- [x] convert `compression` and `io` to string axis type. [see this discussion in nvbench](https://github.com/NVIDIA/nvbench/issues/137). the goal is to choose other values from the CLI without having to run all values in automation.
- [ ] rename `pmu`, `efs`, `trc` in ORC writer chunks to `peak_memory_usage`, `encoded_file_size`, `total_rows`, to conform with the other ORC, PQ, CSV, text benchmarks

**Additional context**
The initial set of topics came from a comparison of file read throughput across the supported formats in cuIO.
<img width=""518"" alt=""image"" src=""https://user-images.githubusercontent.com/12725111/217667722-a5024218-61fb-410d-941d-9f9eed4f4c5a.png"">
We are also preparing for a comparison of memory footprint across cuIO, especially with Zstd compression/decompression.

",2023-02-08T22:43:38Z,0,0,Gregory Kimball,
211,[ENH]: cudf options that map onto pandas ones should have identical names,"A followup to #12619; to enable copy-on-write in pandas one says `set_option(""mode.copy_on_write"", True)`, whereas to enable in cudf one must say `set_option(""copy_on_write"", True)`.

There might be other cases, but where cudf exposes the same configuration options as pandas, the names should match as a principle of least surprise.",2023-02-13T13:00:48Z,0,0,Lawrence Mitchell,
212,[BUG] cudf.cut fails on example from documentation,"**Describe the bug**
last example in https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.cut.html

**Steps/Code to reproduce bug**
```
In [1]: import cudf

In [2]: cudf.__version__
Out[2]: '23.02.00'

In [3]: import numpy as np

In [4]: s = cudf.Series(np.array([2, 4, 6, 8, 10]), index=['a', 'b', 'c', 'd', 'e'])
   ...: cudf.cut(s, 3)
Out[4]: ---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
/opt/conda/envs/rapids/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj)
    700                 type_pprinters=self.type_printers,
    701                 deferred_pprinters=self.deferred_printers)
--> 702             printer.pretty(obj)
    703             printer.flush()
    704             return stream.getvalue()

/opt/conda/envs/rapids/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj)
    392                         if cls is not object \
    393                                 and callable(cls.__dict__.get('__repr__')):
--> 394                             return _repr_pprint(obj, self, cycle)
    395 
    396             return _default_pprint(obj, self, cycle)

/opt/conda/envs/rapids/lib/python3.8/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle)
    698     """"""A pprint that just redirects to the normal repr function.""""""
    699     # Find newlines and replace them with p.break_()
--> 700     output = repr(obj)
    701     lines = output.splitlines()
    702     with p.group():

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/series.py in __repr__(self)
   1323                 )
   1324             else:
-> 1325                 pd_series = preprocess.to_pandas()
   1326             output = pd_series.to_string(
   1327                 name=self.name,

/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)
     73         def inner(*args, **kwds):
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner
     77 

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/series.py in to_pandas(self, index, nullable, **kwargs)
   1900         if index is True:
   1901             index = self.index.to_pandas()
-> 1902         s = self._column.to_pandas(index=index, nullable=nullable)
   1903         s.name = self.name
   1904         return s

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column/categorical.py in to_pandas(self, index, **kwargs)
    913         else:
    914             categories = col.categories.dropna(drop_nan=True).to_pandas()
--> 915         data = pd.Categorical.from_codes(
    916             codes, categories=categories, ordered=col.ordered
    917         )

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype)
    685         Categories (2, object): ['a' < 'b']
    686         """"""
--> 687         dtype = CategoricalDtype._from_values_or_dtype(
    688             categories=categories, ordered=ordered, dtype=dtype
    689         )

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype)
    297             # Note: This could potentially have categories=None and
    298             # ordered=None.
--> 299             dtype = CategoricalDtype(categories, ordered)
    300 
    301         return cast(CategoricalDtype, dtype)

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered)
    184 
    185     def __init__(self, categories=None, ordered: Ordered = False) -> None:
--> 186         self._finalize(categories, ordered, fastpath=False)
    187 
    188     @classmethod

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath)
    338 
    339         if categories is not None:
--> 340             categories = self.validate_categories(categories, fastpath=fastpath)
    341 
    342         self._categories = categories

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath)
    534                 raise ValueError(""Categorical categories cannot be null"")
    535 
--> 536             if not categories.is_unique:
    537                 raise ValueError(""Categorical categories must be unique"")
    538 

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__()

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/indexes/base.py in is_unique(self)
   2384         Return if the index has unique values.
   2385         """"""
-> 2386         return self._engine.is_unique
   2387 
   2388     @final

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.is_unique.__get__()

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine._do_unique_check()

/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine._ensure_mapping_populated()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.map_locations()

TypeError: unhashable type: 'dict'
```",2023-02-16T15:38:22Z,0,0,Matthew Farrellee,
213,[BUG] cudf.cut does not accept sequence of scalars,"**Describe the bug**
working with `import cudf as pd`

**Steps/Code to reproduce bug**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '23.02.00'

In [3]: import numpy as np

In [4]: df = pd.DataFrame({'a': range(100)})

In [5]: pd.cut(df.a, bins=np.linspace(0, 100, num=6))
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-5-1d55c0477181> in <module>
----> 1 pd.cut(df.a, bins=np.linspace(0, 100, num=6))

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/cut.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)
    168                 mn = min(x)
    169                 mx = max(x)
--> 170             bins = np.linspace(mn, mx, bins + 1, endpoint=True)
    171             adj = (mx - mn) * 0.001
    172             if right:

/opt/conda/envs/rapids/lib/python3.8/site-packages/numpy/core/overrides.py in linspace(*args, **kwargs)

/opt/conda/envs/rapids/lib/python3.8/site-packages/numpy/core/function_base.py in linspace(start, stop, num, endpoint, retstep, dtype, axis)
    118 
    119     """"""
--> 120     num = operator.index(num)
    121     if num < 0:
    122         raise ValueError(""Number of samples, %s, must be non-negative."" % num)

TypeError: only integer scalar arrays can be converted to a scalar index

In [6]: import pandas

In [7]: pandas.cut(df.to_pandas().a, bins=np.linspace(0, 100, num=6))
Out[7]: 
0               NaN
1       (0.0, 20.0]
2       (0.0, 20.0]
3       (0.0, 20.0]
4       (0.0, 20.0]
          ...      
95    (80.0, 100.0]
96    (80.0, 100.0]
97    (80.0, 100.0]
98    (80.0, 100.0]
99    (80.0, 100.0]
Name: a, Length: 100, dtype: category
Categories (5, interval[float64, right]): [(0.0, 20.0] < (20.0, 40.0] < (40.0, 60.0] <
                                           (60.0, 80.0] < (80.0, 100.0]]
```

**Additional context**
https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.cut.html
![image](https://user-images.githubusercontent.com/112653/219417718-173071c7-55c3-4bc0-9b4f-425bd0b0ee81.png)
",2023-02-16T15:52:39Z,0,0,Matthew Farrellee,
214,[ENH]: Reworking of `iloc` and `loc` indexing,"## Status quo

Indexing of dataframes and series happens through six user-facing routes:

- `DataFrame.__setitem__`/`DataFrame.__getitem__`
- `DataFrame.iloc.__setitem__`/`DataFrame.iloc.__getitem__`
- `DataFrame.loc.__setitem__`/`DataFrame.loc.__getitem__`
- `Series.__setitem__`/`Series.__getitem__`
- `Series.iloc.__setitem__`/`Series.iloc.__getitem__`
- `Series.loc.__setitem__`/`Series.loc.__getitem__`

These all have slightly different semantics (to match pandas behaviour), but there is still quite a lot of (possibly unnecessary) code duplication and a number of bugs around indexing. Many of these look to be because the business logic of handling slicing/gather-by-mask/indexing is intertwined with error handling and determining exactly what to slice. There's also logic effectively repeated between the loc and iloc versions in both cases.

It would be nice if the number of different paths into indexing was reduced, perhaps it is a pipe dream to share between Series and DataFrame (since a DataFrame is not just a collection of Series), but it feels like it should be possible to share more between iloc/loc/__setgetitem__.

Related issues:

```[tasklist]
### `iloc` bugs
- [ ] #12748 
- [ ] #13013
- [ ] #13015
- [ ] #13265
- [ ] #13266 
- [ ] #13267
- [ ] #13515
- [ ] #13293
```
```[tasklist]
### Index bugs
- [ ] #12954
```

```[tasklist]
### `loc` bugs
- [ ] #7448
- [ ] #8585
- [ ] #8693
- [ ] #11298
- [ ] #11944
- [ ] #12259
- [ ] #12286
- [ ] #12504
- [ ] #12505
- [ ] #12801
- [ ] #12833
- [ ] #13014
- [ ] #13015
- [ ] #13031
- [ ] #13268
- [ ] #13269
- [ ] #13270
- [ ] #13379
- [ ] https://github.com/rapidsai/cudf/issues/13653
- [ ] https://github.com/rapidsai/cudf/issues/13658
- [ ] https://github.com/rapidsai/cudf/issues/13652
```
```[tasklist]
### Views vs. copies
- [ ] #7374
- [ ] #11085
- [ ] #11990 
```

```[tasklist]
### Other (mostly dtype-related)
- [ ] #2684
- [ ] #8184
- [ ] #11477
- [ ] #12039
- [ ] #13532
```

Your issue here.

As we can see from this classification, `loc`-based indexing is definitely the harder nut to crack. The edge-cases that provoke most of the issues are cases where the values used in the indexing are _not_ in the index.",2023-02-16T16:49:43Z,0,0,Lawrence Mitchell,
215,[FEA] broadcast assignment through loc[],"**Is your feature request related to a problem? Please describe.**
working with `import cudf as pd`

**Describe the solution you'd like**
```
In [1]: import cudf as pd

In [2]: pd.__version__
Out[2]: '23.02.00'

In [3]: df = pd.DataFrame({'a': range(10)})

In [4]: df.loc[df.a > 5, ['b']] = 'ok'
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in _setitem_tuple_arg(self, key, value)
    318         try:
--> 319             columns_df = self._frame._get_columns_by_label(key[1])
    320         except KeyError:

/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in _get_columns_by_label(self, labels, downcast)
   1902         """"""
-> 1903         new_data = super()._get_columns_by_label(labels, downcast)
   1904         if downcast:

/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/frame.py in _get_columns_by_label(self, labels, downcast)
    417         """"""
--> 418         return self._data.select_by_label(labels)
    419 

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column_accessor.py in select_by_label(self, key)
    349         elif pd.api.types.is_list_like(key) and not isinstance(key, tuple):
--> 350             return self._select_by_label_list_like(key)
    351         else:

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column_accessor.py in _select_by_label_list_like(self, key)
    464     def _select_by_label_list_like(self, key: Any) -> ColumnAccessor:
--> 465         data = {k: self._grouped_data[k] for k in key}
    466         if self.multiindex:

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column_accessor.py in <dictcomp>(.0)
    464     def _select_by_label_list_like(self, key: Any) -> ColumnAccessor:
--> 465         data = {k: self._grouped_data[k] for k in key}
    466         if self.multiindex:

KeyError: 'b'

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-4-18a695e97af4> in <module>
----> 1 df.loc[df.a > 5, ['b']] = 'ok'

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in __setitem__(self, key, value)
    148         if not isinstance(key, tuple):
    149             key = (key, slice(None))
--> 150         return self._setitem_tuple_arg(key, value)
    151 
    152     @_cudf_nvtx_annotate

/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)
     73         def inner(*args, **kwds):
     74             with self._recreate_cm():
---> 75                 return func(*args, **kwds)
     76         return inner
     77 

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in _setitem_tuple_arg(self, key, value)
    334             new_col = cudf.Series(value, index=idx)
    335             if not self._frame.empty:
--> 336                 new_col = new_col._align_to_index(
    337                     self._frame.index, how=""right""
    338                 )

/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/indexed_frame.py in _align_to_index(self, index, how, sort, allow_non_unique)
   2274         if not allow_non_unique:
   2275             if not self.index.is_unique or not index.is_unique:
-> 2276                 raise ValueError(""Cannot align indices with non-unique values"")
   2277 
   2278         lhs = cudf.DataFrame._from_data(self._data, index=self.index)

ValueError: Cannot align indices with non-unique values

In [5]: pdf = df.to_pandas()

In [6]: pdf.loc[pdf.a > 5, ['b']] = 'ok'

In [7]: pdf
Out[7]: 
   a    b
0  0  NaN
1  1  NaN
2  2  NaN
3  3  NaN
4  4  NaN
5  5  NaN
6  6   ok
7  7   ok
8  8   ok
9  9   ok
```",2023-02-17T14:16:07Z,0,0,Matthew Farrellee,
216,[DEP]: Remove `line_terminator` from `to_csv`,"Followup to #12896, remove the deprecated keyword argument.",2023-03-07T17:19:48Z,0,0,Lawrence Mitchell,
217,dask_cudf.read_csv doesn't support StringIO ,"`dask_cudf.read_csv()` is calling `cudf.read_csv()` internally.
However, dask_cudf.read_csv() doesn't support StringIO input.

Description of api mislead (it seems copied over from cudf.read_csv())
```
    path : str, path object, or file-like object
        Either a path to a file (a str, pathlib.Path, or
        py._path.local.LocalPath), URL (including http, ftp, and S3 locations),
        or any object with a read() method (such as builtin open() file
        handler function or StringIO).
```
Currently, StringIO input falls into https://github.com/rapidsai/cudf/blob/branch-23.04/python/dask_cudf/dask_cudf/io/csv.py#L99
",2023-03-08T16:55:39Z,0,0,,
218,[BUG] Slow performance with high cardinality category columns,"**Describe the bug**
I'm not sure if it is a bug or just limitation of cuDF architecture.
Please correct me. 
 
I have DataFrames with lot of columns and some of columns are strings with type **category**.
My data sets have about 5_000_000 rows. And category columns have more than 500_000 unique values. 
What I'm wondering is that copy of categorical columns (CPU -> GPU) takes a lot time in comparison the same data  not categorized. 
More strange is that **groupby** function on categorical columns is many times slower that on non categorical columns. (Same content)   

**Steps/Code to reproduce bug**
create 2 arrays with categorical data. There are 500_000 unique values
```
cat1 = [ 'col1_cat_' + str(i)  for i in range(1, 500_000)] 
cat2 = [ 'col2_cat_' + str(i)  for i in range(1, 500_000)]
```
initialize Panda DataFrame with 5_000_000 rows
```
rng = np.random.default_rng()
col1 = np.random.choice(a=cat1,  size=5_000_000)  
col2 = np.random.choice(a=cat2,  size=5_000_000)  

df = pd.DataFrame( {  'col1': col1,  'col2': col2,  'col3': col1,  'col4': col2  })
```

size of DataFrame is about 1.5 GB
```
>> df.memory_usage(deep=True) / 1024 / 1024
Index      0.000122
col1     342.262686
col2     342.264298
col3     342.262686
col4     342.264298
dtype: float64
```
We execute groupby on CPU.  
```
%%time
df.groupby(['col1']).count()
```
*CPU times: user 2.43 s, sys: 23.8 ms, total: 2.46 s
Wall time: 2.46 s*

Now we convert string data to category type.
```
df_cat = df[['col1', 'col2', 'col3', 'col4']].astype('category')
>>df_cat.memory_usage(deep=True) / 1024 / 1024
Index     0.000122
col1     69.423543
col2     69.423198
col3     69.423543
col4     69.423198
dtype: float64
```
DF size is about 300 MB
```
%%time
df_cat.groupby(['col1']).count()
```
*CPU times: user 50.5 ms, sys: 8.29 ms, total: 58.8 ms
Wall time: 57.7 ms*

With categorical data we are __40 times__ faster that with non categorical data. That is expected performance.
Now we copy non categorized data to the GPU
```
%%time
gdf = cudf.DataFrame.from_pandas(df)
```
*CPU times: user 511 ms, sys: 221 ms, total: 731 ms
Wall time: 730 ms*
Copy of date takes about 700ms for 1.5GB

```
%%time
gdf.groupby(['col1']).count()
```
*CPU times: user 30.6 ms, sys: 3.8 ms, total: 34.4 ms
Wall time: 33 ms*
**groupby** is about 70 times faster that on CPU (2.46s). Very good performance. IMPORTANT data is **NOT CATEGORIZED**

Now we copy categorized data to the GPU and execute **groupby**
```
%%time
gdf_cat = cudf.DataFrame.from_pandas(df_cat)
```
*CPU times: user 711 ms, sys: 136 ms, total: 847 ms
Wall time: 846 ms*
```
%%time
gdf_cat.groupby(['col1']).count()
```
*CPU times: user 134 ms, sys: 55.8 ms, total: 190 ms
Wall time: 189 ms*

Amount of data is about 300MB. cuDf needs more time to copy the data to the GPU: 846ms (730ms by non categorized 1.5 GB raw strings)
But really strange behaviour is that **groupby**  on categorized data is more than 5 times slower than with raw string data!!!
**Even groupby on CPU is faster that on GPU by categorical data 57ms --> 189ms!!!!!**

Why is performance of cuDF groupy with categorical data so poor?

**Expected behavior**
**groupby** function on GPU should work faster or at least equal than on CPU

**Environment overview (please complete the following information)**
CPU RAM: 64 GB
GPU RAM: 8GB

**Environment details**
tested on 3 different systems with 3 different NVIDIA cards

**Additional context**
In attachments you can find my Jupiter Notebook with example. 
[category.ipynb.zip](https://github.com/rapidsai/cudf/files/10936367/category.ipynb.zip)
",2023-03-09T21:53:26Z,0,0,Slava,TriasDev
219,[BUG] Issues while loading TimeStamp columns,"```
In [2]: import cudf

In [3]: cudf.read_orc('tsrepro.orc')
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
Cell In[3], line 1
----> 1 cudf.read_orc('tsrepro.orc')

File /conda/envs/rapids-23.02/lib/python3.10/site-packages/cudf/io/orc.py:370, in read_orc(filepath_or_buffer, engine, columns, filters, stripes, skiprows, num_rows, use_index, timestamp_type, use_python_file_object, storage_options, bytes_per_thread)
    366         stripes = selected_stripes
    368 if engine == ""cudf"":
    369     return DataFrame._from_data(
--> 370         *liborc.read_orc(
    371             filepaths_or_buffers,
    372             columns,
    373             stripes,
    374             skiprows,
    375             num_rows,
    376             use_index,
    377             timestamp_type,
    378         )
    379     )
    380 else:
    382     def read_orc_stripe(orc_file, stripe, columns):

File orc.pyx:84, in cudf._lib.orc.read_orc()

File orc.pyx:121, in cudf._lib.orc.read_orc()

RuntimeError: CUDF failure at: /opt/conda/conda-bld/work/cpp/src/io/orc/timezone.cpp:138: Failed to open the timezone file.
```

[tsrepro.orc.zip](https://github.com/rapidsai/cudf/files/10946593/tsrepro.orc.zip)
",2023-03-13T02:21:39Z,0,0,Lahir Marni,
220,[BUG] `is_list_like` does not match pandas equivalent for cupy arrays,"**Describe the bug**

`is_list_like` does not match pandas equivalent for cupy array objects

https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_list_like.html

**Steps/Code to reproduce bug**

```python
import pandas as pd
import numpy as np
import cudf
import cupy as cp

pd.api.types.is_list_like(np.array([1]))  # => True
pd.api.types.is_list_like(cp.array([1]))  # => True

cudf.api.types.is_list_like(np.array([1]))  # => True
cudf.api.types.is_list_like(cp.array([1]))  # => False
```

**Expected behavior**

I'd expect `is_list_like` to return True matching the equivalent pandas function when called with a cupy or numpy array containing a list of values

```python
cudf.api.types.is_list_like(cp.array([1]))  # => True
```

**Environment overview (please complete the following information)**
 - Environment location: docker
 - Method of cuDF install: pip

",2023-03-20T15:04:26Z,0,0,Oliver Holworthy,
221,[BUG] loc indexing with length-1 Categorical not possible,"**Describe the bug**
```python
import cudf
import pandas as pd
f = pd.Series([1, 2, 3], index=pd.CategoricalIndex([0, 1, 2]))
f.loc[pd.Categorical([1])] # => second row.
cf = cudf.from_pandas(f)
cf.loc[pd.Categorical([1])] # => KeyErrror
```

I think this is similar to #13013 in that length-one categoricals are treated as scalars in some cases.

**Expected behavior**

Probably this lookup should work.",2023-03-27T10:28:01Z,0,0,Lawrence Mitchell,
222,[FEA] Performance issue with the Parquet reader for very large schemas (especially when containing strings),"
For parquet files that contain very large schemas with strings (either large numbers of columns, or large numbers of nested columns) we pay a very heavy price postprocessing the string data after the core decode kernels runs.  

Essentially, the ""decode"" process for strings is just emitting a large array of pointer/size pairs that are then passed to other cudf functions to reconstruct actual columns.    The problem is that we are doing this with no batching - each output string column results in an entire cudf function call (`make_strings_column`) with multiple internal kernel calls each.  In situations with thousands of columns, this gets very expensive.

![image](https://user-images.githubusercontent.com/56695930/228312025-67ea3177-9d67-4e84-84e5-cb317c895001.png)

In the image above, the green span represents the time spent in the decode kernel and the time spent in all of the `make_strings_column` calls afterwards.  The time is totally dominated by the many many calls to `make_strings_column` (the red span).  

Ideally, we would have some kind of batched interface to `make_strings_column`  (`make_strings_columns` ?) that can do the work for the thousands of output columns coalesced into fewer kernels.  


On a related note, the area under the blue line represents a similar problem involving preprocessing the file (thousands of calls to `thrust::reduce` and `thrust::exclusive_scan_by_key`).   This has been largely addressed by this PR  https://github.com/rapidsai/cudf/pull/12931  
",2023-03-28T17:01:42Z,0,0,,
223,[BUG] loc-based setitem with dataframe/series as rvalue doesn't match pandas,"**Describe the bug**

When performing `loc`-based setitem, pandas aligns the indices of the rvalue to match that of the lvalue. Consequently, the indexed lvalue and rvalue don't have to have the same shape (or even match indices).

```python
import pandas as pd
s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])
o1 = pd.Series([5, 6, 7], index=['a', 'b', 'c'])
o2 = pd.Series([10])
s.loc[['a', 'c']] = o1
s # => [5, 2, 7]
s.loc[['a', 'b', 'c']] = o2
s # => [Nan, Nan, Nan]
```

In contrast, cudf complains in both cases.

For the former: `ValueError: Size mismatch: cannot set value of size 3 to indexing result of size 2`

For the latter: `align_to_index` fails (because the int index cannot be merged with the string index). If `o2` has a string index, it fails because the pruned aligned series is not the right length.

**Expected behavior**

Probably this should behave as pandas. I think the case where the index types are different will probably need to be special-cased.",2023-03-29T14:38:07Z,0,0,Lawrence Mitchell,
224,Span tests have hard-coded values,"Vukasin pointed out in code review of 12981 that the span tests are using some hard-coded magic numbers. These should be addressed.

_Originally posted by @vuule in https://github.com/rapidsai/cudf/pull/12981#discussion_r1149684948_
            ",2023-03-29T17:37:58Z,0,0,Mike Wilson,
225,"[QST] `dask_cudf.read_parquet` failed with ""NotImplementedError: large_string""","I am a new user of `dask`/`dask_cudf`.
I have parquet files of various sizes (11GB, 2.5GB, 1.1GB), all of which failed with `NotImplementedError: large_string`. 

My `dask.dataframe` backend is `cudf`. When the backend is `pandas`, `read.parquet` works fine.

Here's an exerpt of what my data looks like in `csv` format:

    Symbol,Date,Open,High,Low,Close,Volume
    AADR,17-Oct-2017 09:00,57.47,58.3844,57.3645,58.3844,2094
    AADR,17-Oct-2017 10:00,57.27,57.2856,57.25,57.27,627
    AADR,17-Oct-2017 11:00,56.99,56.99,56.99,56.99,100
    AADR,17-Oct-2017 12:00,56.98,57.05,56.98,57.05,200
    AADR,17-Oct-2017 13:00,57.14,57.16,57.14,57.16,700
    AADR,17-Oct-2017 14:00,57.13,57.13,57.13,57.13,100
    AADR,17-Oct-2017 15:00,57.07,57.07,57.07,57.07,200
    AAMC,17-Oct-2017 09:00,87,87,87,87,100
    AAU,17-Oct-2017 09:00,1.1,1.13,1.0832,1.121,67790
    AAU,17-Oct-2017 10:00,1.12,1.12,1.12,1.12,100
    AAU,17-Oct-2017 11:00,1.125,1.125,1.125,1.125,200
    AAU,17-Oct-2017 12:00,1.1332,1.15,1.1332,1.15,27439
    AAU,17-Oct-2017 13:00,1.15,1.15,1.13,1.13,8200
    AAU,17-Oct-2017 14:00,1.1467,1.1467,1.14,1.1467,1750
    AAU,17-Oct-2017 15:00,1.1401,1.1493,1.1401,1.1493,4100
    AAU,17-Oct-2017 16:00,1.13,1.13,1.13,1.13,100
    ABE,17-Oct-2017 09:00,14.64,14.64,14.64,14.64,200
    ABE,17-Oct-2017 10:00,14.67,14.67,14.66,14.66,1200
    ABE,17-Oct-2017 11:00,14.65,14.65,14.65,14.65,600
    ABE,17-Oct-2017 15:00,14.65,14.65,14.65,14.65,836


What I did was really simple:

    import dask.dataframe as dd
    import cudf
    import dask_cudf
    
    # Failed with large_string error
    dask_cudf.read_parquet('path/to/my.parquet')
    # Failed with large_string error
    dd.read_parquet('path/to/my.parquet')

The only large string I could think of is the timestamp string.

Is there a way around this in `cudf` as it is not implemented yet? The format is `2023-03-12 09:00:00+00:00`.



",2023-03-30T16:14:30Z,0,0,QiuxiaoMu,
226,[QST] convert column of datetime string to column of datetime object,"I am a new user of Dask and RapidsAI.
An exerpt of my data (in `csv` format):

    Symbol,Date,Open,High,Low,Close,Volume
    AADR,17-Oct-2017 09:00,57.47,58.3844,57.3645,58.3844,2094
    AADR,17-Oct-2017 10:00,57.27,57.2856,57.25,57.27,627
    AADR,17-Oct-2017 11:00,56.99,56.99,56.99,56.99,100
    AADR,17-Oct-2017 12:00,56.98,57.05,56.98,57.05,200
    AADR,17-Oct-2017 13:00,57.14,57.16,57.14,57.16,700
    AADR,17-Oct-2017 14:00,57.13,57.13,57.13,57.13,100
    AADR,17-Oct-2017 15:00,57.07,57.07,57.07,57.07,200
    AAMC,17-Oct-2017 09:00,87,87,87,87,100
    AAU,17-Oct-2017 09:00,1.1,1.13,1.0832,1.121,67790
    AAU,17-Oct-2017 10:00,1.12,1.12,1.12,1.12,100
    AAU,17-Oct-2017 11:00,1.125,1.125,1.125,1.125,200
    AAU,17-Oct-2017 12:00,1.1332,1.15,1.1332,1.15,27439
    AAU,17-Oct-2017 13:00,1.15,1.15,1.13,1.13,8200
    AAU,17-Oct-2017 14:00,1.1467,1.1467,1.14,1.1467,1750
    AAU,17-Oct-2017 15:00,1.1401,1.1493,1.1401,1.1493,4100
    AAU,17-Oct-2017 16:00,1.13,1.13,1.13,1.13,100
    ABE,17-Oct-2017 09:00,14.64,14.64,14.64,14.64,200
    ABE,17-Oct-2017 10:00,14.67,14.67,14.66,14.66,1200
    ABE,17-Oct-2017 11:00,14.65,14.65,14.65,14.65,600
    ABE,17-Oct-2017 15:00,14.65,14.65,14.65,14.65,836

Note `Date` column is of type string.

I have some example stock market timeseries data (i.e., DOHLCV) in csv files and I read them into a `dask_cudf` dataframe (my `dask.dataframe` backend is cudf and `read.csv` is a creation dispacther that conveniently gives me a `cudf.dataframe`). 

    import dask_cudf 
    import cudf
    from dask import dataframe as dd
    
    ddf = dd.read_csv('path/to/my/data/*.csv')
    ddf
    # output
    <dask_cudf.DataFrame | 450 tasks | 450 npartitions>
    
    
    # test csv data above can be retrieved using following statements
    # df = pd.read_clipboard(sep="","")
    # cdf = cudf.from_pandas(df)
    # ddf = dask_cudf.from_cudf(cdf, npartitions=2)

I then try to convert datetime string into real datetime object (`np.datetime64[ns]` or anything equivalent in `cudf`/`dask` world). I then failed with error.

    df[""Date""] = dd.to_datetime(df[""Date""], format=""%d-%b-%Y %H:%M"").head(5)
    df.set_index(""Date"", inplace=True) # This failed with different error, will raise in a different SO thread.
    # Following statement gives me same error.
    # cudf.to_datetime(df[""Date""], format=""%d-%b-%Y %H:%M"")

Full error log is to the end.

The error message seems to suggest that I'd need to `compute` the `dask_cudf.dataframe`, turning it into a real `cudf` object, then I
can do as I would in `pandas`:

    df[""Date""] = cudf.to_datetime(df.Date)
    df = df.set_index(df.Date)

This apparently isn't ideal and it very much is the thing that `dask` is for: we'd delay this and only calculate the ultimate number we need.

what is the `dask`/`dask_cudf` way to convert a string column to datetime column in `dask_cudf`? As far as I can see, if the backend is `pandas`, the conversion is done smoothly and rarely has problem. 

Or, is it that `cudf` or GPU world in general, is not supposed to do much with date types like `datetime`, `string` ? (e.g., ideally GPU is geared towards expensive numerical computations). 

My use case involves some filtering to do with `string` and `datetime`, therefore I need to set up the `dataframe` with proper `datetime` object.

#### Error Log

    TypeError                                 Traceback (most recent call last)
    Cell In[52], line 1
    ----> 1 dd.to_datetime(df[""Date""], format=""%d-%b-%Y %H:%M"").head(2)
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/dataframe/core.py:1268, in _Frame.head(self, n, npartitions, compute)
       1266 # No need to warn if we're already looking at all partitions
       1267 safe = npartitions != self.npartitions
    -> 1268 return self._head(n=n, npartitions=npartitions, compute=compute, safe=safe)
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/dataframe/core.py:1302, in _Frame._head(self, n, npartitions, compute, safe)
       1297 result = new_dd_object(
       1298     graph, name, self._meta, [self.divisions[0], self.divisions[npartitions]]
       1299 )
       1301 if compute:
    -> 1302     result = result.compute()
       1303 return result
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/base.py:314, in DaskMethodsMixin.compute(self, **kwargs)
        290 def compute(self, **kwargs):
        291     """"""Compute this dask collection
        292 
        293     This turns a lazy Dask collection into its in-memory equivalent.
       (...)
        312     dask.base.compute
        313     """"""
    --> 314     (result,) = compute(self, traverse=False, **kwargs)
        315     return result
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/base.py:599, in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)
        596     keys.append(x.__dask_keys__())
        597     postcomputes.append(x.__dask_postcompute__())
    --> 599 results = schedule(dsk, keys, **kwargs)
        600 return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/threaded.py:89, in get(dsk, keys, cache, num_workers, pool, **kwargs)
         86     elif isinstance(pool, multiprocessing.pool.Pool):
         87         pool = MultiprocessingPoolExecutor(pool)
    ---> 89 results = get_async(
         90     pool.submit,
         91     pool._max_workers,
         92     dsk,
         93     keys,
         94     cache=cache,
         95     get_id=_thread_get_id,
         96     pack_exception=pack_exception,
         97     **kwargs,
         98 )
        100 # Cleanup pools associated to dead threads
        101 with pools_lock:
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/local.py:511, in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)
        509         _execute_task(task, data)  # Re-execute locally
        510     else:
    --> 511         raise_exception(exc, tb)
        512 res, worker_id = loads(res_info)
        513 state[""cache""][key] = res
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/local.py:319, in reraise(exc, tb)
        317 if exc.__traceback__ is not tb:
        318     raise exc.with_traceback(tb)
    --> 319 raise exc
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/local.py:224, in execute_task(key, task_info, dumps, loads, get_id, pack_exception)
        222 try:
        223     task, data = loads(task_info)
    --> 224     result = _execute_task(task, data)
        225     id = get_id()
        226     result = dumps((result, id))
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/core.py:119, in _execute_task(arg, cache, dsk)
        115     func, args = arg[0], arg[1:]
        116     # Note: Don't assign the subtask results to a variable. numpy detects
        117     # temporaries by their reference count and can execute certain
        118     # operations in-place.
    --> 119     return func(*(_execute_task(a, cache) for a in args))
        120 elif not ishashable(arg):
        121     return arg
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/optimization.py:990, in SubgraphCallable.__call__(self, *args)
        988 if not len(args) == len(self.inkeys):
        989     raise ValueError(""Expected %d args, got %d"" % (len(self.inkeys), len(args)))
    --> 990 return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/core.py:149, in get(dsk, out, cache)
        147 for key in toposort(dsk):
        148     task = dsk[key]
    --> 149     result = _execute_task(task, cache)
        150     cache[key] = result
        151 result = _execute_task(out, cache)
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/core.py:119, in _execute_task(arg, cache, dsk)
        115     func, args = arg[0], arg[1:]
        116     # Note: Don't assign the subtask results to a variable. numpy detects
        117     # temporaries by their reference count and can execute certain
        118     # operations in-place.
    --> 119     return func(*(_execute_task(a, cache) for a in args))
        120 elif not ishashable(arg):
        121     return arg
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/utils.py:72, in apply(func, args, kwargs)
         41 """"""Apply a function given its positional and keyword arguments.
         42 
         43 Equivalent to ``func(*args, **kwargs)``
       (...)
         69 >>> dsk = {'task-name': task}  # adds the task to a low level Dask task graph
         70 """"""
         71 if kwargs:
    ---> 72     return func(*args, **kwargs)
         73 else:
         74     return func(*args)
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/dataframe/core.py:6821, in apply_and_enforce(*args, **kwargs)
       6819 func = kwargs.pop(""_func"")
       6820 meta = kwargs.pop(""_meta"")
    -> 6821 df = func(*args, **kwargs)
       6822 if is_dataframe_like(df) or is_series_like(df) or is_index_like(df):
       6823     if not len(df):
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1100, in to_datetime(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)
       1098         result = _convert_and_box_cache(argc, cache_array)
       1099     else:
    -> 1100         result = convert_listlike(argc, format)
       1101 else:
       1102     result = convert_listlike(np.array([arg]), format)[0]
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:413, in _convert_listlike_datetimes(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)
        410         return idx
        411     raise
    --> 413 arg = ensure_object(arg)
        414 require_iso8601 = False
        416 if infer_datetime_format and format is None:
    
    File pandas/_libs/algos_common_helper.pxi:33, in pandas._libs.algos.ensure_object()
    
    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/cudf/core/frame.py:451, in Frame.__array__(self, dtype)
        450 def __array__(self, dtype=None):
    --> 451     raise TypeError(
        452         ""Implicit conversion to a host NumPy array via __array__ is not ""
        453         ""allowed, To explicitly construct a GPU matrix, consider using ""
        454         "".to_cupy()\nTo explicitly construct a host matrix, consider ""
        455         ""using .to_numpy().""
        456     )
    
    TypeError: Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()
    To explicitly construct a host matrix, consider using .to_numpy().



",2023-03-30T16:25:12Z,0,0,QiuxiaoMu,
227,[FEA] Story - Improve performance with long strings,"Many [strings APIs in libcudf](https://docs.rapids.ai/api/libcudf/stable/group__strings__apis.html) use thread-per-string parallelism in their implementation. This approach works great for processing smaller strings of relatively consistent length. However, for long strings (roughly 256 bytes and above) the performance of thread-per-string algorithms begins to degrade. Some strings APIs are compatible with data-parallel algorithms and can be refactored to improve performance for long strings, while other strings APIs are difficult to refactor with data-parallel algorithms. 

Let's use this issue to track the progression: 
✅ - this API works well with long strings
🟢 - we think this API will be straightforward to refactor
🟡 - we have some ideas on how to refactor this API, and we'll need to experiment
🔴 - we think this will be very difficult to refactor!
⚪ - long string support is not a priority for this API

|Module|Function|Status|Notes|
|---|---|---|---|
| [Case](https://docs.rapids.ai/api/libcudf/nightly/group__strings__case.html) | capitalize <br> title <br> is_title <br> to_lower <br> to_upper <br> swapcase | 🟡 <br> 🟡 <br> 🟡 <br> ✅#13142 <br> ✅#13142 <br>✅#13142  | |
| [Character Types](https://docs.rapids.ai/api/libcudf/nightly/group__strings__types.html) | all_characters_of_type <br> filter_characters_of_type | ✅#13259 <br> 🔴 | |
| [Combining](https://docs.rapids.ai/api/libcudf/nightly/group__strings__combine.html) | join_strings <br> concatenate <br> join_list_elements | ✅#13283 <br> 🟡 <br> 🔴 | |
| [Searching](https://docs.rapids.ai/api/libcudf/nightly/group__strings__contains.html) | contains_re <br> matches_re <br> count_re <br> like <br> find_all | 🟡 <br> ⚪ <br> 🔴 <br> 🟢#13594 <br> 🔴 |  |
| [Converting](https://docs.rapids.ai/api/libcudf/nightly/group__strings__convert.html) | to_XXXX <br> from_XXXX  | ⚪ <br> ⚪ | these are rarely long strings|
| [Copying](https://docs.rapids.ai/api/libcudf/nightly/group__strings__copy.html) | repeat_string <br> repeat_strings | ✅ <br> ✅ | One [overload](https://docs.rapids.ai/api/libcudf/nightly/group__strings__copy.html#ga160c075327cb4fb081db19884dba294c) is an exception  |
| [Slicing](https://docs.rapids.ai/api/libcudf/nightly/group__strings__slice.html) | slice_strings | ✅#13057 | One [overload](https://docs.rapids.ai/api/libcudf/nightly/group__strings__slice.html#ga2bc738cebebcf6d1331d6e9d13d4cd28) allows for skipping characters. <br>Long string support is not a priority for <br> `step > 1 or step < 0` |
| [Finding](https://docs.rapids.ai/api/libcudf/nightly/group__strings__find.html) | find <br> rfind <br> contains <br> starts_with <br> ends_with <br> find_multiple | ✅#13226 <br> ✅#13226 <br> ✅#10739 <br> ⚪ <br> ⚪ <br> 🟢  | |
| [Modifying](https://docs.rapids.ai/api/libcudf/nightly/group__strings__modify.html) | pad <br> zfill <br> reverse <br> strip <br> translate <br> filter_characters <br> wrap | 🟡 <br> ⚪ <br> 🟡 <br> ✅ <br> 🟡 <br> 🔴 <br> 🔴 |  |
| [Replacing](https://docs.rapids.ai/api/libcudf/nightly/group__strings__replace.html) | replace  <br> replace_slice <br> replace_re  <br> replace_with_backrefs | ✅#12858 <br> 🟡 <br> 🔴 <br> 🔴 | |
| [Splitting](https://docs.rapids.ai/api/libcudf/nightly/group__strings__split.html) | partition <br> split <br> split_record <br> split_re <br> split_record_re | 🟡 <br> ✅#4922 #13680 <br> ✅#12729 <br> 🔴 <br> 🔴 | |
| other | count_characters  <br> count_bytes| ✅#12779 <br> 🟢 | | 

Libcudf also includes [NVText](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__apis.html) APIs that will benefit from improvements in performance when processing long strings. Generally long string performance is even more important for our text APIs, where each row could represent a sentence, paragraph or document.

|Module|Function|Status|Notes|
|---|---|---|---|
| [NGrams](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__ngrams.html) | generate_ngrams <br> generate_character_ngrams <br> ngrams_tokenize|  ⚪  <br> 🟢 <br> 🟢#13480 | these are generally not long strings |
| [Normalizing](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__normalize.html) | normalize_characters <br> normalize_spaces  |  🟢 <br> 🟢#13480  |  |
| [Stemming](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__stemmer.html) | is_letter <br> porter_stemmer_measure  |   🟢 <br>🟢  | |
| [Edit Distance](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__edit__distance.html) | edit_distance <br> edit_distance_matrix | ⚪ <br> ⚪  | these are generally not long strings |
| [Tokenizing](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__tokenize.html) | byte_pair_encoding <br> subword_tokenize <br> tokenize <br> count_tokens <br> character_tokenize <br> detokenize  | 🟡 <br>🟡 <br>🟢#13480 <br>🟢#13480 <br>🟡 <br>🟡  |  |
| [Replacing](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__replace.html) | replace_tokens <br> filter_tokens | 🟢#13480 <br>🟢#13480 |  |
| [MinHashing](https://docs.rapids.ai/api/libcudf/nightly/group__nvtext__minhash.html) | minhash  | ✅#13333 |  |
",2023-04-03T17:58:26Z,0,0,Gregory Kimball,
228,[FEA] Async mode for cudf.series operations,"**Is your feature request related to a problem? Please describe.**

We get wide dataframes in situations like machine learning (easily 1-5K cols) and genomics (10K+ cols), and while there is some speedup from cudf (say 2-3X), it'd be easy to get to the 10X+ level with much higher GPU utilization if we could spawn concurrent tasks for each column . Getting this all the way to the df level seems tricky, but async primitives at the column level would get us far. 

One Python-native idea is doing via `async/await`, when one cudf operation is getting scheduled, allocated, & run, we can be scheduling the next, and ideally, cudf can run them independently . It smoothed out 2-3 years ago in python + javascript as a popular native choice, and has since been  a lot more popular in pydata, e.g., langchain just rewrote to support async versions of all methods. Ex: https://trends.google.com/trends/explore?date=all&q=async%20await&hl=en . Separately, there's heightened value for pydata dashboarding scenarios like plotly, streamlit, etc as these ecosystem increasingly build for async io underneath as well.

(Another idea with precedent is a lazy mode similar to haskell or dask, discussed below as well)

**Describe the solution you'd like**

I'd like to be do something like:

```python

async def f(s: cudf.Series) -> cudf.Series:
    # async mode for core series operations lets other f() calls proceed while this runs
    s2 = await  s.stra.hex_to_int('AABBCC')
   
    # math can be clean and enable the same
    # if we're super clever, this may even unlock query plan optimizations like fusion in the future
    async with cudf.async.binop_mode:
        s3_a = s2 + 1 / 3
        s3 = await s3_a

   return s3
  
cols2 = await async.gather([  f(df[col]) for col in df ])
```

**Describe alternatives you've considered**

1. Use existing abstractions

In theory we can setup threads or multiple dask workers, but (1) both are super awkward, (2) underneath, cudf will not do concurrent jobs

2. Lazy cudf

Another thought is to create a lazy mode for cudf. This has precedent with Haskell, and in modern pydata land, more so with polars. Dask does this too, and we'd use it if that can work, but it's awkward -- I haven't used, but polars sounds to be more friendly in practice:

```python

def f(s: cudf.Series) -> cudf.Series:
    # explicitly lazy ops
    s2 = s.str_lazy.hex_to_int('AABBCC')

    # binops know they're lazy
    s3 = s2 + 1 / 3

    return s3

# force with async friendliness  
cols2 = await cudf_client.compute_async([  f(df[col]) for col in df ])
```

Underneath, cudf can reinvent async/io, dask, or whatever


**Additional context**

Slack thread: https://rapids-goai.slack.com/archives/C5E06F4DC/p1680710488795869 
",2023-04-07T17:09:44Z,0,0,,Graphistry
229,[FEA] Add 64-bit size type option at build-time for libcudf,"Many libcudf users have expressed interest in using a 64-bit size type (see #3958 for reference). The `cudf::size_type` uses a `int32_t` data type that limits the number of elements in libcudf columns to `INT_MAX` (2.1 billion) elements. For string columns this imposes a ~2 GB limit, for int32 columns this imposes a ~8 GB limit, and for list columns this imposes a leaf element count <2.1 billion. Downstream libraries must partition their data to avoid these limits.

We expect that using a 64-bit size type will incur significant penalties to memory footprint and data throughput. Memory footprint will double for all offset vectors, and runtime of most functions will increase due to the larger data sizes. Kernel performance may degrade even further due to increased register count and unoptimized shared memory usage.

As GPUs increase in memory, the limit from a 32-bit `cudf::size_type` will force data partitions to become smaller fractions of device memory. Excessive data partitioning also leads to performance penalties, so libcudf should enable its community to start experimenting with a 64-bit size type. Scoping for 64-bit size types in the cuDF-python layer will be tracked in a separate issue (#TBD).

- [ ] Consult with thrust/cub experts about outstanding issues with 64-bit indexing. Some libcudf functions may depend on upstream changes in CCCL, please see [cccl/47](https://github.com/NVIDIA/cccl/issues/47), [thrust/1271](https://github.com/NVIDIA/cccl/issues/744), and [cub/212](https://github.com/NVIDIA/cub/issues/212). `copy_if`, `reduce`, `parallel_for`, `merge` and `sort` may have unresolved issues.
- [ ] Consult with thrust/cub experts about making 32-bit kernels optional. Currently the 64-bit kernels and disabled in libcudf builds. Disabling the 32-bit kernels would avoid large increases in compile time and binary size when we enable 64-bit thrust/cub kernels.
- [ ] Verify compatibility of 64-bit size type with cuco data structures (needs additional scoping)
- [ ] Audit custom kernels in libcudf for the impact of a 64-big size type. Introduce conditional logic to adjust shared memory allocations and threads per block as needed based on the size type. Identify implementation details that take a 32-bit size type for granted.
- [ ] Audit cuIO size types and their interaction with `cudf::size_type`
- [ ] Resolve compilation errors from using a 64-bit size type
- [ ] Resolve test failures from using a 64-bit size type
- [ ] Review performance impact of a 64-bit size type using libcudf microbenchmark results 
- [ ] Add a build-time option for advanced users to use a 64-bit size type instead of a 32-bit size type.
- [ ] Add a CI step to build and test the 64-bit size type option.

From this stage we will have a better sense of the impact and value of using a 64-bit size type with libcudf.
",2023-04-17T23:18:55Z,0,0,Gregory Kimball,
230,[DOC] Document cuDF's spilling option,"cuDF can optionally spill buffers to host memory when running short of device memory via `cudf.set_option(""spill"", True)`. We should document this option, similar to how we document copy-on-write: https://docs.rapids.ai/api/cudf/nightly/user_guide/copy-on-write.html",2023-04-18T11:45:49Z,0,0,Ashwin Srinath,Voltron Data
231,[FEA] Support aggregations/scans on lists via groupby,"This is related to https://github.com/rapidsai/cudf/issues/10408.

It's possible to use a combination of `explode()` and `groupby()` to support common aggregations on `list` columns:

```python
In [23]: df
Out[23]:
            a
0   [1, 3, 2]
1      [1, 4]
2  [9, 0, -1]

In [24]: df.explode('a').groupby(level=0).max()
Out[24]:
   a
0  3
1  4
2  9
```

Scans can similarly be computed via an additional call to `groupby-collect()`:

```python
In [33]: df.explode('a').groupby(level=0).cummax().groupby(level=0).collect()
Out[33]:
           a
0  [1, 3, 3]
1     [1, 4]
2  [9, 9, 9]
```

When an aggregation/scan supported by groupby, like `.max()` or `.min()` is called on a list column, we could transparently use this combination of explode + groupby to support that operation. That could look something like:

```python
>>> df
            a
0   [1, 3, 2]
1      [1, 4]
2  [9, 0, -1]

>>> df['a'].list.max()
0    3
1    4
2    9
Name: a, dtype: int64

>>> df['a'].list.cummax()
0    [1, 3, 3]
1       [1, 4]
2    [9, 9, 9]
Name: a, dtype: list
```",2023-04-24T19:29:51Z,0,0,Ashwin Srinath,Voltron Data
232,[BUG] dask_cudf  - aggregate -  to_csv memory error ,"**Describe the bug**
A clear and concise description of what the bug is.
I am loading a large dataframe (~60M x 300) by csv via dask_cudf,  then looking to do a groupby and sum, and resave this to csv. I get an OOM error - I am using an A100-80GB gpu along with 200GB of RAM. 

All rows are numerical values, besides the groupby row left as the index. Thus, this error should be reproducible via a random dataframe. 
I noted a similar issue [@10426](https://github.com/rapidsai/cudf/issues/10426), however this error message is different, therefore I was unsure if this was the case.
Additionally, I do repeatedly get a high cpu garbage collection message, however I assume that is because of the size of the dataframe and many read/writes, correct me if that is not the case.
**Steps/Code to reproduce bug**
Follow this guide http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports to craft a minimal bug report. This helps us reproduce the issue you're having and resolve the issue more quickly.

```
import numpy as np
import pandas as pd
import cudf
import cupy
from dask_cuda import LocalCUDACluster
from dask.distributed import Client
from dask.utils import parse_bytes
import dask_cudf

cluster = LocalCUDACluster(jit_unspill=True,
                           rmm_pool_size=parse_bytes(""64 GB""),
                           n_workers = 1,
                           device_memory_limit=parse_bytes(""160 GB""),
                           local_directory='local_temp',
                           threads_per_worker=32)
client = Client(cluster)


df = dask_cudf.read_csv('../02_all_study/02_tad_80_cluster_ref.tsv',sep = '\t')
df2 = df.drop('Contig',axis=1)
res = df2.groupby('ref90_cluster').sum()
res.to_csv('04_cluster_groups_csv')
```

Output (I think the error message is repeating after nanny restarts, but I have included the entire error message for thoroughness (attached as file for size):
[dask_to_csv_error.txt](https://github.com/rapidsai/cudf/files/11327385/dask_to_csv_error.txt)


**Expected behavior**
A clear and concise description of what you expected to happen.

**Environment overview (please complete the following information)**
 - Environment location: [Bare-metal, Docker, Cloud(specify cloud provider)] RHEL server
 - Method of cuDF install: [conda, Docker, or from source] conda (mamba)
   - If method of install is [Docker], provide `docker pull` & `docker run` commands used

**Environment details**
Please run and paste the output of the `cudf/print_env.sh` script here, to gather any other relevant environment details
<details><summary>Click here to see environment details</summary><pre>

     **git***
     Not inside a git repository

     ***OS Information***
     NAME=""Red Hat Enterprise Linux Server""
     VERSION=""7.9 (Maipo)""
     ID=""rhel""
     ID_LIKE=""fedora""
     VARIANT=""Server""
     VARIANT_ID=""server""
     VERSION_ID=""7.9""
     PRETTY_NAME=""Red Hat Enterprise Linux Server 7.9 (Maipo)""
     ANSI_COLOR=""0;31""
     CPE_NAME=""cpe:/o:redhat:enterprise_linux:7.9:GA:server""
     HOME_URL=""https://www.redhat.com/""
     BUG_REPORT_URL=""https://bugzilla.redhat.com/""

     REDHAT_BUGZILLA_PRODUCT=""Red Hat Enterprise Linux 7""
     REDHAT_BUGZILLA_PRODUCT_VERSION=7.9
     REDHAT_SUPPORT_PRODUCT=""Red Hat Enterprise Linux""
     REDHAT_SUPPORT_PRODUCT_VERSION=""7.9""
     Red Hat Enterprise Linux Server release 7.9 (Maipo)
     Red Hat Enterprise Linux Server release 7.9 (Maipo)
     Linux atl1-1-01-006-7-0.pace.gatech.edu 3.10.0-1160.49.1.el7.x86_64 #1 SMP Tue Nov 9 16:09:48 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux

     ***GPU Information***
     Tue Apr 25 18:48:17 2023
     +-----------------------------------------------------------------------------+
     | NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
     |-------------------------------+----------------------+----------------------+
     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
     |                               |                      |               MIG M. |
     |===============================+======================+======================|
     |   0  NVIDIA A100 80G...  On   | 00000000:25:00.0 Off |                    0 |
     | N/A   33C    P0    61W / 300W |  72218MiB / 81920MiB |      0%      Default |
     |                               |                      |             Disabled |
     +-------------------------------+----------------------+----------------------+

     +-----------------------------------------------------------------------------+
     | Processes:                                                                  |
     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
     |        ID   ID                                                   Usage      |
     |=============================================================================|
     |    0   N/A  N/A     26580      C   ...s/rapids-23.04/bin/python    10315MiB |
     |    0   N/A  N/A     27149      C   ...s/rapids-23.04/bin/python    61901MiB |
     +-----------------------------------------------------------------------------+

     ***CPU***
     Architecture:          x86_64
     CPU op-mode(s):        32-bit, 64-bit
     Byte Order:            Little Endian
     CPU(s):                64
     On-line CPU(s) list:   0-63
     Thread(s) per core:    1
     Core(s) per socket:    32
     Socket(s):             2
     NUMA node(s):          8
     Vendor ID:             AuthenticAMD
     CPU family:            25
     Model:                 1
     Model name:            AMD EPYC 7513 32-Core Processor
     Stepping:              1
     CPU MHz:               2600.000
     CPU max MHz:           2600.0000
     CPU min MHz:           1500.0000
     BogoMIPS:              5200.16
     Virtualization:        AMD-V
     L1d cache:             32K
     L1i cache:             32K
     L2 cache:              512K
     L3 cache:              32768K
     NUMA node0 CPU(s):     0-7
     NUMA node1 CPU(s):     8-15
     NUMA node2 CPU(s):     16-23
     NUMA node3 CPU(s):     24-31
     NUMA node4 CPU(s):     32-39
     NUMA node5 CPU(s):     40-47
     NUMA node6 CPU(s):     48-55
     NUMA node7 CPU(s):     56-63
     Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc art rep_good nopl nonstop_tsc extd_apicid aperfmperf eagerfpu pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_l2 cpb cat_l3 cdp_l3 invpcid_single hw_pstate sme retpoline_amd ssbd ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif umip pku ospke vaes vpclmulqdq overflow_recov succor smca

     ***CMake***
     /bin/cmake
     cmake version 2.8.12.2

     ***g++***
     /usr/lib64/ccache/g++
     g++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)
     Copyright (C) 2015 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


     ***nvcc***
     /usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2022 NVIDIA Corporation
     Built on Tue_May__3_18:49:52_PDT_2022
     Cuda compilation tools, release 11.7, V11.7.64
     Build cuda_11.7.r11.7/compiler.31294372_0

     ***Python***
     /storage/home/hcoda1/6/rridley3/data/dir/anaconda3/envs/rapids-23.04/bin/python
     Python 3.10.10

     ***Environment Variables***
     PATH                            : /usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/extras/qd/bin:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/comm_libs/mpi/bin:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/bin:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/cuda/bin:/usr/local/pace-apps/spack/packages/linux-rhel7-x86_64/gcc-4.8.5/cuda-11.7.0-7sdye3id7ahz34mzhyzzqbxowjxgxkhu/bin:/storage/home/hcoda1/6/rridley3/.cargo/bin:/storage/home/hcoda1/6/rridley3/data/dir/anaconda3/envs/rapids-23.04/bin:/storage/home/hcoda1/6/rridley3/data/dir/apps:/storage/home/hcoda1/6/rridley3/.aspera/connect/bin:/opt/pace-common/bin:/opt/slurm/current/bin:/opt/pace-system/bin:/usr/lpp/mmfs/bin:/usr/lib64/ccache:/sbin:/bin:/usr/sbin:/usr/bin:/opt/iozone/bin:/storage/home/hcoda1/6/rridley3/edirect
     LD_LIBRARY_PATH                 : /usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/comm_libs/nvshmem/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/comm_libs/nccl/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/comm_libs/mpi/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/math_libs/lib64:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/extras/qd/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/cuda/extras/CUPTI/lib64:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/cuda/lib64:/usr/local/pace-apps/spack/packages/linux-rhel7-x86_64/gcc-4.8.5/cuda-11.7.0-7sdye3id7ahz34mzhyzzqbxowjxgxkhu/lib64:/opt/slurm/current/lib::
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /storage/home/hcoda1/6/rridley3/data/dir/anaconda3/envs/rapids-23.04
     PYTHON_PATH                     :

     conda not found
     ***pip packages***
     /storage/home/hcoda1/6/rridley3/data/dir/anaconda3/envs/rapids-23.04/bin/pip
     Package                       Version
     ----------------------------- -----------
     aiofiles                      22.1.0
     aiohttp                       3.8.4
     aiosignal                     1.3.1
     aiosqlite                     0.18.0
     anyio                         3.6.2
     aplus                         0.11.0
     appdirs                       1.4.4
     argon2-cffi                   21.3.0
     argon2-cffi-bindings          21.2.0
     arrow                         1.2.3
     asciitree                     0.3.3
     astropy                       5.2.2
     asttokens                     2.2.1
     async-timeout                 4.0.2
     attrs                         22.2.0
     Babel                         2.12.1
     backcall                      0.2.0
     backports.functools-lru-cache 1.6.4
     beautifulsoup4                4.12.2
     blake3                        0.2.1
     bleach                        6.0.0
     bokeh                         2.4.3
     bqplot                        0.12.39
     branca                        0.6.0
     brotlipy                      0.7.0
     cached-property               1.5.2
     cachetools                    5.3.0
     certifi                       2022.12.7
     cffi                          1.15.1
     charset-normalizer            2.1.1
     click                         8.1.3
     click-plugins                 1.1.1
     cligj                         0.7.2
     cloudpickle                   2.2.1
     colorama                      0.4.6
     colorcet                      3.0.1
     comm                          0.1.3
     confluent-kafka               1.7.0
     contourpy                     1.0.7
     cryptography                  40.0.2
     cubinlinker                   0.2.2
     cucim                         23.4.1
     cuda-python                   11.8.1
     cudf                          23.4.0
     cudf-kafka                    23.4.0
     cugraph                       23.4.0
     cuml                          23.4.0
     cupy                          11.6.0
     cusignal                      23.4.0
     cuspatial                     23.4.0
     custreamz                     23.4.0
     cuxfilter                     23.4.0
     cycler                        0.11.0
     cytoolz                       0.12.0
     dask                          2023.3.2
     dask-cuda                     23.4.0
     dask-cudf                     23.4.0
     dask-labextension             6.1.0
     datashader                    0.14.4
     datashape                     0.5.4
     debugpy                       1.6.7
     decorator                     5.1.1
     defusedxml                    0.7.1
     distributed                   2023.3.2.1
     entrypoints                   0.4
     executing                     1.2.0
     fastapi                       0.95.1
     fastavro                      1.7.3
     fasteners                     0.18
     fastjsonschema                2.16.3
     fastrlock                     0.8
     filelock                      3.12.0
     Fiona                         1.9.1
     flit_core                     3.8.0
     folium                        0.14.0
     fonttools                     4.39.3
     fqdn                          1.5.1
     frozendict                    2.3.7
     frozenlist                    1.3.3
     fsspec                        2023.4.0
     future                        0.18.3
     GDAL                          3.6.2
     geopandas                     0.12.2
     graphviz                      0.20.1
     h5py                          3.8.0
     holoviews                     1.15.4
     idna                          3.4
     imagecodecs                   2023.1.23
     imageio                       2.27.0
     importlib-metadata            6.5.0
     importlib-resources           5.12.0
     ipycytoscape                  1.3.3
     ipydatawidgets                4.3.2
     ipykernel                     6.22.0
     ipyleaflet                    0.17.2
     ipympl                        0.9.3
     ipython                       8.12.0
     ipython-genutils              0.2.0
     ipyvolume                     0.6.1
     ipyvue                        1.8.0
     ipyvuetify                    1.8.4
     ipywebrtc                     0.6.0
     ipywidgets                    8.0.6
     isoduration                   20.11.0
     jedi                          0.18.2
     Jinja2                        3.1.2
     joblib                        1.2.0
     json5                         0.9.5
     jsonpointer                   2.3
     jsonschema                    4.17.3
     jupyter_client                8.2.0
     jupyter_core                  5.3.0
     jupyter-events                0.6.3
     jupyter_server                2.5.0
     jupyter_server_fileid         0.9.0
     jupyter-server-proxy          3.2.2
     jupyter_server_terminals      0.4.4
     jupyter_server_ydoc           0.8.0
     jupyter-ydoc                  0.2.3
     jupyterlab                    3.6.3
     jupyterlab-pygments           0.2.2
     jupyterlab_server             2.22.1
     jupyterlab-widgets            3.0.7
     kiwisolver                    1.4.4
     lazy_loader                   0.2
     llvmlite                      0.39.1
     locket                        1.0.0
     lz4                           4.3.2
     mapclassify                   2.5.0
     Markdown                      3.4.3
     markdown-it-py                2.2.0
     MarkupSafe                    2.1.2
     matplotlib                    3.7.1
     matplotlib-inline             0.1.6
     mdurl                         0.1.0
     mistune                       2.0.5
     msgpack                       1.0.5
     multidict                     6.0.4
     multipledispatch              0.6.0
     munch                         2.5.0
     munkres                       1.1.4
     nbclassic                     0.5.5
     nbclient                      0.7.3
     nbconvert                     7.3.1
     nbformat                      5.8.0
     nest-asyncio                  1.5.6
     networkx                      3.1
     notebook                      6.5.4
     notebook_shim                 0.2.3
     numba                         0.56.4
     numcodecs                     0.11.0
     numexpr                       2.8.4
     numpy                         1.23.5
     nvtx                          0.2.5
     packaging                     23.1
     pandas                        1.5.3
     pandocfilters                 1.5.0
     panel                         0.14.1
     param                         1.13.0
     parso                         0.8.3
     partd                         1.4.0
     patsy                         0.5.3
     pexpect                       4.8.0
     pickleshare                   0.7.5
     Pillow                        9.4.0
     pip                           23.1
     pkgutil_resolve_name          1.3.10
     platformdirs                  3.2.0
     pooch                         1.7.0
     progressbar2                  4.2.0
     prometheus-client             0.16.0
     prompt-toolkit                3.0.38
     protobuf                      4.21.12
     psutil                        5.9.5
     ptxcompiler                   0.7.0
     ptyprocess                    0.7.0
     pure-eval                     0.2.2
     pyarrow                       10.0.1
     pycparser                     2.21
     pyct                          0.4.6
     pydantic                      1.10.7
     pydeck                        0.5.0
     pyee                          8.1.0
     pyerfa                        2.0.0.3
     Pygments                      2.15.1
     pylibcugraph                  23.4.0
     pylibraft                     23.4.0
     pynvml                        11.4.1
     pyOpenSSL                     23.1.1
     pyparsing                     3.0.9
     pyppeteer                     1.0.2
     pyproj                        3.4.0
     pyrsistent                    0.19.3
     PySocks                       1.7.1
     python-dateutil               2.8.2
     python-json-logger            2.0.7
     python-utils                  3.5.2
     pythreejs                     2.4.2
     pytz                          2023.3
     pyviz-comms                   2.2.1
     PyWavelets                    1.4.1
     PyYAML                        6.0
     pyzmq                         25.0.2
     raft-dask                     23.4.0
     requests                      2.28.2
     rfc3339-validator             0.1.4
     rfc3986-validator             0.1.1
     rich                          13.3.4
     rmm                           23.4.0
     Rtree                         1.0.1
     scikit-image                  0.20.0
     scikit-learn                  1.2.2
     scipy                         1.10.1
     seaborn                       0.12.2
     Send2Trash                    1.8.0
     setuptools                    67.6.1
     shapely                       2.0.1
     simpervisor                   0.4
     six                           1.16.0
     sniffio                       1.3.0
     sortedcontainers              2.4.0
     soupsieve                     2.3.2.post1
     spectate                      1.0.1
     stack-data                    0.6.2
     starlette                     0.26.1
     statsmodels                   0.13.5
     streamz                       0.6.4
     tables                        3.7.0
     tabulate                      0.9.0
     tblib                         1.7.0
     terminado                     0.17.1
     threadpoolctl                 3.1.0
     tifffile                      2023.4.12
     tiledb                        0.21.2
     tinycss2                      1.2.1
     tomli                         2.0.1
     toolz                         0.12.0
     tornado                       6.3
     tqdm                          4.65.0
     traitlets                     5.9.0
     traittypes                    0.2.1
     treelite                      3.2.0
     treelite-runtime              3.2.0
     typing_extensions             4.5.0
     ucx-py                        0.31.0
     unicodedata2                  15.0.0
     uri-template                  1.2.0
     urllib3                       1.26.15
     vaex-astro                    0.9.3
     vaex-core                     4.16.1
     vaex-hdf5                     0.14.1
     vaex-jupyter                  0.8.1
     vaex-ml                       0.18.1
     vaex-server                   0.8.1
     vaex-viz                      0.5.4
     wcwidth                       0.2.6
     webcolors                     1.13
     webencodings                  0.5.1
     websocket-client              1.5.1
     websockets                    10.4
     wheel                         0.40.0
     widgetsnbextension            4.0.7
     xarray                        2023.4.1
     xgboost                       1.7.5
     xyzservices                   2023.2.0
     y-py                          0.5.9
     yarl                          1.8.2
     ypy-websocket                 0.8.2
     zarr                          2.14.2
     zict                          3.0.0
     zipp                          3.15.0

</pre></details>



**Additional context**
Add any other context about the problem here.
",2023-04-25T22:55:47Z,0,0,Rodney Ridley,
233,[BUG] Crash running parquet reader benchmarks.,"
The PARQUET_READER_NVBENCH crashes (segfault) at exit on some machines.   It doesn't seem to happen consistently for everyone, but it tends to be reproducible once it starts happening.

To reproduce, run PARQUET_READER_NVBENCH and you should get a segfault right at the end after it has printed out all of it's results.

I've narrowed it down to something specific to the `parquet_read_io_compression` suite.  In addition, `compute-sanitizer` does not turn anything up so this seems to be something purely cpu-side.",2023-04-26T18:24:44Z,1,0,,
234,"[BUG] DataFrame iloc indexing is incorrect for repeated index entries in the ""columns"" part of the key","**Describe the bug**
```python
import cudf
import pandas as pd
import numpy as np
df = pd.DataFrame(np.arange(4).reshape(2, 2))
cdf = cudf.from_pandas(df)

df.iloc[:, [0, 1, 0]]
#    0  1  0
# 0  0  1  0
# 1  2  3  2

cdf.iloc[:, [0, 1, 0]]
#    0  1
# 0  0  1
# 1  2  3
```

This is because `ColumnAccessor.select_by_index` uniquifies input index arguments.

**Expected behavior**

This should match pandas.",2023-05-02T10:33:16Z,0,0,Lawrence Mitchell,
235,[BUG] Series and DataFrame loc indexing does not handle `Ellipsis`,"**Describe the bug**

This is the same as #13267 really, but `loc`-based indexing goes down a different code path, so I will end up fixing it separately.

```python
import cudf
import pandas as pd
import numpy as np
df = pd.DataFrame(np.arange(4).reshape(2, 2))
cdf = cudf.from_pandas(df)

df.loc[..., 0]
# 0    0
# 1    2
# Name: 0, dtype: int64

cdf.loc[..., 0] # => TypeError
```

**Expected behavior**

Should match pandas.",2023-05-02T10:50:15Z,0,0,Lawrence Mitchell,
236,[BUG] DataFrame `loc` indexing is incorrect with repeated column labels.,"**Describe the bug**

This is basically #13266 but for `loc`, I will fix it separately due to different code paths.

```python
import cudf
import pandas as pd
import numpy as np
df = pd.DataFrame(np.arange(4).reshape(2, 2))
cdf = cudf.from_pandas(df)

df.loc[:, [0, 1, 0]]
#    0  1  0
# 0  0  1  0
# 1  2  3  2

cdf.loc[:, [0, 1, 0]]
#    0  1
# 0  0  1
# 1  2  3
```

This is because `ColumnAccessor.select_by_label` uniquifies input label arguments.

**Expected behavior**

This should match pandas.",2023-05-02T11:04:17Z,0,0,Lawrence Mitchell,
237,[BUG] dataframe construction silently drops data with duplicate column names,"**Describe the bug**

In pandas, it is allowable to construct a dataframe where the same name is used for more than one of the columns (seems unlikely you would _want_ to do this, but OK).

In cudf, in contrast, duplicate column names are _not_ allowed. However, this restriction is only checked in a few APIs (`from_pandas` complains, for example, but `DataFrame.__init__` doesn't).

This is rather nefarious because operations succeed but silently drop data.

Example:
```python
import pandas as pd
import numpy as np
import cudf

df = pd.DataFrame(np.arange(4).reshape(2, 2), columns=[""A"", ""A""])
assert df.sum().sum() == 6 # succeeds
cdf = cudf.DataFrame(np.arange(4).reshape(2, 2), columns=[""A"", ""A""]) # succeeds, but throws away first column

assert cdf.sum().sum() == 6 # fails
cdf2 = cudf.from_pandas(df) # raises ValueError
```


**Expected behavior**

Either

1. Support this use case (probably a big job)
2. Raise `ValueError` in all cases (easier, minimal sufficient requirement for xdf).",2023-05-02T15:23:13Z,1,0,Lawrence Mitchell,
238,[BUG] Error when printing large CategoricalIndex,"Printing a `CategoricalIndex` with more than 200 elements results in the following error:

```
TypeError: Cannot interpret 'interval[float64, right]' as a data type
```

Reproducer

```
import cudf
import cupy

p = cudf.cut(cupy.arange(201), 3)

# this works
print(p[:200])

# this doesn't
print(p)
```

with cudf version 23.04.01 and cupy version 11.6.0",2023-05-03T20:41:26Z,0,0,Filippo Simini,Argonne National Laboratory
239,[FEA] Support non-broadcasting (non-scalar) assignment on list columns,"Consider

```python
import cudf

s = cudf.Series([[1], [2], [3]])
g = cudf.Series([[4], [5]])

s.iloc[:2] = g
```

I would expect this to work and produce `[[4], [5], [3]]`. Instead, we get an error:
```
ValueError: Can not set <cudf.core.column.lists.ListColumn object at 0x7fea4b0f5cc0>
[
  [
    4
  ],
  [
    5
  ]
]
dtype: list into ListColumn
```

Indeed, the only things we can `__setitem__` into list columns are `cudf.NA` and a singleton list (treated as a `cudf.Scalar`) that is broadcast to all entries.",2023-05-04T15:42:15Z,0,0,Lawrence Mitchell,
240,[BUG] Setitem on struct columns picks out incorrect pieces when indexing of rvalue is not from zero.,"**Describe the bug**

```python
import cudf

s = cudf.Series([{""a"": 1}, {""a"": 2}, {""a"": 3}])
g = cudf.Series([{""a"": 4}, {""a"": 5}, {""a"": 6}])

s.iloc[1:2] = g.iloc[2:3]

s.iloc[1:2]
# 1    {'a': 4}
# dtype: struct

g.iloc[2:3]
# 2    {'a': 6}
# dtype: struct

# An even more fun:

x = g.iloc[2:3].copy(deep=True)

s.iloc[1] = x.iloc[0]

s.iloc[1] # => {'a': 6} Good!

s.iloc[1] = x.iloc[:]

s.iloc[1] # => {'a': 4} What!
```

Oops.",2023-05-04T16:59:24Z,0,0,Lawrence Mitchell,
241,[BUG] `__repr__` for a high cardinality categorical can take a very long time,"Because it involves copying data to Pandas, just printing a high-cardinality CategoricalIndex can take a very long time:

```python
dt = pd.CategoricalIndex(range(100_000_000))
print(dt)  # almost instantaneous

dt = cudf.CategoricalIndex(range(100_000_000))
print(dt)  # can take several seconds
```

We should figure out if we can do this by copying only the minimum amount of data to Pandas (or not copying to Pandas at all).",2023-05-04T21:46:48Z,0,0,Ashwin Srinath,Voltron Data
242,[ENH] Indices are immutable by definition and should take advantage of that,"**Is your feature request related to a problem? Please describe.**

Indices advertise a bunch of properties (for example `is_monotonic_increasing`). These are implemented by inheriting from `Frame` or `SingleColumnFrame`. But those latter classes are _mutable_, and so their implementation of the property must recompute every time.

For an index, this is not the case, and so we lose some performance (for example, every time we do a slice `.loc` we'll run a libcudf kernel to check if the index is sorted).

**Describe the solution you'd like**

Index properties (especially where they return scalars, and therefore the memory footprint is negligible) should use `functools.cached_property` to provide their (immutable) properties.

**Describe alternatives you've considered**

None

",2023-05-16T15:34:03Z,2,0,Lawrence Mitchell,
243,[FEA] Expand string operator support in libcudf ASTs,"After adding string scalar support in #13061, libcudf now supports string column and string scalar operands, plus comparison operators.

There are additional operators that would be useful for string types, and this issue will track the most-requested operators.

in scope:
string contains, startswith, endswith
length, find, rfind

out of scope for now:
casting to and from string to other AST types
regex support
concatenation

(Also see background issue #8858)",2023-05-16T16:20:49Z,0,0,Gregory Kimball,
244,[FEA] Rename `filters=` argument to `row_group_filters=` in `read_parquet` and `read_orc` and provide examples that show its use,"The `filters=` argument to the `read_parquet` and `read_orc` functions is misleading in its name. Because it filters by row _group_, rather than by row, I think we should rename it to `row_group_filters=`.

Additionally, the description for this kwarg is complicated and laden with jargon. I think we should simplify and provide some examples that clarify the use of this keyword:

```
    If not None, specifies a filter predicate used to filter out row groups
    using statistics stored for each row group as Parquet metadata. Row groups
    that do not match the given filter predicate are not read. The
    predicate is expressed in disjunctive normal form (DNF) like
    `[[('x', '=', 0), ...], ...]`. DNF allows arbitrary boolean logical
    combinations of single column predicates. The innermost tuples each
    describe a single column predicate. The list of inner predicates is
    interpreted as a conjunction (AND), forming a more selective and
    multiple column predicate. Finally, the outermost list combines
    these filters as a disjunction (OR). Predicates may also be passed
    as a list of tuples. This form is interpreted as a single conjunction.
    To express OR in predicates, one must use the (preferred) notation of
    list of lists of tuples
```
",2023-05-17T19:02:46Z,0,0,Ashwin Srinath,Voltron Data
245,[FEA] Support self comparisons in `cudf::experimental::row::lexicographic::two_table_comparator`,"As showcased in https://github.com/rapidsai/cudf/pull/13347, there's a need for `{lhs, lhs}` and `{rhs, rhs}` comparisons in an instance of `two_table_comparator`.

This can't simply be achieved by adding more overloads because `left` and `right` terminology is [baked into the comparator](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L1141-L1157) when it's constructed at the host-side. In a device function, the [strongly typed indices](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L1012-L1039) now work with the assumption that a `comp(i, j)` that is called in a device function operates on `{lhs, rhs}` or `{rhs, lhs}`.

We need to settle on a design that lets us refactor the row operators such that the assumption of working on two different tables can be removed.

Do we strongly type `device_row_comparator::operator()` [over here](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L541-L542) such that we can decide which columns of which tables to pass along to the `element_comparator` over [here](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L568-L575)?

I see the design looking something like this:
```
class device_row_comparator {
  class element_comparator {
    operator() (size_type lhs_index, size_type rhs_index);
  };
  dispatch_element_operator(lhs_col, rhs_col, lhs_index, rhs_index);

  // these call dispatch_element_operator with the correct columns and indices
  operator() (lhs_index_type lhs_index, rhs_index_type rhs_index);
  operator() (lhs_index_type lhs_index, lhs_index_type rhs_index);
  operator() (rhs_index_type lhs_index, rhs_index_type rhs_index);
};

// the template `Comparator` here and below will be an instance of `device_row_comparator`,
// such that the strongly type indices can be passed along directly
template <typename Comparator, weak_ordering... values>
class single_table_ordering {
  operator() (size_type lhs_index, size_type rhs_index) {
    return comparator(lhs_index_type{lhs_index}, lhs_index_type{rhs_index});
};

template <typename Comparator, weak_ordering... values>
class two_table_ordering {
// same as current version of strong_index_comparator with added overloads for {lhs, lhs} and {rhs, rhs}
};

class self_comparator {
  auto less() {
    return less_comparator{single_table_ordering{device_row_comparator{...}}};
  }
};

class two_table_comparator {
  auto less() {
    return less_comparator{two_table_ordering{device_row_comparator{...}}};
  }
};
```
Note: In this example, [weak_ordering_comparator_impl](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L612-L626) will be removed and it's functionality will instead be baked into `single_table_ordering` and `two_table_ordering`. [less_comparator](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L634-L644) will then be reworked with CRTP such that:
```
template <typename Comparator>
class less_comparator : Comparator<weak_ordering::LESS>
```
",2023-05-17T19:21:59Z,1,0,Divye Gala,
246,[FEA] Pass dataframe as a parameter to .apply_rows,"looking the apply_rows, how can I pass in a cudf dataframe as an argument  so something like 
```
import cudf
import numpy as np

dfA = cudf.DataFrame({'A': [0, 1, 2, 3, 4],
                   'B': [5, 6, 7, 8, 9],
                   'C': ['a', 'b', 'c', 'd', 'e']})
dfA

dfB = cudf.DataFrame({'A': [0, 1, 2, 3, 4],
                   'B': [5, 6, 7, 8, 9],
                   'C': ['a', 'b', 'c', 'd', 'e']})

def fn(A, B, out1,k1):
    for i, (a, b) in enumerate(zip(A, B)):
        out1[i] = 1 # awesome work done here that uses all k1

dfB.apply_rows(fn, incols = ['A','B'], outcols = dict(out1=np.float64), kwargs=dict(k1=dfA))
```",2023-05-18T03:28:58Z,0,0,,
247,[BUG] `loc`-based indexing of DataFrames silently discards missing keys if at least one key is present in indexer,"**Describe the bug**

When performing `loc` indexing of a `DataFrame`, if one asks for a missing key, pandas raises a `KeyError`. In constrast,  cudf only does so if none of the requested keys are in the index. If at least one requested key is present then the subsetted data frame with that key is returned and the missing keys are silently dropped. 

Series `loc` indexing does the right thing here and raises `KeyError` if any keys are missing.

**Steps/Code to reproduce bug**

```python
import pandas as pd
import cudf

# same failure with rangeindex too.
df = pd.DataFrame({""A"": range(5)}, index=list(range(5)))
cdf = cudf.from_pandas(df)

df.loc[[0, 5]] # 5 is missing, raises KeyError

cdf.loc[[0, 5]]
#    A
# 0  0
```

**Expected behavior**

Should match pandas behaviour and raise `KeyError`.",2023-05-18T10:13:54Z,0,0,Lawrence Mitchell,
248,`tz_convert` sometimes returns results different from Pandas (but same as `zoneinfo`),"`tz_convert` returns a result different from Pandas for this pre-1900 example:

```python
>>> pd.Series([""1899-01-01 12:00""], dtype=""datetime64[s]"").dt.tz_localize(""Europe/Paris"").dt.tz_convert(""America/New_York"")
0   1899-01-01 06:55:00-04:56
dtype: datetime64[ns, America/New_York]

>>> cudf.Series([""1899-01-01 12:00""], dtype=""datetime64[s]"").dt.tz_localize(""Europe/Paris"").dt.tz_convert(""America/New_York"")
0   1899-01-01 06:50:39-04:56
dtype: datetime64[s, America/New_York]
```

However, our result is the same as you would get with `zoneinfo`:

```python
>>> datetime(1899, 1, 1, 12, 0, tzinfo=ZoneInfo(""Europe/Paris"")).astimezone(ZoneInfo(""America/New_York""))
datetime.datetime(1899, 1, 1, 6, 50, 39, tzinfo=zoneinfo.ZoneInfo(key='America/New_York'))
```

@mroeschke I'm curious if this aligns with your experience with the difference between Pandas (pytz) and zoneinfo?

_Originally posted by @shwina in https://github.com/rapidsai/cudf/pull/13328#discussion_r1196584991_
            ",2023-05-18T10:27:08Z,0,0,Ashwin Srinath,Voltron Data
249,[ENH] Avoid repeated bounds-checking in `take` when arguments are known in bounds,"As noted in #13419, there are likely places where we call `take` on a column with a gather map that is known to be in-bounds. We should therefore avoid an (unnecessary) bounds-check in these cases where we know this by passing `check_bounds=False`.

_Originally posted by @bdice in https://github.com/rapidsai/cudf/pull/13419#discussion_r1203131049_
            
```[tasklist]
### Tasks
- [ ] parquet.py `_get_groups_and_offsets`
- [ ] `_DataFrameLocIndexer._getitem_tuple_arg`
- [ ] `CategoricalColumn._get_decategorized_column`
- [ ] `ColumnBase.slice`
- [ ] `Rangindex._gather` ?
- [ ] `Groupby.agg`
- [ ] timezones.py `utc_to_local` and `local_to_utc`
- [ ] `MultiIndex.__repr__`
```
",2023-05-26T09:08:20Z,0,0,Lawrence Mitchell,
250,[FEA] Support V2 encodings in Parquet reader and writer,"Parquet V1 format supports three types of page encodings: PLAIN, DICTIONARY, and RLE (run-length encoded) ([reference from Spark Jira](https://issues.apache.org/jira/browse/SPARK-36879)). The newer and evolving Parquet V2 specification adds support for several [additional encodings](https://parquet.apache.org/docs/file-format/data-pages/encodings/), including DELTA_BINARY_PACKED for `INT32` and `INT64` types, DELTA_BYTE_ARRAY for `strings` logical type, and DELTA_LENGTH_BYTE_ARRAY for `strings` logical type. 

In the parquet reader and writer, libcudf should support V2 metadata as well as the three variants of DELTA encoding.

| Feature | Status | Notes | 
|---|---|---|
| Add V2 reader support |  ✅ #11778 | |
| Multi-warp decode of Dremel data streams | ✅ #13203 |  | 
| Use efficient strings column factory in decoder | ✅ #13302 |  | 
| Implement DELTA_BINARY_PACKED decoding |  ✅  #13637 | see #12948 for reference |
| Implement DELTA_BYTE_ARRAY decoding | ✅ #14101 | see #12948 for reference |
| Add V2 writer support | ✅ #13751 | |
| Implement DELTA_BINARY_PACKED encoding | ✅ #14100 | | 
| Add python bindings for V2 header and options | ✅ #14316 | |
| Implement DELTA_BYTE_ARRAY encoding | ✅ #15239 | some outdated reviews in #14938 |
| Implement DELTA_LENGTH_BYTE_ARRAY encoding and decoding for unsorted data | ✅ #14590 | |
| Add C++ API support for specifying encodings | ✅ #15081 | |
| Add cuDF-python API support for specifying encodings |  | |
| Add BYTE_STREAM_SPLIT encoding and decoding  | ✅ #15311 | see issue #15226 and [parquet reference](https://github.com/apache/parquet-format/blob/master/Encodings.md#byte-stream-split-byte_stream_split--9) |

",2023-06-02T03:38:40Z,0,0,Gregory Kimball,
251,[FEA] JSON reader improvements for Spark-RAPIDS,"libcudf includes a GPU-accelerated JSON reader that uses a finite-state transducer parser combined with token-processing tree algorithms to transform character buffers into columnar data. This issue tracks the technical work leading up to the launch of libcudf's JSON reader as a default component of the Spark-RAPIDS plugin. Please also refer to the [Nested JSON reader milestone](https://github.com/rapidsai/cudf/milestone/13) and [Spark-RAPIDS JSON epic](https://github.com/NVIDIA/spark-rapids/issues/9458).


### Spark compatibility issues: Blockers
| Status | Impact for Spark | Change to libcudf |
|---|---|---|
| ✅ #13344  | #12532, Blocker: if any line has an error, libcudf throws an exception  | Rework state machine to include error states and scrub tokens from lines with error | 
| ✅ #14252 | #14227, Blocker: Incorrect parsing | Fix bug in error recovery state transitions |  
✅ #14279 | #14226, Blocker: requesting alternate error recovery behavior from #13344, where valid data before an error state are preserved  | Changes in JSON parser pushdown automaton for JSON_LINES_RECOVER option  | 
| ✅ #14936 | #14288, Blocker: libcudf does not have an efficient representation for map types in Spark |  libcudf does not support map types, and modeling the map types as structs results in poor performance due to one child column per unique key. We will return the struct data that represents map types as string and then the plugin can use [unify_json_strings](https://github.com/NVIDIA/spark-rapids-jni/blob/54ef9991f46fa873d580315212aeae345da7152a/src/main/cpp/src/map_utils.cu#L63-L112) to parse tokens |
| ✅ #14572  | #14239, Blocker: fields with mixed types raise an exception | add libcudf reader option to return mixed types as strings. Also see improvements in  #15236 and  #14939 | 
| ✅ #14545 | #10004, Blocker: Can't parse data with single quote variant of JSON when `allowSingleQuotes` is enabled in Spark | Introduce a preprocessing function to normalize single and double quotes as double quotes | 
| ✅ #15324 | #15303, escaped single quotes have their escapes dropped during quote normalization | Adjust quote normalization FST |
| 🔄 #15419 | #15390 + #15409, Blocker: race conditions found in nested JSON reader | Solve synchronization problems in nested JSON reader  |
| | #15260, Blocker: crash in mixed type support | |
| 🔄 | #15278, Blocker: allow list type to be coerced to string, also see #14239. Without this, Spark-RAPIDS will fallback when user requests a field as ""string"" | Support List types coercion to string | 
| | #15277, Blocker: we need to support multi-line JSON objects. Also see #10267 | libcudf is scoping a ""multi-object"" reader |  



### Spark compatibility issues: non-blockers

| Status  | Impact for Spark | Change to libcudf  | 
|---|---|---|
| | #15222, compatibility problems with leading zeros, ""NAN"" and escape options | None for now. This feature should live in Spark-RAPIDS as a post-processing option for now, based on the approach for `get_json_object` modeled after Spark CPU code (see https://github.com/NVIDIA/spark-rapids-jni/pull/1836). Then the plugin can set to null any entries from objects that Spark would treat as invalid. Later we could provide Spark-RAPIDS access to raw tokens that they could run through a more efficient validator.  |
| ✅ #15033 |  #14865, Strip whitespace from JSON inputs, otherwise Spark will have to add this in post-processing the coerced strings types | Create new normalization pre-processing tool for whitespace | 
| 🔄 #14996 | #13473, Performance: only process columns in the schema | Skip parsing and column creation for keys not specified in the schema |
| 🔄 #15124 | Reader option performance is unknown | #15041, add JSON reader option benchmarking | |
| | Performance: Avoid preprocessing to replace empty lines with `{}`. Also see #5712 |  libcudf provides strings column data source | 
|  | #15280 find a solution when whitespace normalization fixes a line that originally was invalid | We could move whitespace normalization after tokenization. Also we would like to address #15277 so that we can remove unquoted newline characters as well. |
| | n/a, Spark-RAPIDS doesn't use byte range reading | #15185, reduce IO overhead in JSON byte range reading |
| | n/a, Spark-RAPIDS doesn't use byte range reading | #15186, address data loss edge case for byte range reading |
|  | reduce peak memory usage | add chunking to the JSON reader | 
| | #15222, Spark-RAPIDS must return null if any field is invalid | Provide token stream to Spark-RAPIDS for validation, including checks or leading zeros, special string numbers like `NaN`, `+INF`, `-INF`, and optional limits for which characters can be escaped |


",2023-06-07T16:30:32Z,0,0,Gregory Kimball,
252,[FEA] Use table_view interface in scatter-by-foo API in CUDF,"Both the scatter-like and gather-like Cython interfaces to libcudf's copying API accept a list of source and target columns as a ""table"". This feature is, however, only _used_ in the front-facing API by the gather-like calls.

For scatter-like calls on a dataframe, the final result is usually achieved by creating series for each column to scatter to/from and calling the singleton scatter on the series before reconstructing. This is more wasteful than it needs to be and we should probably instead just create the list of columns we wish to scatter and scatter that instead.

For example, the low-level Cython interface to scatter accepts a list of source and target columns:

https://github.com/rapidsai/cudf/blob/8055c2db6f80286b64d36f3927510bcf2e0eec02/python/cudf/cudf/_lib/copying.pyx#L240

However, the only caller in the python codebase is `ColumnBase._scatter_by_column` https://github.com/rapidsai/cudf/blob/8055c2db6f80286b64d36f3927510bcf2e0eec02/python/cudf/cudf/core/column/column.py#L647-L682 where we only have a single column to hand and hence can only pass one column.

This is usage is a consequence of `__setitem__` on `DataFrame`s ultimately being implemented by spinning over the columns (as series) and calling setitem on each series in turn. For example, `DataFrameIlocIndexer.__setitem__` has this code (when setting columns using a dataframe as the rvalue):

https://github.com/rapidsai/cudf/blob/8055c2db6f80286b64d36f3927510bcf2e0eec02/python/cudf/cudf/core/dataframe.py#L466-L477

This calls (on line 474) `Series.__setitem__` on each which either goes to `series.iloc.__setitem__` or `series.loc.__setitem__`, and eventually devolves to `ColumnBase.__setitem__`.

(Aside, this is actually a bug, since `iloc.__setitem__` should not do index alignment which `loc` will do).

Ignoring that bug issue, this code is somewhat wasteful in a number of ways:

1. we eventually throw away the `Series` object when reconstructing the dataframe, so should just operate on columns
2. at this point in `DataFrame.iloc.__setitem__` we _already know_ everything about the key (and hence which low-level libcudf operation to dispatch to) so we should do that rather than going through the front door of `Series.__setitem__` which will endeavour to rediscover everything we already know.
3. we call into libcudf n times (once for each column), rather than once with n columns, which negates the ability to use the stream parallelism that is implemented in the `scatter` code in libcudf

To fix this, I propose that `DataFrame` and `Series` should both get a new set of methods. Here's a first pass at what these should be called/their interface. These are internal and should do no argument normalisation or bounds-checking (it being the responsibility of the caller to sanitise appropriately), this includes kind/dtype casting as appropriate of the source and target.

- `_scatter_by_indices(self, source_columns, index_column, *, keep_index=True)`
- `_scatter_by_mask(self, source_columns, mask_column, *, keep_index=True)`
- `_scatter_by_slice(self, source_columns, slice, *, keep_index=True)`

Since there is also a broadcasting `scatter_from_scalar` operation in libcudf we'll probably need to support that too. This should be done with a `value_type` tag in the interface (rather than isinstancing on the `source_columns`) since, again, the caller must have already determined this information.",2023-06-07T16:46:17Z,0,0,Lawrence Mitchell,
253,[BUG] `Column._scatter_by_slice` doesn't handle negative-stride slices correctly.,"**Describe the bug**

```python
In [49]: col = cudf.core.column.as_column([1, 2, 3, 4])

In [50]: col
Out[50]: 
<cudf.core.column.numerical.NumericalColumn object at 0x7fcd07e6c4c0>
[
  1,
  2,
  3,
  4
]
dtype: int64

In [51]: col[::-1] = cudf.Scalar(7)

In [52]: col
Out[52]: 
<cudf.core.column.numerical.NumericalColumn object at 0x7fcd07e6c4c0>
[
  1,
  2,
  3,
  4
]
dtype: int64
```

This eventually calls `_scatter_by_slice`, which does this:

```python
    def _scatter_by_slice(
        self,
        key: builtins.slice,
        value: Union[cudf.core.scalar.Scalar, ColumnBase],
    ) -> Optional[Self]:
        """"""If this function returns None, it's either a no-op (slice is empty),
        or the inplace replacement is already performed (fill-in-place).
        """"""
        start, stop, step = key.indices(len(self))
        if start >= stop:
            return None
        num_keys = len(range(start, stop, step))

```

But that first check is not right to determine if the slice is empty.

```python
# x[::-1]
slice(None, None, -1).indices(3)
# => (2, -1, -1)
```

**Expected behavior**

This should work.",2023-06-08T08:50:43Z,0,0,Lawrence Mitchell,
254,[ENH]: Reimagining cudf user-input boundaries,"tl;dr: If you squint, everything is really a compiler problem in disguise.


## Overview

The pandas API is very broad and has numerous places where ""best effort"" attempts are made to DWIM (do what I mean). One example is during dataframe indexing, where a significant effort is made to ""desugar"" the user input into a canonical form.

For example, turning `df.loc[[1, 2, 3]]` into `df.loc[[1, 2, 3], :]` (that is, a single entry on a dataframe is equivalent to taking rows and *all* the columns).

This pattern is pervasive, to take another different example, `read_parquet` accepts as the ""file"" object:

1.  a string (indicating a file to open)
2.  a Path object
3.  raw bytes
4.  Anything with a `read` method
5.  A list (maybe sequence?) of the above


## The status quo

To handle this kind of multi-modal unstructured input, the user-visible API of cudf carries out inspection and validation of the inputs before dispatching to appropriate lower-level routines. By the time we reach libcudf, all decisions must have been made.

This works, but has a number of problems:

1.  It is not always clear *whose* job it is to do the validation. Is any ""pseudo-public"" method required to validate correctness of its inputs? Or is it always the job of the definitively public API to validate all inputs before handing off. One sees this in private `Frame` methods like `_gather` which have an explicit `check_bounds` flag (which often is not set when it could be, because the only *safe* default is `True`).
2.  Validation just checks for valid inputs and then returns types unchanged (so defensive programming requires consumers of the input to assume worst-case scenarios and check things again).
3.  Consequently, validation and inspection often occur (on any given input): 
    i. More than once 
    ii. Inconsistently (generally this is not deliberate, it's just hard to keep track).


## Proposal

I propose that we take a leaf out of the type-driven design crowd's book and treat the user-facing input validation as a *parsing* rather than *validating* problem. What does this mean? Rather than just checking input in user-facing API functions and dispatching to internal functions that *receive the same type* we should tighten the types as we go, ""parsing"" the unstructured user input into more structured data as we transit through the call stack.

This has, I think, a number of advantages:

1.  It clarifies *where* in the implementation validation in dispatch takes place (any time a type changes), separating the business logic of making sense of the input from the concrete implementation for the different paths.
2.  It makes cross-calling between internal APIs that *don't* do validation safe. For example, rather than `_gather` having the signature `a -> Column -> Maybe a` for some dataframe type `a` and always having to check that the provided column is inbounds as a gather map, we would tighten the type to `a -> InBoundsFor a Column -> a`. Now the gather map comes with a ""proof"" that it is inbounds for the dataframe we are gathering, and we therefore do not have to do bounds checking[^1]. Now, we can't statically enforce this (in the sense that in the implementation, someone will be able to conjure the ""proof"" out of thin air if they really want to), but type checking will at least indicate when we don't promise an in-bounds column.
3.  By separating the business logic from the backend dispatch we keep the good work we've done in producing a pandas-like API and make it *easier* to (on the long term) slot in other backends (for example a distributed, multi-node, backend underneath the cudf front-facing API).


[^1]: In a statically typed language with rank-N types you can actually make these proofs [part of the type system](https://kataskeue.com/gdp.pdf), though we can't here in Python.

## Further reading

- A nice overview of this idea with more examples: https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/
- Similar ideas as the ""typestate"" pattern: https://cliffle.com/blog/rust-typestate/
- ""Make illegal states unrepresentable"": https://buttondown.email/hillelwayne/archive/making-illegal-states-unrepresentable/",2023-06-09T17:26:44Z,0,0,Lawrence Mitchell,
255,"When the amount of data is not small,The parameter Num of the parallel process becomes larger, but the running time becomes longer","**Describe the bug**

**Steps/Code to reproduce bug**
```
import cudf
from multiprocessing import get_context
import time
pdf = cudf.DataFrame({
        'low':[i for i in range(1000)],
        'close':[i for i in range(1000)],
    })

def get_df(idx):
    return idx.rolling(5).mean()

if __name__ == ""__main__"":
    ctx = get_context(""spawn"")
    start = time.time()
    num =1
    with ctx.Pool(num) as pool:
        cudf.concat(pool.map(get_df, [pdf.a[i:] for i in range(100, 200)]))
    print(time.time()-start)

```

num =1 ,time 3.2659552097320557
num =2, time 7.382307291030884",2023-06-10T15:14:43Z,0,0,,
256,[ENH] Audit `argsort + gather/scatter` patterns for missing performance,"During review of #13419 we noted a few places where there is a pattern like:

```python
some_frame = ...
indices = some_frame.some_column.argsort()
new_frame = some_frame.take(indices)
```

As well as the unnecessary bounds-check (see #13456), this is a pattern that is captured by libcudf's [`sort_by_key`](https://docs.rapids.ai/api/libcudf/stable/group__column__sort.html#ga6db0403a43150b3bca0fbb9b2fbd68a3) and [`stable_sort_by_key`](https://docs.rapids.ai/api/libcudf/stable/group__column__sort.html#gaea04f441fe246b5a7e4f6420864024d4) functions (we would want to use the latter in pandas-compat mode).

At present, libcudf implements this as a `argsort` of the key columns followed by a gather. But that's an implementation detail (there may in the future be updates to that implementation). In the Python layer we should ""say what we mean"" and call into the appropriate libcudf API.

A cursory search shows:

```
/usr/bin/rg -U -e argsort.\*'     
'.\*take

core/_base_index.py
1305:        indices = self.argsort(ascending=ascending, na_position=na_position)
1306:        index_sorted = self.take(indices)

core/indexed_frame.py
2464:                # double-argsort to map back from sorted to unsorted positions
2465:                df = df.take(index.argsort(ascending=True).argsort())

core/column/column.py
1382:        order = order.take(left_gather_map, check_bounds=False).argsort()
1383:        codes = codes.take(order)

core/groupby/groupby.py
686:            gather_map = ordering.take(to_take).argsort()
687:            return result.take(gather_map)
```

Of these, the calls in `_base_index.py`, `_column.py`, and `groupby.py` can definitely be replaced by `sort_by_key`. Note also that none of these calls pass `check_bounds=False` to `take` so incur an unnecessary kernel launch to check in-boundsness for something that is guaranteed in bounds.

The `take(argsort().argsort())` pattern is not a `sort_by_key`, however, we can elide one of the argsorts by noticing that `take` is a gather operation and for a permutation, the dual to gather is scatter. So this should be implemented as `df.scatter(index.argsort())` instead...

These are just the cases where an argsort is _immediately_ followed by a take, probably more diligent searching would find more.
```[tasklist]
### Tasks
- [ ] `RollingGroupby.__init__`
- [ ] `Groupby._head_tail`
- [ ] `IndexedFrame.interpolate`
- [ ] `IndexedFrame.sort_index`
- [ ] `IndexedFrame._reindex`
- [ ] `IndexedFrame.sort_values`
- [ ] `IndexedFrame._n_largest_or_smallest`
- [ ] `BaseIndex.sort_values`
- [ ] `MultiIndex.__repr__`
```
",2023-06-13T10:57:12Z,0,0,Lawrence Mitchell,
257,[FEA] Support indicator=True in cudf.DataFrame.merge,"**Is your feature request related to a problem? Please describe.**
I wish dask_cudf dataframes would support the `indicator=True` option in the merge function

**Describe the solution you'd like**
In dask dataframe the code:
```python
import pandas as pd
import dask.dataframe as dd

dfa = pd.DataFrame({""id"":[1,2,2,4], ""a"":[""a"",""b"",""c"",""d""]})
dfb = pd.DataFrame({""id"":[2,3,3,4], ""b"":[""e"",""f"",""g"",""h""]})
ddfa = dd.from_pandas(dfa, npartitions=1)
ddfb = dd.from_pandas(dfb, npartitions=1)

ddf = ddfa.merge(ddfb, on=""id"", how=""outer"", indicator=True)
print(ddf.compute())
```
returns:
```
   id    a    b      _merge
0   1    a  NaN   left_only
1   2    b    e        both
2   2    c    e        both
3   4    d    h        both
4   3  NaN    f  right_only
5   3  NaN    g  right_only
```

but in dask_cudf:
```python
import cudf
import dask_cudf as dd

dfa = cudf.DataFrame({""id"":[1,2,2,4], ""a"":[""a"",""b"",""c"",""d""]})
dfb = cudf.DataFrame({""id"":[2,3,3,4], ""b"":[""e"",""f"",""g"",""h""]})
ddfa = dd.from_cudf(dfa, npartitions=1)
ddfb = dd.from_cudf(dfb, npartitions=1)

ddf = ddfa.merge(ddfb, on=""id"", how=""outer"", indicator=True)
print(ddf.compute())
```
this throws a `NotImplementedError`:
```
Traceback (most recent call last):                                                                                                                             
  File ""/raid/cjarrett/dask-sql/min.py"", line 13, in <module>     
    ddf = ddfa.merge(ddfb, on=""id"", how=""outer"", indicator=True)
  File ""/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/nvtx/nvtx.py"", line 101, in inner
    result = func(*args, **kwargs)
  File ""/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/dask_cudf/core.py"", line 121, in merge
    return super().merge(
  File ""/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/dask/dataframe/core.py"", line 5644, in merge
    return merge(
  File ""/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/dask/dataframe/multi.py"", line 724, in merge
    return hash_join(
  File ""/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/dask/dataframe/multi.py"", line 398, in hash_join
    meta = _lhs_meta.merge(_rhs_meta, **kwargs)
  File ""/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/nvtx/nvtx.py"", line 101, in inner
    result = func(*args, **kwargs)
  File ""/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/cudf/core/dataframe.py"", line 3969, in merge
    raise NotImplementedError(
NotImplementedError: Only indicator=False is currently supported
```


",2023-06-14T21:07:36Z,0,0,,
258,"Let `size_in_bits` take a `bytes` argument, rather than just being a templated function to multiply `sizeof(T)` by `CHAR_BIT`.","As noted by [@harrism in #13577](https://github.com/rapidsai/cudf/pull/13577#discussion_r1230283942_).
 
> I would agree with you @bdice  if `size_in_bits` took a size in bytes argument. But as it is, you have to write `data_buffer->size() * size_in_bits<std::byte>()`, which is kinda dumb.  `size_in_bits(data_buffer->size())` would be OK.  I think `* CHAR_BIT` is OK too.

This could be solved by removing the template argument from `size_in_bits` and just implementing it as a `constexpr` function that multiplies its argument by `CHAR_BIT`. All of the usages in `static_assert`s would still work (since the call would just change from `size_in_bits<T>()` to `size_in_bits(sizeof(T))`).",2023-06-19T08:50:37Z,1,0,Lawrence Mitchell,
259,[FEA] Add Parquet and ORC unit tests based on Apache sample files,"During the 23.06 release, we encountered several important Parquet and ORC writer issues that risked data corruption. These issues included:
* Rare failure with page size estimator (PQ writer, [Report](https://github.com/rapidsai/cudf/issues/13250), [Fix](https://github.com/rapidsai/cudf/pull/13364))
* Failure with >1GB tables (PQ writer, [Report](https://github.com/rapidsai/cudf/issues/13414), [Fix](https://github.com/rapidsai/cudf/pull/13438)) 
* Failure with 10k nulls followed by >5 valid values (ORC Writer, [Report](https://github.com/rapidsai/cudf/issues/13460), [Fix](https://github.com/rapidsai/cudf/pull/13466))

After discussion with the team we agreed on these additions to our testing suite to help prevent similar issues in the future:
* Based on test files in [parquet-testing/data](https://github.com/apache/parquet-testing/tree/b2e7cc755159196e3a068c8594f7acbaecfdaaac/data), verify that ""read"" versus ""read-write-read"" result in identical tables
* Based on test files in [orc/examples](https://github.com/apache/orc/tree/main/examples), verify that ""read"" versus ""read-write-read"" result in identical tables
* Based on test files in [parquet-testing/data](https://github.com/apache/parquet-testing/tree/b2e7cc755159196e3a068c8594f7acbaecfdaaac/data), verify that ""read"" versus ""read_with_Arrow-convert_to_cudf"" result in identical tables
* Based on test files in [orc/examples](https://github.com/apache/orc/tree/main/examples), verify that ""read"" versus ""read_with_Arrow-convert_to_cudf"" result in identical tables

Note: please also see (#12739), for reader benchmarks, verify that the roundtripped table matches the starting table
",2023-06-27T19:58:33Z,0,0,Gregory Kimball,
260,[ENH] benchmark gather then sort vs sort then gather in merge with `sort=True`,"**Is your feature request related to a problem? Please describe.**

When we request `sort=True` in a `cudf.merge`, the current implementation does:

1. deduce left and right join columns
2. join, producing left and right gather maps
3. gather left and right columns, and merge results
4. deduce key columns to sort by
5. argsort the key columns
6. gather the result using the argsort return value

Trivially, steps 5 and 6 can be merged into a `sort_by_key` (that's #13557). However, this order probably does more data movement than it needs to. This makes two calls to gather, and one sort-by-key, at the cost of moving the full dataframe through memory twice (once in step 3, once in step 6).

Instead, we could (if sorting) first gather only the key columns we will sort by, argsort those and then use that ordering to sort the left and right gather maps.

1. deduce left and right join columns
2. join, producing left and right gather maps
3. deduce left and right key columns to order by
4. gather left key columns with left map, right key columns with right map
5. sort-by-key the left and right gather maps with the columns from step 4
6. gather left and right columns with new gather maps and merge

This makes four calls to gather and one sort-by-key, but only moves the full dataframe through memory once (in step 6). For dataframes with many non-key columns this might well be an advantage. The latency will be a bit higher, but the total data movement will be less. For example, consider (for simplicity) a left join with one key column and 10 total columns in both left and right dataframes.

The current approach (once the left and right gather maps have been determined) gathers 20 columns in step 3, argsorts one column, then gathers 20 columns again (sort-by-key merges the sort + gather into argsort + gather at the libcudf level).

The proposed alternative would gather 1 column in step 4, sorts-by-key two columns (the two gather maps), then gathers 20 columns. So we move effectively 23 columns through memory rather than 41.",2023-06-28T11:56:18Z,0,0,Lawrence Mitchell,
261,[BUG] loc-based indexing fails when looking up array like with ordered categorical index,"**Describe the bug**

When a frame's index is a `CategoricalIndex` that is _ordered_, looking up an array-like list of indices fails with `TypeError: Merging on categorical variables with mismatched ordering is ambiguous`.

This occurs because to perform the merge between the index and the to-be-looked-up values (to find matches), the values are turned into a categorical column, but the default category dtype is un-ordered.

**Steps/Code to reproduce bug**
```python
import cudf
s = cudf.Series([1, 2, 3, 4, 5], index=cudf.CategoricalIndex([1, 2, 3, 4, 5], categories=[1, 2, 3, 4, 5], ordered=True))
s.loc[[1, 4]] # => KeyError
```

**Expected behavior**

```python
s.to_pandas().loc[[1, 4]]
# 1    1
# 4    4
# dtype: int64
```

I note actually that pandas doesn't care at all about ordered-ness of categoricals in lookup. Which kind of makes sense because you're just looking up values.

So probably the solution is to merge the decategorized index column with the asked-for labels.",2023-07-03T12:04:54Z,0,0,Lawrence Mitchell,
262,[BUG] Scalar loc-based lookup in integer categorical indices is incorrect,"**Describe the bug**

`loc`-based lookup does (I think incorrect) fallback to positional indexing rather than label-based lookup when the index is a categorical one with integer values.

**Steps/Code to reproduce bug**
```python
import cudf

s = cudf.Series([1, 2], index=cudf.CategoricalIndex([3, 4], categories=[3, 4]))
s.loc[3] # IndexError: single positional indexer is out-of-bounds
```

**Expected behavior**

```python
s.to_pandas().loc[3]
# 1
```

~Annoyingly, one can't just stop doing positional indexing fallback in all cases because if the index is (say) a string index then integer indexing _does_ fall back to positional.~ This is for `Series.__getitem__` and the behaviour is deprecated in pandas 2.",2023-07-03T12:11:57Z,0,0,Lawrence Mitchell,
263,[FEA] Support nested fields for `filter` in `cudf.read_parquet()`,"**Is your feature request related to a problem? Please describe.**

I wish I could use the `filter` argument of `cudf.read_parquet()` on nested columns. The in-progress GeoArrow specification is considering allowing a `struct<x: double, y: double>` coordinate representation which provides out-of-the-box column statistics for the inner `x` and `y`. Linestrings, polygons, and multipolygons involve layers of `list<>` nesting that still produce column statistics for the coordinates that would be nice to use with a bounding box filter (see example below).

**Describe the solution you'd like**

It would be nice if the left-hand side of a filter expression could be a tuple instead of a string to specify a nested field. I imagine the nested field of a list is more complicated here but even a nested struct field would be helpful.

**Describe alternatives you've considered**

The current workaround I've used is to flatten the fields before writing the parquet. This is OK but looses the extension type metadata (e.g., CRS) and doesn't scale to the nested types (e.g., linestring, polygon, multipolygon).

**Additional context**

A small illustration with some test data:

```python
>>> import pyarrow as pa
>>> import pyarrow.parquet as pq
>>> 
>>> 
>>> xs = pa.array([0.0, 1.0, 2.0, 3.0])
>>> ys = pa.array([1.0, 2.0, 3.0, 4.0])
>>> xys = pa.array([
...     {""x"": 0.0, ""y"": 1.0}, 
...     {""x"": 1.0, ""y"": 2.0}, 
...     {""x"": 2.0, ""y"": 3.0}, 
...     {""x"": 3.0, ""y"": 4.0}, 
... ])
>>> table = pa.table([xs, ys, xys], names=[""x"", ""y"", ""xy""])
>>> pq.write_table(table, ""test.parquet"")
>>> 
>>> # Works!
>>> bounds = [0.5, 1.5, 2.5, 3.5]
>>> cudf.read_parquet(
...     ""test.parquet"",
...     filters=[
...         [
...             ('x', '>=', bounds[0]),
...             ('y', '>=', bounds[1]),
...             ('x', '<=', bounds[2]),
...             ('y', '<=', bounds[3])
...         ]
...     ]
... )
     x    y                    xy
0  1.0  2.0  {'x': 1.0, 'y': 2.0}
1  2.0  3.0  {'x': 2.0, 'y': 3.0}
>>> 
>>> # Doesn't work:
>>> cudf.read_parquet(
...     ""test.parquet"",
...     filters=[
...         [
...             (('xy', 'x'), '>=', bounds[0]),
...             (('xy', 'y'), '>=', bounds[1]),
...             (('xy', 'x'), '<=', bounds[2]),
...             (('xy', 'y'), '<=', bounds[3])
...         ]
...     ]
... )
.conda/lib/python3.10/site-packages/cudf/io/parquet.py:674: UserWarning: Row-wise filtering failed in read_parquet for [[(('xy', 'x'), '>=', 0.5), (('xy', 'y'), '>=', 1.5), (('xy', 'x'), '<=', 2.5), (('xy', 'y'), '<=', 3.5)]]
  warnings.warn(
     x    y                    xy
0  0.0  1.0  {'x': 0.0, 'y': 1.0}
1  1.0  2.0  {'x': 1.0, 'y': 2.0}
2  2.0  3.0  {'x': 2.0, 'y': 3.0}
3  3.0  4.0  {'x': 3.0, 'y': 4.0}
```
",2023-07-11T01:39:09Z,0,0,Dewey Dunnington,@voltrondata
264,[FEA] Support left-semi and left-anti joins in `cudf::hash_join`,"**Is your feature request related to a problem? Please describe.**

`cudf::hash_join` makes it possible to build the hash table once and probe it multiple times. But it only supports inner join, left join and full join. I wish `cudf::hash_join` can support left-semi and left-anti join as well.
",2023-07-16T00:38:38Z,0,0,,
265,[FEA] Increase maximum characters in strings columns,"In libcudf, strings columns have child columns containing character data and offsets, and the offsets child column uses a 32-bit signed size type. This limits strings columns to containing ~2.1 billion characters. For LLM training, documents have up to 1M characters, and a median around 3K characters. Due to the size type limit, LLM training pipelines have to carefully batch the data down to a few thousand rows to stay comfortably within the size type limit. We have a general issue open to explore a 64-bit size type in libcudf (#13159). For size issues with LLM training pipelines, we should consider a targeted change to only address the size limit for strings columns.

### Requirements
* We must maintain or improve throughput for functions processing strings columns with <2.1 billion characters. This requirement prevents us from using 64-bit offsets for all strings columns. It does not prevent us from using 64-bit offsets for strings columns with >2.1 billion characters.
* We must not introduce a new data type or otherwise increase compile times significantly. This requirement prevents us from dispatching between ""strings"" types and ""large strings"" types. 

### Proposed solution
One idea that satisfies these requirements would be to represent the character data as an `int64` typed column instead of an `int8` typed column. This would allow us to store 8x more bytes of character data. To access the character bytes, we would use an offset-normalizing iterator (inspired by [""indexalator""](https://github.com/rapidsai/cudf/blob/branch-23.08/cpp/include/cudf/detail/indexalator.cuh)) to identify byte positions using an `int64` iterator output. Please note that the row count 32-bit size type would still apply to the proposed ""large strings"" columns.

We should also consider an ""unbounded"" character data allocation that is not typed, but rather a single buffer up to 2^64 bytes in size. The 64-bit offset type would be able to index into much larger allocations.

Please note that this solution will not impact the offsets for list columns. We believe that the best design to allow for more than 2.1B elements in lists will be to use 64-bit size type in libcudf as discussed in #13159.

### Creating strings columns
Strings columns factories would choose child column types at the time of column creation, based on the size of the character data. This change would impact strings column factories, as well as algorithms that use strings column utilities or generate their own offsets buffers. At column creation time, the constructor will choose between `int32` offsets with `int8` character data and `int64` offsets with `int64` character data, based on the size of the character data. Any function that calls [make_offsets_child_column](https://github.com/rapidsai/cudf/blob/9e099cef25b11821c6307bb9c231656a2bae700f/cpp/include/cudf/detail/sizes_to_offsets_iterator.cuh#L298-L302) will need to be aware of the alternate child column types for large strings.

### Accessing strings data
The offset-normalizing iterator would always return `int64` type so that strings column consumers would not need to support both `int32` and `int64` offset types. See [cudf::detail::sizes_to_offsets_iterator](https://github.com/rapidsai/cudf/pull/12180) for an example of how an iterator operating on `int32` data can output `int64` data.

### Interoperability with Arrow
The new strings column variant with `int64` offsets with `int64` character data may already be Arrow-compatible. This requires more testing and some changes to our Arrow interop utilities.

### Part 1: libcudf changes to support large strings columns

Definitions:
""strings column"": `int8` character data and `int32` offset data (2.1B characters) 
""large strings column"": `int8` character data up to 2^64 bytes and `int64` offset data (18400T characters)

| Step | PR | Notes | 
|---|---|---|
| Replace `offset_type` references with `size_type` | ✅ #13788 | offsets generated by the offset-normalizing iterator will have type `int64_t` | 
| <s> Add new data-size member to `cudf::column_view`, `cudf::mutable_column_view` and `cudf::column_device_view` </s> | ❌ #14031 | solution for character counts greater than `int32` | 
| Create an offset-normalizing iterator over character data that always outputs 64-bit offsets| ✅ #14206 <br> ✅ #14234 | First step in #14043 |
| * Add the character data buffer to the parent strings column, rather than as a child column <br> * Also refactor algorithms such as concat, contiguous split and gather which access character data <br> * Update code in cuDF-python that interact with character child columns <br> * Update code in cudf-java that interact with character child columns | ✅ #14202 | See performance blocker resolved in ✅ #14540 |
| Deprecate unneeded factories and use strings column factories consistently | ✅ | #14461, #14771, #14695, #14612, +one more | 
| Introduce an environment variable to control the threshold for converting to 64-bit indices, to enable testing on smaller strings columns | ✅ `LIBCUDF_LARGE_STRINGS_THRESHOLD` added | part of #14612 | 
| Transition strings APIs to use the offset-normalizing iterator (""offsetalator"") | ✅ | See #14611, #14700, #14744, #14745, #14757, #14783, #14824  | 
| Remove references to `strings_column_view::offsets_begin()` in libcudf since it hardcodes the return type as int32. | ✅ | See #15112 #15077  | 
| Remove references to `create_chars_child_column` in libcudf since it wraps a column around chars data. | ✅ | #15241 | 
| Change the current `make_strings_children` to return a uvector for chars instead of a column | ✅ | See #15171  | 
| Introduce an environment variable `LIBCUDF_LARGE_STRINGS_ENABLED` to let users force libcudf to throw rather than start using 64-bit offsets, to allow try-catch-repartitioning instead | ✅ |  #15195  | 
| Introduce an environment variable `LIBCUDF_LARGE_STRINGS_THRESHOLD` | ✅ |  #14612 | 
| Rework `concatenate` to produce large strings when `LIBCUDF_LARGE_STRINGS_ENABLED` and character count is above the `LIBCUDF_LARGE_STRINGS_THRESHOLD` | ✅ |  See #15195  |
| cuDF-python testing. use concat to create a large string column. We should be able to operate on this column, as long as we aren't creating a large string. Can we: (1) returns int/bool, like, contains, (2) slice (3) returns smaller strings. | 🔄 | |
| Add an `experimental` version of `make_strings_children` that generates 64-bit offsets when the total character length exceeds the threshold | ✅ |#15363 | 
| Add a large strings test fixture that stores large columns between unit tests and controls the environment variables | ✅ | #15513  | 
| Check appropriate cudf tests pass with `LIBCUDF_LARGE_STRINGS_THRESHOLD` at zero  | | |
| benchmark regressions analyzed and approved | | |
| Spark-RAPIDS tests pass | | |
| Remove `experimental` namespace. Replace `make_strings_children` with implementation with the `experimental` namespace version. | ✅ | #15702  | 
| Live session with cuDF-python expert to start producing and operating on large strings | | |
| Ensure that we can interop strings columns with 64-bit offsets to arrow as LARGE_STRING type | | Also see #15093 about `large_strings` compatibility for pandas-2.2 |

### Part 2: cuIO changes to read and write large strings columns

| Step | PR | Notes |
|---|---|---| 
| Add functionality to JSON reader to construct large string columns | | Could require building a chunked JSON reader |
| Add functionality to Parquet reader to construct large string columns | | | 
| to be continued... | | | ",2023-07-22T20:58:01Z,2,0,Gregory Kimball,
266,[BUG] `cudf.read_text` throws an exception when reading a host buffer,"**Describe the bug**
`cudf.read_text` throws an exception when reading a host buffer, unlike the CSV, Parquet, ORC and JSON readers. Hopefully it is straightforward to enable `cudf.read_text` to read from host buffers. 

**Steps/Code to reproduce bug**
Here is a small code snippet that shows the exception:
```
from io import BytesIO
import cudf

df = cudf.DataFrame({'a':['aaaa','bbbb']})

buf = BytesIO()
df.to_csv(buf, index=False)
df2 = cudf.read_csv(buf) # this is ok
print(df2)

buf = BytesIO()
df.to_csv(buf, index=False)
df2 = cudf.read_text(buf, delimiter='\n') # this crashes
print(df2)
```

**Expected behavior**
I expect that `read_text` would support host buffers correctly in the python layer. ""multibyte_split"" works fine with HOST_BUFFER data source in the libcudf benchmarks.

**Environment overview (please complete the following information)**
nightly docker image from 23.08, A100 DGX workstation
",2023-07-22T21:20:47Z,0,0,Gregory Kimball,
267,[FEA] Add `bytes_per_second` to all libcudf benchmarks,"Many libcudf benchmarks report the `bytes_per_second` processed as part of the output data. This value is useful for comparing benchmarks because it normalizes the increasing execution time from processing more data. Also, `bytes_per_second` and `real_time_s` together let us compute `bytes_processed` values which serve as a useful Y-axis.

As of the end of 23.12 development, many benchmarks still do not report `bytes_per_second` in the output data. Here is a figure summarizing the metrics reported by the benchmark suite.

![image](https://github.com/rapidsai/cudf/assets/12725111/aeb8176c-e869-4200-83aa-074aa4aaee5a)

| benchmark | status | notes | 
|---|---|---|
|`APPLY_BOOLEAN_MASK` | | see #13937 | 
| `BINARYOP` | | see #13938 |
| `COPY_IF_ELSE` | | see #13960 |
| `GROUPBY` | | see #13984 |
| `GROUPBY_NV` | | |
| `HASHING` | | see #13967, #13965|
| `JOIN` | | |
| `JOIN_NV` | | |
| `QUANTILES` | | |
| `REDUCTION` | | |
| `REPLACE` | | |
| `SEARCH` | | |
| `SEARCH_NV` | | |
| `SET_OPS_NV` | | |
| `SHIFT` | | see #13950 |
| `SORT` | | |
| `SORT_NV` | | |
| `STREAM_COMPACTION_NV` | | see #14172 |
| `TRANSPOSE` | | see #14170 |


Note: For this tracking list, cuIO benchmarks are omitted because ""encoded file size"" serves a similar purpose. ",2023-07-23T21:11:18Z,0,0,Gregory Kimball,
268,[BUG]The cudf to_csv interface cannot read files larger than 2GB and displays a negative size error.,"**Describe the bug**
The cudf to_csv interface cannot write files larger than 2GB and displays a negative size error.


**Steps/Code to reproduce bug**
import cudf

df = cudf.read_csv(""3G.csv"")
df.to_csv(""result.csv"")


**Expected behavior**
i hope df.to_csv() create a 3G size csv

**Environment overview (please complete the following information)**
 - Environment location: [Bare-metal, Docker, Cloud(specify cloud provider)]
 - Method of cuDF install: [conda, Docker, or from source]
   - If method of install is [Docker], provide `docker pull` & `docker run` commands used

**Environment details**
Please run and paste the output of the `cudf/print_env.sh` script here, to gather any other relevant environment details

**Additional context**
Add any other context about the problem here.
",2023-07-31T03:21:24Z,0,0,,
269,[BUG] The hasNull in ORC Statistics is incorrect,"**Describe the bug**
The ORC Statistics show hasNull is true but the column values are all non-nulls.

**Steps/Code to reproduce bug**
Refer to the reproduce in [13793](https://github.com/rapidsai/cudf/issues/13793), RAPIDS Accelerator bug is:[8826](https://github.com/NVIDIA/spark-rapids/issues/8826)

```
$ orc-tool meta TestAllNulls.orc
Processing data file TestAllNulls.orc [length: 267]
Structure for TestAllNulls.orc
File Version: 0.12 with ORIGINAL by ORC Java 
Rows: 3
Compression: SNAPPY
Compression size: 262144
Calendar: Julian/Gregorian
Type: struct<c1:string,c2:double>

Stripe Statistics:
  Stripe 1:
    Column 0: count: 3 hasNull: true
    Column 1: count: 3 hasNull: true min: 1 max: 3 sum: 3
    Column 2: count: 0 hasNull: true

File Statistics:
  Column 0: count: 3 hasNull: true
  Column 1: count: 3 hasNull: true min: 1 max: 3 sum: 3
  Column 2: count: 0 hasNull: true

Stripes:
  Stripe: offset: 3 data: 19 rows: 3 tail: 71 index: 50
    Stream: column 0 section ROW_INDEX start: 3 length 7
    Stream: column 1 section ROW_INDEX start: 10 length 26
    Stream: column 2 section ROW_INDEX start: 36 length 17
    Stream: column 1 section DATA start: 53 length 6
    Stream: column 1 section LENGTH start: 59 length 5
    Stream: column 2 section PRESENT start: 64 length 5
    Stream: column 2 section DATA start: 69 length 3
    Encoding column 0: DIRECT
    Encoding column 1: DIRECT_V2
    Encoding column 2: DIRECT

File length: 267 bytes
Padding length: 0 bytes
Padding ratio: 0%
```

This static is wrong:  
Column 1: count: 3 hasNull: true min: 1 max: 3 sum: 3
This column values are 1,2,3. The hasNull should be false.

**Expected behavior**
Stripe Statistics and File Statistics report correct hasNull info.

**Additional context**
I'm checking the `count` statistics for nested types, seems also has problem. I'll report another issue after one more check.",2023-08-04T02:42:34Z,0,0,Chong Gao,
270,[FEA] Reduce page faults when using managed memory,"**Is your feature request related to a problem? Please describe.**
In cuDF-python and RMM, it's easy to opt into [managed memory](https://docs.rapids.ai/api/rmm/stable/api/#rmm.reinitialize) (also known as Unified Memory, UM, and Unified Virtual Memory, UVM). However, libcudf is not optimized for use with managed memory and encounters many ""[just too late](https://www.nextplatform.com/2019/01/24/unified-memory-the-final-piece-of-the-gpu-programming-puzzle/)"" page faults when the ""[oversubscription factor](https://developer.nvidia.com/blog/improving-gpu-memory-oversubscription-performance/)"" is >1.

### Hinting options and strategies
* Use hinting with [cudaMemPrefetchAsync](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42) before operating on a column_view. I believe this hint will eagerly migrate the data to device. Open questions include: does it require an extra sync? do kernels page fault for a while until the data fully migrates? 
* Use hinting with [cudaMemAdviseSetAccessedBy](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c85750a22279bce0dc29956ad4f257084623). This hinting also does not eagerly migrate the data, and seems to be focused on preventing faults between devices on the same node. It also allows direct memory access (DMA) from the device to pinned host buffers.
* Use hinting with [cudaMemAdviseSetPreferredLocation](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857a4a2bc3c7d218dcd9a1b425b432759eb). This does not eagerly migrate the data, instead it influences the page migration system. If we set the preferred location to device, I believe this hint would prevent those allocations from being evicted and could lead to poor performance of the page migration engine.  
*  Use hinting with [cudaMemAdviseSetReadMostly](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0). For column_view data, processing in libcudf algorithms will be read-only by design. We can communicate this to UVM, but for libcudf's common access pattern - read once and then write a new allocation for the results - I don't think ""read mostly"" hinting will give us higher throughput or reduced faulting.
* Use host-pinned buffers and use direct memory access (DMA) from the device to extend working memory ([see.""zero-copy"" in this blog](https://developer.nvidia.com/blog/improving-gpu-memory-oversubscription-performance/)). To execute this strategy we hint ""preferred location"" to host and ""accessed by"" to device. Memory throughput will be lower using DMA to host than using device memory, but stalling kernels on page faults will be much slower than waiting on DMA. We still need to design how and when we would choose to leave data on the host and access by DMA (always??? except intermediate allocations).
* In addition to preventing page faults, we may also want to prevent evictions by preemptively clearing device memory. There does not appear to be a mechanism for eagerly migrating data from device to host. Perhaps preferred location hinting can also drive evictions on groups of pages instead of one page at a time.

### Implementation ideas for libcudf
* Where would this hinting be located in the repository? We could implement a RAII ""advisor"" class that takes a (non-owning) reference to a column_view and performs the appropriate hinting. The advisor class would only perform hinting for column_views created using managed memory resources. It may be difficult to add hinting to column_view because the column_view object can't tell if it's underlying data was a managed or unmanaged allocation.
* Is a way to identify from a device pointer if the associated allocation is managed or unmanaged? Perhaps [cuPointerGetAttribute()](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html) should return  CU_MEMORYTYPE_UNIFIED as [CU_POINTER_ATTRIBUTE_MEMORY_TYPE](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc2cce590e35080745e72633dfc6e0b600409e16293b60b383f30a9b417b2917c) for managed memory. Is there a runtime API for accessing device pointer attributes? (TBD)


### Useful reference for cudaMemAdvise
![image](https://github.com/rapidsai/cudf/assets/12725111/9ff97f3c-3e42-4664-b6b6-fcfdfc07dc90)

<br>
<br>
<br>

_Please note: Using managed memory in libcudf is in early stages of scoping. This issue will improve over time._

<br>
<br>

**Describe the solution you'd like**
I would like to add a libcudf benchmark for studying managed memory performance, and then some targeted experiments (with profiling) to observe the impact of different hinting strategies. When we have identified a promising design, we will open a more targeted issue.

**Describe alternatives you've considered**
Continue to let Dask and Spark-RAPIDS catch and retry when there are device OOM errors.

**Additional context**
Please note that with managed memory pools, the pool allocation is lazy. This is different from unmanaged memory pools where we allocate the full pool upfront, trading slightly longer startup time for much faster algorithm allocations.

Useful blog posts:
https://developer.nvidia.com/blog/unified-memory-cuda-beginners/
https://developer.nvidia.com/blog/improving-gpu-memory-oversubscription-performance/
https://developer.nvidia.com/blog/maximizing-unified-memory-performance-in-cuda/
https://developer.nvidia.com/blog/beyond-gpu-memory-limits-unified-memory-pascal/
",2023-08-04T18:50:40Z,1,0,Gregory Kimball,
271,[FEA] Increase reader throughput by pipelining IO and compute,"-- this is a draft, please do not comment yet -- 

The end-to-end throughput of a file reader is limited by the sequential read speed of the underlying data source. We can use ""pipelining"" to overlap processing data on the device with reading data from the data source. Pipelining works by processing the data in batches, so that the previous chunk can be processed as the next chunk is reading. Pipelined readers show higher end-to-end throughput if the overlap between reading and processing is greater than the overhead from processing smaller batches. 

In cuIO, `multibyte_split` used a pipelined design that reads text data in ~33 MB chunks (2^25 bytes) into a pinned host buffer, copies the data to device, and then generates offsets data. Here's a profile reading ""Common Crawl"" document data with `cudf.read_text` from a 410 MB file:
![image](https://github.com/rapidsai/cudf/assets/12725111/0c2c8b2d-f23b-4688-8ef7-fe3286da4a72)

Note how the `get_next_chunk` function includes the OS `read` and `Memcopy HtoD`, and how the `Memcpy HtoD` overlaps with the next OS `read`. Stream-ordered kernel launches also overlap with the next OS `read`. For each 10 ms OS `read`, there is 1.5 ms of overlapping copy/compute work and 0.2 ms of overhead between each OS `read`. 

We can applying pipelining to the Parquet reader as well. Parquet reading includes several major steps: raw IO, header decoding, decompression, and data decoding. The runtime of each step varies based on the properties of the data in the file, including the data types, encoding efficiency, and compression efficiency. Furthermore Parquet files have [internal row group and page structure](https://github.com/apache/parquet-format#file-format) that restricts how the file can be split. Here is an example profile reading the same ""Common Crawl"" data as above, but from a 240 MB Snappy-compressed Parquet file:
![image](https://github.com/rapidsai/cudf/assets/12725111/a1f6700a-ab9f-42bd-bd70-eb285a042770)

Note how 90 ms is spent in OS read on the file and ~20 ms is spent processing, with decompression taking most (11.5 ms) of the processing time. Also note the GPU utilization data during the `read_parquet` function, with zero GPU utilization during the copy followed by good good SM utilization and moderate warp utilization during the compute.

We've completed prototyping work in #12358, experimenting with several approaches for pipelining the Parquet reader. Here are some performance analysis ideas for the next time we tackle this feature:
* Curate a library of real world (not generated) data files and use that to evaluate the performance of pipelining approach
* Analyze the copying, decompression, decoding times in the curated library and track which files show the biggest benefit from pipelining
* Consider setting a floor (such as 200 MB of compressed data) before pipelining kicks in, to make sure we aren't accruing too much overhead
* Evaluate network-attached storage in addition to local NVMe data sources

As far as pipelining approaches, here are some areas to consider:
| Stream usage | Chunking pattern | Notes | 
|---|---|---|
| entire read per stream | row group | tbd |
| decompression stream and decoding stream | row group | tbd |

-- this is a draft, please do not comment yet -- ",2023-08-07T19:43:53Z,0,0,Gregory Kimball,
272,[BUG] ORC file count statistic for nested type is wrong,"**Describe the bug**
The GPU ORC file statistics show that the count for nested type is wrong while the CPU ORC file is correct.

GPU file shows different counts for nested type:
GPU:  
```
File Statistics:
  Column 0: count: 8 hasNull: true
  Column 1: count: 1 hasNull: true
```
CPU: 
```
File Statistics:
  Column 0: count: 8 hasNull: false
  Column 1: count: 8 hasNull: false
```
The data in both files are:
```
+------------+
|    struct_s|
+------------+
|{null, null}|
|      {1, 1}|
|{null, null}|
|      {3, 3}|
|{null, null}|
|      {5, 5}|
|{null, null}|
|      {7, 7}|
+------------+
```



**Steps/Code to reproduce bug**
##### Generate GPU file
```cpp
TEST_F(OrcWriterTest, NestedColumnSelection)
{
  auto const num_rows  = 8;
  std::vector<int> child_col1_data(num_rows);
  std::vector<int> child_col2_data(num_rows);
  for (int i = 0; i < num_rows; ++i) {
    child_col1_data[i] = i;
    child_col2_data[i] = i;
  }

  auto validity = cudf::detail::make_counting_transform_iterator(0, [](auto i) { return i % 2; });
  int32_col child_col1{child_col1_data.begin(), child_col1_data.end(), validity};
  int32_col child_col2{child_col2_data.begin(), child_col2_data.end(), validity};
  struct_col s_col{child_col1, child_col2};
  cudf::table_view expected({s_col});

  cudf::io::table_input_metadata expected_metadata(expected);
  expected_metadata.column_metadata[0].set_name(""struct_s"");
  expected_metadata.column_metadata[0].child(0).set_name(""field_a"");
  expected_metadata.column_metadata[0].child(1).set_name(""field_b"");

  auto filepath = ""/tmp/test-count-for-nested-type-gpu.orc"";
  cudf::io::orc_writer_options out_opts =
    cudf::io::orc_writer_options::builder(cudf::io::sink_info{filepath}, expected)
      .metadata(std::move(expected_metadata));
  cudf::io::write_orc(out_opts);
}
```

Read the GPU file
SPARK_HOME/bin/pyspark

spark.read.orc(""/tmp/test-count-for-nested-type-gpu.orc"").show()
+------------+
|    struct_s|
+------------+
|{null, null}|
|      {1, 1}|
|{null, null}|
|      {3, 3}|
|{null, null}|
|      {5, 5}|
|{null, null}|
|      {7, 7}|
+------------+

##### Generate CPU file
SPARK_HOME/bin/pyspark

```python
from pyspark.sql.types import *
schema = StructType([StructField(""struct_s"",
    StructType([
        StructField(""field_a"", IntegerType()),
        StructField(""field_b"", IntegerType()),
]))])

def get_value(i):
  if i % 2 == 0:
    return None
  else:
    return i

data = [
    ({ 'field_a': get_value(i), 'field_b': get_value(i) }, ) for i in range(0, 8)
]
df = spark.createDataFrame(
        SparkContext.getOrCreate().parallelize(data, numSlices=1),
        schema)

path = '/tmp/test-count-for-nested-type-cpu.orc'
df.coalesce(1).write.mode(""overwrite"").orc(path)
spark.read.orc(path).show()
```

```
+------------+
|    struct_s|
+------------+
|{null, null}|
|      {1, 1}|
|{null, null}|
|      {3, 3}|
|{null, null}|
|      {5, 5}|
|{null, null}|
|      {7, 7}|
+------------+
```

##### print count statistic for GPU file
```
$ orc-tool meta test-count-for-nested-type-gpu.orc
Processing data file test-count-for-nested-type-gpu.orc [length: 360]
Structure for test-count-for-nested-type-gpu.orc
File Version: 0.12 with ORIGINAL by ORC Java 
Rows: 8
Compression: SNAPPY
Compression size: 262144
Calendar: Julian/Gregorian
Type: struct<struct_s:struct<field_a:int,field_b:int>>

Stripe Statistics:
  Stripe 1:
    Column 0: count: 8 hasNull: true
    Column 1: count: 1 hasNull: true
    Column 2: count: 4 hasNull: true min: 1 max: 7 sum: 16
    Column 3: count: 4 hasNull: true min: 1 max: 7 sum: 16

File Statistics:
  Column 0: count: 8 hasNull: true
  Column 1: count: 1 hasNull: true
  Column 2: count: 4 hasNull: true min: 1 max: 7 sum: 16
  Column 3: count: 4 hasNull: true min: 1 max: 7 sum: 16

Stripes:
  Stripe: offset: 3 data: 24 rows: 8 tail: 92 index: 70
    Stream: column 0 section ROW_INDEX start: 3 length 7
    Stream: column 1 section ROW_INDEX start: 10 length 11
    Stream: column 2 section ROW_INDEX start: 21 length 26
    Stream: column 3 section ROW_INDEX start: 47 length 26
    Stream: column 2 section PRESENT start: 73 length 5
    Stream: column 2 section DATA start: 78 length 7
    Stream: column 3 section PRESENT start: 85 length 5
    Stream: column 3 section DATA start: 90 length 7
    Encoding column 0: DIRECT
    Encoding column 1: DIRECT
    Encoding column 2: DIRECT_V2
    Encoding column 3: DIRECT_V2

File length: 360 bytes
Padding length: 0 bytes
Padding ratio: 0%
```

##### print count statistic for CPU file
```
$ orc-tool meta /tmp/test-count-for-nested-type-cpu.orc 
Processing data file file:/tmp/test-count-for-nested-type-cpu.orc/part-00000-6b490836-0c65-4355-9d0e-fbaff96aec33-c000.snappy.orc [length: 388]
Structure for file:/tmp/test-count-for-nested-type-cpu.orc/part-00000-6b490836-0c65-4355-9d0e-fbaff96aec33-c000.snappy.orc
File Version: 0.12 with ORC_14 by ORC Java 1.7.4
Rows: 8
Compression: SNAPPY
Compression size: 262144
Calendar: Julian/Gregorian
Type: struct<struct_s:struct<field_a:int,field_b:int>>

Stripe Statistics:
  Stripe 1:
    Column 0: count: 8 hasNull: false
    Column 1: count: 8 hasNull: false
    Column 2: count: 4 hasNull: true bytesOnDisk: 12 min: 1 max: 7 sum: 16
    Column 3: count: 4 hasNull: true bytesOnDisk: 12 min: 1 max: 7 sum: 16

File Statistics:
  Column 0: count: 8 hasNull: false
  Column 1: count: 8 hasNull: false
  Column 2: count: 4 hasNull: true bytesOnDisk: 12 min: 1 max: 7 sum: 16
  Column 3: count: 4 hasNull: true bytesOnDisk: 12 min: 1 max: 7 sum: 16

Stripes:
  Stripe: offset: 3 data: 24 rows: 8 tail: 71 index: 76
    Stream: column 0 section ROW_INDEX start: 3 length 11
    Stream: column 1 section ROW_INDEX start: 14 length 11
    Stream: column 2 section ROW_INDEX start: 25 length 27
    Stream: column 3 section ROW_INDEX start: 52 length 27
    Stream: column 2 section PRESENT start: 79 length 5
    Stream: column 2 section DATA start: 84 length 7
    Stream: column 3 section PRESENT start: 91 length 5
    Stream: column 3 section DATA start: 96 length 7
    Encoding column 0: DIRECT
    Encoding column 1: DIRECT
    Encoding column 2: DIRECT_V2
    Encoding column 3: DIRECT_V2

File length: 388 bytes
Padding length: 0 bytes
Padding ratio: 0%

User Metadata:
  org.apache.spark.version=3.3.0
```



**Expected behavior**
The all statistics should be correct, including the `hasNull`, refer to this [issue](https://github.com/rapidsai/cudf/issues/13817)

**Environment details**
Environment details
cuDF 23.08 branch
Spark 3.3.0
orc-core-1.7.4.jar

**Additional context**
",2023-08-09T05:57:28Z,0,0,Chong Gao,
273,[FEA] Improve ORC reader filtering and performance,"### Background

libcudf includes readers and writers for two popular binary formats for columnar data: [Apache Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) and [Apache ORC](https://en.wikipedia.org/wiki/Apache_ORC). These formats were originally introduced in 2013, and both have open source specifications ([ORC](https://orc.apache.org/specification/ORCv1/), [PQ](https://github.com/apache/parquet-format)) and reference implementations ([ORC](https://github.com/apache/orc), [PQ](https://github.com/apache/parquet-mr)) maintained by Apache. ORC also serves as the foundation for [Meta’s variant DWRF and their new format ""Alpha""](https://www.cidrdb.org/cidr2023/papers/p77-chattopadhyay.pdf).

Both formats have hierarchical data layouts, support encoding and compression, include fully-featured type systems, and find widespread use in database systems and data warehousing. Please refer to [this paper](https://arxiv.org/pdf/2304.05028.pdf) by Zeng et al for a detailed comparison of the concepts, features and performance of Parquet and ORC binary formats. Please note that Parquet files are composed of “row groups” (~128 MB) and “pages” (~1 MB), and ORC files are composed of “stripes” (~70 MB) and “row groups” (10K rows). 

Some of the differences include:
* finer granularity in data buffers by default in ORC (better for filtered IO and targeted lookups)
* finer granularity in bloom filters in ORC (supported at ""row group"" level in ORC, but not at the ""page"" level in Parquet)
* Dremel-encoding for list types in Parquet (faster decoding for >8 levels of nesting)
* support for [ACID transaction tables](https://orc.apache.org/docs/acid.html) in ORC datasets (enabling data updates without full re-write)
* In Parquet the data ""page"" is also the unit of encoding and compression, whereas in ORC each encoding ""stream"" and ""compression chunk"" often includes multiple ""row groups"".

### Expanding functionality of the ORC reader

The libcudf Parquet reader has gained functionality in key areas, including the chunked reader (release 22.12) to control how much of a table is materialized, and AST-based filtering (release 23.08) to avoid reading row groups that aren’t needed. Filtered IO (including bloom filters) is even more important to ORC users thanks to the fine granularity of ORC row groups (10k rows per row group). We should align our Parquet and ORC reader designs and separate shared utilities from format-specific details wherever possible.

| Topic | Status | Notes
|---|---|---|
| Add AST-based stripe filtering to the ORC reader | | #13348 added AST-based row group filtering to the Parquet reader. For this topic, we should accept an AST filter parameter, use it to determine matches stripes, read only those strips, and then post-filter the rows in the resulting table. We already have a `read_raw_orc_statistics` function to support these steps. We may refactor some of the AST + min/max stats tools to `utilities`. Also see issue #12512 | 
| Add chunked reader for ORC | | See #12228 about this topic from Spark-RAPIDS. Chunked readers are useful because they allow for partial materialization of tables from their binary representation. #11867 added chunking for Parquet decoding, which means the compressed row groups were fully read and decompressed and then decoded up to a requested size in bytes. (tbd) is extending chunking to include Parquet decompression as well. Chunking helps libcudf applications avoid two limits: the [size_type](https://github.com/rapidsai/cudf/issues/13159)  limit on row count and the GPU working memory limit for each worker |  
| Support [bloom filters](https://en.wikipedia.org/wiki/Bloom_filter) in ORC reader | | See #4410. Due to ORC’s common usage for data lookup and filtered IO, supporting bloom filters in reads is especially important for ORC. This feature would allow the caller to specify equality conditions and check against ORC bloom filters.  | 
| Support index roundtripping in ORC | | See #8708, a request from cuDF-python to preserve the index when writing+reading a file | 

### Performance optimizations for binary format reading

| Topic | Status | Notes
|---|---|---|
| Optimize ORC reader performance for list data | ✅ #13708 | We observed poor performance with singlely-nested lists and high row counts |
| Optimize ORC reader performance for decimal data | | See #13251, we need a parallel algorithm to replace the single-thread decoding of the variable-width encoded representation |
| Evaluate multi-kernel decoding in ORC | | See #13622 for experiments with multiple decode kernels, and #13302 for an example of a specialized strings decode kernel | 
| Experiment with pipelining ORC reads | | See #13828 for information about reader pipelining |",2023-08-15T04:13:18Z,0,0,Gregory Kimball,
274,[FEA] Modernize CSV reader and expand reader options,"### Background

The CSV reader in cuDF/libcudf is a common IO interface for ingesting raw data, and is frequently the first IO interface that new users test when getting started with RAPIDS. There have been many improvements to the CSV reader over the years, but much of the implementation has remained the same from its introduction in #3213 and rework in #5024. We see several opportunities to address the [CSV reader continuous improvement](https://github.com/rapidsai/cudf/milestone/12) milestone, and this story associates open issues with particular functions and kernels in the CSV reading process.

### Step 1: Decompression and preprocessing
The CSV reader begins with host-side processing in `select_data_and_row_offsets`. With the exception of decompression, we would like to migrate this processing to be done device side and refactor this function to use a kvikIO data source. Note, this refactor could also include adding support for the `header` parameter and `byte_range` at the same time ([code pointer](https://github.com/rapidsai/cudf/blob/b798a70d608cbbe2c7f372a8c21354455ba56f74/cpp/src/io/csv/reader_impl.cu#L442)).

The initial processing interacts with several issues:
* #13797 is small story issue about this topic
* #4999 batch the full read as small chunks
* #5142 
* #11728 describes how the initial byte range parsing to find the first row assumes the byte_range starts in an unquoted state. If a user provides a byte_range that starts in a quoted field, then the reader will fail! The solution described in this issue interacts the next step ""identify row offsets"". 
* #12255 needs investigation
* #12582 return empty `metadata.schema_info` when column names are autogenerated

### Step 2: Identify row offsets (delimiters)
The next step is identifying record delimiters and computing row offsets in `load_data_and_gather_row_offsets` (invoked by `select_data_and_row_offsets`). This algorithm operates in three main steps: `gather_row_offsets` called with empty data, `select_row_context`, and `gather_row_offsets` called with row context data. The row context state machine is difficult to refactor because it uses a custom data representation that stores several logical values within a single 32-bit or 64-bit physical type ([code pointer](https://github.com/rapidsai/cudf/blob/b798a70d608cbbe2c7f372a8c21354455ba56f74/cpp/src/io/csv/csv_gpu.hpp#L64)). The row context tracks whether the content is in a comment block or in a quoted block. 
* `gather_row_offsets` runs a [4-state](https://github.com/rapidsai/cudf/blob/b798a70d608cbbe2c7f372a8c21354455ba56f74/cpp/src/io/csv/csv_gpu.hpp#L40) ""row context"" state machine over 16 KB blocks of characters and returns the number of un-quoted, un-commented record delimiters from the block given each possible initial state
* `select_row_context` is invoked in a host-side loop over `row_ctr` data for each 16 KB block, starting from a `state 0` initial context. 
* `gather_row_offsets` is called in a second pass with a valid `all_row_offsets` data parameter.

Major design topics:
* We should consider a larger refactor of the ""identify row offsets"" code based on using a new FST instance ([code pointer](https://github.com/rapidsai/cudf/tree/branch-23.10/cpp/src/io/fst)). Using an FST instance would easily allow us to add additional states beyond the existing 4-state machine. Please refer to the [ParPaRaw paper](https://arxiv.org/pdf/1905.13415.pdf) from Elias Stehle et al for more information about parallel algorithms for CSV parsing.
* To unblock Spark-RAPIDS usage of the CSV, we may also choose to support user-provided `all_row_offsets` parameter to the read function or as a reader option. This would allow Spark to bypass the first `gather_row_offsets` pass and `select_row_context` in `load_data_and_gather_row_offsets`. When calling `read_csv` on a strings column, Spark already has the row offsets. 
* Also note that refactoring the interface to provide row offsets is relevant to #11728, where we would want to provide pre-computed offsets. For this issue we might prefer a new detail API rather than new parameters in the public API - more design work is needed.

The row offsets algorithm interacts with several open issues:
* #6572 complex preprocessing or changes to the row context state machine. 
* (Spark blocker) #11984 Pandas and Spark don't have the same escaping conventions, and the row offset state machine doesn't have an escaped state. Needs confirmation - does this impact the row offsets step?
* (Spark blocker) #11948 to handle misplaced quotes. The issue shows a file getting truncated so fields with misplaced quotes seem to compromise the row offset data. #2398 suggests a workaround
* #6305 another quoting/escaping issue 
* #13856 commented lines should not emit row offsets
* Issue n/a: Add unit tests for `gather_row_offsets` kernel

### Step 3: Determine column types
The next step is determining the data types for each column that does not map to a user-provided data type. The function `determine_column_types` completes this work by collecting the user-provided data types, and then calling `infer_column_types` to handle the unspecified data types. `infer_column_types` invokes the `detect_column_types`->`data_type_detection` kernel to collect statistics about the data in each field, and then use the conventions of the pandas CSV reader to select a column type. 
* We should consider refactoring the ""determine"", ""infer"", and ""detect"" function names to improve clarity
* (good first issue) #14066 update thread indexing
* #5080 performance improvements for type inference
* (Spark blocker) #11984 `seek_field_end` supports escape characters within data fields. perhaps field traversal is already Spark-compatible
* (Spark blocker) #11948 misplaced quotes could fail with `seek_field_end`
* #6313 pandas doesn't infer as `float` if there are any nulls
* #9987 would change `seek_field_end`, maybe not much else
* Issue n/a: Add unit tests for `seek_field_end` kernel

### Step 4: Decode data and populate device buffers
The final step, `decode_data`, does another pass over the data to decode values according to the determined columns types. The kernel is `decode_row_column_data`->`convert_csv_to_cudf`
* (Spark blocker) #13892 trim white space . Probably a modest change to `trim_whitespaces_quotes`. Related to #6659
* (Spark blocker) #12145 add option to decode `""""` as empty strings or `null`. Probably an additional parsing option.
* (Spark blocker) #11984 `convert_csv_to_cudf` also uses `seek_field_end` which nominally supports escape characters
* (Spark blocker) #11948 misplaced quotes could fail with `seek_field_end`
* #4001 support additional `nanValue` options
* #10599 float parsing consistency, this is probably a `wontfix`



",2023-08-18T19:27:48Z,0,0,Gregory Kimball,
275,[QST] Dask-cudf/Xgboost out of memory error,"I'm trying to train an xgboost model on a machine with 8xA100 GPUs with 80GB memory each but I'm getting an out of memory error:
`MemoryError('std::bad_alloc: out_of_memory: CUDA error at: .../include/rmm/mr/device/cuda_memory_resource.hpp')`. The error is slightly different if I use `rmm_pool_size` parameter but it is still a memory error `""MemoryError('std::bad_alloc: out_of_memory: RMM failure at:../include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')`

I'm using a `LocalCUDACluster` to distribute the workload amongst the 8 GPUs. I can tell by looking at the dask dashboard, that the data is mostly loading into a single GPU and all of the other GPUs are sitting empty and idle. 

I read the data using `dask_cudf.read_parquet(file_name, blocksize=int(2e4))` and it is a dataframe of size `(20459297, 213)`. Though I would like to try it with much larger datasets.  The training completes successfully with a smaller dataframe of size `(16304159, 213)` and fewer workers but it still mostly uses a single GPU. 

Edit: Here's a screenshot of the dashboard when the model is successfully training - note this is with only 2 GPUs and the smaller dataframe noted above

<img width=""1672"" alt=""Screenshot"" src=""https://github.com/rapidsai/cudf/assets/18453604/98706b71-19e3-4266-9c9c-23472994675c"">

The GPUs are running CUDA 12.0 and driver  525.60.13
Here are the versions of some relevant packages

```
xgboost                   1.7.4           rapidsai_py310h1395376_6    rapidsai
rapids                    23.08.00        cuda12_py310_230809_g2a5b6f0_0    rapidsai
python                    3.10.12         hd12c33a_0_cpython    conda-forge
rapids-xgboost            23.08.00        cuda12_py310_230809_g2a5b6f0_0    rapidsai
cuda-version              12.0                 hffde075_2    conda-forge
cudf                      23.08.00        cuda12_py310_230809_g8150d38e08_0    rapidsai
dask                      2023.7.1           pyhd8ed1ab_0    conda-forge
dask-core                 2023.7.1           pyhd8ed1ab_0    conda-forge
dask-cuda                 23.08.00        py310_230809_gefbd6ca_0    rapidsai
dask-cudf                 23.08.00        cuda12_py310_230809_g8150d38e08_0    rapidsai
```

Any help on the memory issue would be much appreciated

",2023-08-31T08:34:47Z,0,0,,
276,[FEA] provide external libraries a way of getting a `DeviceBuffer` pointer that can become spillable again,"**Is your feature request related to a problem? Please describe.**

When running in a multi-gpu setting, message passing with ucx-py takes a `DeviceBuffer` and obtains the device memory pointer through the `__cuda_array_interface__`. This, correctly, marks the buffer as unspillable. 

It would be nice if there were a way to expose a pointer that is marked as unspillable until the external library drops the reference (kind of like `acquire_spill_lock`). `ucx-py` could then use it, and scope the pointer use to the lifetime of the message request (once the request is completed, the pointer can be dropped and is available for spilling again).

**Describe the solution you'd like**

If we were to hand back an object that had a `weakref.finalize(obj, unmark_spillable)` callback, when it was dropped, we could let the buffer be spillable again.

**Describe alternatives you've considered**

Making ucx-py aware of cudf and using `acquire_spill_lock`.

cc @madsbk / @vyasr / @galipremsagar ",2023-09-01T16:35:34Z,0,0,Lawrence Mitchell,
277,[FEA] Parallelize gpuInitStringDescriptors when Parquet input type is FIXED_LEN_BYTE_ARRAY,"As part of the preprocessing of PLAIN encoded string data in the parquet reader, a pass through the page data is performed to either gather string sizes, or initialize `{ptr, length}` tuples for use by the decoder. For variable width string data, this pass must be performed by a single thread. But in the case of fixed width data, all threads in the warp should be able to participate.

https://github.com/rapidsai/cudf/blob/1bfeee7575e137bc75741cb2caf015e55ecab2cd/cpp/src/io/parquet/page_decode.cuh#L409
",2023-09-14T22:18:22Z,0,0,Ed Seidl,@LLNL
278,[BUG] Sanitizer reports misaligned error when doing reduction on short type values in cuda12 ENV,"**Describe the bug**
Sanitizer reports misaligned error when doing reduction on short type values in cuda12 ENV


**Steps/Code to reproduce bug**
Code:
```cpp
#include <cudf/types.hpp>
#include <cudf/aggregation.hpp>
#include <cudf/reduction.hpp>
#include <cudf_test/base_fixture.hpp>
#include <cudf_test/column_wrapper.hpp>

template <typename T, typename SourceElementT = T>
using column_wrapper =
  typename std::conditional<std::is_same_v<T, cudf::string_view>,
                            cudf::test::strings_column_wrapper,
                            cudf::test::fixed_width_column_wrapper<T, SourceElementT>>::type;
using int16_col   = column_wrapper<int16_t>;

struct MyReductionTest : public cudf::test::BaseFixture {};
TEST_F(MyReductionTest, AlignmentIssue)
{
  std::vector<int16_t> v({1, 2, 3});
  int16_col col(v.begin(), v.end());
  
  auto const output_dtype                 = cudf::data_type{cudf::type_id::INT16};
  auto min_agg = cudf::make_min_aggregation();
  std::unique_ptr<cudf::scalar> reduction1 = cudf::reduce(col, *dynamic_cast<cudf::reduce_aggregation *>(&(*min_agg)), output_dtype);

  auto const output_dtype2                 = cudf::data_type{cudf::type_id::BOOL8};
  auto any_agg = cudf::make_any_aggregation();
  std::unique_ptr<cudf::scalar> reduction2 = cudf::reduce(col, *dynamic_cast<cudf::reduce_aggregation *>(&(*any_agg)), output_dtype2);
}

```

Compile and Run with sanitizer:
```
compute-sanitizer --tool memcheck \
    --launch-timeout 600 \
    --error-exitcode -2 \
    --log-file ""./sanitizer_for_pid_%p.log"" \
    ./my-exe
```

Print sanitizer log:
```
head sanitizer_for_pid_42.log 
========= COMPUTE-SANITIZER
========= Invalid __shared__ read of size 16 bytes
=========     at 0x38c0 in void cub::CUB_101702_600_700_750_800_860_900_NS::DeviceReduceSingleTileKernel<cub::CUB_101702_600_700_750_800_860_900_NS::DeviceReducePolicy<short, short, int, cudf::DeviceMin>::Policy600, thrust::transform_iterator<thrust::identity<short>, thrust::transform_iterator<cudf::detail::value_accessor<short>, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, thrust::use_default, thrust::use_default>, thrust::use_default, thrust::use_default>, short *, int, cudf::DeviceMin, short>(T2, T3, T4, T5, T6)
=========     by thread (0,0,0) in block (0,0,0)
=========     Address 0x8 is misaligned
=========     Saved host backtrace up to driver entry point at kernel launch time
=========     Host Frame: [0x2d18f2]
=========                in /usr/lib64/libcuda.so.1
=========     Host Frame:__cudart1049 [0xd9bd3b]
=========                in /home/chongg/code/spark-rapids-jni/target/cmake-build/gtests/./my-exe
```

The main errors are:
```
Invalid __shared__ read of size 16 bytes
Address 0x8 is misaligned
```

Others:
```
There are 2 reductions in the code.
If another reduction follows a min reduction, then errors occur.
```

**Expected behavior**
Fix Sanitizer error.

**Environment overview (please complete the following information)**
 - Environment location: Docker
 - Method of cuDF install: from source

**Environment details**
Docker image:  urm.nvidia.com/sw-spark-docker/plugin-jni:centos7-cuda12.0.1-blossom
CUDA 12, for more details, refer to https://github.com/NVIDIA/spark-rapids-jni/issues/1349

**Additional context**
Refer to https://github.com/NVIDIA/spark-rapids-jni/issues/1349",2023-09-26T09:42:13Z,0,0,Chong Gao,
279,[BUG] Potential for use-after-free on libcudf/cudf interface boundaries,"**Describe the bug**

This comes out of [a review of #14133](https://github.com/rapidsai/cudf/pull/14133#discussion_r1338480398) which introduces a new `Scalar` type on the python side in pylibcudf, but I think that the issues are pervasive.

## Background

`libcudf` uses RMM for all memory allocations, this happens through a `memory_resource` object. Allocating `libcudf` functions all take an explicit `memory_resource` argument (as a raw pointer) that is defaulted to `rmm::get_current_device_resource()` (the resource set by `rmm::set_per_device_resource`). RMM `device_buffer`s hold a raw pointer of their allocating memory resource (needed for deallocation), and it is the user's (in this case `libcudf`'s) responsibility to keep that `memory_resource` alive until the `device_buffer` has been dropped:

This is fine:
```c++
memory_resource mr = ...;
{
    device_buffer buf{..., &mr};
    ... // do things with buf
   ~buf(); // called here, fine.
}
```

This is not (this is not a real example, since I think the `device_buffer` constructors don't allow exactly this, but bear with me):
```c++
device_buffer buf;
{
   memory_resource mr = ...;
   buf = {..., &mr};
   ... // do things with buf
   ~mr(); // called here, boom;
}
buf no longer valid
```

### How does `get_current_device_resource` work?

`set_per_device_resource` stores a raw pointer to a memory resource in a `std::unordered_map` and `get_current_device_resource` just looks up in the map. Again, the user is responsible for keeping the `mr` alive.

### How does this work in cudf (python) land?

The Cython wrappers in RMM expose memory resources, and `set/get_current_device_resource`. `set_per_device_memory_resource` sets the value in both the C++ level `std::unordered_map` _and_ a Python level dict (https://github.com/rapidsai/rmm/blob/5f07014db51535902f8cdb515596af162d1ae6ca/python/rmm/_lib/memory_resource.pyx#L1041-L1049). `get_current_device_resource` looks up in the Python dict (https://github.com/rapidsai/rmm/blob/5f07014db51535902f8cdb515596af162d1ae6ca/python/rmm/_lib/memory_resource.pyx#L1013-1026). `DeviceBuffer`s keep the ""current"" memory resource alive by storing a reference: https://github.com/rapidsai/rmm/blob/5f07014db51535902f8cdb515596af162d1ae6ca/python/rmm/_lib/device_buffer.pyx#L93-L93, but when taking ownership of a C++-level device buffer https://github.com/rapidsai/rmm/blob/5f07014db51535902f8cdb515596af162d1ae6ca/python/rmm/_lib/device_buffer.pyx#L161-L171, we don't use the mr stored in the C++ struct.

The Python level dict is ""necessary"" due to the usual expected way in which people will use things from python. That is they will expect that: `set_per_device_resource(device, CudaMemoryResource())` keeps the created memory resource alive. 

If a C++ library calls `set_per_device_resource` at some point, C++-land (`libcudf`) and Python-land (cudf) can end up disagreeing about what the current memory resource is (because Python-level `get_current_device_resource` doesn't look at the C++-level map).

## So what's the problem?

If `libcudf` ever allocates memory that it hands off to cudf with a memory resource that is _not_ managed by cudf, we have the potential for use-after-free, because cudf has no way of taking (or sharing) ownership of that memory resource from the RMM buffer.

AFAICT, cudf never explicitly passes a memory resource into `libcudf`, and so the allocation behaviour is always relying on C++ and Python agreeing about what `get_current_device_resource` returns, _and_ that cudf was the creator of that resource. Effectively the pattern is:

```python
# In python
...
1. mr = rmm.get_current_device_resource()
# No mr passed here, so C++-level get_current_device_resource() is used
2. new_column = libcudf.some_algorithm(existing_data)
# take ownership of the data, fingers crossed that new_column.data.mr is mr
3. cudf_column = Column.from_unique_ptr(new_column, mr)
```

If _either_ someone in C++ has set a different per-device resource _or_ the current thread is pre-empted between lines 1 and 2 (and the current device resource is changed), then line 3 will take ""ownership"" of the data, but not be keeping the correct memory resource for the data alive.

## How can we fix this?

If the Cython layer in cudf always explicitly passes a memory resource to `libcudf` algorithms, this problem goes away. We can then always guarantee that the memory resource we have on the Python side is the one used to allocate the data in libcudf so we can keep it alive.

Alternately, if the memory_resource pointers in RMM were smart pointers it might be possible to keep things alive that way. Right now we can't make Python and C++ always agree on what the current default resource is (because on the C++ side RMM doesn't have a smart pointer stored, because it doesn't take ownership).",2023-09-28T17:29:46Z,0,0,Lawrence Mitchell,
280,[FEA] Add option to read JSON field as unparsed string,"**Is your feature request related to a problem? Please describe.**

When reading JSON in Spark, if a field has mixed types,  Spark will infer the type as String to avoid data loss due to the uncertainty of the actual data type.

For example, given this input file, Spark will read column `bar` as a numeric type and column `foo` as a string type.

```
$ cat test.json
{ ""foo"": [1,2,3], ""bar"": 123 }
{ ""foo"": { ""a"": 1 }, ""bar"": 456 }
```

Here is the Spark code that demonstrates this:

```
scala> val df = spark.read.json(""test.json"")
df: org.apache.spark.sql.DataFrame = [bar: bigint, foo: string]                 

scala> df.show
+---+-------+
|bar|    foo|
+---+-------+
|123|[1,2,3]|
|456|{""a"":1}|
+---+-------+
```

Currently, Spark RAPIDS fails for this example because cuDF does not support mixed types in a column:

```
Caused by: ai.rapids.cudf.CudfException: CUDF failure at: /home/jenkins/agent/workspace/jenkins-spark-rapids-jni_nightly-pre_release-181-cuda11/thirdparty/cudf/cpp/src/io/json/json_column.cu:577: A mix of lists and structs within the same column is not supported
  at ai.rapids.cudf.Table.readJSON(Native Method)
```

**Describe the solution you'd like**
I would like the ability to specify to read certain columns as unparsed strings.

**Describe alternatives you've considered**
I am also exploring some workarounds in the Spark RAPIDS plugin.

**Additional context**

",2023-09-29T21:37:44Z,0,0,Andy Grove,@Apple
281,[BUG] AST Limitation: Unable to Handle Single String Literal Expressions,"**Describe the bug**

The AST evaluator currently encounters a limitation where it is unable to handle an expression consisting of just one string literal, this is not a problem with other data types. While this scenario may be considered an edge case, it would be nice to address it for consistency with how other libraries, such as Pandas, handle similar situations.  

```
df.eval("" 'alex' "")
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/alexander/envs/cudf_dev/lib/python3.10/site-packages/nvtx/nvtx.py"", line 101, in inner
    result = func(*args, **kwargs)
  File ""/home/alexander/envs/cudf_dev/lib/python3.10/site-packages/cudf/core/dataframe.py"", line 7065, in eval
    None: libcudf.transform.compute_column(
  File ""/home/alexander/envs/cudf_dev/lib/python3.10/contextlib.py"", line 79, in inner
    return func(*args, **kwds)
  File ""transform.pyx"", line 196, in cudf._lib.transform.compute_column
RuntimeError: CUDF failure at: /opt/mambaforge/conda-bld/libcudf-ext_1692118605400/work/cpp/src/column/column_factories.cpp:161: Invalid, non-fixed-width type.

```
**Steps/Code to reproduce bug**
```
import cudf
df = cudf.DataFrame({'A': [], 'B': []})
df.eval("" 'alex' "")
```

`RuntimeError: CUDF failure at: /opt/mambaforge/conda-bld/libcudf-ext_1692118605400/work/cpp/src/column/column_factories.cpp:161: Invalid, non-fixed-width type.`

**Expected behavior**

For a similar  example but with other data types. 

```
import cudf
df = cudf.DataFrame({'A': [], 'B': []})
df.eval("" 123 "")
```

**Environment overview (please complete the following information)**
 - Environment location: conda
 - Method of cuDF install: conda
 -  branch-23.10, origin/branch-23.10
 
",2023-10-24T20:46:43Z,0,0,Alexander Ocsa,@voltrondata 
282,[FEA][JNI] Throw specific exception from `Table.readJSON` instead of `AssertionError`,"**Is your feature request related to a problem? Please describe.**
Per the discussion at https://github.com/NVIDIA/spark-rapids/pull/9304#discussion_r1372291170, the Spark plugin currently has to parse the error message from an `AssertionError`, which is an anti-pattern. This happens when the plugin calls `Table.readJSON` where the input is not JSON format.

This exception is thrown in the constructor for `Table`:

```java
  public Table(long[] cudfColumns) {
    assert cudfColumns != null && cudfColumns.length > 0 : ""CudfColumns can't be null or empty"";
```

**Describe the solution you'd like**
We should throw a specific exception instead.

**Describe alternatives you've considered**
None

**Additional context**
None
",2023-10-25T21:10:05Z,0,0,Andy Grove,@Apple
283,[FEA] center implementation for rolling window,"Hi, 

I am currently doing some feature engineering on a timeseries. My index is a datetime and I want to apply a rolling window. 
FYI the pandas code is running. 
`df['feature'] = df['feature'].rolling(f'{120}s', center=True, min_periods=1).sum()`

which leads to the following error: 

`NotImplementedError: center is not implemented for offset-based windows`

basically, I want to change to cudf for runtime optimization. As I have a datetime as an index, rolling operation with centring is much appreciated due to the fact of handling missing values, just shifting by timestamp is not trivial as discussed [here.](https://github.com/pandas-dev/pandas/issues/20012) 

I would appreciate if you could take a look. (Maybe it occurs due to some changes in the API interface)
",2023-10-26T16:19:44Z,0,0,Marc,
284,[BUG] Inconsistent Results Between AST and Pandas Evaluators for Expressions with Nullable Columns,"## Describe the bug

The AST evaluator and pandas evaluator are yielding divergent outcomes when evaluating expressions that include nullable columns.
 
Steps/Code to reproduce bug

```
import cudf
import pandas as pd
from io import StringIO

# Your CSV data as a string
csv_data = """"""\
Brand#32,MED PKG,,,754.84,4428,3537.78
Brand#53,MED BOX,,,3.98,1646,23333.44
Brand#41,WRAP BAG,1,8,763.34,3547,14687.36
Brand#43,SM BOX,2,46,15.45,6523,72572.36
Brand#42,WRAP PKG,3,31,778.19,3849,33608.96
Brand#23,LG JAR,4,43,101.93,4592,50407.61
""""""
dtype_schema = {
    'p_brand': 'string',   
    'p_container': 'string', 
    'l_linenumber': 'float64',
    'l_quantity': 'float64',  
    'ps_supplycost': 'float64',   
    'ps_availqty': 'float64',  
    'l_extendedprice': 'float64'
}

df = pd.read_csv(StringIO(csv_data), header=None, delimiter=',', dtype=dtype_schema, names=[name for name in dtype_schema])

df.eval(""(p_brand == 'Brand#23' or p_container == 'MED BOX') or (l_quantity < ps_supplycost)"").value_counts()
gdf = cudf.from_pandas(df)

gdf.eval(""(p_brand == 'Brand#23' or p_container == 'MED BOX') or (l_quantity < ps_supplycost)"").value_counts()
``` 

## Expected behavior

The cuDF AST evaluator is expected to yield results consistent with those produced by the pandas evaluator.

See: 
```
>>> df.eval(""(p_brand == 'Brand#23' or p_container == 'MED BOX') or (l_quantity < ps_supplycost)"").value_counts()
True     4
False     2
dtype: int64

>>> gdf = cudf.from_pandas(df)
>>> gdf.eval(""(p_brand == 'Brand#23' or p_container == 'MED BOX') or (l_quantity < ps_supplycost)"").value_counts()
True     3
False     1
dtype: int32

>>> df[ ((df['p_brand'] == 'Brand#23') | (df['p_container'] == 'MED BOX')) | (df['l_quantity'] < df['ps_supplycost']) ]
    p_brand p_container  l_linenumber  l_quantity  ps_supplycost  ps_availqty  l_extendedprice
1  Brand#53     MED BOX           NaN         NaN           3.98       1646.0         23333.44
2  Brand#41    WRAP BAG           1.0         8.0         763.34       3547.0         14687.36
4  Brand#42    WRAP PKG           3.0        31.0         778.19       3849.0         33608.96
5  Brand#23      LG JAR           4.0        43.0         101.93       4592.0         50407.61
>>> gdf[ ((gdf['p_brand'] == 'Brand#23') | (gdf['p_container'] == 'MED BOX')) | (gdf['l_quantity'] < gdf['ps_supplycost']) ]
    p_brand p_container  l_linenumber  l_quantity  ps_supplycost  ps_availqty  l_extendedprice
2  Brand#41    WRAP BAG           1.0         8.0         763.34       3547.0         14687.36
4  Brand#42    WRAP PKG           3.0        31.0         778.19       3849.0         33608.96
5  Brand#23      LG JAR           4.0        43.0         101.93       4592.0         50407.61
>>>
```


Environment overview  

Environment location: conda
Method of cuDF install: conda
branch-23.10, origin/branch-23.10",2023-11-04T00:47:47Z,0,0,Alexander Ocsa,@voltrondata 
285,[FEA] Respect `set_output_as_binary` in ORC writer,"**Is your feature request related to a problem? Please describe.**
The cuDF ORC writer does not follow the `set_output_as_binary` option added for Parquet to write a string column with binary type.

**Describe the solution you'd like**
To respect the `set_output_as_binary` option added in #6816 for the ORC writer as well.

**Describe alternatives you've considered**
We could copy the table to host and use the Arrow ORC writer or similar instead, but this would mean more copying.

**Additional context**
Quick demo using libcudf 23.10: https://github.com/lidavidm/cudf-orc-binary-feature-request",2023-11-08T14:58:57Z,0,0,David Li,
286,[FEA] need multibyte_split support stream ,"**Is your feature request related to a problem? Please describe.**
want to use cuda multi stream (pool)  read a big file.

**Describe the solution you'd like**
just add a new `multibyte_split` method with  ` rmm::cuda_stream_view stream` param  to public use.

head: https://github.com/rapidsai/cudf/blob/branch-23.12/cpp/include/cudf/io/text/multibyte_split.hpp
```
std::unique_ptr<cudf::column> multibyte_split(
  data_chunk_source const& source,
  std::string const& delimiter,
  parse_options options               = {},
  rmm::cuda_stream_view stream = cudf::get_default_stream(),
  rmm::mr::device_memory_resource* mr = rmm::mr::get_current_device_resource());
```

src: https://github.com/rapidsai/cudf/blob/branch-23.12/cpp/src/io/text/multibyte_split.cu
```
std::unique_ptr<cudf::column> multibyte_split(cudf::io::text::data_chunk_source const& source,
                                              std::string const& delimiter,
                                              parse_options options,
                                              rmm::cuda_stream_view stream,
                                              rmm::mr::device_memory_resource* mr)
{
  auto result = detail::multibyte_split(
    source, delimiter, options.byte_range, options.strip_delimiters, stream, mr);

  return result;
}
```

**Describe alternatives you've considered**

**Additional context**
",2023-11-09T13:50:28Z,0,0,weedge,
287,[QST] Respecting pandas options that affect default behaviors,"**What is your question?**
How should pandas global options interact with cudf.pandas? These can change the behavior/result of pandas operations _without_ changing the call being made.

For example, pandas has a `use_inf_as_na` option that makes inf behave like nulls. Should the pandas-path be forced if cudf.pandas detects a global option that isn't supported?

```python
# with %load_ext cudf.pandas

In [3]: ser = pd.Series([np.inf, np.nan])

In [4]: ser
Out[4]:
0     Inf
1    <NA>
dtype: float64

# Incorrect
In [5]: ser.dropna()
Out[5]:
0    inf
dtype: float64

In [6]: pd.options.mode.use_inf_as_na = True

In [7]: ser
Out[7]:
0     Inf
1    <NA>
dtype: float64

In [8]: ser.dropna()
Out[8]:
0    inf
dtype: float64

# if we try setting this option in a non-cudf supported way we get a different (incorrect) answer
In [10]: with pd.option_context(""use_inf_as_na"", True):
    ...:     print(ser.dropna())
    ...:
0   NaN
dtype: float64
```

The pandas result is:

```
>>> import pandas as pd; import numpy as np
>>> ser = pd.Series([np.inf, np.nan])
>>> pd.options.mode.use_inf_as_na = True
>>> ser.dropna()
Series([], dtype: float64)
```",2023-11-14T13:57:47Z,0,0,Ashwin Srinath,Voltron Data
288,Report results of running pandas unit tests in CI and fail the job when necessary,"Every PR runs a job called `pandas-tests` that run the Pandas unit tests using `cudf.pandas`. Currently, there are two issues with this job:

- the results of those tests aren't reported in the job summary or anywhere convenient to look at
- the job always passes, regardless of how many tests were passed or failed

Ideally, we should post the results as a job summary and fail the job if the number of tests passed relative to the development branch falls below a threshold (say, 0.1%). ",2023-11-14T14:24:16Z,0,0,Ashwin Srinath,Voltron Data
289,[QST] How how to expose __dict__ when `cudf.pandas` is enabled?,"
Some of the pandas tests spelunk the `__dict__` of a module to determine what to collect. E.g. `tests/dtypes/test_generic.py` does:
```
from pandas.core.dtypes import generic as gt
...
    @pytest.mark.parametrize(""abctype"", [e for e in gt.__dict__ if e.startswith(""ABC"")])
    def test_abc_coverage(self, abctype):
```

with `cudf.pandas` enabled:
```
from pandas.core.dtypes import generic as gt
gt.__dict__.keys() # does _not_ contain ABCCategorical
```
",2023-11-14T14:35:41Z,0,0,Ashwin Srinath,Voltron Data
290,Groupby hash aggregations use sort-based implementation if nested-type columns are used as values,"We should be able to use nested-type columns as values and still be able to invoke a hash-based groupby, as hash-based is generally faster so we do not want to be silently using sort-based. https://github.com/rapidsai/cudf/blob/abc0d41d1d9033d581948ae19384e0aa0f33da77/cpp/src/groupby/hash/groupby.cu#L654-L656

Reference thread: https://github.com/rapidsai/cudf/pull/13795#discussion_r1373454172",2023-11-14T19:44:30Z,1,0,Divye Gala,
291,`read_json` does not compile if using `std::string_view` instead of `std::string`,"Reference thread: https://github.com/rapidsai/cudf/pull/13795#discussion_r1373437533

Error:
```/home/nfs/dgala/cudf/cpp/examples/nested_types/deduplication.cpp: In function 'cudf::io::table_with_metadata read_json(std::string_view)':
/home/nfs/dgala/cudf/cpp/examples/nested_types/deduplication.cpp:66:52: error: no matching function for call to 'cudf::io::source_info::source_info(std::string_view&)'
   66 |   auto source_info = cudf::io::source_info(filepath);```",2023-11-14T19:47:51Z,0,0,Divye Gala,
292,[FEA] The C++ tests for parquet don't test row group selection very well.,"
There's only a very basic row group selection test in the C++ gtests.  It would probably be useful to have a more thorough set of tests.",2023-11-15T21:29:37Z,0,0,,
293,[FEA] Parquet reader:  replace skip_rows / num_rows with start_row / end_row,"
Our external interface to the parquet reader allows the user to specify `skip_rows` / `num_rows` parameters when calling it.  Internally, we use the same values.  But it is a very unwieldy way to think about things.  I think it would be easier to immediately convert those values to `start_row` and `end_row` and use that everywhere.  It's a nontrivial amount of work to do this without causing bugs but I think the code would be more natural (in the std::algorithms / iterator sense of the word).",2023-11-21T20:35:55Z,0,0,,
294,[FEA] Check dtype requirements on multiindex codes,"**Is your feature request related to a problem? Please describe.**

(Seen as part of a review of #14470).

Multiindex codes and levels are effectively a categorical encoding of the columns of the multiindex entries. The codes are used to index the levels. As such, they should probably have type equivalent to `cudf::size_type`. Currently, however, they are a int64. This is a larger memory footprint than necessary. Moreover, it (in some constructor circumstances) necessitates more copies than necessary.

**Describe the solution you'd like**

Use correct dtype. Since the public `codes` and `levels` properties wrap the results in pandas `FrozenList` objects to mimic the pandas API, it may be possible to just store the codes/levels pairs as `CategoricalColumn`s internally, rather than the current structure.

**Describe alternatives you've considered**

n/a

**Additional context**

n/a",2023-11-22T14:23:32Z,0,0,Lawrence Mitchell,
295,[ENH] Audit cudf APIs for use of inappropriate algorithms,"**Is your feature request related to a problem? Please describe.**

Historically (I think) certain features were available in libcudf before others. For example, while hash joins appeared quite early on `cudf::contains` was only factored out of the semi join infrastructure in #11100.

As a result, there are a number of places in cudf where an API was implemented using a sub-optimal approach (be that in terms of memory footprint or performance) just because it was needed in the Python API.

For example in #14478, we replace a sub-optimal (in both memory _and_ performance) inner join, with a call to `cudf::contains` now that it is available.

**Describe the solution you'd like**

We should go through and check for other instances of this historical anti-pattern and either:

- replace with calls to appropriate (existing) libcudf primitives
- gather feature requests for new libcudf primitives based on the usage we observe.

**Describe alternatives you've considered**

n/a

**Additional context**

It is probable that candidates can be found by looking calls to `merge` in the cudf codebase. As well as argsort/scatter/gather patterns (that's #13557).
```[tasklist]
### Tasks
- [ ] https://github.com/rapidsai/cudf/issues/13557
- [ ] https://github.com/rapidsai/cudf/pull/14478
- [ ] https://github.com/rapidsai/cudf/issues/14480
- [ ] https://github.com/rapidsai/cudf/issues/14485
- [ ] https://github.com/rapidsai/cudf/issues/14486
- [ ] https://github.com/rapidsai/cudf/issues/13630
- [ ] https://github.com/rapidsai/cudf/issues/13565
- [ ] https://github.com/rapidsai/cudf/issues/13456
- [ ] https://github.com/rapidsai/cudf/issues/14487
```
",2023-11-22T18:58:02Z,2,0,Lawrence Mitchell,
296,[FEA] Remove special-case implementation of `MultiIndex.isin`,"**Is your feature request related to a problem? Please describe.**

`isin` is implemented ""by-hand"" for `MultiIndex` by going via the frame representation and then calling `merge`. This means that any updates to correctness/performance of `DataFrame.isin` must be hand-ported to the `MultiIndex` case.

**Describe the solution you'd like**

`MultiIndex.isin` should do necessary pre-/post-processing and call `DataFrame.isin` rather than re-implementing the core algorithm.

**Describe alternatives you've considered**

n/a

",2023-11-22T19:05:26Z,0,0,Lawrence Mitchell,
297,[FEA] Implement column-wise hashes,"**Is your feature request related to a problem? Please describe.**

cudf columns are mutable and therefore do not (or should not) implement `__hash__` (in the same way that numpy arrays do not do so).

_However_, there are circumstances under which we would nonetheless like to be able to compute a hash of a column:

1. When the wrapping object is actually an immutable one (for example `Index` objects) and so `__hash__` is safe;
2. When tokenizing keys for dask task graphs (see https://github.com/rapidsai/cudf/pull/13695), where the objects may be mutable, but the required semantics are ""two objects that compare equal should hash the same"". This enables dask to perform some amount of optimisation on the task graph for repeated execution and task merging.

**Describe the solution you'd like**

I would like to be able to hash a column with a libcudf call and receive a single $k$-bit hash. The first point above does not need to worry excessively about collisions, and python hash values are 64bit ints, so a 64-bit murmur- or xx-hash is likely sufficient. For dask, collisions are more problematic, so a 128-bit md5 would be better (this is what dask uses for pandas dataframes).

**Describe alternatives you've considered**

Compute row-wise hashes of columns (on dataframes) to produce a single column of hashes and then copy to host to hash there.",2023-11-23T11:09:38Z,0,0,Lawrence Mitchell,
298,[PERF/ENH] `Series.map` sorts a larger dataset than it needs to,"`Series.map` which substitutes values in `self` that match some key with its corresponding value does:
```
            lhs = cudf.DataFrame({""x"": self, ""orig_order"": arange(len(self))})
            rhs = cudf.DataFrame(
                {
                    ""x"": arg.keys(),
                    ""s"": arg.values(),
                    ""bool"": full(len(arg), True, dtype=self.dtype),
                }
            )
            res = lhs.merge(rhs, on=""x"", how=""left"").sort_values(
                by=""orig_order""
            )
            result = res[""s""]
            result.name = self.name
            result.index = self.index
```

So the order is the same as the input.

This has two pessimisations:

1. In pandas-compat mode (since #14428) this merge doesn't need sorting
2. Since we only return `s`, we can get away with `sort_by_key` of `res[""s""]` rather than sorting a multi-column dataframe",2023-11-23T15:12:00Z,0,0,Lawrence Mitchell,
299,[PERF/ENH] `Index.intersection` does more hashing work than necessary,"Index intersection performs an inner merge of the unique values of the left and right indices (the unique is done so that indices with repeated values don't blow up the memory footprint). This does a full hash of both indices, then the merge (hashing again). Finally, if requested, the result is sorted.

This could be replaced, I think with positive performance effect by either:

- `leftsemi` join + `drop_duplicates`
- `libcudf.search.contains` + `apply_boolean_mask` + `drop_duplicates`

One would have to think through the consequences of either of these wrt any ordering guarantees we might want when `sort=False` (possibly gated behind pandas-compat mode).

This applies _mutatis mutandis_ to `MultiIndex.intersection` too.",2023-11-23T17:08:58Z,0,0,Lawrence Mitchell,
300,[BUG] `Index.union` does not match pandas for indexes with duplicate entries,"**Describe the bug**

Pandas treats, for `Index.union` only, indexes with duplicate entries as [multisets](https://en.wikipedia.org/wiki/Multiset#Basic_properties_and_operations), for which the union operation produces multiplicities that are the max of the left and right multiplicities. I've asked for clarification of this here https://github.com/pandas-dev/pandas/issues/56137, since it is _only_ `union` that uses the multiset definitions.

cudf, in contrast, performs the union as an outer join. Which produces multiplicities that are the product of the multiplicities of the left and right indexes (with identity for missing values of 1). This matches the pandas behaviour in the case where all entries have multiplicity greater than one in exactly one of the left or right indexes. However, if an entry has a multiplicity larger than one in both left and right indexes, we get the wrong answer.

**Steps/Code to reproduce bug**

```
import cudf
import pandas as pd

left = pd.Index([1, 1])
right = pd.Index([1, 2, 1, 1])
print(left.union(right))

cleft = cudf.from_pandas(left)
cright = cudf.from_pandas(right)

print(cleft.union(cright))
# Int64Index([1, 1, 1, 2], dtype='int64')
# Int64Index([1, 1, 1, 1, 1, 1, 2], dtype='int64')
```

**Expected behavior**

Match pandas.

This can be done with `value_counts`/`merge`/`repeat` in some combo, but there's probably a slightly smarter way.

**Notes**

Also applies to `MultiIndex`.",2023-11-23T17:23:39Z,0,0,Lawrence Mitchell,
301,[FEA] Remove inconsistencies in cython wrappers when  handling order/null-precedence,"Where libcudf search/sort functions accept a `table_view` as input, one must specify the order (ascending or descending) and null precedence (beginning or end) as a `std::vector` of length equal to the number of columns in the `table_view` (or else an empty such vector to used libcudf's defaults).

In the cudf cython wrapping of these functions we are, in contrast, inconsistent in the way we handle these arguments. Some functions accept a list for both order and null precedence (e.g. `libcudf.sort.sort`); some accept a list for order but only a single value for null precedence (e.g. `libcudf.sort.order_by`); some accept a list for neither order nor null precedence (e.g. `libcudf.search.search_sorted`).

This should be cleaned up and all such functions should uniformly accept a list for both order and null precedence. Higher-level python functions that operate on single columns and call the table interfaces should be responsible for any argument munging.
",2023-11-24T14:53:40Z,0,0,Lawrence Mitchell,
302,[BUG] codecov doesn't include tests run in `cudf_pandas_tests/` when generating report,"The codecov report generated in every PR doesn't consider the tests in `cudf_pandas_tests/` when generating its coverage report.  To fix this, we should update our invocation here:

https://github.com/rapidsai/cudf/blob/branch-24.02/ci/cudf_pandas_scripts/run_tests.sh#L52

to match the ones we use when running other python tests:

https://github.com/rapidsai/cudf/blob/branch-24.02/ci/test_python_cudf.sh#L17

(in particular, all the `--cov*` arguments)



",2023-11-27T17:31:24Z,0,0,Ashwin Srinath,Voltron Data
303,[QST] cudf.pandas prefer using CPU over GPU in some cases,"Hi,
I'm trying to move from a basic pandas to cudf.pandas and I faced with the issue. It's not clear how cudf decides to use **CPU** or **GPU** in calculations.
Here is the example when I have a dataframe with around 280kk rows and 9 columns.
The steps:
1) I perform `.groupby.sum() `for the original df. I takes too much time and the profiler show that all calculations were on **CPU** not GPU.
2) I cut df like `[:100000000]` so that there are 100kk rows left.
3)  I perform `.groupby.sum() `for the modified df and... it takes 0.1 sec and the profiler says **GPU** was using for that.

So, here is some question.
- what's the reason that 100kk df is being calculated on GPU and 280kk df on CPU? Hard to belive that the size is the reason.
- If not the size then what's the criteria for that?

Thanks in advance.
p.s. I also tried `.sort_values()` and there were the same.

```
COM_ORDER_LINE.shape
(284125143, 9)
```
```
COM_ORDER_LINE.head()

CODE | ORDER_CODE | VERSION_CODE | ID_WARE | QTY_ORDERED | CATALOG_PRICE | PRICE | TO_PAY | DISCOUNT_TOTAL
10000006215177 | 10000006215175 | 10000006215176 | 1.787585e+11 | 1 | 3799.0 | 2659.0 | 2659.0 | 1140.0
10000006215189 | 10000006215187 | 10000006215188 | 1.736505e+11 | 1 | 9999.0 | 6999.0 | 6999.0 | 3000.0
10000006215364 | 10000006215362 | 10000006215363 | 1.736709e+11 | 1 | 1399.0 | 980.0 | 980.0 | 419.0
```
```
%%cudf.pandas.profile
df=COM_ORDER_LINE.groupby(['ID_WARE'])['PRICE'].sum()
```


```
Total time elapsed: 31.764 seconds                                    
                                          0 GPU function calls in 0.000 seconds                                   
                                          3 CPU function calls in 23.186 seconds                                  
                                                                                                                  
                                                          Stats                                                   
                                                                                                                  
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Function                     ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ DataFrame.groupby            │ 0          │ 0.000       │ 0.000       │ 1          │ 2.929       │ 2.929       │
│ DataFrameGroupBy.__getitem__ │ 0          │ 0.000       │ 0.000       │ 1          │ 2.915       │ 2.915       │
│ SeriesGroupBy.sum            │ 0          │ 0.000       │ 0.000       │ 1          │ 17.341      │ 17.341      │
└──────────────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘

Not all pandas operations ran on the GPU. The following functions required CPU fallback:

- DataFrame.groupby
- DataFrameGroupBy.__getitem__
- SeriesGroupBy.sum
```

```
COM_ORDER_LINE_100KK = COM_ORDER_LINE[:100000000]
COM_ORDER_LINE_100KK.shape
(100000000, 9)
```

```
%%cudf.pandas.profile
df=COM_ORDER_LINE_100KK.groupby(['ID_WARE'])['PRICE'].sum()
```

```
Total time elapsed: 0.109 seconds                                     
                                          3 GPU function calls in 0.082 seconds                                   
                                          0 CPU function calls in 0.000 seconds                                   
                                                                                                                  
                                                          Stats                                                   
                                                                                                                  
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Function                     ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ DataFrame.groupby            │ 1          │ 0.000       │ 0.000       │ 0          │ 0.000       │ 0.000       │
│ DataFrameGroupBy.__getitem__ │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │
│ SeriesGroupBy.sum            │ 1          │ 0.081       │ 0.081       │ 0          │ 0.000       │ 0.000       │
└──────────────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘
```

",2023-11-27T18:14:30Z,0,0,Andrey Komrakov,Sportmaster Ltd.
304,[FEA] Add GZIP compression support to parquet writer,"**Is your feature request related to a problem? Please describe.**
The parquet format in Apache Spark supports many compression codecs ([link](https://spark.apache.org/docs/2.4.3/sql-data-sources-parquet.html#configuration)), including: none, uncompressed, snappy, gzip, lzo, brotli, lz4, zstd. 

cuDF has both internal implementation and an nvCOMP integration to provide compression and decompression codecs.  For the parquet format, GZIP compression is [DEFLATE](https://developer.nvidia.com/blog/accelerating-load-times-for-directx-games-and-apps-with-gdeflate-for-directstorage/) plus a header. nvCOMP does not support the deflate version with this header, so the reader still uses the internal gzip decompression implementation. We don't have internal gzip compression implementation. To support GZIP in the PQ writer we would need to use nvCOMP GDEFLATE codec + write the header on our own.

**Describe the solution you'd like**
Add support for GZIP compressioning to the cuDF parquet writer by adding a header writing implementation and using nvCOMP deflate.

**Describe alternatives you've considered**
n/a

**Additional context**
Also see Spark-RAPIDS request here: https://github.com/NVIDIA/spark-rapids/issues/9718
",2023-11-28T05:27:35Z,0,0,Gregory Kimball,
305,[FEA] Expose `negative_index_policy` from `cudf::detail::gather` in public `cudf::gather` API,"**Is your feature request related to a problem? Please describe.**

The libcudf detail API for `gather` allows one to separately specify how negative indices are handled (whether or not a negative index `i` should map to `i + length(column)`) and how out of bounds indices are handled (whether they should be nullified or not checked for).

In contrast, the public API only allows specifying the policy for out-of-bounds indices explicitly, whether or not negative indices are wrapped is a function of the signedness of the input map column: if the map is an unsigned type, then ""negative"" indices are not allowed, if the type is signed then wrapping occurs.

In cudf, there are cases where we ingest data where pandas specifies that the marker for ""missing"" data is `-1`. For example `MultiIndex` construction can take `levels` and `codes` where `codes` indexes levels and `-1` means ""produce a null"". Right now we use `cudf::gather` to produce the indexed levels, but must first pre-process the `codes` column to replace `-1` with an actually out of bounds size type. This requires an extra pass over the input (and copy to set values).

Whenever we perform a join, we obtain gather maps from libcudf which store signed entries (`cudf::size_type`). The entries are guaranteed to either be positive and in-bounds or the sentinel value `std::numeric_limits<size_type>::min()` indicating that an output row should be nullified. Despite this knowledge, since the column we're using for the gather map is a signed type, we have no way of performing the gather without paying the cost of wrapping negative indices, which we _know_ will be a no-op.

**Describe the solution you'd like**
I'd like to be able to specify the treatment of negative indices independently of the signedness of the gather map when calling `cudf::gather`.

**Describe alternatives you've considered**

For data ingest, we could just build the user input as an unsigned type. However, that has the disadvantage that they then don't see what they might ""expect"" if inspecting the result that cudf delivers.

For the join case, I don't think there is a way without copying the gather map (since it is UB to `reinterpret_cast` between pointers of different types).",2023-11-28T13:09:37Z,0,0,Lawrence Mitchell,
306,[FEA] Allow control of mask state in return value of `cudf::contains`,"**Is your feature request related to a problem? Please describe.**

`cudf::contains`, specifically the column overload, searches for a bunch of needles in a haystack. If any of the needles are null, the return value has nulls in the same location. The detail API has finer-grained control over whether nulls should compare equal (so that if the haystack contains a null and one of needles is null, the output column has a `true` value in that slot).

It would be nice to be able to control whether the bitmask is copied from the needles to the result or not. In Python cudf, we use `contains` to implement `Series.isin` where the semantics are that nulls are just treated as any other value. So if the needles contain a null, the result is true or false depending on whether the haystack also has a null. Right now, we call contains, and then must perform some post-processing to obtain a result that internally has already been computed.

**Describe the solution you'd like**

A flag specifying whether `contains` masks its output.

**Describe alternatives you've considered**

Above-board, I do this in Python with:

```
if needles.null_count > 0:
    result.fillna(haystack.null_count > 0)
```
This is an extra allocation + kernel launch.

The cheap way of doing it is to obtain the result, and then drop the mask on the floor. This happens to work due to the way `cudf::contains` is implemented. However, I would rather not do this because libcudf explicitly does not guarantee that the masked out entries of a column contain valid data, so I am relying on an implementation detail which could change.",2023-11-28T17:13:09Z,0,0,Lawrence Mitchell,
307,[BUG] Treatment of logical and bitwise binops in `DataFrame.eval` does not match pandas,"**Describe the bug**

In pandas, `eval` treats `a op b` as always meaning the bitwise version `op in {and, or, &, |, ^}`. In cudf, due to the way we parse the expression without type information (and the dispatching scheme to the AST interpreter in libcudf), `and` and `or` mean ""logical"" and `&`, `|`, and `^` mean ""bitwise"". There's a final wrinkle that (like spark) for bools only, masked values are treated as `False`.

This can cause differences in the result between calling `eval` with pandas and with cudf. Although the docstring mentions these differences, when using `cudf.pandas`, we don't see the cudf docstring (only the pandas one).

**Expected behavior**

Eventually, we should match pandas. I think this should be done by running a type inference pass on the user-provided expression and rewriting to an appropriate combination of bitwise and logical operations. This would have the nice side-effect of also allowing mixed-type operands in `eval` expressions by cudf upcasting before passing off to libcudf.

In the short term, we should probably raise a `NotImplementedError` when running in pandas-compat mode if the expression contains logical/bitwise binops.",2023-11-28T18:15:07Z,0,0,Lawrence Mitchell,
308,[FEA] Proxy ndarrays don't pass an `instancecheck()` for `np.ndarray`,"There's a lot of code out there that does something like:

```python
if not isinstance(x, np.ndarray):
    raise TypeError(""Not a numpy array"")
```

This is a problem for `cudf.pandas`, because proxy ndarray types, such as those returned by `pd.Series.values` do not pass the `isinstance()` check.

Ideally, more projects would avoid doing a hard `isinstance()` check and instead use something like EAFP:

```python
np.asarray(x)
```

..but that is not the world we live in today. Too many third-party libraries that people want to use with `cudf.pandas` use the pattern above, so it's on us to solve the problem right now.",2023-11-30T17:23:07Z,0,0,Ashwin Srinath,Voltron Data
309,"[BUG] Parquet column selection by name with schemas including   list<struct<X, Y>> does not work.","If you have a schema that contains a list-of-struct, selecting a subset of the inner columns doesn't work.  Example

`list<struct<int, float>>`
If the schema for this column was

```
A           (list)
   B        (struct)
       C    (int)
       D    (float)
```
Attempting to select ""A.B.C"" would not work.  I believe this is being caused by some schema preprocessing that we are doing that is injecting fake schema elements to ease schema interpretation.  Essentially we see a schema that looks like this:

```
A            (list)
  list       (the fake element
     B       (struct)
        C    (int)
        D    (float)
```
So ""A.B.C"" doesn't actually exist, only ""A.list.B.C"" and the code returns 0 columns.",2023-11-30T21:30:21Z,0,0,,
310,[BUG] `MultiIndex.equals` does not match pandas for numerical indexes with unequal dtypes,"**Describe the bug**

```python
import cudf

left = cudf.MultiIndex.from_tuples([(1,)])
right = cudf.MultiIndex.from_tuples([(1.0,)])

print(left.equals(right)) # => False

print(left.to_pandas().equals(right.to_pandas())) # => True
```

**Expected behavior**

This should match pandas. Note that `Index.equals` does do dtype casting.",2023-12-05T15:58:40Z,0,0,Lawrence Mitchell,
311,[BUG] merge join key matching is too eager to cast strings,"**Describe the bug**

```
import cudf

left = cudf.DataFrame({""key"": [1, 2, 3]})
right = cudf.DataFrame({""key"": [""1"", ""4"", ""5""]})

# Casts both key columns to float64 and merges
got = left.merge(right, on=""key"", how=""outer"")

# raises ValueError (merging on int + string column)
expect = left.to_pandas().merge(right.to_pandas(), on=""key"", how=""outer"")
```

**Expected behavior**

This should match pandas. A consequence, since merge is also used for Index setops, `union`, `intersection`, and `difference` are buggy.",2023-12-05T17:34:17Z,0,0,Lawrence Mitchell,
312,[FEA] Add Avro reader benchmarks to the cuIO benchmarking suite,"**Is your feature request related to a problem? Please describe.**
We have reader benchmarks for CSV, JSON, Parquet and ORC in the cuIO nvbench benchmarking suite. We should add benchmarking for the Avro reader. 

The cuIO benchmarks are located here:
https://github.com/rapidsai/cudf/tree/branch-24.02/cpp/benchmarks/io

Unfortunately, we don't have an Avro writer implementation in libcudf, so the naive approach of modeling benchmarks after [json_reader_input.cpp](https://github.com/rapidsai/cudf/blob/branch-24.02/cpp/benchmarks/io/json/json_reader_input.cpp) will not work. 

**Describe the solution you'd like**
Our options would be:
* add an MVP Avro writer to libcudf
* add/use a dependency to write Avro files 
* maintain a repository of large Avro files (>100 MB) for benchmarking purposes

**Describe alternatives you've considered**
Continue without automated benchmarks for the Avro reader

**Additional context**
The libcudf Avro reader does not support nested types so the benchmarks should start by only covering primitive types.
",2023-12-05T19:34:27Z,0,0,Gregory Kimball,
313,[FEA] Support canonical arrow extension types: FixedShapeTensorType and VariableShapeTensorType,"**Is your feature request related to a problem? Please describe.**
Feeding data from the CPU to the GPU is a bottleneck especially for computer vision. I'd like to store satellite images as parquet with georeferencing information in some columns and a column with Arrow's new FixedShapeTensorType extension array and then load it with cudf and get zero copy benefits when passing the tensor to the GPU and pytorch.

However it looks like cudf can't interpret this type.
```
import pyarrow as pa

tensor_type = pa.fixed_shape_tensor(pa.int32(), (2, 2))
arr = [[1, 2, 3, 4], [10, 20, 30, 40], [100, 200, 300, 400]]
storage = pa.array(arr, pa.list_(pa.int32(), 4))
tensor_array = pa.ExtensionArray.from_storage(tensor_type, storage)

data = [
     pa.array([1, 2, 3]),
     pa.array(['foo', 'bar', None]),
     tensor_array,
]
my_schema = pa.schema([('f0', pa.int8()),
                        ('f1', pa.string()),
                        ('tensors_int', tensor_type)])
table = pa.Table.from_arrays(data, schema=my_schema)

table.cast(table.schema)
```

```
import cudf

cudf.DataFrame.from_arrow(table)
```

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
Cell In[2], line 3
      1 import cudf
----> 3 cudf.DataFrame.from_arrow(table)

File ~/miniforge3/envs/rapids-23.10/lib/python3.10/site-packages/nvtx/nvtx.py:115, in annotate.__call__.<locals>.inner(*args, **kwargs)
    112 @wraps(func)
    113 def inner(*args, **kwargs):
    114     libnvtx_push_range(self.attributes, self.domain.handle)
--> 115     result = func(*args, **kwargs)
    116     libnvtx_pop_range(self.domain.handle)
    117     return result

File ~/miniforge3/envs/rapids-23.10/lib/python3.10/site-packages/cudf/core/dataframe.py:5322, in DataFrame.from_arrow(cls, table)
   5319         for col_meta in table.schema.pandas_metadata[""column_indexes""]:
   5320             col_index_names.append(col_meta[""name""])
-> 5322 out = super().from_arrow(table)
   5323 if col_index_names is not None:
   5324     out._data._level_names = col_index_names

File ~/miniforge3/envs/rapids-23.10/lib/python3.10/site-packages/nvtx/nvtx.py:115, in annotate.__call__.<locals>.inner(*args, **kwargs)
    112 @wraps(func)
    113 def inner(*args, **kwargs):
    114     libnvtx_push_range(self.attributes, self.domain.handle)
--> 115     result = func(*args, **kwargs)
    116     libnvtx_pop_range(self.domain.handle)
    117     return result

File ~/miniforge3/envs/rapids-23.10/lib/python3.10/site-packages/cudf/core/frame.py:1053, in Frame.from_arrow(cls, data)
   1036     cudf_category_frame = {
   1037         name: build_categorical_column(
   1038             cudf_dictionaries_columns[name],
   (...)
   1046         )
   1047     }
   1049 # Handle non-dict arrays
   1050 cudf_non_category_frame = {
   1051     name: col
   1052     for name, col in zip(
-> 1053         data.column_names, libcudf.interop.from_arrow(data)
   1054     )
   1055 }
   1057 result = {**cudf_non_category_frame, **cudf_category_frame}
   1059 # There are some special cases that need to be handled
   1060 # based on metadata.

File ~/miniforge3/envs/rapids-23.10/lib/python3.10/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File interop.pyx:199, in cudf._lib.interop.from_arrow()

RuntimeError: CUDF failure at:/opt/conda/conda-bld/work/cpp/src/interop/from_arrow.cu:87: Unsupported type_id conversion to cudf
```


**Describe the solution you'd like**
I want to be able to load parquet files with cudf that contain a column with this tensor type and then easily hand it off from cudf to pytorch.

**Describe alternatives you've considered**
There are other formats like zarr for N-D arrays and direct loading to gpu, but I don't think zero copy between cpu and gpu is supported https://xarray.dev/blog/xarray-kvikio

Or I can continue loading parquet files with references to cloud optimized geotiff files, which is a lot slower.

**Additional context**
docs for the type are here: https://arrow.apache.org/docs/python/generated/pyarrow.FixedShapeTensorArray.html
and others are looking at implementing it for dataloading https://github.com/huggingface/datasets/issues/5272
there's also a variable shape equal dimension number type which would be very useful for efficiently loading satellite imagery time series where the time length can vary a lot depending on the sample, or the height and width can vary a lot depending on the sensor resolution: https://arrow.apache.org/docs/format/CanonicalExtensions.html#variable-shape-tensor
",2023-12-06T21:04:04Z,1,0,Ryan Avery,@wherobots
314,[FEA] Tighten up promotion when merging with non-equal key column dtypes,"**Is your feature request related to a problem? Please describe.**

To date, cudf has attempted to match pandas semantics when matching join keys in a merge. libcudf does not perform merges between mismatching table dtypes. Consequently, the first step of a merge in cudf is to determine a ""common"" dtype for each pair of columns used as keys in the merge.

The pandas rules are mostly (though not completely since there is some under the table work that happens in the join algorithm) encoded in https://github.com/pandas-dev/pandas/blob/f7c73a5f1aaf0724598e60c0cc5732604ec842a8/pandas/core/reshape/merge.py#L1340

There are a few problems when trying to match these in cudf:

- not all column types in pandas can be represented in cudf (we do not have an `object` column for example)
- it is difficult to unambiguously determine the type promotion rules since they are not written down anywhere
    - for example, promotion rules for categorical columns differ depending on whether the categorical is the left or right key.

Moreover, there are other, correctness, problems. The current type promotion rules admit lossy conversions that can result in false positive matches in merges.

Example:
```
left = cudf.DataFrame({""key"": [1, 2, 2**53]})
right = cudf.DataFrame({""key"": [2**53 + 1, 10]})
right[""key""] = right.key.astype(""uint64"")
left.merge(right, on=""key"", how=""inner"")
#            key
# 0  9.007199e+15
left
#                key
# 0                 1
# 1                 2
# 2  9007199254740992
right
#                key
# 0  9007199254740993
# 1                10
```

Pandas is also susceptible to this, but produces a different wrong result.

I would like to tighten up the rules in cudf, so that it is impossible for the user to get a ""surprising"" result without some explicit intervention on their behalf. We would also try and match pandas more closely where that is possible, but my preference is to be correct in a subset of cases over dubiously correct in a larger set.

**Describe the solution you'd like**

There are, I think, three levels of things we could do:

1. Push the burden of dtype matching completely on to the user: complain (raise) if merge keys do not match dtypes _exactly_
2. Promote keys whose dtypes allow so safely (without needing to inspect values), and raise for cases where that is not possible. The user can still perform the merge by intentionally casting to matching types. But then they must know that it is safe.
3. Try and match pandas promotions as closely as possible and accept that there might be false positives.

I would like to go for (2). (1) is easiest; (3) is difficult, probably a moving target and can result in false positives without the user explicitly ""requesting"" them.

With cudf-pandas (2), I think, skates the line between ease of use and correctness reasonably well. We can run as much on the GPU as possible and raise (possibly providing a warning in pandas-compat mode) with fallback to CPU. When using cudf directly, users will hopefully be willing to accept a few more edge cases in the name of consistency. 


Concretely this would mean:

- No casting for strings
- No casting for lists
- No casting for structs
- Categoricals:
    - if both columns are categorical and match, no casting
    - if both columns are categorical and _do not_ match, raise[^1]
    - if one column is categorical, unwrap, and go round again[^2]
 - No casting for decimals
 - No casting for datetimes[^3]
 - For numeric types, use a type promotion lattice that has lossless least upper bounds for all types[^4]

For numeric types, that means that we would only promote pairs of types where there exists a wider type whose values are uniquely and unambiguously mapped onto from the narrower types.

For example `(int32, uint32) -> int64` would be allowed, but merging a pair `(int32, uint64)` would raise (since there is no signed 128bit int that we could use). Similarly, we would safely be able to promote `(intX, floatY)` pairs (and similarly with `uintX`) as long as the integer type is 32 or fewer bits wide[^5].



[^1]: I could also be convinced to unwrap and go round again, but that would lose information about the categorical nature of the inputs
[^2]: Pandas behaviour in this case depends on whether the left or right key is categorical (and which merge type it is): it casts the non-categorical to object, and the categorical to its underlying dtype, then imperfectly goes through its matching process again
[^3]: I haven't looked at what pandas does here, but I guess the other thing one could do is promote when one can losslessly convert
[^4]: See, for example https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html though I disagree with their approach of selecting a ""weak"" float64 as the least upper bound for `(int64, uint64)`
[^5]: Merging between float and int columns is kind of weird, so I could also be convinced to raise when merging between mismatching numeric kinds.",2023-12-07T19:04:54Z,0,0,Lawrence Mitchell,
315,[BUG] DIV on decimal types appears to lose fractional part,"**Describe the bug**

Dividing two decimal columns with equal scale N results in 0 fractional digits in the output (i.e. the result is truncated). I would expect that if division returns a result of scale N, then we should have N fractional digits of output. Instead, the number of fractional digits computed appears to be `LHS.scale - RHS.scale`, so dividing equal scale decimals always truncates the fractional part. It's possible I'm misunderstanding how scale is handled here, though. (It looks vaguely like cuDF is just doing the raw integer division, then possibly rescaling? IIRC, PyArrow rescales before and after)

**Steps/Code to reproduce bug**

```python
from decimal import Decimal

import cudf
import pyarrow
import pyarrow.compute

print(""cuDF version: "", cudf.__version__)
print(""PyArrow version: "", pyarrow.__version__)

lhs_py = [Decimal(""1.0""), Decimal(""2.0"")]
rhs_py = [Decimal(""2.0""), Decimal(""3.0"")]

print(""* cuDF:"")
lhs = cudf.Series(lhs_py, dtype=cudf.Decimal128Dtype(precision=10, scale=4))
rhs = cudf.Series(rhs_py, dtype=cudf.Decimal128Dtype(precision=10, scale=4))

# There are 0 actual fractional digits in the result, although the dtype
# indicates precision=25, scale=15.
result = lhs / rhs
print(result)
print(repr(result.dtype))

# If we arbitrarily add more fractional digits to the LHS, we get (LHS.scale -
# RHS.scale) fractional digits in the result.
result = lhs.astype(cudf.Decimal128Dtype(precision=10, scale=8)) / rhs
print(result)
print(repr(result.dtype))

print(""* PyArrow"")
lhs = pyarrow.array(lhs_py, type=pyarrow.decimal128(10, 4))
rhs = pyarrow.array(rhs_py, type=pyarrow.decimal128(10, 4))

# PyArrow computes 11 fractional digits, and the result scale is 11.
result = pyarrow.compute.divide(lhs, rhs)
print(result)
print(result.type)
```

The result:

```
cuDF version:  23.12.00a717
PyArrow version:  14.0.1
* cuDF:
0    0E-15
1    0E-15
dtype: decimal128
Decimal128Dtype(precision=25, scale=15)
0    0.5000000000000000000
1    0.6666000000000000000
dtype: decimal128
Decimal128Dtype(precision=25, scale=19)
* PyArrow
[
  0.50000000000,
  0.66666666666
]
decimal128(21, 11)
```

**Expected behavior**
A clear and concise description of what you expected to happen.

**Environment overview (please complete the following information)**
 - Environment location: Bare-metal
 - Method of cuDF install: conda

<details>
<summary><tt>conda list</tt></summary>

```
# packages in environment at /home/lidavidm/miniforge3/envs/cudf:
#
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                 conda_forge    conda-forge
_openmp_mutex             4.5                       2_gnu    conda-forge
aws-c-auth                0.7.8                h538f98c_2    conda-forge
aws-c-cal                 0.6.9                h5d48c4d_2    conda-forge
aws-c-common              0.9.10               hd590300_0    conda-forge
aws-c-compression         0.2.17               h7f92143_7    conda-forge
aws-c-event-stream        0.3.2                h0bcb0bb_8    conda-forge
aws-c-http                0.7.14               hd268abd_3    conda-forge
aws-c-io                  0.13.36              he0cd244_2    conda-forge
aws-c-mqtt                0.9.10               h35285c7_2    conda-forge
aws-c-s3                  0.4.4                h0448019_0    conda-forge
aws-c-sdkutils            0.1.13               h7f92143_0    conda-forge
aws-checksums             0.1.17               h7f92143_6    conda-forge
aws-crt-cpp               0.24.11              h5bdc202_2    conda-forge
aws-sdk-cpp               1.11.210             h967ea9e_4    conda-forge
bzip2                     1.0.8                hd590300_5    conda-forge
c-ares                    1.23.0               hd590300_0    conda-forge
ca-certificates           2023.11.17           hbcca054_0    conda-forge
cachetools                5.3.2              pyhd8ed1ab_0    conda-forge
cubinlinker               0.3.0           py310hfdf336d_1    rapidsai-nightly
cuda-python               11.8.3          py310h70a93da_0    conda-forge
cuda-version              11.8                 h70ddcb2_2    conda-forge
cudatoolkit               11.8.0              h4ba93d1_12    conda-forge
cudf                      23.12.00a717    cuda11_py310_231212_gfd2f6a6fd1_717    rapidsai-nightly
cupy                      12.3.0          py310hf4db66c_0    conda-forge
dlpack                    0.5                  h9c3ff4c_0    conda-forge
fastrlock                 0.8.2           py310hc6cd4ac_1    conda-forge
fmt                       10.1.1               h00ab1b0_1    conda-forge
fsspec                    2023.12.2          pyhca7485f_0    conda-forge
gflags                    2.2.2             he1b5a44_1004    conda-forge
glog                      0.6.0                h6f12383_0    conda-forge
gmock                     1.14.0               ha770c72_1    conda-forge
gtest                     1.14.0               h00ab1b0_1    conda-forge
icu                       73.2                 h59595ed_0    conda-forge
keyutils                  1.6.1                h166bdaf_0    conda-forge
krb5                      1.21.2               h659d440_0    conda-forge
ld_impl_linux-64          2.40                 h41732ed_0    conda-forge
libabseil                 20230802.1      cxx17_h59595ed_0    conda-forge
libarrow                  14.0.1           h0f82fcc_9_cpu    conda-forge
libarrow-acero            14.0.1           h59595ed_9_cpu    conda-forge
libarrow-dataset          14.0.1           h59595ed_9_cpu    conda-forge
libarrow-flight           14.0.1           h120cb0d_9_cpu    conda-forge
libarrow-flight-sql       14.0.1           h61ff412_9_cpu    conda-forge
libarrow-gandiva          14.0.1           hacb8726_9_cpu    conda-forge
libarrow-substrait        14.0.1           h61ff412_9_cpu    conda-forge
libblas                   3.9.0           20_linux64_openblas    conda-forge
libbrotlicommon           1.1.0                hd590300_1    conda-forge
libbrotlidec              1.1.0                hd590300_1    conda-forge
libbrotlienc              1.1.0                hd590300_1    conda-forge
libcblas                  3.9.0           20_linux64_openblas    conda-forge
libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge
libcudf                   23.12.00a717    cuda11_231212_gfd2f6a6fd1_717    rapidsai-nightly
libcufile                 1.4.0.31                      0    nvidia
libcufile-dev             1.4.0.31                      0    nvidia
libcurl                   8.5.0                hca28451_0    conda-forge
libedit                   3.1.20191231         he28a2e2_2    conda-forge
libev                     4.33                 hd590300_2    conda-forge
libevent                  2.1.12               hf998b51_1    conda-forge
libffi                    3.4.2                h7f98852_5    conda-forge
libgcc-ng                 13.2.0               h807b86a_3    conda-forge
libgfortran-ng            13.2.0               h69a702a_3    conda-forge
libgfortran5              13.2.0               ha4646dd_3    conda-forge
libgomp                   13.2.0               h807b86a_3    conda-forge
libgoogle-cloud           2.12.0               h5206363_4    conda-forge
libgrpc                   1.59.3               hd6c4280_0    conda-forge
libiconv                  1.17                 hd590300_1    conda-forge
libkvikio                 23.12.00a       cuda11_231212_g26efdd1_23    rapidsai-nightly
liblapack                 3.9.0           20_linux64_openblas    conda-forge
libllvm14                 14.0.6               hcd5def8_4    conda-forge
libllvm15                 15.0.7               hb3ce162_4    conda-forge
libnghttp2                1.58.0               h47da74e_1    conda-forge
libnsl                    2.0.1                hd590300_0    conda-forge
libnuma                   2.0.16               h0b41bf4_1    conda-forge
libopenblas               0.3.25          pthreads_h413a1c8_0    conda-forge
libparquet                14.0.1           h352af49_9_cpu    conda-forge
libprotobuf               4.24.4               hf27288f_0    conda-forge
libre2-11                 2023.06.02           h7a70373_0    conda-forge
librmm                    23.12.00             h4725429_0    conda-forge
libsqlite                 3.44.2               h2797004_0    conda-forge
libssh2                   1.11.0               h0841786_0    conda-forge
libstdcxx-ng              13.2.0               h7e041cc_3    conda-forge
libthrift                 0.19.0               hb90f79a_1    conda-forge
libutf8proc               2.8.0                h166bdaf_0    conda-forge
libuuid                   2.38.1               h0b41bf4_0    conda-forge
libxml2                   2.12.2               h232c23b_0    conda-forge
libzlib                   1.2.13               hd590300_5    conda-forge
llvmlite                  0.40.1          py310h1b8f574_0    conda-forge
lz4-c                     1.9.4                hcb278e6_0    conda-forge
markdown-it-py            3.0.0              pyhd8ed1ab_0    conda-forge
mdurl                     0.1.0              pyhd8ed1ab_0    conda-forge
ncurses                   6.4                  h59595ed_2    conda-forge
numba                     0.57.1          py310h0f6aa51_0    conda-forge
numpy                     1.24.4          py310ha4c1d20_0    conda-forge
nvcomp                    3.0.4                h838ba91_1    conda-forge
nvtx                      0.2.8           py310h2372a71_1    conda-forge
openssl                   3.2.0                hd590300_1    conda-forge
orc                       1.9.2                h4b38347_0    conda-forge
packaging                 23.2               pyhd8ed1ab_0    conda-forge
pandas                    1.5.3           py310h9b08913_1    conda-forge
pip                       23.3.1             pyhd8ed1ab_0    conda-forge
protobuf                  4.24.4          py310h620c231_0    conda-forge
ptxcompiler               0.8.1           py310h70a93da_2    conda-forge
pyarrow                   14.0.1          py310hf9e7431_9_cpu    conda-forge
pygments                  2.17.2             pyhd8ed1ab_0    conda-forge
python                    3.10.13         hd12c33a_0_cpython    conda-forge
python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge
python_abi                3.10                    4_cp310    conda-forge
pytz                      2023.3.post1       pyhd8ed1ab_0    conda-forge
rdma-core                 49.0                 hd3aeb46_1    conda-forge
re2                       2023.06.02           h2873b5e_0    conda-forge
readline                  8.2                  h8228510_1    conda-forge
rich                      13.7.0             pyhd8ed1ab_0    conda-forge
rmm                       23.12.00        cuda11_py310_231206_g2db5cbb3_0    rapidsai
s2n                       1.4.0                h06160fa_0    conda-forge
setuptools                68.2.2             pyhd8ed1ab_0    conda-forge
six                       1.16.0             pyh6c4a22f_0    conda-forge
snappy                    1.1.10               h9fff704_0    conda-forge
spdlog                    1.12.0               hd2e6256_2    conda-forge
tk                        8.6.13          noxft_h4845f30_101    conda-forge
typing_extensions         4.9.0              pyha770c72_0    conda-forge
tzdata                    2023c                h71feb2d_0    conda-forge
ucx                       1.15.0               hae80064_1    conda-forge
wheel                     0.42.0             pyhd8ed1ab_0    conda-forge
xz                        5.2.6                h166bdaf_0    conda-forge
zstd                      1.5.5                hfc55251_0    conda-forge
```

</details>

**Environment details**

<details><summary>Click here to see environment details</summary><pre>
     
     **git***
     Not inside a git repository
     
     ***OS Information***
     PRETTY_NAME=""Debian GNU/Linux 12 (bookworm)""
     NAME=""Debian GNU/Linux""
     VERSION_ID=""12""
     VERSION=""12 (bookworm)""
     VERSION_CODENAME=bookworm
     ID=debian
     HOME_URL=""https://www.debian.org/""
     SUPPORT_URL=""https://www.debian.org/support""
     BUG_REPORT_URL=""https://bugs.debian.org/""
     Linux debian 6.1.0-12-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.52-1 (2023-09-07) x86_64 GNU/Linux
     
     ***GPU Information***
     Tue Dec 12 14:17:51 2023
     +---------------------------------------------------------------------------------------+
     | NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |
     |-----------------------------------------+----------------------+----------------------+
     | GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
     |                                         |                      |               MIG M. |
     |=========================================+======================+======================|
     |   0  Quadro T2000 with Max-Q ...    On  | 00000000:01:00.0 Off |                  N/A |
     | N/A   49C    P8               1W /  40W |      5MiB /  4096MiB |      0%      Default |
     |                                         |                      |                  N/A |
     +-----------------------------------------+----------------------+----------------------+
     
     +---------------------------------------------------------------------------------------+
     | Processes:                                                                            |
     |  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
     |        ID   ID                                                             Usage      |
     |=======================================================================================|
     |    0   N/A  N/A      1347      G   /usr/lib/xorg/Xorg                            4MiB |
     +---------------------------------------------------------------------------------------+
     
     ***CPU***
     Architecture:                       x86_64
     CPU op-mode(s):                     32-bit, 64-bit
     Address sizes:                      39 bits physical, 48 bits virtual
     Byte Order:                         Little Endian
     CPU(s):                             16
     On-line CPU(s) list:                0-15
     Vendor ID:                          GenuineIntel
     Model name:                         Intel(R) Core(TM) i9-10885H CPU @ 2.40GHz
     CPU family:                         6
     Model:                              165
     Thread(s) per core:                 2
     Core(s) per socket:                 8
     Socket(s):                          1
     Stepping:                           2
     CPU(s) scaling MHz:                 64%
     CPU max MHz:                        5300.0000
     CPU min MHz:                        800.0000
     BogoMIPS:                           4800.00
     Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp pku ospke md_clear flush_l1d arch_capabilities
     Virtualization:                     VT-x
     L1d cache:                          256 KiB (8 instances)
     L1i cache:                          256 KiB (8 instances)
     L2 cache:                           2 MiB (8 instances)
     L3 cache:                           16 MiB (1 instance)
     NUMA node(s):                       1
     NUMA node0 CPU(s):                  0-15
     Vulnerability Gather data sampling: Mitigation; Microcode
     Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled
     Vulnerability L1tf:                 Not affected
     Vulnerability Mds:                  Not affected
     Vulnerability Meltdown:             Not affected
     Vulnerability Mmio stale data:      Mitigation; Clear CPU buffers; SMT vulnerable
     Vulnerability Retbleed:             Mitigation; Enhanced IBRS
     Vulnerability Spec rstack overflow: Not affected
     Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl
     Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
     Vulnerability Spectre v2:           Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence
     Vulnerability Srbds:                Mitigation; Microcode
     Vulnerability Tsx async abort:      Not affected
     
     ***CMake***
     
     ***g++***
     /usr/bin/g++
     g++ (Debian 12.2.0-14) 12.2.0
     Copyright (C) 2022 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
     
     
     ***nvcc***
     /usr/local/cuda-11.8/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2022 NVIDIA Corporation
     Built on Wed_Sep_21_10:33:58_PDT_2022
     Cuda compilation tools, release 11.8, V11.8.89
     Build cuda_11.8.r11.8/compiler.31833905_0
     
     ***Python***
     /home/lidavidm/miniforge3/envs/cudf/bin/python
     Python 3.10.13
     
     ***Environment Variables***
     PATH                            : /home/lidavidm/miniforge3/envs/cudf/bin:/home/lidavidm/miniforge3/condabin:/usr/local/cuda-11.8/bin:/home/lidavidm/go/bin:/home/lidavidm/.local/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
     LD_LIBRARY_PATH                 :
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /home/lidavidm/miniforge3/envs/cudf
     PYTHON_PATH                     :
     
     ***conda packages***
     /home/lidavidm/miniforge3/condabin/conda
     # packages in environment at /home/lidavidm/miniforge3/envs/cudf:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                       2_gnu    conda-forge
     aws-c-auth                0.7.8                h538f98c_2    conda-forge
     aws-c-cal                 0.6.9                h5d48c4d_2    conda-forge
     aws-c-common              0.9.10               hd590300_0    conda-forge
     aws-c-compression         0.2.17               h7f92143_7    conda-forge
     aws-c-event-stream        0.3.2                h0bcb0bb_8    conda-forge
     aws-c-http                0.7.14               hd268abd_3    conda-forge
     aws-c-io                  0.13.36              he0cd244_2    conda-forge
     aws-c-mqtt                0.9.10               h35285c7_2    conda-forge
     aws-c-s3                  0.4.4                h0448019_0    conda-forge
     aws-c-sdkutils            0.1.13               h7f92143_0    conda-forge
     aws-checksums             0.1.17               h7f92143_6    conda-forge
     aws-crt-cpp               0.24.11              h5bdc202_2    conda-forge
     aws-sdk-cpp               1.11.210             h967ea9e_4    conda-forge
     bzip2                     1.0.8                hd590300_5    conda-forge
     c-ares                    1.23.0               hd590300_0    conda-forge
     ca-certificates           2023.11.17           hbcca054_0    conda-forge
     cachetools                5.3.2              pyhd8ed1ab_0    conda-forge
     cubinlinker               0.3.0           py310hfdf336d_1    rapidsai-nightly
     cuda-python               11.8.3          py310h70a93da_0    conda-forge
     cuda-version              11.8                 h70ddcb2_2    conda-forge
     cudatoolkit               11.8.0              h4ba93d1_12    conda-forge
     cudf                      23.12.00a717    cuda11_py310_231212_gfd2f6a6fd1_717    rapidsai-nightly
     cupy                      12.3.0          py310hf4db66c_0    conda-forge
     dlpack                    0.5                  h9c3ff4c_0    conda-forge
     fastrlock                 0.8.2           py310hc6cd4ac_1    conda-forge
     fmt                       10.1.1               h00ab1b0_1    conda-forge
     fsspec                    2023.12.2          pyhca7485f_0    conda-forge
     gflags                    2.2.2             he1b5a44_1004    conda-forge
     glog                      0.6.0                h6f12383_0    conda-forge
     gmock                     1.14.0               ha770c72_1    conda-forge
     gtest                     1.14.0               h00ab1b0_1    conda-forge
     icu                       73.2                 h59595ed_0    conda-forge
     keyutils                  1.6.1                h166bdaf_0    conda-forge
     krb5                      1.21.2               h659d440_0    conda-forge
     ld_impl_linux-64          2.40                 h41732ed_0    conda-forge
     libabseil                 20230802.1      cxx17_h59595ed_0    conda-forge
     libarrow                  14.0.1           h0f82fcc_9_cpu    conda-forge
     libarrow-acero            14.0.1           h59595ed_9_cpu    conda-forge
     libarrow-dataset          14.0.1           h59595ed_9_cpu    conda-forge
     libarrow-flight           14.0.1           h120cb0d_9_cpu    conda-forge
     libarrow-flight-sql       14.0.1           h61ff412_9_cpu    conda-forge
     libarrow-gandiva          14.0.1           hacb8726_9_cpu    conda-forge
     libarrow-substrait        14.0.1           h61ff412_9_cpu    conda-forge
     libblas                   3.9.0           20_linux64_openblas    conda-forge
     libbrotlicommon           1.1.0                hd590300_1    conda-forge
     libbrotlidec              1.1.0                hd590300_1    conda-forge
     libbrotlienc              1.1.0                hd590300_1    conda-forge
     libcblas                  3.9.0           20_linux64_openblas    conda-forge
     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge
     libcudf                   23.12.00a717    cuda11_231212_gfd2f6a6fd1_717    rapidsai-nightly
     libcufile                 1.4.0.31                      0    nvidia
     libcufile-dev             1.4.0.31                      0    nvidia
     libcurl                   8.5.0                hca28451_0    conda-forge
     libedit                   3.1.20191231         he28a2e2_2    conda-forge
     libev                     4.33                 hd590300_2    conda-forge
     libevent                  2.1.12               hf998b51_1    conda-forge
     libffi                    3.4.2                h7f98852_5    conda-forge
     libgcc-ng                 13.2.0               h807b86a_3    conda-forge
     libgfortran-ng            13.2.0               h69a702a_3    conda-forge
     libgfortran5              13.2.0               ha4646dd_3    conda-forge
     libgomp                   13.2.0               h807b86a_3    conda-forge
     libgoogle-cloud           2.12.0               h5206363_4    conda-forge
     libgrpc                   1.59.3               hd6c4280_0    conda-forge
     libiconv                  1.17                 hd590300_1    conda-forge
     libkvikio                 23.12.00a       cuda11_231212_g26efdd1_23    rapidsai-nightly
     liblapack                 3.9.0           20_linux64_openblas    conda-forge
     libllvm14                 14.0.6               hcd5def8_4    conda-forge
     libllvm15                 15.0.7               hb3ce162_4    conda-forge
     libnghttp2                1.58.0               h47da74e_1    conda-forge
     libnsl                    2.0.1                hd590300_0    conda-forge
     libnuma                   2.0.16               h0b41bf4_1    conda-forge
     libopenblas               0.3.25          pthreads_h413a1c8_0    conda-forge
     libparquet                14.0.1           h352af49_9_cpu    conda-forge
     libprotobuf               4.24.4               hf27288f_0    conda-forge
     libre2-11                 2023.06.02           h7a70373_0    conda-forge
     librmm                    23.12.00             h4725429_0    conda-forge
     libsqlite                 3.44.2               h2797004_0    conda-forge
     libssh2                   1.11.0               h0841786_0    conda-forge
     libstdcxx-ng              13.2.0               h7e041cc_3    conda-forge
     libthrift                 0.19.0               hb90f79a_1    conda-forge
     libutf8proc               2.8.0                h166bdaf_0    conda-forge
     libuuid                   2.38.1               h0b41bf4_0    conda-forge
     libxml2                   2.12.2               h232c23b_0    conda-forge
     libzlib                   1.2.13               hd590300_5    conda-forge
     llvmlite                  0.40.1          py310h1b8f574_0    conda-forge
     lz4-c                     1.9.4                hcb278e6_0    conda-forge
     markdown-it-py            3.0.0              pyhd8ed1ab_0    conda-forge
     mdurl                     0.1.0              pyhd8ed1ab_0    conda-forge
     ncurses                   6.4                  h59595ed_2    conda-forge
     numba                     0.57.1          py310h0f6aa51_0    conda-forge
     numpy                     1.24.4          py310ha4c1d20_0    conda-forge
     nvcomp                    3.0.4                h838ba91_1    conda-forge
     nvtx                      0.2.8           py310h2372a71_1    conda-forge
     openssl                   3.2.0                hd590300_1    conda-forge
     orc                       1.9.2                h4b38347_0    conda-forge
     packaging                 23.2               pyhd8ed1ab_0    conda-forge
     pandas                    1.5.3           py310h9b08913_1    conda-forge
     pip                       23.3.1             pyhd8ed1ab_0    conda-forge
     protobuf                  4.24.4          py310h620c231_0    conda-forge
     ptxcompiler               0.8.1           py310h70a93da_2    conda-forge
     pyarrow                   14.0.1          py310hf9e7431_9_cpu    conda-forge
     pygments                  2.17.2             pyhd8ed1ab_0    conda-forge
     python                    3.10.13         hd12c33a_0_cpython    conda-forge
     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge
     python_abi                3.10                    4_cp310    conda-forge
     pytz                      2023.3.post1       pyhd8ed1ab_0    conda-forge
     rdma-core                 49.0                 hd3aeb46_1    conda-forge
     re2                       2023.06.02           h2873b5e_0    conda-forge
     readline                  8.2                  h8228510_1    conda-forge
     rich                      13.7.0             pyhd8ed1ab_0    conda-forge
     rmm                       23.12.00        cuda11_py310_231206_g2db5cbb3_0    rapidsai
     s2n                       1.4.0                h06160fa_0    conda-forge
     setuptools                68.2.2             pyhd8ed1ab_0    conda-forge
     six                       1.16.0             pyh6c4a22f_0    conda-forge
     snappy                    1.1.10               h9fff704_0    conda-forge
     spdlog                    1.12.0               hd2e6256_2    conda-forge
     tk                        8.6.13          noxft_h4845f30_101    conda-forge
     typing_extensions         4.9.0              pyha770c72_0    conda-forge
     tzdata                    2023c                h71feb2d_0    conda-forge
     ucx                       1.15.0               hae80064_1    conda-forge
     wheel                     0.42.0             pyhd8ed1ab_0    conda-forge
     xz                        5.2.6                h166bdaf_0    conda-forge
     zstd                      1.5.5                hfc55251_0    conda-forge
     
</pre></details>

**Additional context**

I'm actually using C++, but chose Python to reproduce.
",2023-12-12T19:27:33Z,0,0,David Li,
316,[BUG] `as_column` of pandas timestamps delivers different resolution datetime depending on whether we pass a scalar or list,"**Describe the bug**

```
import pandas as pd
from cudf.core.column import as_column

data = pd.Timestamp(""2000-01-01"")

from_scalar = as_column(data)
from_list = as_column([data])

assert from_scalar.dtype == from_list.dtype # False
```

**Expected behavior**

The resolution should be inferred consistently. Note that `cudf.Scalar(data)` infers the same (nanosecond) resolution as `as_column([data])`.",2023-12-14T11:33:07Z,0,0,Lawrence Mitchell,
317,[QST] Calling cudf.dataframe.apply from c++ or porting to libcudf ,"Dear Rapids.Ai Team,

in the cuDF python API documentation there are several methods which are not in libcudf for c++:
cudf.dataframe.apply
cudf.dataframe.applymap
cudf.dataframe.apply_rows
cudf.dataframe.apply_chunks

1) Is there any chance that those functions will be made available in libcudf for c++ ?
2) Is there a way we could call the cuDF python functions from libcudf c++ context or from a general c++ context using pybind11 or  python c-api ?
3) Could you enhance the examples section with such a code which shows how to call python cuDF from c++ ?

Best regards
Developer
",2023-12-14T13:10:54Z,0,0,,Freelancer
318,"[BUG] For certain parquet list schemas, the root PageNestingInfo struct can end up uninitialized.","
Inside of the `allocate_nesting_info` function, we allocate PageNestingInfo and PageNestingDecodeInfo structs and initialize them.  However, the logic for traversing the schema in the file can sometimes leave the 0th element uninitialized.  This is a mild bug that leads to a slightly wrong size calculating for output chunk sizes in the chunked reader.  

The easiest way to repro is with the file `python/cudf/cudf/tests/data/parquet/one_level_list.parquet`

",2023-12-14T21:40:52Z,0,0,,
319,[QST] How'd this work with multi-threading pandas ? ,"**What is your question?**
I have a multi-thread pandas process to divide large dataset by date ranges  then combine them,  trying cudf now for speed . 

It does something like this ,  args contains the start/end_dt for each segment, run to process segments
while Pool() as pool : 
   result = pool.starmap(run,  args)

However , running in cudf it  threw this error just now. 
__pickle.PicklingError: Can't pickle <built-in function _timedelta_unpickle>: it's not the same object as pandas._libs.tslibs.timedeltas._timedelta_unpickle_
",2023-12-20T07:47:29Z,0,0,Henry Zhang,
320,[QST] Does the read_json() method support GPU acceleration?,"At first, I see this article: [GPU-Accelerated JSON Data Processing with RAPIDS](https://developer.nvidia.com/blog/gpu-accelerated-json-data-processing-with-rapids/)
I follow it to use the cudf.read_json(), but I get the warning
`UserWarning: Using CPU via Pandas to read JSON dataset, this may be GPU accelerated in the future` 
and I use `%%cudf.pandas.line_profile`, it shows there is no GPU TIME.
![image](https://github.com/rapidsai/cudf/assets/76741680/e96c4355-e6f9-430e-be36-71a78159ebd7)

But, when I load the cudf before by running `%load_ext cudf.pandas`
and I change `import cudf as pd` to `import pandas as pd`
It still has the warning, but show the GPU TIME.
So I want to know does the read_json() method support GPU acceleration?
![image](https://github.com/rapidsai/cudf/assets/76741680/5d4465aa-7b41-47af-bfbf-9692ff1025c8)

",2023-12-25T10:13:46Z,0,0,TX,NJUPT
321,"[BUG] The read_json() method of cudf can't parse the string like ""5-0""","**Describe the bug**
The read_json() method of cudf can't parse the string like ""5-0"".
It seems that the number in front cannot be larger than the number in the back.

**Steps/Code to reproduce bug**
run code
```
import cudf as pd

data = '''[{""id"":""1"",""Col_01"":""test"",""Col_02"":""77""},

{""id"":""2"",""Col_01"":""test"",""Col_02"":""1355-0652142""}]
'''

df = pd.read_json(data, orient = ""records"")

df
```
get error
![image](https://github.com/rapidsai/cudf/assets/76741680/b8998b5d-a4e6-4ea3-83d0-4474dccfc39b)

If I use the normal pandas, it can get the correct answer.
```
import pandas as pd

data = '''[{""id"":""1"",""Col_01"":""test"",""Col_02"":""77""},

{""id"":""2"",""Col_01"":""test"",""Col_02"":""1355-0652142""}]
'''

df = pd.read_json(data, orient = ""records"")

df
```
If I change the `5-0` to `5-5` and still use cudf, it also right.
```
import cudf as pd

data = '''[{""id"":""1"",""Col_01"":""test"",""Col_02"":""77""},

{""id"":""2"",""Col_01"":""test"",""Col_02"":""1355-5652142""}]
'''

df = pd.read_json(data, orient = ""records"")

df
```

**Environment overview (please complete the following information)**
 - Environment location: Bare-metal
 - Method of cuDF install: pip

",2023-12-25T10:32:51Z,0,0,TX,NJUPT
322,[BUG] Type checks fail with cuDF pandas objects,"**Describe the bug**
Some type checks fail with cuDF pandas objects.

**Steps/Code to reproduce bug**
The following examples fail with assertion errors:
```
import cudf.pandas
cudf.pandas.install()
import pandas as pd

freq = ""D""
assert isinstance(pd.tseries.frequencies.to_offset(freq), pd.tseries.offsets.BaseOffset)
```

```
import cudf.pandas
import numpy as np
cudf.pandas.install()
import pandas as pd

df = pd.DataFrame([0, 1, 2])

assert isinstance(df.to_numpy(), np.ndarray)
```

Both of these examples pass if we remove the `cudf.pandas.install()` line.

**Expected behavior**
I expected the code blocks above to run so that I could use the accelerated version of pandas with zero code changes. The errors I'm facing make it difficult to work with cuDF pandas and other libraries (e.g. https://github.com/Nixtla/statsforecast).

**Environment overview (please complete the following information)**
 - Environment location: Bare-metal
 - Method of cuDF install: conda

**Environment details**

<details><summary>Click here to see environment details</summary><pre>
     
     **git***
     Not inside a git repository
     
     ***OS Information***
     DISTRIB_ID=Ubuntu
     DISTRIB_RELEASE=20.04
     DISTRIB_CODENAME=focal
     DISTRIB_DESCRIPTION=""Ubuntu 20.04.4 LTS""
     NAME=""Ubuntu""
     VERSION=""20.04.4 LTS (Focal Fossa)""
     ID=ubuntu
     ID_LIKE=debian
     PRETTY_NAME=""Ubuntu 20.04.4 LTS""
     VERSION_ID=""20.04""
     HOME_URL=""https://www.ubuntu.com/""
     SUPPORT_URL=""https://help.ubuntu.com/""
     BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
     PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
     VERSION_CODENAME=focal
     UBUNTU_CODENAME=focal
     Linux TurinTech-0004 5.15.0-91-generic #101~20.04.1-Ubuntu SMP Thu Nov 16 14:22:28 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux
     
     ***GPU Information***
     Wed Dec 27 21:18:49 2023
     +-----------------------------------------------------------------------------+
     | NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |
     |-------------------------------+----------------------+----------------------+
     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
     |                               |                      |               MIG M. |
     |===============================+======================+======================|
     |   0  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |
     |  0%   54C    P8    22W / 170W |   1681MiB / 12288MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     
     +-----------------------------------------------------------------------------+
     | Processes:                                                                  |
     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
     |        ID   ID                                                   Usage      |
     |=============================================================================|
     |    0   N/A  N/A      1512      G   /usr/lib/xorg/Xorg                198MiB |
     |    0   N/A  N/A      2685      G   /usr/lib/xorg/Xorg               1239MiB |
     |    0   N/A  N/A      2814      G   /usr/bin/gnome-shell               22MiB |
     |    0   N/A  N/A      3403      G   ...AAAAAAAAA= --shared-files      198MiB |
     |    0   N/A  N/A      5817      G   gnome-control-center                2MiB |
     +-----------------------------------------------------------------------------+
     
     ***CPU***
     Architecture:                       x86_64
     CPU op-mode(s):                     32-bit, 64-bit
     Byte Order:                         Little Endian
     Address sizes:                      48 bits physical, 48 bits virtual
     CPU(s):                             24
     On-line CPU(s) list:                0-23
     Thread(s) per core:                 2
     Core(s) per socket:                 12
     Socket(s):                          1
     NUMA node(s):                       1
     Vendor ID:                          AuthenticAMD
     CPU family:                         25
     Model:                              33
     Model name:                         AMD Ryzen 9 5900X 12-Core Processor
     Stepping:                           0
     Frequency boost:                    enabled
     CPU MHz:                            3597.987
     CPU max MHz:                        3700.0000
     CPU min MHz:                        2200.0000
     BogoMIPS:                           7386.52
     Virtualisation:                     AMD-V
     L1d cache:                          384 KiB
     L1i cache:                          384 KiB
     L2 cache:                           6 MiB
     L3 cache:                           64 MiB
     NUMA node0 CPU(s):                  0-23
     Vulnerability Gather data sampling: Not affected
     Vulnerability Itlb multihit:        Not affected
     Vulnerability L1tf:                 Not affected
     Vulnerability Mds:                  Not affected
     Vulnerability Meltdown:             Not affected
     Vulnerability Mmio stale data:      Not affected
     Vulnerability Retbleed:             Not affected
     Vulnerability Spec rstack overflow: Mitigation; safe RET, no microcode
     Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp
     Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
     Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP always-on, RSB filling, PBRSB-eIBRS Not affected
     Vulnerability Srbds:                Not affected
     Vulnerability Tsx async abort:      Not affected
     Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm
     
     ***CMake***
     
     ***g++***
     /usr/bin/g++
     g++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
     Copyright (C) 2019 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
     
     
     ***nvcc***
     /home/paul/anaconda3/envs/rapids-23.12/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2022 NVIDIA Corporation
     Built on Mon_Oct_24_19:12:58_PDT_2022
     Cuda compilation tools, release 12.0, V12.0.76
     Build cuda_12.0.r12.0/compiler.31968024_0
     
     ***Python***
     /home/paul/anaconda3/envs/rapids-23.12/bin/python
     Python 3.9.18
     
     ***Environment Variables***
     PATH                            : /home/paul/.local/bin:/home/paul/.cargo/bin:/home/paul/anaconda3/envs/rapids-23.12/bin:/home/paul/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
     LD_LIBRARY_PATH                 :
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /home/paul/anaconda3/envs/rapids-23.12
     PYTHON_PATH                     :
     
     ***conda packages***
     /home/paul/anaconda3/condabin/conda
     # packages in environment at /home/paul/anaconda3/envs/rapids-23.12:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                       2_gnu    conda-forge
     accelerate                0.19.0                   pypi_0    pypi
     adagio                    0.2.4                    pypi_0    pypi
     aiohttp                   3.9.1            py39hd1e30aa_0    conda-forge
     aiosignal                 1.3.1              pyhd8ed1ab_0    conda-forge
     alabaster                 0.7.13                   pypi_0    pypi
     alembic                   1.13.1                   pypi_0    pypi
     antlr4-python3-runtime    4.11.1                   pypi_0    pypi
     anyio                     4.2.0              pyhd8ed1ab_0    conda-forge
     aom                       3.7.1                h59595ed_0    conda-forge
     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
     argon2-cffi               23.1.0             pyhd8ed1ab_0    conda-forge
     argon2-cffi-bindings      21.2.0           py39hd1e30aa_4    conda-forge
     arrow                     1.3.0              pyhd8ed1ab_0    conda-forge
     astroid                   2.15.8                   pypi_0    pypi
     async-timeout             4.0.3              pyhd8ed1ab_0    conda-forge
     attrs                     23.1.0             pyh71513ae_1    conda-forge
     aws-c-auth                0.7.8                hcf8cf63_3    conda-forge
     aws-c-cal                 0.6.9                h5d48c4d_2    conda-forge
     aws-c-common              0.9.10               hd590300_0    conda-forge
     aws-c-compression         0.2.17               h7f92143_7    conda-forge
     aws-c-event-stream        0.3.2                h0bcb0bb_8    conda-forge
     aws-c-http                0.7.15               hd268abd_0    conda-forge
     aws-c-io                  0.13.36              he0cd244_2    conda-forge
     aws-c-mqtt                0.10.0               hbafccad_1    conda-forge
     aws-c-s3                  0.4.5                h47b1690_1    conda-forge
     aws-c-sdkutils            0.1.13               h7f92143_0    conda-forge
     aws-checksums             0.1.17               h7f92143_6    conda-forge
     aws-crt-cpp               0.25.0               h169d4cb_3    conda-forge
     aws-sdk-cpp               1.11.210             h0853bfa_5    conda-forge
     azure-core-cpp            1.10.3               h91d86a7_0    conda-forge
     azure-storage-blobs-cpp   12.10.0              h00ab1b0_0    conda-forge
     azure-storage-common-cpp  12.5.0               hb858b4b_2    conda-forge
     babel                     2.14.0                   pypi_0    pypi
     beautifulsoup4            4.12.2             pyha770c72_0    conda-forge
     black                     23.7.0                   pypi_0    pypi
     bleach                    6.1.0              pyhd8ed1ab_0    conda-forge
     blosc                     1.21.5               h0f2a231_0    conda-forge
     bokeh                     3.3.2              pyhd8ed1ab_0    conda-forge
     branca                    0.7.0              pyhd8ed1ab_1    conda-forge
     brotli                    1.1.0                hd590300_1    conda-forge
     brotli-bin                1.1.0                hd590300_1    conda-forge
     brotli-python             1.1.0            py39h3d6467e_1    conda-forge
     brunsli                   0.1                  h9c3ff4c_0    conda-forge
     bzip2                     1.0.8                hd590300_5    conda-forge
     c-ares                    1.24.0               hd590300_0    conda-forge
     c-blosc2                  2.11.3               hb4ffafa_0    conda-forge
     ca-certificates           2023.11.17           hbcca054_0    conda-forge
     cached-property           1.5.2                hd8ed1ab_1    conda-forge
     cached_property           1.5.2              pyha770c72_1    conda-forge
     cachetools                5.3.2              pyhd8ed1ab_0    conda-forge
     cairo                     1.18.0               h3faef2a_0    conda-forge
     catboost                  1.2.2                    pypi_0    pypi
     category-encoders         2.6.3                    pypi_0    pypi
     certifi                   2023.11.17         pyhd8ed1ab_0    conda-forge
     cffi                      1.16.0           py39h7a31438_0    conda-forge
     cfgv                      3.4.0                    pypi_0    pypi
     cfitsio                   4.3.1                hbdc6101_0    conda-forge
     charls                    2.4.2                h59595ed_0    conda-forge
     charset-normalizer        3.3.2              pyhd8ed1ab_0    conda-forge
     click                     8.0.4                    pypi_0    pypi
     click-plugins             1.1.1                      py_0    conda-forge
     cligj                     0.7.2              pyhd8ed1ab_1    conda-forge
     cloudpickle               3.0.0              pyhd8ed1ab_0    conda-forge
     cmaes                     0.10.0                   pypi_0    pypi
     colorama                  0.4.6              pyhd8ed1ab_0    conda-forge
     colorcet                  3.0.1              pyhd8ed1ab_0    conda-forge
     colorlog                  6.8.0                    pypi_0    pypi
     contourpy                 1.2.0            py39h7633fee_0    conda-forge
     coverage                  7.3.4                    pypi_0    pypi
     cryptography              41.0.7                   pypi_0    pypi
     cucim                     23.12.01        cuda12_py39_231211_ga3445df_0    rapidsai
     cuda-cccl_linux-64        12.0.90              ha770c72_1    conda-forge
     cuda-cudart               12.0.107             hd3aeb46_8    conda-forge
     cuda-cudart-dev           12.0.107             hd3aeb46_8    conda-forge
     cuda-cudart-dev_linux-64  12.0.107             h59595ed_8    conda-forge
     cuda-cudart-static        12.0.107             hd3aeb46_8    conda-forge
     cuda-cudart-static_linux-64 12.0.107             h59595ed_8    conda-forge
     cuda-cudart_linux-64      12.0.107             h59595ed_8    conda-forge
     cuda-nvcc-dev_linux-64    12.0.76              ha770c72_1    conda-forge
     cuda-nvcc-impl            12.0.76              h59595ed_1    conda-forge
     cuda-nvcc-tools           12.0.76              h59595ed_1    conda-forge
     cuda-nvrtc                12.0.76              hd3aeb46_2    conda-forge
     cuda-nvtx                 12.0.76              h59595ed_1    conda-forge
     cuda-profiler-api         12.0.76              ha770c72_0    conda-forge
     cuda-python               12.0.0           py39h2d39e0c_4    conda-forge
     cuda-version              12.0                 hffde075_2    conda-forge
     cudf                      23.12.01        cuda12_py39_231208_g2ce46216b5_0    rapidsai
     cudf_kafka                23.12.01        cuda12_py39_231208_g2ce46216b5_0    rapidsai
     cugraph                   23.12.00        cuda12_py39_231206_g1309813f_0    rapidsai
     cuml                      23.12.00        cuda12_py39_231206_gad2bd2b65_0    rapidsai
     cuproj                    23.12.00        cuda12_py39_231206_g3a357729_0    rapidsai
     cupy                      12.3.0           py39hc7c1505_0    conda-forge
     cuspatial                 23.12.01        cuda12_py39_231207_g16727064_0    rapidsai
     custreamz                 23.12.01        cuda12_py39_231208_g2ce46216b5_0    rapidsai
     cuxfilter                 23.12.00        cuda12_py39_231206_g63dabeb_0    rapidsai
     cycler                    0.12.1             pyhd8ed1ab_0    conda-forge
     cyrus-sasl                2.1.27               h54b06d7_7    conda-forge
     cython                    3.0.7                    pypi_0    pypi
     cytoolz                   0.12.2           py39hd1e30aa_1    conda-forge
     daal                      2023.2.0                 pypi_0    pypi
     daal4py                   2023.2.0                 pypi_0    pypi
     darts                     0.27.1                   pypi_0    pypi
     dask                      2023.11.0          pyhd8ed1ab_0    conda-forge
     dask-core                 2023.11.0          pyhd8ed1ab_0    conda-forge
     dask-cuda                 23.12.00        py39_231206_ge1638ae_0    rapidsai
     dask-cudf                 23.12.01        cuda12_py39_231208_g2ce46216b5_0    rapidsai
     datasets                  2.15.0                   pypi_0    pypi
     datashader                0.16.0             pyhd8ed1ab_0    conda-forge
     dav1d                     1.2.1                hd590300_0    conda-forge
     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge
     deprecated                1.2.14                   pypi_0    pypi
     dill                      0.3.7                    pypi_0    pypi
     distlib                   0.3.8                    pypi_0    pypi
     distributed               2023.11.0          pyhd8ed1ab_0    conda-forge
     dlpack                    0.5                  h9c3ff4c_0    conda-forge
     docutils                  0.18.1                   pypi_0    pypi
     entrypoints               0.4                pyhd8ed1ab_0    conda-forge
     exceptiongroup            1.2.0              pyhd8ed1ab_0    conda-forge
     execnet                   2.0.2                    pypi_0    pypi
     expat                     2.5.0                hcb278e6_1    conda-forge
     fastrlock                 0.8.2            py39h3d6467e_2    conda-forge
     filelock                  3.13.1                   pypi_0    pypi
     fiona                     1.9.5            py39hcfcd403_2    conda-forge
     flake8                    6.0.0                    pypi_0    pypi
     fmt                       9.1.0                h924138e_0    conda-forge
     folium                    0.15.1             pyhd8ed1ab_0    conda-forge
     font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge
     font-ttf-inconsolata      3.000                h77eed37_0    conda-forge
     font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge
     font-ttf-ubuntu           0.83                 h77eed37_1    conda-forge
     fontconfig                2.14.2               h14ed4e7_0    conda-forge
     fonts-conda-ecosystem     1                             0    conda-forge
     fonts-conda-forge         1                             0    conda-forge
     fonttools                 4.47.0           py39hd1e30aa_0    conda-forge
     fqdn                      1.5.1              pyhd8ed1ab_0    conda-forge
     freetype                  2.12.1               h267a509_2    conda-forge
     freexl                    2.0.0                h743c826_0    conda-forge
     frozendict                2.3.10                   pypi_0    pypi
     frozenlist                1.4.1            py39hd1e30aa_0    conda-forge
     fs                        2.4.16                   pypi_0    pypi
     fsspec                    2023.10.0                pypi_0    pypi
     fugue                     0.8.7                    pypi_0    pypi
     fugue-sql-antlr           0.2.0                    pypi_0    pypi
     gdal                      3.8.2            py39h14df8fe_0    conda-forge
     gdk-pixbuf                2.42.10              h829c605_4    conda-forge
     geopandas                 0.14.1             pyhd8ed1ab_0    conda-forge
     geopandas-base            0.14.1             pyha770c72_0    conda-forge
     geos                      3.12.1               h59595ed_0    conda-forge
     geotiff                   1.7.1               h6b2125f_15    conda-forge
     gettext                   0.21.1               h27087fc_0    conda-forge
     gflags                    2.2.2             he1b5a44_1004    conda-forge
     giflib                    5.2.1                h0b41bf4_3    conda-forge
     glog                      0.6.0                h6f12383_0    conda-forge
     gmock                     1.14.0               ha770c72_1    conda-forge
     greenlet                  3.0.3                    pypi_0    pypi
     gtest                     1.14.0               h00ab1b0_1    conda-forge
     hdf4                      4.2.15               h2a13503_7    conda-forge
     hdf5                      1.14.3          nompi_h4f84152_100    conda-forge
     holidays                  0.27                     pypi_0    pypi
     holoviews                 1.18.1             pyhd8ed1ab_0    conda-forge
     huggingface-hub           0.20.1                   pypi_0    pypi
     icu                       73.2                 h59595ed_0    conda-forge
     identify                  2.5.33                   pypi_0    pypi
     idna                      3.6                pyhd8ed1ab_0    conda-forge
     imagecodecs               2023.9.18        py39hf9b8f0e_2    conda-forge
     imageio                   2.33.1             pyh8c1a49c_0    conda-forge
     imagesize                 1.4.1                    pypi_0    pypi
     imbalanced-learn          0.11.0                   pypi_0    pypi
     importlib-metadata        7.0.0              pyha770c72_0    conda-forge
     importlib-resources       6.1.1              pyhd8ed1ab_0    conda-forge
     importlib_metadata        7.0.0                hd8ed1ab_0    conda-forge
     importlib_resources       6.1.1              pyhd8ed1ab_0    conda-forge
     iniconfig                 2.0.0                    pypi_0    pypi
     isoduration               20.11.0            pyhd8ed1ab_0    conda-forge
     isort                     5.13.2                   pypi_0    pypi
     jaraco-classes            3.3.0                    pypi_0    pypi
     jbig                      2.1               h7f98852_2003    conda-forge
     jeepney                   0.8.0                    pypi_0    pypi
     jinja2                    3.1.2              pyhd8ed1ab_1    conda-forge
     joblib                    1.3.2              pyhd8ed1ab_0    conda-forge
     json-c                    0.17                 h7ab15ed_0    conda-forge
     jsonpointer               2.4              py39hf3d152e_3    conda-forge
     jsonschema                4.20.0             pyhd8ed1ab_0    conda-forge
     jsonschema-specifications 2023.11.2          pyhd8ed1ab_0    conda-forge
     jsonschema-with-format-nongpl 4.20.0             pyhd8ed1ab_0    conda-forge
     jupyter-server-proxy      4.1.0              pyhd8ed1ab_0    conda-forge
     jupyter_client            8.6.0              pyhd8ed1ab_0    conda-forge
     jupyter_core              5.5.1            py39hf3d152e_0    conda-forge
     jupyter_events            0.9.0              pyhd8ed1ab_0    conda-forge
     jupyter_server            2.12.1             pyhd8ed1ab_0    conda-forge
     jupyter_server_terminals  0.5.0              pyhd8ed1ab_0    conda-forge
     jupyterlab_pygments       0.3.0              pyhd8ed1ab_0    conda-forge
     jxrlib                    1.1                  h7f98852_2    conda-forge
     kealib                    1.5.3                h2f55d51_0    conda-forge
     keyring                   24.3.0                   pypi_0    pypi
     keyutils                  1.6.1                h166bdaf_0    conda-forge
     kiwisolver                1.4.5            py39h7633fee_1    conda-forge
     krb5                      1.21.2               h659d440_0    conda-forge
     lazy-object-proxy         1.10.0                   pypi_0    pypi
     lazy_loader               0.3                pyhd8ed1ab_0    conda-forge
     lcms2                     2.16                 hb7c19ff_0    conda-forge
     ld_impl_linux-64          2.40                 h41732ed_0    conda-forge
     lerc                      4.0.0                h27087fc_0    conda-forge
     libabseil                 20230802.1      cxx17_h59595ed_0    conda-forge
     libaec                    1.1.2                h59595ed_1    conda-forge
     libarchive                3.7.2                h2aa1ff5_1    conda-forge
     libarrow                  14.0.2           hfb4d3a9_0_cpu    conda-forge
     libarrow-acero            14.0.2           h59595ed_0_cpu    conda-forge
     libarrow-dataset          14.0.2           h59595ed_0_cpu    conda-forge
     libarrow-flight           14.0.2           h120cb0d_0_cpu    conda-forge
     libarrow-flight-sql       14.0.2           h61ff412_0_cpu    conda-forge
     libarrow-gandiva          14.0.2           hacb8726_0_cpu    conda-forge
     libarrow-substrait        14.0.2           h61ff412_0_cpu    conda-forge
     libavif16                 1.0.3                hef5bec9_1    conda-forge
     libblas                   3.9.0           20_linux64_openblas    conda-forge
     libboost-headers          1.84.0               ha770c72_0    conda-forge
     libbrotlicommon           1.1.0                hd590300_1    conda-forge
     libbrotlidec              1.1.0                hd590300_1    conda-forge
     libbrotlienc              1.1.0                hd590300_1    conda-forge
     libcblas                  3.9.0           20_linux64_openblas    conda-forge
     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge
     libcublas                 12.0.1.189           hd3aeb46_3    conda-forge
     libcublas-dev             12.0.1.189           hd3aeb46_3    conda-forge
     libcucim                  23.12.01        cuda12_231211_ga3445df_0    rapidsai
     libcudf                   23.12.01        cuda12_231208_g2ce46216b5_0    rapidsai
     libcudf_kafka             23.12.01        cuda12_231208_g2ce46216b5_0    rapidsai
     libcufft                  11.0.0.21            hd3aeb46_2    conda-forge
     libcufile                 1.5.0.59             hd3aeb46_1    conda-forge
     libcufile-dev             1.5.0.59             hd3aeb46_1    conda-forge
     libcugraph                23.12.00        cuda12_231206_g1309813f_0    rapidsai
     libcugraph_etl            23.12.00        cuda12_231206_g1309813f_0    rapidsai
     libcugraphops             23.12.00        cuda12_231206_g42d08202_0    nvidia
     libcuml                   23.12.00        cuda12_231206_gad2bd2b65_0    rapidsai
     libcumlprims              23.12.00        cuda12_231206_gc120fe0_0    nvidia
     libcurand                 10.3.1.50            hd3aeb46_1    conda-forge
     libcurand-dev             10.3.1.50            hd3aeb46_1    conda-forge
     libcurl                   8.5.0                hca28451_0    conda-forge
     libcusolver               11.4.2.57            hd3aeb46_2    conda-forge
     libcusolver-dev           11.4.2.57            hd3aeb46_2    conda-forge
     libcusparse               12.0.0.76            hd3aeb46_2    conda-forge
     libcusparse-dev           12.0.0.76            hd3aeb46_2    conda-forge
     libcuspatial              23.12.01        cuda12_231207_g16727064_0    rapidsai
     libdeflate                1.19                 hd590300_0    conda-forge
     libedit                   3.1.20191231         he28a2e2_2    conda-forge
     libev                     4.33                 hd590300_2    conda-forge
     libevent                  2.1.12               hf998b51_1    conda-forge
     libexpat                  2.5.0                hcb278e6_1    conda-forge
     libffi                    3.4.2                h7f98852_5    conda-forge
     libgcc-ng                 13.2.0               h807b86a_3    conda-forge
     libgdal                   3.8.2                hed8bd54_0    conda-forge
     libgfortran-ng            13.2.0               h69a702a_3    conda-forge
     libgfortran5              13.2.0               ha4646dd_3    conda-forge
     libglib                   2.78.3               h783c2da_0    conda-forge
     libgomp                   13.2.0               h807b86a_3    conda-forge
     libgoogle-cloud           2.12.0               h5206363_4    conda-forge
     libgrpc                   1.59.3               hd6c4280_0    conda-forge
     libiconv                  1.17                 hd590300_2    conda-forge
     libjpeg-turbo             3.0.0                hd590300_1    conda-forge
     libkml                    1.3.0             h01aab08_1018    conda-forge
     libkvikio                 23.12.00        cuda12_231206_gf90bfbe_0    rapidsai
     liblapack                 3.9.0           20_linux64_openblas    conda-forge
     libllvm14                 14.0.6               hcd5def8_4    conda-forge
     libllvm15                 15.0.7               hb3ce162_4    conda-forge
     libnetcdf                 4.9.2           nompi_h9612171_113    conda-forge
     libnghttp2                1.58.0               h47da74e_1    conda-forge
     libnl                     3.9.0                hd590300_0    conda-forge
     libnsl                    2.0.1                hd590300_0    conda-forge
     libntlm                   1.4               h7f98852_1002    conda-forge
     libnuma                   2.0.16               h0b41bf4_1    conda-forge
     libnvjitlink              12.0.76              hd3aeb46_2    conda-forge
     libnvjpeg                 12.0.0.28            h59595ed_1    conda-forge
     libopenblas               0.3.25          pthreads_h413a1c8_0    conda-forge
     libparquet                14.0.2           h352af49_0_cpu    conda-forge
     libpng                    1.6.39               h753d276_0    conda-forge
     libpq                     16.1                 h33b98f1_7    conda-forge
     libprotobuf               4.24.4               hf27288f_0    conda-forge
     libraft                   23.12.00        cuda12_231206_g9e2d6277_0    rapidsai
     libraft-headers           23.12.00        cuda12_231206_g9e2d6277_0    rapidsai
     libraft-headers-only      23.12.00        cuda12_231206_g9e2d6277_0    rapidsai
     librdkafka                1.9.2                ha5a0de0_2    conda-forge
     libre2-11                 2023.06.02           h7a70373_0    conda-forge
     librmm                    23.12.00        cuda12_231206_g2db5cbb3_0    rapidsai
     librttopo                 1.1.0               h8917695_15    conda-forge
     libsodium                 1.0.18               h36c2ea0_1    conda-forge
     libspatialindex           1.9.3                h9c3ff4c_4    conda-forge
     libspatialite             5.1.0                h7bd4643_4    conda-forge
     libsqlite                 3.44.2               h2797004_0    conda-forge
     libssh2                   1.11.0               h0841786_0    conda-forge
     libstdcxx-ng              13.2.0               h7e041cc_3    conda-forge
     libthrift                 0.19.0               hb90f79a_1    conda-forge
     libtiff                   4.6.0                ha9c0a0a_2    conda-forge
     libutf8proc               2.8.0                h166bdaf_0    conda-forge
     libuuid                   2.38.1               h0b41bf4_0    conda-forge
     libuv                     1.46.0               hd590300_0    conda-forge
     libwebp                   1.3.2                h658648e_1    conda-forge
     libwebp-base              1.3.2                hd590300_0    conda-forge
     libxcb                    1.15                 h0b41bf4_0    conda-forge
     libxgboost                1.7.6           rapidsai_h52ede06_7    rapidsai
     libxml2                   2.12.3               h232c23b_0    conda-forge
     libzip                    1.10.1               h2629f0a_3    conda-forge
     libzlib                   1.2.13               hd590300_5    conda-forge
     libzopfli                 1.0.3                h9c3ff4c_0    conda-forge
     lightgbm                  3.3.5                    pypi_0    pypi
     lightning-utilities       0.10.0                   pypi_0    pypi
     linkify-it-py             2.0.0              pyhd8ed1ab_0    conda-forge
     llvmlite                  0.41.1                   pypi_0    pypi
     locket                    1.0.0              pyhd8ed1ab_0    conda-forge
     lz4                       4.3.2            py39h79d96da_1    conda-forge
     lz4-c                     1.9.4                hcb278e6_0    conda-forge
     lzo                       2.10              h516909a_1000    conda-forge
     mako                      1.3.0                    pypi_0    pypi
     mapclassify               2.6.1              pyhd8ed1ab_0    conda-forge
     markdown                  3.5.1              pyhd8ed1ab_0    conda-forge
     markdown-it-py            3.0.0              pyhd8ed1ab_0    conda-forge
     markupsafe                2.1.3            py39hd1e30aa_1    conda-forge
     matplotlib-base           3.8.2            py39he9076e7_0    conda-forge
     mccabe                    0.7.0                    pypi_0    pypi
     mdit-py-plugins           0.4.0              pyhd8ed1ab_0    conda-forge
     mdurl                     0.1.0              pyhd8ed1ab_0    conda-forge
     metaml                    1.0.19rc0                pypi_0    pypi
     minizip                   4.0.3                h0ab5242_0    conda-forge
     mistune                   3.0.2              pyhd8ed1ab_0    conda-forge
     more-itertools            10.1.0                   pypi_0    pypi
     mpmath                    1.3.0                    pypi_0    pypi
     mrmr-selection            0.2.8                    pypi_0    pypi
     msgpack-python            1.0.7            py39h7633fee_0    conda-forge
     multidict                 6.0.4            py39hd1e30aa_1    conda-forge
     multipledispatch          0.6.0                      py_0    conda-forge
     multiprocess              0.70.15                  pypi_0    pypi
     munkres                   1.1.4              pyh9f0ad1d_0    conda-forge
     mypy                      1.4.1                    pypi_0    pypi
     mypy-extensions           1.0.0                    pypi_0    pypi
     nbclient                  0.8.0              pyhd8ed1ab_0    conda-forge
     nbconvert-core            7.13.1             pyhd8ed1ab_0    conda-forge
     nbformat                  5.9.2              pyhd8ed1ab_0    conda-forge
     nccl                      2.19.4.1             h3a97aeb_0    conda-forge
     ncurses                   6.4                  h59595ed_2    conda-forge
     networkx                  3.2                      pypi_0    pypi
     nfoursid                  1.0.1                    pypi_0    pypi
     nh3                       0.2.15                   pypi_0    pypi
     nodeenv                   1.8.0                    pypi_0    pypi
     nodejs                    20.9.0               hb753e55_0    conda-forge
     nspr                      4.35                 h27087fc_0    conda-forge
     nss                       3.96                 h1d7d5a4_0    conda-forge
     nuitka                    1.7.5                    pypi_0    pypi
     numba                     0.58.1                   pypi_0    pypi
     numpy                     1.24.4           py39h6183b62_0    conda-forge
     nvcomp                    3.0.4                h10b603f_1    conda-forge
     nvidia-cublas-cu12        12.1.3.1                 pypi_0    pypi
     nvidia-cuda-cupti-cu12    12.1.105                 pypi_0    pypi
     nvidia-cuda-nvrtc-cu12    12.1.105                 pypi_0    pypi
     nvidia-cuda-runtime-cu12  12.1.105                 pypi_0    pypi
     nvidia-cudnn-cu12         8.9.2.26                 pypi_0    pypi
     nvidia-cufft-cu12         11.0.2.54                pypi_0    pypi
     nvidia-curand-cu12        10.3.2.106               pypi_0    pypi
     nvidia-cusolver-cu12      11.4.5.107               pypi_0    pypi
     nvidia-cusparse-cu12      12.1.0.106               pypi_0    pypi
     nvidia-nccl-cu12          2.18.1                   pypi_0    pypi
     nvidia-nvjitlink-cu12     12.3.101                 pypi_0    pypi
     nvidia-nvtx-cu12          12.1.105                 pypi_0    pypi
     nvtx                      0.2.8            py39hd1e30aa_1    conda-forge
     openjpeg                  2.5.0                h488ebb8_3    conda-forge
     openslide                 3.4.1               h58ba908_12    conda-forge
     openssl                   3.2.0                hd590300_1    conda-forge
     optuna                    3.3.0                    pypi_0    pypi
     orc                       1.9.2                h4b38347_0    conda-forge
     ordered-set               4.1.0                    pypi_0    pypi
     overrides                 7.4.0              pyhd8ed1ab_0    conda-forge
     packaging                 23.2               pyhd8ed1ab_0    conda-forge
     pandas                    1.5.3            py39h2ad29b5_1    conda-forge
     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge
     panel                     1.3.4              pyhd8ed1ab_0    conda-forge
     param                     2.0.1              pyhca7485f_0    conda-forge
     partd                     1.4.1              pyhd8ed1ab_0    conda-forge
     pathspec                  0.12.1                   pypi_0    pypi
     patsy                     0.5.4                    pypi_0    pypi
     pcre2                     10.42                hcad00b1_0    conda-forge
     pillow                    10.1.0           py39had0adad_0    conda-forge
     pip                       23.3.2             pyhd8ed1ab_0    conda-forge
     pipdeptree                2.10.2                   pypi_0    pypi
     pixman                    0.42.2               h59595ed_0    conda-forge
     pkginfo                   1.9.6                    pypi_0    pypi
     pkgutil-resolve-name      1.3.10             pyhd8ed1ab_1    conda-forge
     platformdirs              4.1.0              pyhd8ed1ab_0    conda-forge
     plotly                    5.18.0                   pypi_0    pypi
     pluggy                    1.3.0                    pypi_0    pypi
     pmdarima                  2.0.4                    pypi_0    pypi
     polars                    0.20.2                   pypi_0    pypi
     poppler                   23.12.0              h590f24d_0    conda-forge
     poppler-data              0.4.12               hd8ed1ab_0    conda-forge
     portion                   2.4.2                    pypi_0    pypi
     postgresql                16.1                 h7387d8b_7    conda-forge
     pre-commit                3.3.3                    pypi_0    pypi
     proj                      9.3.1                h1d62c97_0    conda-forge
     prometheus_client         0.19.0             pyhd8ed1ab_0    conda-forge
     protobuf                  3.20.3                   pypi_0    pypi
     psutil                    5.9.7            py39hd1e30aa_0    conda-forge
     pthread-stubs             0.4               h36c2ea0_1001    conda-forge
     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge
     py-xgboost                1.7.6           rapidsai_py39h84d37f7_7    rapidsai
     pyarrow                   14.0.2          py39h6925388_0_cpu    conda-forge
     pyarrow-hotfix            0.6                pyhd8ed1ab_0    conda-forge
     pycodestyle               2.10.0                   pypi_0    pypi
     pycparser                 2.21               pyhd8ed1ab_0    conda-forge
     pyct                      0.5.0              pyhd8ed1ab_0    conda-forge
     pydantic                  1.10.13                  pypi_0    pypi
     pyee                      8.1.0              pyhd8ed1ab_0    conda-forge
     pyflakes                  3.0.1                    pypi_0    pypi
     pygments                  2.17.2             pyhd8ed1ab_0    conda-forge
     pylibcugraph              23.12.00        cuda12_py39_231206_g1309813f_0    rapidsai
     pylibraft                 23.12.00        cuda12_py39_231206_g9e2d6277_0    rapidsai
     pylint                    2.17.4                   pypi_0    pypi
     pynndescent               0.5.11                   pypi_0    pypi
     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge
     pyod                      1.1.2                    pypi_0    pypi
     pyparsing                 3.1.1              pyhd8ed1ab_0    conda-forge
     pyppeteer                 1.0.2              pyhd8ed1ab_0    conda-forge
     pyproj                    3.6.1            py39h15b0fa6_5    conda-forge
     pysocks                   1.7.1              pyha2e5f31_6    conda-forge
     pytest                    7.4.0                    pypi_0    pypi
     pytest-cov                4.1.0                    pypi_0    pypi
     pytest-split              0.8.1                    pypi_0    pypi
     pytest-xdist              3.3.1                    pypi_0    pypi
     python                    3.9.18          h0755675_0_cpython    conda-forge
     python-confluent-kafka    1.9.2            py39hb9d737c_2    conda-forge
     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge
     python-fastjsonschema     2.19.0             pyhd8ed1ab_0    conda-forge
     python-graphviz           0.20.1                   pypi_0    pypi
     python-json-logger        2.0.7              pyhd8ed1ab_0    conda-forge
     python_abi                3.9                      4_cp39    conda-forge
     pytorch-lightning         2.1.3                    pypi_0    pypi
     pytz                      2023.3.post1       pyhd8ed1ab_0    conda-forge
     pyviz_comms               3.0.0              pyhd8ed1ab_0    conda-forge
     pywavelets                1.4.1            py39h44dd56e_1    conda-forge
     pyyaml                    6.0.1            py39hd1e30aa_1    conda-forge
     pyzmq                     25.1.2           py39h8c080ef_0    conda-forge
     qpd                       0.4.4                    pypi_0    pypi
     raft-dask                 23.12.00        cuda12_py39_231206_g9e2d6277_0    rapidsai
     rapids                    23.12.00        cuda12_py39_231206_g1d8bed4_0    rapidsai
     rapids-dask-dependency    23.12.01                      0    rapidsai
     rapids-xgboost            23.12.00        cuda12_py39_231206_g1d8bed4_0    rapidsai
     rav1e                     0.6.6                he8a937b_2    conda-forge
     rdma-core                 49.0                 hd3aeb46_2    conda-forge
     re2                       2023.06.02           h2873b5e_0    conda-forge
     readline                  8.2                  h8228510_1    conda-forge
     readme-renderer           42.0                     pypi_0    pypi
     referencing               0.32.0             pyhd8ed1ab_0    conda-forge
     regex                     2023.10.3                pypi_0    pypi
     requests                  2.31.0             pyhd8ed1ab_0    conda-forge
     requests-toolbelt         1.0.0                    pypi_0    pypi
     rfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge
     rfc3986                   2.0.0                    pypi_0    pypi
     rfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge
     rich                      13.7.0             pyhd8ed1ab_0    conda-forge
     rmm                       23.12.00        cuda12_py39_231206_g2db5cbb3_0    rapidsai
     rpds-py                   0.15.2           py39h9fdd4d6_0    conda-forge
     rtree                     1.1.0            py39hb102c33_0    conda-forge
     ruamel-yaml               0.18.5                   pypi_0    pypi
     ruamel-yaml-clib          0.2.8                    pypi_0    pypi
     s2n                       1.4.0                h06160fa_0    conda-forge
     scikit-image              0.21.0           py39h3d6467e_0    conda-forge
     scikit-learn              1.1.3                    pypi_0    pypi
     scikit-learn-intelex      2023.2.0                 pypi_0    pypi
     scipy                     1.11.4           py39h474f0d3_0    conda-forge
     secretstorage             3.3.3                    pypi_0    pypi
     send2trash                1.8.2              pyh41d4057_0    conda-forge
     setuptools                68.2.2             pyhd8ed1ab_0    conda-forge
     shap                      0.44.0                   pypi_0    pypi
     shapely                   2.0.2            py39h6404dd3_1    conda-forge
     simpervisor               1.0.0              pyhd8ed1ab_0    conda-forge
     six                       1.16.0             pyh6c4a22f_0    conda-forge
     sklearn-contrib-lightning 0.6.2.post0              pypi_0    pypi
     sktime                    0.17.1                   pypi_0    pypi
     slicer                    0.0.7                    pypi_0    pypi
     snappy                    1.1.10               h9fff704_0    conda-forge
     sniffio                   1.3.0              pyhd8ed1ab_0    conda-forge
     snowballstemmer           2.2.0                    pypi_0    pypi
     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge
     soupsieve                 2.5                pyhd8ed1ab_1    conda-forge
     spdlog                    1.11.0               h9b3ece8_1    conda-forge
     sphinx                    6.2.1                    pypi_0    pypi
     sphinx-rtd-theme          1.2.2                    pypi_0    pypi
     sphinxcontrib-applehelp   1.0.7                    pypi_0    pypi
     sphinxcontrib-devhelp     1.0.5                    pypi_0    pypi
     sphinxcontrib-htmlhelp    2.0.4                    pypi_0    pypi
     sphinxcontrib-jquery      4.1                      pypi_0    pypi
     sphinxcontrib-jsmath      1.0.1                    pypi_0    pypi
     sphinxcontrib-qthelp      1.0.6                    pypi_0    pypi
     sphinxcontrib-serializinghtml 1.1.9                    pypi_0    pypi
     sqlalchemy                2.0.23                   pypi_0    pypi
     sqlglot                   20.4.0                   pypi_0    pypi
     sqlite                    3.44.2               h2c6b66d_0    conda-forge
     statsforecast             1.7.0                    pypi_0    pypi
     statsmodels               0.14.1                   pypi_0    pypi
     streamz                   0.6.4              pyh6c4a22f_0    conda-forge
     svt-av1                   1.8.0                h59595ed_0    conda-forge
     sympy                     1.12                     pypi_0    pypi
     tbats                     1.1.3                    pypi_0    pypi
     tbb                       2021.11.0                pypi_0    pypi
     tblib                     3.0.0              pyhd8ed1ab_0    conda-forge
     tenacity                  8.2.3                    pypi_0    pypi
     tensorboardx              2.6                      pypi_0    pypi
     terminado                 0.18.0             pyh0d859eb_0    conda-forge
     threadpoolctl             3.2.0              pyha21a80b_0    conda-forge
     tifffile                  2023.12.9          pyhd8ed1ab_0    conda-forge
     tiledb                    2.18.3               hc1131af_1    conda-forge
     tinycss2                  1.2.1              pyhd8ed1ab_0    conda-forge
     tk                        8.6.13          noxft_h4845f30_101    conda-forge
     tokenizers                0.13.3                   pypi_0    pypi
     tomli                     2.0.1                    pypi_0    pypi
     tomlkit                   0.12.3                   pypi_0    pypi
     toolz                     0.12.0             pyhd8ed1ab_0    conda-forge
     torch                     2.1.2                    pypi_0    pypi
     torchmetrics              1.2.1                    pypi_0    pypi
     tornado                   6.3.3            py39hd1e30aa_1    conda-forge
     tqdm                      4.66.1             pyhd8ed1ab_0    conda-forge
     traitlets                 5.14.0             pyhd8ed1ab_0    conda-forge
     transformers              4.28.1                   pypi_0    pypi
     treelite                  3.9.1            py39h9b5fa3e_0    conda-forge
     treelite-runtime          3.9.1                    pypi_0    pypi
     triad                     0.9.3                    pypi_0    pypi
     triton                    2.1.0                    pypi_0    pypi
     twine                     4.0.2                    pypi_0    pypi
     types-python-dateutil     2.8.19.14          pyhd8ed1ab_0    conda-forge
     typing-extensions         4.9.0                hd8ed1ab_0    conda-forge
     typing_extensions         4.9.0              pyha770c72_0    conda-forge
     typing_utils              0.1.0              pyhd8ed1ab_0    conda-forge
     tzcode                    2023c                h0b41bf4_0    conda-forge
     tzdata                    2023c                h71feb2d_0    conda-forge
     uc-micro-py               1.0.1              pyhd8ed1ab_0    conda-forge
     ucx                       1.15.0               h6d2d1ec_2    conda-forge
     ucx-proc                  1.0.0                       gpu    rapidsai
     ucx-py                    0.35.00         py39_231206_gb5f60ca_0    rapidsai
     umap-learn                0.5.5                    pypi_0    pypi
     unicodedata2              15.1.0           py39hd1e30aa_0    conda-forge
     uri-template              1.3.0              pyhd8ed1ab_0    conda-forge
     uriparser                 0.9.7                hcb278e6_1    conda-forge
     urllib3                   1.26.18            pyhd8ed1ab_0    conda-forge
     utilsforecast             0.0.23                   pypi_0    pypi
     vecstack                  0.4.0                    pypi_0    pypi
     virtualenv                20.25.0                  pypi_0    pypi
     webcolors                 1.13               pyhd8ed1ab_0    conda-forge
     webencodings              0.5.1              pyhd8ed1ab_2    conda-forge
     websocket-client          1.7.0              pyhd8ed1ab_0    conda-forge
     websockets                10.4             py39hb9d737c_1    conda-forge
     wheel                     0.42.0             pyhd8ed1ab_0    conda-forge
     wrapt                     1.16.0                   pypi_0    pypi
     xarray                    2023.12.0          pyhd8ed1ab_0    conda-forge
     xerces-c                  3.2.5                hac6953d_0    conda-forge
     xgboost                   1.7.6           rapidsai_py39h0b6c2bb_7    rapidsai
     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge
     xorg-libice               1.1.1                hd590300_0    conda-forge
     xorg-libsm                1.2.4                h7391055_0    conda-forge
     xorg-libx11               1.8.7                h8ee46fc_0    conda-forge
     xorg-libxau               1.0.11               hd590300_0    conda-forge
     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge
     xorg-libxext              1.3.4                h0b41bf4_2    conda-forge
     xorg-libxrender           0.9.11               hd590300_0    conda-forge
     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge
     xorg-xextproto            7.3.0             h0b41bf4_1003    conda-forge
     xorg-xproto               7.0.31            h7f98852_1007    conda-forge
     xxhash                    3.4.1                    pypi_0    pypi
     xyzservices               2023.10.1          pyhd8ed1ab_0    conda-forge
     xz                        5.2.6                h166bdaf_0    conda-forge
     yaml                      0.2.5                h7f98852_2    conda-forge
     yarl                      1.9.3            py39hd1e30aa_0    conda-forge
     zeromq                    4.3.5                h59595ed_0    conda-forge
     zfp                       1.0.1                h59595ed_0    conda-forge
     zict                      3.0.0              pyhd8ed1ab_0    conda-forge
     zipp                      3.17.0             pyhd8ed1ab_0    conda-forge
     zlib                      1.2.13               hd590300_5    conda-forge
     zlib-ng                   2.0.7                h0b41bf4_0    conda-forge
     zstandard                 0.22.0                   pypi_0    pypi
     zstd                      1.5.5                hfc55251_0    conda-forge



**Additional context**
Add any other context about the problem here.
",2023-12-27T21:20:01Z,0,0,Paul Brookes,UCL
323,[BUG] `str.character_ngrams` produces <NA> with strings < ngram length,"**Describe the bug**
The `str.character_ngrams` function produces token `<NA>` for strings which are lesser than the provided `n` (shown in image for the case of bigrams).
![result output](https://github.com/rapidsai/cudf/assets/68988130/946aeebb-6be3-4719-91e7-25eb9e2c0091)

I have debugged this and as far as I understand it, it is being caused by an empty list returned by the `libstrings.generate_character_ngrams` function. This causes <NA> to be a part of the result when it is exploded in the problematic function.
This issue causes several bugs in downstream tasks (like when using cuml for `CountVectorizer` etc).


**Steps/Code to reproduce bug**
Minimum code required to reproduce the bug:
```
import cudf
str_series = cudf.Series(['1744', '4'])
str_series.str.character_ngrams(2)
```

**Expected behavior**
<NA> should not be a part of the output. This causes several downstream tasks to fail because <NA> is not a valid token in the actual input string series.

**Environment overview (please complete the following information)**
 - Environment location: Cloud GCP
 - Method of cuDF install: pip
 
**Environment details**
```
**git***
     Not inside a git repository
     
     ***OS Information***
     PRETTY_NAME=""Debian GNU/Linux 11 (bullseye)""
     NAME=""Debian GNU/Linux""
     VERSION_ID=""11""
     VERSION=""11 (bullseye)""
     VERSION_CODENAME=bullseye
     ID=debian
     HOME_URL=""https://www.debian.org/""
     SUPPORT_URL=""https://www.debian.org/support""
     BUG_REPORT_URL=""https://bugs.debian.org/""
     Linux janmey-gpu-c2 5.10.0-26-cloud-amd64 #1 SMP Debian 5.10.197-1 (2023-09-29) x86_64 GNU/Linux
     
     ***GPU Information***
     Fri Dec 29 10:21:54 2023
     +-----------------------------------------------------------------------------+
     | NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |
     |-------------------------------+----------------------+----------------------+
     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
     |                               |                      |               MIG M. |
     |===============================+======================+======================|
     |   0  Tesla T4            On   | 00000000:00:04.0 Off |                    0 |
     | N/A   70C    P0    33W /  70W |    459MiB / 15360MiB |      0%      Default |
     |                               |                      |                  N/A |
     +-------------------------------+----------------------+----------------------+
     
     +-----------------------------------------------------------------------------+
     | Processes:                                                                  |
     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
     |        ID   ID                                                   Usage      |
     |=============================================================================|
     |    0   N/A  N/A    316341      C   ..._log_ner/.venv/bin/python      454MiB |
     +-----------------------------------------------------------------------------+
     
     ***CPU***
     Architecture:                       x86_64
     CPU op-mode(s):                     32-bit, 64-bit
     Byte Order:                         Little Endian
     Address sizes:                      46 bits physical, 48 bits virtual
     CPU(s):                             16
     On-line CPU(s) list:                0-15
     Thread(s) per core:                 2
     Core(s) per socket:                 8
     Socket(s):                          1
     NUMA node(s):                       1
     Vendor ID:                          GenuineIntel
     CPU family:                         6
     Model:                              79
     Model name:                         Intel(R) Xeon(R) CPU @ 2.20GHz
     Stepping:                           0
     CPU MHz:                            2199.998
     BogoMIPS:                           4399.99
     Hypervisor vendor:                  KVM
     Virtualization type:                full
     L1d cache:                          256 KiB
     L1i cache:                          256 KiB
     L2 cache:                           2 MiB
     L3 cache:                           55 MiB
     NUMA node0 CPU(s):                  0-15
     Vulnerability Gather data sampling: Not affected
     Vulnerability Itlb multihit:        Not affected
     Vulnerability L1tf:                 Mitigation; PTE Inversion
     Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT Host state unknown
     Vulnerability Meltdown:             Mitigation; PTI
     Vulnerability Mmio stale data:      Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown
     Vulnerability Retbleed:             Mitigation; IBRS
     Vulnerability Spec rstack overflow: Not affected
     Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp
     Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
     Vulnerability Spectre v2:           Mitigation; IBRS, IBPB conditional, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected
     Vulnerability Srbds:                Not affected
     Vulnerability Tsx async abort:      Mitigation; Clear CPU buffers; SMT Host state unknown
     Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities
     
     ***CMake***
     /usr/bin/cmake
     cmake version 3.18.4
     
     CMake suite maintained and supported by Kitware (kitware.com/cmake).
     
     ***g++***
     /usr/bin/g++
     g++ (Debian 10.2.1-6) 10.2.1 20210110
     Copyright (C) 2020 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
     
     
     ***nvcc***
     /usr/local/cuda/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2022 NVIDIA Corporation
     Built on Wed_Sep_21_10:33:58_PDT_2022
     Cuda compilation tools, release 11.8, V11.8.89
     Build cuda_11.8.r11.8/compiler.31833905_0
     
     ***Python***
     /home/janmeysandeepshukla/datasci/transaction_log_ner/.venv/bin/python
     Python 3.10.13
     
     ***Environment Variables***
     PATH                            : /home/janmeysandeepshukla/datasci/transaction_log_ner/.venv/bin:/home/janmeysandeepshukla/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/usr/local/cuda/bin:/opt/conda/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
     LD_LIBRARY_PATH                 : /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /opt/conda
     PYTHON_PATH                     :
     
     ***conda packages***
     /opt/conda/bin/conda
     # packages in environment at /opt/conda:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                       2_gnu    conda-forge
     absl-py                   2.0.0                    pypi_0    pypi
     aiofiles                  22.1.0                   pypi_0    pypi
     aiohttp                   3.9.1                    pypi_0    pypi
     aiohttp-cors              0.7.0                    pypi_0    pypi
     aiorwlock                 1.3.0                    pypi_0    pypi
     aiosignal                 1.3.1                    pypi_0    pypi
     aiosqlite                 0.19.0                   pypi_0    pypi
     anyio                     3.7.1                    pypi_0    pypi
     archspec                  0.2.2              pyhd8ed1ab_0    conda-forge
     argon2-cffi               23.1.0             pyhd8ed1ab_0    conda-forge
     argon2-cffi-bindings      21.2.0          py310h2372a71_4    conda-forge
     arrow                     1.3.0              pyhd8ed1ab_0    conda-forge
     asttokens                 2.4.1              pyhd8ed1ab_0    conda-forge
     async-lru                 2.0.4              pyhd8ed1ab_0    conda-forge
     async-timeout             4.0.3                    pypi_0    pypi
     attrs                     23.1.0             pyh71513ae_1    conda-forge
     babel                     2.13.1             pyhd8ed1ab_0    conda-forge
     backoff                   2.2.1                    pypi_0    pypi
     beatrix-jupyterlab        2023.128.151533          pypi_0    pypi
     beautifulsoup4            4.12.2             pyha770c72_0    conda-forge
     bleach                    6.1.0              pyhd8ed1ab_0    conda-forge
     blessed                   1.20.0                   pypi_0    pypi
     boltons                   23.0.0             pyhd8ed1ab_0    conda-forge
     brotli-python             1.1.0           py310hc6cd4ac_1    conda-forge
     bzip2                     1.0.8                hd590300_5    conda-forge
     c-ares                    1.23.0               hd590300_0    conda-forge
     ca-certificates           2023.11.17           hbcca054_0    conda-forge
     cached-property           1.5.2                hd8ed1ab_1    conda-forge
     cached_property           1.5.2              pyha770c72_1    conda-forge
     cachetools                5.3.2                    pypi_0    pypi
     certifi                   2023.11.17         pyhd8ed1ab_0    conda-forge
     cffi                      1.16.0          py310h2fee648_0    conda-forge
     charset-normalizer        3.3.2              pyhd8ed1ab_0    conda-forge
     click                     8.1.7                    pypi_0    pypi
     cloud-tpu-client          0.10                     pypi_0    pypi
     cloudpickle               3.0.0                    pypi_0    pypi
     colorama                  0.4.6              pyhd8ed1ab_0    conda-forge
     colorful                  0.5.5                    pypi_0    pypi
     comm                      0.2.0                    pypi_0    pypi
     conda                     23.11.0         py310hff52083_1    conda-forge
     conda-libmamba-solver     23.11.1            pyhd8ed1ab_0    conda-forge
     conda-package-handling    2.2.0              pyh38be061_0    conda-forge
     conda-package-streaming   0.9.0              pyhd8ed1ab_0    conda-forge
     contourpy                 1.2.0                    pypi_0    pypi
     cryptography              41.0.7                   pypi_0    pypi
     cycler                    0.12.1                   pypi_0    pypi
     cython                    3.0.6                    pypi_0    pypi
     dacite                    1.8.1                    pypi_0    pypi
     dataproc-jupyter-plugin   0.1.59                   pypi_0    pypi
     db-dtypes                 1.1.1                    pypi_0    pypi
     debugpy                   1.8.0           py310hc6cd4ac_1    conda-forge
     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge
     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge
     deprecated                1.2.14                   pypi_0    pypi
     distlib                   0.3.7                    pypi_0    pypi
     distro                    1.8.0              pyhd8ed1ab_0    conda-forge
     dlenv-base                1.0.20231210            py310_0    file:///tmp/conda-pkgs
     dm-tree                   0.1.8                    pypi_0    pypi
     docker                    7.0.0                    pypi_0    pypi
     docstring-parser          0.15                     pypi_0    pypi
     entrypoints               0.4                pyhd8ed1ab_0    conda-forge
     exceptiongroup            1.2.0              pyhd8ed1ab_0    conda-forge
     executing                 2.0.1              pyhd8ed1ab_0    conda-forge
     farama-notifications      0.0.4                    pypi_0    pypi
     fastapi                   0.104.1                  pypi_0    pypi
     filelock                  3.13.1                   pypi_0    pypi
     fmt                       10.1.1               h00ab1b0_1    conda-forge
     fonttools                 4.46.0                   pypi_0    pypi
     fqdn                      1.5.1              pyhd8ed1ab_0    conda-forge
     frozenlist                1.4.0                    pypi_0    pypi
     fsspec                    2023.12.1                pypi_0    pypi
     gcsfs                     2023.12.1                pypi_0    pypi
     gitdb                     4.0.11                   pypi_0    pypi
     gitpython                 3.1.40                   pypi_0    pypi
     google-api-core           1.34.0                   pypi_0    pypi
     google-api-python-client  1.8.0                    pypi_0    pypi
     google-auth               2.25.2                   pypi_0    pypi
     google-auth-httplib2      0.1.1                    pypi_0    pypi
     google-auth-oauthlib      1.1.0                    pypi_0    pypi
     google-cloud-aiplatform   1.37.0                   pypi_0    pypi
     google-cloud-artifact-registry 1.10.0                   pypi_0    pypi
     google-cloud-bigquery     3.13.0                   pypi_0    pypi
     google-cloud-bigquery-storage 2.23.0                   pypi_0    pypi
     google-cloud-core         2.4.1                    pypi_0    pypi
     google-cloud-datastore    1.15.5                   pypi_0    pypi
     google-cloud-jupyter-config 0.0.5                    pypi_0    pypi
     google-cloud-language     2.12.0                   pypi_0    pypi
     google-cloud-monitoring   2.17.0                   pypi_0    pypi
     google-cloud-resource-manager 1.11.0                   pypi_0    pypi
     google-cloud-storage      2.13.0                   pypi_0    pypi
     google-crc32c             1.5.0                    pypi_0    pypi
     google-resumable-media    2.6.0                    pypi_0    pypi
     googleapis-common-protos  1.62.0                   pypi_0    pypi
     gpustat                   1.0.0                    pypi_0    pypi
     greenlet                  3.0.2                    pypi_0    pypi
     grpc-google-iam-v1        0.13.0                   pypi_0    pypi
     grpcio                    1.60.0                   pypi_0    pypi
     grpcio-status             1.48.2                   pypi_0    pypi
     gymnasium                 0.28.1                   pypi_0    pypi
     h11                       0.14.0                   pypi_0    pypi
     htmlmin                   0.1.12                   pypi_0    pypi
     httplib2                  0.22.0                   pypi_0    pypi
     httptools                 0.6.1                    pypi_0    pypi
     icu                       73.2                 h59595ed_0    conda-forge
     idna                      3.6                pyhd8ed1ab_0    conda-forge
     imagehash                 4.3.1                    pypi_0    pypi
     imageio                   2.33.0                   pypi_0    pypi
     importlib-metadata        6.11.0                   pypi_0    pypi
     importlib_metadata        7.0.0                hd8ed1ab_0    conda-forge
     importlib_resources       6.1.1              pyhd8ed1ab_0    conda-forge
     ipykernel                 6.27.1                   pypi_0    pypi
     ipython                   8.18.1             pyh707e725_3    conda-forge
     ipython-genutils          0.2.0                    pypi_0    pypi
     ipython-sql               0.5.0                    pypi_0    pypi
     ipywidgets                8.1.1                    pypi_0    pypi
     isoduration               20.11.0            pyhd8ed1ab_0    conda-forge
     jaraco-classes            3.3.0                    pypi_0    pypi
     jax-jumpy                 1.0.0                    pypi_0    pypi
     jedi                      0.19.1             pyhd8ed1ab_0    conda-forge
     jeepney                   0.8.0                    pypi_0    pypi
     jinja2                    3.1.2              pyhd8ed1ab_1    conda-forge
     joblib                    1.3.2                    pypi_0    pypi
     json5                     0.9.14             pyhd8ed1ab_0    conda-forge
     jsonpatch                 1.33               pyhd8ed1ab_0    conda-forge
     jsonpointer               2.4             py310hff52083_3    conda-forge
     jsonschema                4.20.0             pyhd8ed1ab_0    conda-forge
     jsonschema-specifications 2023.11.2          pyhd8ed1ab_0    conda-forge
     jsonschema-with-format-nongpl 4.20.0             pyhd8ed1ab_0    conda-forge
     jupyter-client            7.4.9                    pypi_0    pypi
     jupyter-http-over-ws      0.0.8                    pypi_0    pypi
     jupyter-lsp               2.2.1              pyhd8ed1ab_0    conda-forge
     jupyter-server-fileid     0.9.0                    pypi_0    pypi
     jupyter-server-mathjax    0.2.6                    pypi_0    pypi
     jupyter-server-proxy      4.1.0                    pypi_0    pypi
     jupyter-server-ydoc       0.8.0                    pypi_0    pypi
     jupyter-ydoc              0.2.5                    pypi_0    pypi
     jupyter_client            8.6.0              pyhd8ed1ab_0    conda-forge
     jupyter_core              5.5.0           py310hff52083_0    conda-forge
     jupyter_events            0.9.0              pyhd8ed1ab_0    conda-forge
     jupyter_server            2.12.1             pyhd8ed1ab_0    conda-forge
     jupyter_server_terminals  0.4.4              pyhd8ed1ab_1    conda-forge
     jupyterlab                3.6.6                    pypi_0    pypi
     jupyterlab-git            0.44.0                   pypi_0    pypi
     jupyterlab-widgets        3.0.9                    pypi_0    pypi
     jupyterlab_pygments       0.3.0              pyhd8ed1ab_0    conda-forge
     jupyterlab_server         2.25.2             pyhd8ed1ab_0    conda-forge
     jupytext                  1.16.0                   pypi_0    pypi
     kernels-mixer             0.0.7                    pypi_0    pypi
     keyring                   24.3.0                   pypi_0    pypi
     keyrings-google-artifactregistry-auth 1.1.2                    pypi_0    pypi
     keyutils                  1.6.1                h166bdaf_0    conda-forge
     kfp                       2.4.0                    pypi_0    pypi
     kfp-pipeline-spec         0.2.2                    pypi_0    pypi
     kfp-server-api            2.0.5                    pypi_0    pypi
     kiwisolver                1.4.5                    pypi_0    pypi
     krb5                      1.21.2               h659d440_0    conda-forge
     kubernetes                26.1.0                   pypi_0    pypi
     lazy-loader               0.3                      pypi_0    pypi
     ld_impl_linux-64          2.40                 h41732ed_0    conda-forge
     libarchive                3.7.2                h2aa1ff5_1    conda-forge
     libcurl                   8.5.0                hca28451_0    conda-forge
     libedit                   3.1.20191231         he28a2e2_2    conda-forge
     libev                     4.33                 hd590300_2    conda-forge
     libffi                    3.4.2                h7f98852_5    conda-forge
     libgcc-ng                 13.2.0               h807b86a_3    conda-forge
     libgomp                   13.2.0               h807b86a_3    conda-forge
     libiconv                  1.17                 h166bdaf_0    conda-forge
     libmamba                  1.5.4                had39da4_0    conda-forge
     libmambapy                1.5.4           py310h39ff949_0    conda-forge
     libnghttp2                1.58.0               h47da74e_1    conda-forge
     libnsl                    2.0.1                hd590300_0    conda-forge
     libsodium                 1.0.18               h36c2ea0_1    conda-forge
     libsolv                   0.7.27               hfc55251_0    conda-forge
     libsqlite                 3.44.2               h2797004_0    conda-forge
     libssh2                   1.11.0               h0841786_0    conda-forge
     libstdcxx-ng              13.2.0               h7e041cc_3    conda-forge
     libuuid                   2.38.1               h0b41bf4_0    conda-forge
     libuv                     1.46.0               hd590300_0    conda-forge
     libxml2                   2.12.2               h232c23b_0    conda-forge
     libzlib                   1.2.13               hd590300_5    conda-forge
     llvmlite                  0.41.1                   pypi_0    pypi
     lz4                       4.3.2                    pypi_0    pypi
     lz4-c                     1.9.4                hcb278e6_0    conda-forge
     lzo                       2.10              h516909a_1000    conda-forge
     markdown-it-py            3.0.0                    pypi_0    pypi
     markupsafe                2.1.3           py310h2372a71_1    conda-forge
     matplotlib                3.7.3                    pypi_0    pypi
     matplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge
     mdit-py-plugins           0.4.0                    pypi_0    pypi
     mdurl                     0.1.2                    pypi_0    pypi
     menuinst                  2.0.0           py310hff52083_1    conda-forge
     mistune                   3.0.2              pyhd8ed1ab_0    conda-forge
     more-itertools            10.1.0                   pypi_0    pypi
     msgpack                   1.0.7                    pypi_0    pypi
     multidict                 6.0.4                    pypi_0    pypi
     multimethod               1.10                     pypi_0    pypi
     nb_conda                  2.2.1                    unix_6    conda-forge
     nb_conda_kernels          2.3.1              pyhd8ed1ab_3    conda-forge
     nbclassic                 1.0.0                    pypi_0    pypi
     nbclient                  0.9.0                    pypi_0    pypi
     nbconvert-core            7.12.0             pyhd8ed1ab_0    conda-forge
     nbdime                    3.2.0                    pypi_0    pypi
     nbformat                  5.9.2              pyhd8ed1ab_0    conda-forge
     ncurses                   6.4                  h59595ed_2    conda-forge
     nest-asyncio              1.5.8              pyhd8ed1ab_0    conda-forge
     networkx                  3.2.1                    pypi_0    pypi
     nodejs                    20.9.0               hb753e55_0    conda-forge
     notebook                  6.5.6                    pypi_0    pypi
     notebook-executor         0.2                      pypi_0    pypi
     notebook-shim             0.2.3              pyhd8ed1ab_0    conda-forge
     numba                     0.58.1                   pypi_0    pypi
     numpy                     1.25.2                   pypi_0    pypi
     nvidia-ml-py              11.495.46                pypi_0    pypi
     oauth2client              4.1.3                    pypi_0    pypi
     oauthlib                  3.2.2                    pypi_0    pypi
     opencensus                0.11.3                   pypi_0    pypi
     opencensus-context        0.1.3                    pypi_0    pypi
     openssl                   3.2.0                hd590300_1    conda-forge
     opentelemetry-api         1.21.0                   pypi_0    pypi
     opentelemetry-exporter-otlp 1.21.0                   pypi_0    pypi
     opentelemetry-exporter-otlp-proto-common 1.21.0                   pypi_0    pypi
     opentelemetry-exporter-otlp-proto-grpc 1.21.0                   pypi_0    pypi
     opentelemetry-exporter-otlp-proto-http 1.21.0                   pypi_0    pypi
     opentelemetry-proto       1.21.0                   pypi_0    pypi
     opentelemetry-sdk         1.21.0                   pypi_0    pypi
     opentelemetry-semantic-conventions 0.42b0                   pypi_0    pypi
     overrides                 7.4.0              pyhd8ed1ab_0    conda-forge
     packaging                 23.2               pyhd8ed1ab_0    conda-forge
     pandas                    2.0.3                    pypi_0    pypi
     pandas-profiling          3.6.6                    pypi_0    pypi
     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge
     papermill                 2.5.0                    pypi_0    pypi
     parso                     0.8.3              pyhd8ed1ab_0    conda-forge
     patsy                     0.5.4                    pypi_0    pypi
     pexpect                   4.9.0                    pypi_0    pypi
     phik                      0.12.3                   pypi_0    pypi
     pickleshare               0.7.5                   py_1003    conda-forge
     pillow                    10.1.0                   pypi_0    pypi
     pip                       23.3.1             pyhd8ed1ab_0    conda-forge
     pkgutil-resolve-name      1.3.10             pyhd8ed1ab_1    conda-forge
     platformdirs              3.11.0                   pypi_0    pypi
     plotly                    5.18.0                   pypi_0    pypi
     pluggy                    1.3.0              pyhd8ed1ab_0    conda-forge
     prettytable               3.9.0                    pypi_0    pypi
     prometheus_client         0.19.0             pyhd8ed1ab_0    conda-forge
     prompt-toolkit            3.0.41             pyha770c72_0    conda-forge
     proto-plus                1.23.0                   pypi_0    pypi
     protobuf                  3.20.3                   pypi_0    pypi
     psutil                    5.9.3                    pypi_0    pypi
     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge
     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge
     py-spy                    0.3.14                   pypi_0    pypi
     pyarrow                   14.0.1                   pypi_0    pypi
     pyasn1                    0.5.1                    pypi_0    pypi
     pyasn1-modules            0.3.0                    pypi_0    pypi
     pybind11-abi              4                    hd8ed1ab_3    conda-forge
     pycosat                   0.6.6           py310h2372a71_0    conda-forge
     pycparser                 2.21               pyhd8ed1ab_0    conda-forge
     pydantic                  1.10.13                  pypi_0    pypi
     pygments                  2.17.2             pyhd8ed1ab_0    conda-forge
     pyjwt                     2.8.0                    pypi_0    pypi
     pyparsing                 3.1.1                    pypi_0    pypi
     pysocks                   1.7.1              pyha2e5f31_6    conda-forge
     python                    3.10.13         hd12c33a_0_cpython    conda-forge
     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge
     python-dotenv             1.0.0                    pypi_0    pypi
     python-fastjsonschema     2.19.0             pyhd8ed1ab_0    conda-forge
     python-json-logger        2.0.7              pyhd8ed1ab_0    conda-forge
     python_abi                3.10                    4_cp310    conda-forge
     pytz                      2023.3.post1       pyhd8ed1ab_0    conda-forge
     pywavelets                1.5.0                    pypi_0    pypi
     pyyaml                    6.0.1           py310h2372a71_1    conda-forge
     pyzmq                     24.0.1                   pypi_0    pypi
     ray                       2.8.1                    pypi_0    pypi
     ray-cpp                   2.8.1                    pypi_0    pypi
     readline                  8.2                  h8228510_1    conda-forge
     referencing               0.32.0             pyhd8ed1ab_0    conda-forge
     reproc                    14.2.4.post0         hd590300_1    conda-forge
     reproc-cpp                14.2.4.post0         h59595ed_1    conda-forge
     requests                  2.31.0             pyhd8ed1ab_0    conda-forge
     requests-oauthlib         1.3.1                    pypi_0    pypi
     requests-toolbelt         0.10.1                   pypi_0    pypi
     retrying                  1.3.4                    pypi_0    pypi
     rfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge
     rfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge
     rich                      13.7.0                   pypi_0    pypi
     rpds-py                   0.13.2          py310hcb5633a_0    conda-forge
     ruamel.yaml               0.18.5          py310h2372a71_0    conda-forge
     ruamel.yaml.clib          0.2.7           py310h2372a71_2    conda-forge
     scikit-image              0.22.0                   pypi_0    pypi
     scikit-learn              1.3.2                    pypi_0    pypi
     scipy                     1.11.4                   pypi_0    pypi
     seaborn                   0.12.2                   pypi_0    pypi
     secretstorage             3.3.3                    pypi_0    pypi
     send2trash                1.8.2              pyh41d4057_0    conda-forge
     setuptools                68.2.2             pyhd8ed1ab_0    conda-forge
     shapely                   2.0.2                    pypi_0    pypi
     simpervisor               1.0.0                    pypi_0    pypi
     six                       1.16.0             pyh6c4a22f_0    conda-forge
     smart-open                6.4.0                    pypi_0    pypi
     smmap                     5.0.1                    pypi_0    pypi
     sniffio                   1.3.0              pyhd8ed1ab_0    conda-forge
     soupsieve                 2.5                pyhd8ed1ab_1    conda-forge
     sqlalchemy                2.0.23                   pypi_0    pypi
     sqlparse                  0.4.4                    pypi_0    pypi
     stack-data                0.6.3                    pypi_0    pypi
     stack_data                0.6.2              pyhd8ed1ab_0    conda-forge
     starlette                 0.27.0                   pypi_0    pypi
     statsmodels               0.14.0                   pypi_0    pypi
     tabulate                  0.9.0                    pypi_0    pypi
     tangled-up-in-unicode     0.2.0                    pypi_0    pypi
     tenacity                  8.2.3                    pypi_0    pypi
     tensorboardx              2.6.2.2                  pypi_0    pypi
     terminado                 0.18.0             pyh0d859eb_0    conda-forge
     threadpoolctl             3.2.0                    pypi_0    pypi
     tifffile                  2023.12.9                pypi_0    pypi
     tinycss2                  1.2.1              pyhd8ed1ab_0    conda-forge
     tk                        8.6.13          noxft_h4845f30_101    conda-forge
     toml                      0.10.2                   pypi_0    pypi
     tomli                     2.0.1              pyhd8ed1ab_0    conda-forge
     tornado                   6.3.3           py310h2372a71_1    conda-forge
     tqdm                      4.66.1             pyhd8ed1ab_0    conda-forge
     traitlets                 5.14.0             pyhd8ed1ab_0    conda-forge
     truststore                0.8.0              pyhd8ed1ab_0    conda-forge
     typeguard                 4.1.5                    pypi_0    pypi
     typer                     0.9.0                    pypi_0    pypi
     types-python-dateutil     2.8.19.14          pyhd8ed1ab_0    conda-forge
     typing-extensions         4.8.0                hd8ed1ab_0    conda-forge
     typing_extensions         4.8.0              pyha770c72_0    conda-forge
     typing_utils              0.1.0              pyhd8ed1ab_0    conda-forge
     tzdata                    2023.3                   pypi_0    pypi
     uri-template              1.3.0              pyhd8ed1ab_0    conda-forge
     uritemplate               3.0.1                    pypi_0    pypi
     urllib3                   1.26.18                  pypi_0    pypi
     uvicorn                   0.24.0.post1             pypi_0    pypi
     uvloop                    0.19.0                   pypi_0    pypi
     virtualenv                20.21.0                  pypi_0    pypi
     visions                   0.7.5                    pypi_0    pypi
     watchfiles                0.21.0                   pypi_0    pypi
     wcwidth                   0.2.12             pyhd8ed1ab_0    conda-forge
     webcolors                 1.13               pyhd8ed1ab_0    conda-forge
     webencodings              0.5.1              pyhd8ed1ab_2    conda-forge
     websocket-client          1.7.0              pyhd8ed1ab_0    conda-forge
     websockets                12.0                     pypi_0    pypi
     wheel                     0.42.0             pyhd8ed1ab_0    conda-forge
     widgetsnbextension        4.0.9                    pypi_0    pypi
     wordcloud                 1.9.3                    pypi_0    pypi
     wrapt                     1.16.0                   pypi_0    pypi
     xz                        5.2.6                h166bdaf_0    conda-forge
     y-py                      0.6.2                    pypi_0    pypi
     yaml                      0.2.5                h7f98852_2    conda-forge
     yaml-cpp                  0.8.0                h59595ed_0    conda-forge
     yarl                      1.9.4                    pypi_0    pypi
     ydata-profiling           4.6.0                    pypi_0    pypi
     ypy-websocket             0.8.4                    pypi_0    pypi
     zeromq                    4.3.5                h59595ed_0    conda-forge
     zipp                      3.17.0             pyhd8ed1ab_0    conda-forge
     zlib                      1.2.13               hd590300_5    conda-forge
     zstandard                 0.22.0          py310h1275a96_0    conda-forge
     zstd                      1.5.5                hfc55251_0    conda-forge
     ```
",2023-12-29T10:26:09Z,0,0,Janmey Shukla,
324,pd.concat() of dictionaries [FEA],"**Missing Pandas Feature Request**

Please implement concatenation of dictionaries, as shown at the very bottom of the page in the [Pandas package](https://pandas.pydata.org/docs/reference/api/pandas.concat.html). Currently, cudf only supports DataFrame and Series objects; dictionaries would be a very useful addition.


**Additional context**

The following should return a cudf DataFrame stored in GPU ram.

Input >> `cudf.concat({'a': 1.1, 'b': 2.2}, axis=1)`

Stored variable >>

'a' | 1.1
'b' | 2.2

",2024-01-10T19:34:43Z,0,0,,
325,MixedTypeError when there is no mixed type [BUG],"**Describe the bug**
I load a pandas dataframe into cudf using cudf.from_pandas(originaldataframe) and it gives me a mixed type error.

**Steps/Code to reproduce bug**
Original Dataframe: 
```
     symbol                                               name STOCK_TYPE  first_date   last_date    AGE                INDUSTRY   marketcap
0     WHFBZ      WhiteHorse Finance, Inc. 6.50% Notes due 2025     common  2018-11-30  2021-12-16   1112                 Unknown    0.000000
1       ANH                 Anworth Mortgage Asset Corporation     common  1998-03-12  2021-03-19   8408                 Unknown    0.000000
2       CEE          The Central and Eastern Europe Fund, Inc.     common  1990-02-28  2024-01-09  12368        Asset Management    0.062059
3      SEMR                             SEMrush Holdings, Inc.     common  2021-03-24  2024-01-09   1021  Software - Application    1.780361
4      BWMX  Betterware de Mexico, S.A.P.I. de C.V. Ordinar...     common  2020-03-16  2024-01-09   1394        Specialty Retail    0.470934
...     ...                                                ...        ...         ...         ...    ...                     ...         ...
9281    GHI  Greystone Housing Impact Investors LP Benefici...     common  1986-04-02  2024-01-09  13796        Mortgage Finance    0.387465
9282    LMT                              Lockheed Martin Corp.     common  1977-01-03  2024-01-09  17172     Aerospace & Defense  113.205101
9283   ^DJI                                          Dow Jones      index  1970-01-02  2024-01-08  19729                   Index    0.000000
9284   ^INX                                            S&P 500      index  1970-01-02  2024-01-08  19729                   Index    0.000000
9285  ^IXIC                                             NASDAQ      index  1971-02-05  2024-01-08  19330                   Index    0.000000
```
I created the following function to create a dictionary of all the unique datatypes found for each column, even if there are more than one type in a single column.  Here's the function:
```
def get_column_data_types(dataframe):
    column_data_types = {}
    
    for column in dataframe.columns:
        unique_types = set(type(value) for value in dataframe[column])
        column_data_types[column] = unique_types
    
    return column_data_types
```
Here's the output of the column data types:
```
{
    'AGE': set([<class 'int'>]),
    'INDUSTRY': set([<class 'str'>]),
    'STOCK_TYPE': set([<class 'str'>]),
    'first_date': set([<class 'datetime.date'>]),
    'last_date': set([<class 'datetime.date'>]),
    'marketcap': set([<class 'float'>]),
    'name': set([<class 'str'>]),
    'symbol': set([<class 'str'>]),
}
```

As you can see, the function only found one datatype for each column.

Alternatively, if I use pandas built in datatype command `dataframe.dtypes` I get the following:
```
symbol         object
name           object
STOCK_TYPE     object
first_date     object
last_date      object
AGE             int64
INDUSTRY       object
marketcap     float64
dtype: object
```
So by both tests, each column has only one data type.  Though the .dtypes command shows ""object"" as the datatype.  Perhaps that's causing cudf to throw the error?

Here is another example:
```
            date        NVDA
0     1999-01-22    0.376356
1     1999-01-25    0.415730
2     1999-01-26    0.383428
3     1999-01-27    0.382281
4     1999-01-28    0.381134
...          ...         ...
6277  2024-01-03  475.690000
6278  2024-01-04  479.980000
6279  2024-01-05  490.970000
6280  2024-01-08  522.530000
6281  2024-01-09  531.400000
```
Running the following:

```
pprint(get_column_data_types(df))
pprint(df.dtypes)
```
gives you the following:

```
{'NVDA': set([<class 'float'>]), 'date': set([<class 'datetime.date'>])}

date     object
NVDA    float64
dtype: object
```
As you can see, each column has only one data type.  Yet when I try to convert df to a cudf using cudf.from_pandas(df), it throws the same mixed type error.


**Expected behavior**
There's no apparent mixtype column in the dataframe so it should be able to open the dataframe without throwing the mixedtype error.

**Environment overview (please complete the following information)**
 - Environment location: Local machine.  PC running Win 11 using WSL2 Ubuntu
 - Method of cuDF install: pip

CUDA 12 installed
NVIDIA GTX 1080 graphics card


**Environment details**
Error thrown in detail:
```
Traceback (most recent call last):
  File ""/usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""/home/notwopr/.local/lib/python3.10/site-packages/cudf/pandas/__main__.py"", line 91, in <module>
    main()
  File ""/home/notwopr/.local/lib/python3.10/site-packages/cudf/pandas/__main__.py"", line 87, in main
    runpy.run_path(args.args[0], run_name=""__main__"")
  File ""/usr/lib/python3.10/runpy.py"", line 289, in run_path
    return _run_module_code(code, init_globals, run_name,
  File ""/usr/lib/python3.10/runpy.py"", line 96, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""scratchp7.py"", line 29, in <module>
    stockdatastats = FileOperations().readpkl(oldfn, DirPaths().full_info_db)
  File ""/home/notwopr/beluga/beluga3/file_functions.py"", line 57, in readpkl
    data = cudf.from_pandas(data)
  File ""/home/notwopr/.local/lib/python3.10/site-packages/nvtx/nvtx.py"", line 115, in inner
    result = func(*args, **kwargs)
  File ""/home/notwopr/.local/lib/python3.10/site-packages/cudf/core/dataframe.py"", line 7891, in from_pandas
    return DataFrame.from_pandas(obj, nan_as_null=nan_as_null)
  File ""/home/notwopr/.local/lib/python3.10/site-packages/nvtx/nvtx.py"", line 115, in inner
    result = func(*args, **kwargs)
  File ""/home/notwopr/.local/lib/python3.10/site-packages/cudf/core/dataframe.py"", line 5237, in from_pandas
    data[col_name] = column.as_column(
  File ""/home/notwopr/.local/lib/python3.10/site-packages/cudf/core/column/column.py"", line 2279, in as_column
    raise MixedTypeError(""Cannot create column with mixed types"")
cudf.errors.MixedTypeError: Cannot create column with mixed types
```

**Additional context**
Add any other context about the problem here.
",2024-01-19T06:53:54Z,0,0,David Choi,
326,[BUG] `RollingGroupBy` objects cannot be pickled,"I noticed that `RollingGroupby` objects in cuDF cannot be pickled:

```python
In [5]: df = cudf.DataFrame({'a': [1, 1, 2], 'b': [1, 2, 3]})

In [6]: pickle.dumps(df.groupby('a').rolling(2))
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[6], line 1
----> 1 pickle.dumps(df.groupby('a').rolling(2))

ValueError: ctypes objects containing pointers cannot be pickled
```

This has something to do with the `.window` attribute being a numba DeviceArray, and the latter being unpicklable. ",2024-01-23T20:18:08Z,0,0,Ashwin Srinath,Voltron Data
327,[BUG][JNI] java.lang.IllegalArgumentException: Unknown scalar type: STRUCT,"**Describe the bug**
cuDF Java supports creating Scalar types to represent structs, but printing them for debug purposes causes an exception.

```
java.lang.IllegalArgumentException: Unknown scalar type: STRUCT
```

**Steps/Code to reproduce bug**
Create a scalar using `Scalar.structFromNull` or `Scalar.structFromColumnViews` and then call its `toString` method or try and print it using `System.out.println`

**Expected behavior**
Should print some useful debug info as per other scalar types, rather than throw an exception.

**Environment overview (please complete the following information)**
N/A

**Environment details**

**Additional context**
",2024-01-23T23:50:46Z,0,0,Andy Grove,@Apple
328,[FEA] Consolidate python code-style checking and formatting to just use `ruff`,"**Is your feature request related to a problem? Please describe.**

We have already migrated to using [ruff](https://docs.astral.sh/ruff/) to replace flake8 and pyflakes. A previous barrier to using ruff's `isort` lint was lack of support for custom sections, [that is now supported](https://docs.astral.sh/ruff/settings/#isort-sections). Similarly, `ruff format` (which produces effectively black-compatible formatting) is now in ""stable"" beta and very usable.

We should consider migrating the separate `isort` and `black` configs to use `ruff check --fix` and `ruff format` respectively.

The advantage here is that ruff is orders of magnitude faster than both isort and black. For those of us that use format-on-save this is a significant quality of life improvement (formatting a large python file when editing cudf can easily take a few seconds with black).

We would also reduce our tool configuration options.

We might also at the same time consider increasing the default line length from the current (somewhat miserly) 79 characters.",2024-01-25T12:30:01Z,0,0,Lawrence Mitchell,
329,[FEA] Produce and Consume ArrowDeviceArray struct from cudf::table / cudf::column,"**Is your feature request related to a problem? Please describe.**
I would like to generate Arrow IPC payloads from a `cudf::table` without copying the data off of the GPU device. Currently the `to_arrow` and `from_arrow` functions explicitly perform copies to and from the GPU device. There is not currently any efficient way to generate Arrow IPC payloads from libcudf without copying all of the data off of the device.

**Describe the solution you'd like**
In addition to the existing `to_arrow` and `from_arrow` functions, we could have a `to_arrow_device_arr` function that populates an `ArrowDeviceArray` struct from a `cudf::table` or `cudf::column`. We'd also create a `from_arrow_device_arr` function that could construct a `cudf::table` / `cudf::column` from an `ArrowDeviceArray` that describes Arrow data which is already on the device. Once you have the `ArrowDeviceArray` struct, the Arrow C++ library itself can be used to generate the IPC payloads without needing to copy the data off the device. This would also increase the interoperability options that libcudf has, as anything which produces or consumes `ArrowDeviceArray` structs could hand data off to libcudf and vice versa.

**Describe alternatives you've considered**
An alternative would be to implement Arrow IPC creating inside of the libcudf library, but I saw that this was explicitly removed from libcudf due to the requirement of linking against `libarrow_cuda.so`. (https://github.com/rapidsai/cudf/issues/10994). Implementing conversions to and from `ArrowDeviceArray` wouldn't require linking against `libarrow_cuda.so` at all and would provide an easy way to allow any consumers to create Arrow IPC payloads, or whatever else they want to do with the resulting Arrow data. Such as leveraging CUDA IPC with the data.

**Additional context**
When designing the `ArrowDeviceArray` struct, I created https://github.com/zeroshade/arrow-non-cpu as a POC which used Python numba to generate and operate on some GPU data before handing it off to libcudf, and then getting it back without copying off the device. Using `ArrowDeviceArray` as the way it handed the data off.

More recently I've been working on creating a protocol for sending Arrow IPC data that is located on GPUs across high-performance transports like UCX. To this end, I created a POC using libcudf to pass the data. As a result I have a partial implementation of the `to_arrow_device_arr` which can be found [here](https://github.com/zeroshade/cudf-flight-ucx/blob/main/to_arrow.cc). There's likely better ways than what I'm doing in there, but at least for my POC it was working.

The contribution guidelines say I should file this issue first for discussion rather than just submitting a PR, so that's where I'm at. I plan on trying to create a full implementation that I can contribute but wanted to have this discussion and get feedback here first. 

Thanks for hearing me out everyone!
",2024-01-29T21:39:04Z,0,0,Matt Topol,@voltrondata
330,[BUG] dask_cudf pivot_table function is broken: TypeError: StringIndex object is not iterable.,"**Describe the bug**
Pivot_table fails on a dask_cudf dataframe due to an unimplemented Index iteration function:

**Steps/Code to reproduce bug**
```python
ddf = dask_cudf.from_cudf(cudf.DataFrame(
    data={
        ""A"": [""foo"", ""bar"", ""bar""],
        ""B"": [""one"", ""two"", ""one""],
        ""C"": [1, 2, 3]
    }
), npartitions=1)
ddf = ddf.categorize(""B"")
ddf.pivot_table(index=""A"", columns=""B"", values=""C"")
```

Error:
```python
TypeError                                 Traceback (most recent call last)
Cell In[3], line 9
      1 ddf = dask_cudf.from_cudf(cudf.DataFrame(
      2     data={
      3         ""A"": [""foo"", ""bar"", ""bar""],
   (...)
      6     }
      7 ), npartitions=1)
      8 ddf = ddf.categorize(""B"")
----> 9 ddf.pivot_table(index=""A"", columns=""B"", values=""C"")

File lib/python3.10/site-packages/dask/dataframe/core.py:6373, in DataFrame.pivot_table(self, index, columns, values, aggfunc)
   6352 """"""
   6353 Create a spreadsheet-style pivot table as a DataFrame. Target ``columns``
   6354 must have category dtype to infer result's ``columns``.
   (...)
   6369 table : DataFrame
   6370 """"""
   6371 from dask.dataframe.reshape import pivot_table
-> 6373 return pivot_table(
   6374     self, index=index, columns=columns, values=values, aggfunc=aggfunc
   6375 )

File lib/python3.10/site-packages/dask/dataframe/reshape.py:233, in pivot_table(df, index, columns, values, aggfunc)
    226     raise ValueError(
    227         ""aggfunc must be either "" + "", "".join(f""'{x}'"" for x in available_aggfuncs)
    228     )
    230 # _emulate can't work for empty data
    231 # the result must have CategoricalIndex columns
--> 233 columns_contents = pd.CategoricalIndex(df[columns].cat.categories, name=columns)
    234 if is_scalar(values):
    235     new_columns = columns_contents

File lib/python3.10/site-packages/pandas/core/indexes/category.py:234, in CategoricalIndex.__new__(cls, data, categories, ordered, dtype, copy, name)
    231 if is_scalar(data):
    232     raise cls._scalar_data_error(data)
--> 234 data = Categorical(
    235     data, categories=categories, ordered=ordered, dtype=dtype, copy=copy
    236 )
    238 return cls._simple_new(data, name=name)

File lib/python3.10/site-packages/pandas/core/arrays/categorical.py:410, in Categorical.__init__(self, values, categories, ordered, dtype, fastpath, copy)
    408         dtype = CategoricalDtype(values.categories, dtype.ordered)
    409 elif not isinstance(values, (ABCIndex, ABCSeries, ExtensionArray)):
--> 410     values = com.convert_to_list_like(values)
    411     if isinstance(values, list) and len(values) == 0:
    412         # By convention, empty lists result in object dtype:
    413         values = np.array([], dtype=object)

File lib/python3.10/site-packages/pandas/core/common.py:541, in convert_to_list_like(values)
    539     return values
    540 elif isinstance(values, abc.Iterable) and not isinstance(values, str):
--> 541     return list(values)
    543 return [values]

File lib/python3.10/site-packages/cudf/utils/utils.py:242, in NotIterable.__iter__(self)
    235 def __iter__(self):
    236     """"""
    237     Iteration is unsupported.
    238 
    239     See :ref:`iteration <pandas-comparison/iteration>` for more
    240     information.
    241     """"""
--> 242     raise TypeError(
    243         f""{self.__class__.__name__} object is not iterable. ""
    244         f""Consider using `.to_arrow()`, `.to_pandas()` or `.values_host` ""
    245         f""if you wish to iterate over the values.""
    246     )

TypeError: StringIndex object is not iterable. Consider using `.to_arrow()`, `.to_pandas()` or `.values_host` if you wish to iterate over the values.
```

**Expected behavior**
Pivot_table succeeds as documented.

**Environment overview (please complete the following information)**
Installed cuDF using pip, using the stable release:
```bash
pip install \
    --extra-index-url=https://pypi.nvidia.com \
    cudf-cu12==23.12.* dask-cudf-cu12==23.12.* cuml-cu12==23.12.* \
    cugraph-cu12==23.12.* cuspatial-cu12==23.12.* cuproj-cu12==23.12.* \
    cuxfilter-cu12==23.12.* cucim-cu12==23.12.* pylibraft-cu12==23.12.* \
    raft-dask-cu12==23.12.*
```

**Environment details**
```
<details><summary>Click here to see environment details</summary><pre>
     
     **git***
fatal: your current branch 'master' does not have any commits yet
     **git submodules***
     
     ***OS Information***
     NAME=""Red Hat Enterprise Linux""
     VERSION=""8.8 (Ootpa)""
     ID=""rhel""
     ID_LIKE=""fedora""
     VERSION_ID=""8.8""
     PLATFORM_ID=""platform:el8""
     PRETTY_NAME=""Red Hat Enterprise Linux 8.8 (Ootpa)""
     ANSI_COLOR=""0;31""
     CPE_NAME=""cpe:/o:redhat:enterprise_linux:8::baseos""
     HOME_URL=""https://www.redhat.com/""
     DOCUMENTATION_URL=""https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8""
     BUG_REPORT_URL=""https://bugzilla.redhat.com/""
     
     REDHAT_BUGZILLA_PRODUCT=""Red Hat Enterprise Linux 8""
     REDHAT_BUGZILLA_PRODUCT_VERSION=8.8
     REDHAT_SUPPORT_PRODUCT=""Red Hat Enterprise Linux""
     REDHAT_SUPPORT_PRODUCT_VERSION=""8.8""
     Red Hat Enterprise Linux release 8.8 (Ootpa)
     Red Hat Enterprise Linux release 8.8 (Ootpa)
     Linux c1000a-s23.ufhpc 4.18.0-477.27.1.el8_8.x86_64 #1 SMP Thu Aug 31 10:29:22 EDT 2023 x86_64 x86_64 x86_64 GNU/Linux
     
     ***GPU Information***
     Tue Jan 30 11:09:21 2024
     +---------------------------------------------------------------------------------------+
     | NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |
     |-----------------------------------------+----------------------+----------------------+
     | GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
     |                                         |                      |               MIG M. |
     |=========================================+======================+======================|
     |   0  NVIDIA A100-SXM4-80GB          On  | 00000000:07:00.0 Off |                    0 |
     | N/A   25C    P0              56W / 400W |      4MiB / 81920MiB |      0%      Default |
     |                                         |                      |             Disabled |
     +-----------------------------------------+----------------------+----------------------+
     |   1  NVIDIA A100-SXM4-80GB          On  | 00000000:0F:00.0 Off |                    0 |
     | N/A   26C    P0              57W / 400W |      4MiB / 81920MiB |      0%      Default |
     |                                         |                      |             Disabled |
     +-----------------------------------------+----------------------+----------------------+
     |   2  NVIDIA A100-SXM4-80GB          On  | 00000000:47:00.0 Off |                    0 |
     | N/A   24C    P0              54W / 400W |      4MiB / 81920MiB |      0%      Default |
     |                                         |                      |             Disabled |
     +-----------------------------------------+----------------------+----------------------+
     |   3  NVIDIA A100-SXM4-80GB          On  | 00000000:4E:00.0 Off |                    0 |
     | N/A   24C    P0              56W / 400W |      4MiB / 81920MiB |      0%      Default |
     |                                         |                      |             Disabled |
     +-----------------------------------------+----------------------+----------------------+
     |   4  NVIDIA A100-SXM4-80GB          On  | 00000000:87:00.0 Off |                    0 |
     | N/A   29C    P0              67W / 400W |    583MiB / 81920MiB |     40%      Default |
     |                                         |                      |             Disabled |
     +-----------------------------------------+----------------------+----------------------+
     |   5  NVIDIA A100-SXM4-80GB          On  | 00000000:90:00.0 Off |                    0 |
     | N/A   45C    P0             177W / 400W |    775MiB / 81920MiB |     94%      Default |
     |                                         |                      |             Disabled |
     +-----------------------------------------+----------------------+----------------------+
     |   6  NVIDIA A100-SXM4-80GB          On  | 00000000:B7:00.0 Off |                    0 |
     | N/A   60C    P0             338W / 400W |  76523MiB / 81920MiB |    100%      Default |
     |                                         |                      |             Disabled |
     +-----------------------------------------+----------------------+----------------------+
     |   7  NVIDIA A100-SXM4-80GB          On  | 00000000:BD:00.0 Off |                    0 |
     | N/A   28C    P0              54W / 400W |      4MiB / 81920MiB |      0%      Default |
     |                                         |                      |             Disabled |
     +-----------------------------------------+----------------------+----------------------+
     
     +---------------------------------------------------------------------------------------+
     | Processes:                                                                            |
     |  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
     |        ID   ID                                                             Usage      |
     |=======================================================================================|
     |    4   N/A  N/A   2669759      C   python3                                     570MiB |
     |    5   N/A  N/A   1903237      C   pmemd.cuda_SPFP                             762MiB |
     |    6   N/A  N/A   1446394      C   python                                    76510MiB |
     +---------------------------------------------------------------------------------------+
     
     ***CPU***
     Architecture:        x86_64
     CPU op-mode(s):      32-bit, 64-bit
     Byte Order:          Little Endian
     CPU(s):              128
     On-line CPU(s) list: 0-127
     Thread(s) per core:  1
     Core(s) per socket:  64
     Socket(s):           2
     NUMA node(s):        8
     Vendor ID:           AuthenticAMD
     CPU family:          23
     Model:               49
     Model name:          AMD EPYC 7742 64-Core Processor
     Stepping:            0
     CPU MHz:             3386.055
     CPU max MHz:         2250.0000
     CPU min MHz:         1500.0000
     BogoMIPS:            4491.84
     Virtualization:      AMD-V
     L1d cache:           32K
     L1i cache:           32K
     L2 cache:            512K
     L3 cache:            16384K
     NUMA node0 CPU(s):   0-15
     NUMA node1 CPU(s):   16-31
     NUMA node2 CPU(s):   32-47
     NUMA node3 CPU(s):   48-63
     NUMA node4 CPU(s):   64-79
     NUMA node5 CPU(s):   80-95
     NUMA node6 CPU(s):   96-111
     NUMA node7 CPU(s):   112-127
     Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip rdpid overflow_recov succor smca sme sev sev_es
     
     ***CMake***
     /apps/jupyter/6.5.4/bin/cmake
./print_env.sh: /apps/jupyter/6.5.4/bin/cmake: /apps/jupyter/6.5.4/bin/python3.11: bad interpreter: No such file or directory
     
     ***g++***
     /usr/bin/g++
     g++ (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
     Copyright (C) 2018 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
     
     
     ***nvcc***
     /apps/compilers/cuda/12.2.2/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2023 NVIDIA Corporation
     Built on Tue_Aug_15_22:02:13_PDT_2023
     Cuda compilation tools, release 12.2, V12.2.140
     Build cuda_12.2.r12.2/compiler.33191640_0
     
     ***Python***
     /blue/ptighe-rapidsai/pvnick/rapids-test/rapids-test/bin/python
     Python 3.10.12
     
     ***Environment Variables***
     PATH                            : /apps/compilers/cuda/12.2.2/bin:/blue/ptighe-rapidsai/pvnick/rapids-test/rapids-test/bin:/opt/slurm/bin:/usr/local/cuda/bin:/opt/bin:/apps/jupyter/6.5.4/bin:/apps/ufrc/ufhpc/bin:/apps/git/2.30.1/bin:/home/pvnick/.local/bin:/home/pvnick/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/bin
     LD_LIBRARY_PATH                 : /apps/compilers/cuda/12.2.2/lib64:/opt/slurm/lib64::
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    :
     PYTHON_PATH                     :
     
     conda not found
     ***pip packages***
     /blue/ptighe-rapidsai/pvnick/rapids-test/rapids-test/bin/pip
     Package                   Version
     ------------------------- ---------------
     aiohttp                   3.9.3
     aiosignal                 1.3.1
     anyio                     4.2.0
     argon2-cffi               23.1.0
     argon2-cffi-bindings      21.2.0
     arrow                     1.3.0
     asttokens                 2.4.1
     async-lru                 2.0.4
     async-timeout             4.0.3
     attrs                     23.2.0
     Babel                     2.14.0
     beautifulsoup4            4.12.3
     bleach                    6.1.0
     bokeh                     3.3.4
     cachetools                5.3.2
     certifi                   2023.11.17
     cffi                      1.16.0
     charset-normalizer        3.3.2
     click                     8.1.7
     click-plugins             1.1.1
     cligj                     0.7.2
     cloudpickle               3.0.0
     colorcet                  3.0.1
     comm                      0.2.1
     contourpy                 1.2.0
     cucim-cu12                23.12.1
     cuda-python               12.3.0
     cudf-cu12                 23.12.1
     cugraph-cu12              23.12.0
     cuml-cu12                 23.12.0
     cuproj-cu12               23.12.1
     cupy-cuda12x              13.0.0
     cuspatial-cu12            23.12.1
     cuxfilter-cu12            23.12.0
     dask                      2023.11.0
     dask-cuda                 23.12.0
     dask-cudf-cu12            23.12.0
     datashader                0.16.0
     debugpy                   1.8.0
     decorator                 5.1.1
     defusedxml                0.7.1
     distributed               2023.11.0
     exceptiongroup            1.2.0
     executing                 2.0.1
     fastjsonschema            2.19.1
     fastrlock                 0.8.2
     fiona                     1.9.5
     fqdn                      1.5.1
     frozenlist                1.4.1
     fsspec                    2023.12.2
     geopandas                 0.14.2
     holoviews                 1.18.1
     idna                      3.6
     imageio                   2.33.1
     importlib-metadata        7.0.1
     ipykernel                 6.29.0
     ipython                   8.20.0
     ipywidgets                8.1.1
     isoduration               20.11.0
     jedi                      0.19.1
     Jinja2                    3.1.3
     joblib                    1.3.2
     json5                     0.9.14
     jsonpointer               2.4
     jsonschema                4.21.1
     jsonschema-specifications 2023.12.1
     jupyter                   1.0.0
     jupyter_client            8.6.0
     jupyter-console           6.6.3
     jupyter_core              5.7.1
     jupyter-events            0.9.0
     jupyter-lsp               2.2.2
     jupyter_server            2.12.5
     jupyter_server_proxy      4.1.0
     jupyter_server_terminals  0.5.2
     jupyterlab                4.0.11
     jupyterlab_pygments       0.3.0
     jupyterlab_server         2.25.2
     jupyterlab-widgets        3.0.9
     lazy_loader               0.3
     linkify-it-py             2.0.2
     llvmlite                  0.40.1
     locket                    1.0.0
     Markdown                  3.5.2
     markdown-it-py            3.0.0
     MarkupSafe                2.1.4
     matplotlib-inline         0.1.6
     mdit-py-plugins           0.4.0
     mdurl                     0.1.2
     mistune                   3.0.2
     msgpack                   1.0.7
     multidict                 6.0.4
     multipledispatch          1.0.0
     nbclient                  0.9.0
     nbconvert                 7.14.2
     nbformat                  5.9.2
     nest-asyncio              1.6.0
     networkx                  3.2.1
     notebook                  7.0.7
     notebook_shim             0.2.3
     numba                     0.57.1
     numpy                     1.24.4
     nvtx                      0.2.8
     overrides                 7.7.0
     packaging                 23.2
     pandas                    1.5.3
     pandocfilters             1.5.1
     panel                     1.3.8
     param                     2.0.2
     parso                     0.8.3
     partd                     1.4.1
     pexpect                   4.9.0
     pillow                    10.2.0
     pip                       23.0.1
     platformdirs              4.1.0
     prometheus-client         0.19.0
     prompt-toolkit            3.0.43
     protobuf                  4.25.2
     psutil                    5.9.8
     ptyprocess                0.7.0
     pure-eval                 0.2.2
     pyarrow                   14.0.2
     pycparser                 2.21
     pyct                      0.5.0
     Pygments                  2.17.2
     pylibcugraph-cu12         23.12.0
     pylibraft-cu12            23.12.0
     pynvml                    11.4.1
     pyproj                    3.6.1
     python-dateutil           2.8.2
     python-json-logger        2.0.7
     pytz                      2023.4
     pyviz_comms               3.0.1
     PyWavelets                1.5.0
     PyYAML                    6.0.1
     pyzmq                     25.1.2
     qtconsole                 5.5.1
     QtPy                      2.4.1
     raft-dask-cu12            23.12.0
     rapids-dask-dependency    23.12.1
     referencing               0.33.0
     requests                  2.31.0
     rfc3339-validator         0.1.4
     rfc3986-validator         0.1.1
     rich                      13.7.0
     rmm-cu12                  23.12.0
     rpds-py                   0.17.1
     scikit-image              0.21.0
     scipy                     1.12.0
     Send2Trash                1.8.2
     setuptools                65.5.0
     shapely                   2.0.2
     simpervisor               1.0.0
     six                       1.16.0
     sniffio                   1.3.0
     sortedcontainers          2.4.0
     soupsieve                 2.5
     stack-data                0.6.3
     tblib                     3.0.0
     terminado                 0.18.0
     tifffile                  2024.1.30
     tinycss2                  1.2.1
     tomli                     2.0.1
     toolz                     0.12.1
     tornado                   6.4
     tqdm                      4.66.1
     traitlets                 5.14.1
     treelite                  3.9.1
     treelite-runtime          3.9.1
     types-python-dateutil     2.8.19.20240106
     typing_extensions         4.9.0
     uc-micro-py               1.0.2
     ucx-py-cu12               0.35.0
     uri-template              1.3.0
     urllib3                   2.1.0
     wcwidth                   0.2.13
     webcolors                 1.13
     webencodings              0.5.1
     websocket-client          1.7.0
     widgetsnbextension        4.0.9
     xarray                    2024.1.1
     xyzservices               2023.10.1
     yarl                      1.9.4
     zict                      3.0.0
     zipp                      3.17.0

[notice] A new release of pip is available: 23.0.1 -> 23.3.2
[notice] To update, run: pip install --upgrade pip
     
</pre></details>
```
",2024-01-30T16:11:19Z,0,0,paul,
331,[FEA] Implement a templated parquet decoding kernel suitable for reuse in micro-kernel optimization approach.,"As part of the drive towards implementing the micro-kernel parquet decoding strategy, we would like to start centralizing the core parquet decoding loop into a generic templated implementation that can be reused.  At the high level, all of various parquet kernels are structured similar to this:
```
kernel(PageInfo p)
{
    // page setup, bounds checking (for skip_rows/num_rows), etc
    setup_code();

   while(there are still values to decode in p){
      def_levels = def_stream.decode(def_levels);
      rep_levels = p.has_lists ? rep_stream.decode(rep_levels);
      dict_indices = p.has_dict ? dict_stream.decode(dict_indices);
      decode_general_outputs(def_levels, rep_levels, dict_indices);

      PROCESS(p, def_levels, rep_levels, dict_indices);
   }
}
```
The various *_stream.decode() functions are the key bottleneck in decoding parquet data. At the moment, the kernels we have mostly utilize the older/slower way of decoding these streams.  The `rle_stream` class was developed to do this in a more parallel (and more confiurable) way, but only a few kernels use it at the moment because it does not currently handle dictionaries.  The work for that is underway and very close to completion (https://github.com/rapidsai/cudf/issues/14950)

`decode_general_outputs` is a function that produces validity, list offset information and the mapping of source data (location in the parquet data page) to destination data (location in the final cudf column).  The amount of work this function has to do varies greatly based on the characteristics of the input data - nullability, presence of lists, etc.

PROCESS is something that varies from kernel-to-kernel.  Essentially, the user-provided function that actually does the final data decoding.

We would like to implement this high level loop as a templated function that can be tailored to produce multiple, more optimal kernels based on they key data characteristics. For example:

```
template<// page data characteristics
                bool nullable,
                bool has_lists,
                bool has_dictionary,
                etc

                // parameters which can be tuned 
                int decode_buffer_size,
                int decode_warp_count,
                etc,
                
                // user provided PROCESS functor
                ProcessFunc Proc>
```

There are several reasons to do this:
- The `rle_stream` class uses shared memory, so it is a big advantage to be able to have kernels that don't need a given feature (say, list decoding) to be able to use less.
- It is useful to be able to tune block size per kernel as they tend to get bottlenecked in different ways.  
- It would allow us to eliminate the old level decoding path.

The first candidates for using this would be two new micro-kernels:  Fixed-width and fixed-width-with-dictionaries (the non-list case for both of them). We would like to get these in for 24.04 and then later on we can start refactoring the larger mass of existing kernels (especially the general-purpose `gpuDecodePageData` and `gpuDecodeStringPageData`",2024-02-01T19:09:50Z,0,0,,
332,[FEA] Zero-copy nested types with other GPU libraries (like Awkward array),"In a conversation with @martindurant and @jpivarski, it came up that there's no supported way to exchange data zero copy between cuDF and [Awkward Array](https://awkward-array.org/doc/main/) (which has GPU support).

The standard 0-copy mechanisms like dlpack and `__cuda_array_interface__` don't support nested types like lists or structs. And our `to/from_arrow()` methods convert to and from _host_ data so they're not useful when we want to 0-copy _device_ data.

## Option 1

We support a `gpu=True` (or similar) keyword argument in `to_arrow()` which would then return a PyArrow array backed by device data. Now, PyArrow does not seemingly support it, but it's _possible_ to create a PyArrow array backed by device data:

```python
In [5]: a = cp.asarray([1, 2, 3])

In [6]: buf = pa.foreign_buffer(a.data.ptr, a.nbytes, a)

In [7]: type(buf)
Out[7]: pyarrow.lib.Buffer

In [8]: print(buf)
<pyarrow.Buffer address=0x7f2f6fa00200 size=24 is_cpu=True is_mutable=False>
```

The problem (as can be seen above) is that PyArrow thinks this is a CPU-backed buffer. So attempting to do anything with it segfaults:

```python
In [9]: arr = pa.Array.from_buffers(pa.int64(), len(a), buffers=[None, buf])

In [10]: print(arr)  # segfault
```

## Option 2

We could expose new `Series.to_buffers()` and `Series.from_buffers()` functions that would produce and consume GPU buffers (along with a schema), presumably in the same order as arrow's [from_buffers](https://arrow.apache.org/docs/python/generated/pyarrow.Array.html#pyarrow.Array.from_buffers) and [buffers](https://arrow.apache.org/docs/python/generated/pyarrow.Array.html#pyarrow.Array.buffers) methods. We could use CuPy arrays to represent the buffers.

---

Curious what folks think? Interested also in @kkraus14's thoughts here if any.",2024-02-02T21:21:47Z,0,0,Ashwin Srinath,Voltron Data
333,[FEA] Incorporate chunked parquet reading into cuDF-python,"**Is your feature request related to a problem? Please describe.**
libcudf provides a `chunked_parquet_reader` in its public API. This reader uses new reader options to process the data in a parquet file in sub-file units. The `chunk_read_limit` option limits the table size in bytes to be returned per read by only decoding a subset of pages per chunked read. The `pass_read_limit` option limits the memory used for reading and decompressing data by only decompressing a subset of pages per chunked read.

The chunked parquet reader allows cuDF-python to expose two types of useful functionality:
1. an API that acts as an iterator to yield dataframe chunks. This is similar to the `iter_row_groups` behavior in [fastparquet](https://fastparquet.readthedocs.io/en/latest/api.html). This approach would let users work with parquet files that contain more rows than 2.1B rows (see #13159 for more information about the row limit in libcudf). 
2. a ""low_memory"" mode that reads the full file, but has a lower peak memory footprint thanks to the smaller sizes of intermediate allocations. This is similar to the the `low_memory` argument in [polars](https://docs.pola.rs/py-polars/html/reference/api/polars.read_parquet.html). This approach would make it easier to read large parquet datasets with limited GPU memory.

**Describe the solution you'd like**
We should make chunked parquet reading available to cuDF-python users. Perhaps this functionality could be made available to `cudf.pandas` users as well. 


**Additional context**
Pandas does not seem to have a method for chunking parquet reads, and I'm not sure if pandas makes use of the `iter_row_groups` behavior in fastparquet as a pass-through parameter.


API docs references:
* pandas: [read_parquet](https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html)
* pyarrow: [parquet.read_table](https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html)
* fastparquet: [read_parquet](https://fastparquet.readthedocs.io/en/latest/api.html)
* polars: [read_parquet](https://docs.pola.rs/py-polars/html/reference/api/polars.read_parquet.html)
* cudf: [read_parquet](https://docs.rapids.ai/api/cudf/nightly/user_guide/api_docs/api/cudf.read_parquet/)
",2024-02-04T19:10:28Z,0,0,Gregory Kimball,
334,[FEA] Update JSON reader benchmarks to include JSON lines and normalization,"**Is your feature request related to a problem? Please describe.**

First pass changes:
- [ ] I believe [this line](https://github.com/rapidsai/cudf/blob/bb6ae07079f3c36dca8387bab578b75d06be6b33/cpp/benchmarks/io/json/nested_json.cpp#L91) in the benchmark `nested_json.cpp` should use `max_list_size` instead of `max_struct_size`. We should also add `int64` nvbench axes for these two size values, sticking with a standard value of `{10}`, and adding the ability to sweep these parameters in custom tests.
- [ ] Add JSON versus JSON Lines benchmark. We have a `parquet_reader_options` benchmark and we could add something similar e.g. `json_reader_options`. This benchmark can start by choosing a single data type and a device buffer data source. As a follow-on step we would want to allow data type and IO source to be nvbench enum axes.
- [ ] Add `_normalize_single_quotes` and `_normalize_whitespace` to the `json_reader_options` benchmark. Since the JSON writer can't generate single quotes or extra whitespace, these normalization steps will not change the resulting table, but we should track the added runtime.
- [ ] Add `_recovery_mode` and `_mixed_types_as_string` to the `json_reader_options` benchmark as ""no-op"" tests. The benchmark would use the the existing data generator without invalid records and without mixed types.
- [ ] Add post-processing to the generated data to introduce mixed types, and then benchmark against similar data without mixed types. The approach could be using the existing data generator, but then changing one list entry into a struct entry, e.g. `[1,2,3]` => `{""a"": [1,2,3]}`

Lower priority ideas. If we have reason to believe these benchmarks would highlight performance issues, then we should raise their priority.
- [ ] For the quote and whitespace normalization options, create a modified data generator or character buffer post-processing to introduce un-normalized data. For instance, we could replace `""` with `'` for quote normalization and `:` with ` : ` for whitespace normalization.
- [ ] Update the data generator to introduce invalid JSON lines and exercises the `_recovery_mode` as nulls code path. We could add a fraction of invalid records as well as valid records followed by invalid characters.
- [ ] Add a normalization benchmark into the `benchmarks/io/json/` suite that measures the runtime of `detail::normalize_single_quotes` and the upcoming detil API for whitespace normalization. This benchmark would not test the overall reader, but only the FST-based normalization functions.

",2024-02-13T21:15:10Z,0,0,Gregory Kimball,
335,[FEA] Update chunked parquet reader benchmarks to include `pass_read_limit`,"**Is your feature request related to a problem? Please describe.**
The `BM_parquet_read_chunks` benchmark in `benchmarks/io/parquet/parquet_reader_input.cpp` includes a `byte_limit` nvbench axis. This axis controls the `chunk_read_limit`. With the new features added in #14360, there is a new `chunked_parquet_reader` API that exposes both `chunk_read_limit` and `pass_read_limit` parameters to control reader behavior. We currently do not have a method for benchmarking `pass_read_limit` values.

**Describe the solution you'd like**
- [ ] Add a new benchmark, such as `BM_parquet_read_subrowgroup_chunks`, that provides nvbench axes for both `chunk_read_limit` and `pass_read_limit`
- [ ] Rename `byte_limit` to `chunk_read_limit` in `BM_parquet_read_chunks` for clarity, now that we have both input and output byte limits in chunked parquet reading.
- [ ] Also, please consider adding an nvbench axis for `data_size` for at least the chunked parquet reader benchmarks. It would be useful to allow the benchmarks to operate on tables larger than 536 MB.

**Describe alternatives you've considered**
n/a",2024-02-14T21:27:40Z,0,0,Gregory Kimball,
336,[FEA] Implement center for offset based windows,"Suppose I have a Series as follows:
```python
s = cudf.Series(range(100), index=cudf.date_range('2024', periods=100, freq='D'))
```
If I want to perform 3-day rolling window mean, I can do:
```python
window_size = 3
s.rolling(f'{window_size}D').mean()
```
This is not centered. If I want to set the window labels as the center of the window index (like in pandas):
```python
a = s.rolling(f'{window_size}D', center=True).mean()
```
then I get a NotImplementedError.

I wish I could do this in cudf.

Right now, I can just compute the rolling mean, shift it by half the window size and fill in the NaN values by using a loop over a variable window but it's a little ugly.
```python
shift = -(window_size-1)//2
b = s.rolling(f'{window_size}D').mean().shift(shift)
b.iloc[shift:] = [s.loc[i:].mean() for i in s.index[-window_size+1:-window_size-shift+1]]
```

Pandas' `DataFrame.rolling` uses a cython optimized function to implement `center` (and `closed`) parameters. Its function to get variable window indexers is `pandas._libs.window.indexers.calculate_variable_window_bounds`. My suggestion is to implement this function in cudf.",2024-02-19T07:50:52Z,0,0,Manlai Amar,
337,"[BUG] Unlike its pandas counterpart, `cudf.date_range` doesn't include the end if it's specified","If I create a DatetimeIndex object using `cudf.date_range()` by passing `start`, `end` and `freq` parameters:
```python
cudf.date_range('2020-01-01', '2020-01-05', freq='D')

DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04'], 
              dtype='datetime64[ns]', freq='D')
```
As you can see, the result is an object with length 4. The same code in pandas results in an object with length 5:
```python
pd.date_range('2020-01-01', '2020-01-05', freq='D')

DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04', '2020-01-05'],
              dtype='datetime64[ns]', freq='D')
```

Is it possible to make it consistent with pandas' `date_range()` in that the result includes both ends? Because, `closed` parameter is nonfunctional at the moment, to make `cudf.date_range()` produce the same output as its pandas counterpart, we need to add 1 `freq` to `end`, which creates a whole lot of work: convert the string to datetime, convert freq to timedelta and add them to define a new end.

Anyway, is it possible to make it clear in the documentation that this is different from its pandas counterpart?

<sup>I didn't know how to tag this since it's not really a bug. It's just different from pandas API that results in a subtle bug _in my code_.</sup>",2024-02-22T04:35:02Z,0,0,Manlai Amar,
338,[FEA] NamedAgg in groupby context,"**Is your feature request related to a problem? Please describe.**

please support namedagg in groupby(...).agg

**Describe the solution you'd like**

to be able to write
```python
df.groupby(""A"").agg(
    b_min=cudf.NamedAgg(column=""B"", aggfunc=""min""),
    c_sum=cudf.NamedAgg(column=""C"", aggfunc=""sum"")
)
```

**Describe alternatives you've considered**


**Additional context**

https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html
",2024-02-22T12:58:24Z,0,0,Marco Edward Gorelli,Quansight
339,[BUG] Rolling window aggregations are very slow with large windows,"With large windows, the `.rolling()` function in cuDF can be pathologically slow:

```python
In [6]: dt = cudf.date_range(""2001-01-01"", ""2002-01-01"", freq=""1s"")
In [7]: df = cudf.DataFrame({""x"": np.random.rand(len(dt))}, index=dt)
In [8]: %time df.rolling(""1D"").sum()
CPU times: user 10.3 s, sys: 57.1 ms, total: 10.3 s
Wall time: 10.4 s
Out[8]:
                                x
2001-01-01 00:00:00      0.815418
2001-01-01 00:00:01      1.238151
2001-01-01 00:00:02      1.811390
2001-01-01 00:00:03      2.065794
2001-01-01 00:00:04      2.195230
...                           ...
2001-12-31 23:59:55  43308.909704
2001-12-31 23:59:56  43309.098228
2001-12-31 23:59:57  43308.658888
2001-12-31 23:59:58  43308.790256
2001-12-31 23:59:59  43308.915838

[31536000 rows x 1 columns]
```

## Why is it slow?

Of the 10s of execution time above, about 8s is spent in computing the window sizes, which is done in a hand-rolled numba CUDA kernel: https://github.com/rapidsai/cudf/blob/6f6e521257dce5732eea7b6b9d56243f8b0a69cc/python/cudf/cudf/utils/cudautils.py#L17. Note that running the code through a profiler will show execution time being spent in the _next_ CUDA kernel (`column.full`) - but that's a red herring I think, because there's no synchronization after the numba kernel call.

## What can we do about it?

I see a couple of options here:

1. I wonder if there's a better way to write that kernel. Currently, it naively launches one thread per element, and does a linear search for the next element that would exceed the window bounds. 
2. We could make it `libcudf`'s responsibility to compute the window sizes. I believe they already do window sizes computation in the context of _grouped_ rolling window aggreagations: see [`grouped_range_rolling_window()`](https://github.com/rapidsai/cudf/blob/6f6e521257dce5732eea7b6b9d56243f8b0a69cc/cpp/include/cudf/rolling.hpp#L542).",2024-02-22T16:04:49Z,0,0,Ashwin Srinath,Voltron Data
340,[FEA] Pass column indices as `index_col` in `read_csv`,"If I want to use the `index_col` parameter to set certain columns as indices when reading a csv file, I cannot pass a list of column indices (like in pandas). I can pass a list of column labels though:
```python
cudf.read_csv(filepath, index_col=[0])
KeyError: 'None of [0] are in the columns'

cudf.read_csv(filepath, index_col=['family'])
```
While this is not a huge issue, I imagine the following is a common scenario: You have know that the first 3 columns are index columns, but you don't exactly know how each are spelt (`'date'` vs `'Date'` etc.). In this case, if passing a list of column indices were possible, `index_col=[0,1,2]` would have worked fine; otherwise, you will have to read the file without specifying index columns and set index later (or require trial and error to guess the column labels).

Is it possible for `index_col` to accept list of indices like in pandas?",2024-02-23T08:21:24Z,0,0,Manlai Amar,
341,[FEA] Add python bindings in the parquet reader for `num_rows`/`skiprows`,"**Is your feature request related to a problem? Please describe.**
Unfortunately there has been churn in libcudf around support for `num_rows`/`skiprows` in the Parquet and ORC readers. In 22.08 we deprecated these parameters in the parquet reader (#11218) and then in 22.10 we removed them from C++ (#11503) and python (#11480). We also deprecated `num_rows`/`skiprows` in the ORC reader (#11522, see issue #11519).

At this point, we realized that chunked parquet reading (#11867) would require adding `num_rows`/`skiprows` back to the C++ implementation (#11657).

Let's stabilize row selection APIs in libcudf by completing these tasks:
- [ ] Add python bindings in the parquet reader for `num_rows`/`skiprows`
- [ ] Remove the deprecation notice in the ORC reader for `num_rows`/`skiprows` (#11522)

**Additional context**
We also dropped `num_rows`/`skiprows` support in the cuDF-python fuzz tests (#11505). My preference is to not include any python fuzz testing changes in the scope of this issue.
",2024-02-26T19:36:33Z,0,0,Gregory Kimball,
342,[FEA] Expose memory_resource arguments in pylibcudf,"**Is your feature request related to a problem? Please describe.**

As discussed in #14229, cudf currently relies on fate (working well so far) to ensure there are no use-after-free bugs when calling into, and taking ownership of return values from, libcudf.

In cudf-classic cython wrappers, the memory resource argument is never exposed to cython land. In pylibcudf, it is not currently exposed either.

**Describe the solution you'd like**

All pylibcudf calls should take a memory resource argument, that is then called with the memory resource cudf considers to be currently active. This needs to go hand-in-hand with #15163, since when both a stream and memory resource are exposed in the public libcudf API, the memory resource is second, so we can't rely on overloaded defaulting for the stream argument.

**Describe alternatives you've considered**

None.",2024-02-28T12:48:36Z,0,0,Lawrence Mitchell,
343,[FEA] Provide type stubs for pylibcudf package,"**Is your feature request related to a problem? Please describe.**

As we build out the pylibcudf API, having type stubs for lsp and type-checking integration becomes increasingly useful.

**Describe the solution you'd like**

Provide type stubs (with docstrings) so that lsp/type-checker integration works.

We don't want to replicate docstrings in more than one place, I don't know if the right place for them is the type stub file.

**Describe alternatives you've considered**

Having the relevant pyx file open in an editor at the same time.

**Additional context**

There are a number of half-working auto-generation engines for stubs, but none of them seem to work that well, so we should probably just do this by hand.
",2024-02-29T12:38:48Z,0,0,Lawrence Mitchell,
344,[FEA] Implement `closed=` parameter for rolling window,"The `closed=` parameter to rolling windows is currently unsupported:

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html

",2024-02-29T15:09:37Z,0,0,Ashwin Srinath,Voltron Data
345,[FEA] Reduce arrow library dependencies in cudf,"**Is your feature request related to a problem? Please describe.**
Arrow is in general a difficult dependency to work with, increasing build system complexity and fragility on its own while simultaneously expanding the full dependency tree, which particularly complicates use cases like conda where it leads to meaningful constraints on core system packages like protobuf, abseil, or the AWS SDK. This often hinders developer velocity when builds or CI are broken, but can also have far-reaching impacts when it creates problems with installation or running in specific environments. To prevent this, we would like to reduce or remove our dependence on Arrow libraries entirely.

Currently cudf makes use of Arrow in various ways at different levels of the stack. The primary uses of Arrow boil down to interop with host Arrow data and I/O with specific types of files. This involves interaction at both the Python layer via pyarrow, at the Cython layer (also via pyarrow), and in C++. Both Cython and C++ interactions are particularly problematic because they involve C-level interactions, which sets ABI-level constraints that are significantly tighter than we would like while also significantly complicating build (CMake, Python builds) and packaging (narrow Arrow version support ranges leading to limited support of other packages in the dependency tree). Python interactions are generally less difficult to work around, especially since Python code can be written to dynamically adapt to the pyarrow version.

**Describe the solution you'd like**

We should look to remove the Arrow dependencies from the various layers of cudf (Java, Python, Cython, C++) to the greatest extent possible, ideally entirely.

For Arrow Array interop code, this can be accomplished by using the Arrow C Data Interface (see #5097), which provides an ABI-stable way to interchange Arrow data without directly using Arrow libraries. To make this even easier, the [nanoarrow](https://github.com/apache/arrow-nanoarrow) library was created to support clients that wish to produce or interpret [Arrow C Data](https://arrow.apache.org/docs/format/CDataInterface.html) and [Arrow C Streams](https://arrow.apache.org/docs/format/CStreamInterface.html) structures, without having to include a dependency on libarrow. We can make use of that (see also #13678 which discusses this in depth). For Python interaction we can use [Arrow's pycapsule interface](https://arrow.apache.org/docs/format/CDataInterface/PyCapsuleInterface.html), which provides a standard way to interchange this data from Python. We can write Cython code leveraging this interface to get Arrow C Data from pyarrow objects without relying directly on pyarrow's Cython, therefore also allowing us to remove this dependency from the Cython layer.

For I/O, the question is a bit trickier. We currently have limited usage of libarrow headers in our C++, and those features largely exist only for Python support for reading Arrow's NativeFiles. We could in principle remove those from the C++ entirely, which would in turn allow us to remove libarrow as a dependency of libcudf. However, libcudf tests would still need libarrow (removing that dependency would require significant additional work). Moreover, those features would still be used by cudf Cython, so we would just be limiting the dependency. However, this could at least allow us to remove Arrow as a build-time dependency for both libcudf and the low-level pylibcudf Python API (#13921) that we are currently developing, which would still be a significant improvement since it would avoid imposing the Arrow dependency on low-level consumers of our APIs at the Python level. Then we could come back to working on replacing the cudf Cython usage.

Based on the above, the current plan is the following:
1. Remove libarrow as a dependency of libcudf/pylibcudf:
    a. Remove the compiled parts of `arrow_io_source.cpp` and make `arrow_io_source.hpp` a standalone header not compiled by anything in libcudf.
    b. Rewrite cudf Cython to use the arrow headers directly.
    c. Add new interop code that uses the Arrow C Data interface (see #15047)
    d. Rewrite Python interop code to call through to the new interfaces
    e. Remove the old Cython bindings for interop
2. Remove pyarrow Cython linkages from cudf Cython
    a. This will require some exploration as to how we can maintain performant file reading. We may have to implement our own minimal version of something like Arrow's NativeFile reader interface.
    b. Once the above is done, we'll need to rewrite cuIO C++ to consume this interface and remove the current functions.
3. Rewrite libcudf tests to remove libarrow dependence.
    a. This will require further investigation into how tests could be rewritten without Arrow. One possibility would be rewriting these tests as pylibcudf tests (see #15133) that use pyarrow instead (only the Python API, no Cython). That would give us access to the same functionality without tying us to linking to the libarrow library

**Additional context**

Code pointers where libarrow is used in 24.04
| Source file | Arrow include | Notes |
|---|---|---|
| `detail/interop.hpp` | `api.h` | `to_arrow_array` uses many array classes: `arrow::*Array`, `arrow::TimeUnit::*`, `arrow::*Type` also `arrow::MemoryPool`, `arrow::Scalar`, `arrow::Table`. I believe all of these are covered by nanoarrow |
| `include/cudf/interop.hpp`  | `api.h` | uses `arrow::Table`, `arrow::MemoryPool`, `arrow::default_memory_pool`, `arrow::Scalar`. I believe all of these are covered by nanoarrow |
| `include/cudf/io/arrow_io_source.hpp` | `filesystem/filesystem.h` <br> `io/interfaces.h`  | uses `arrow::io:RandomAccessFile`, `arrow::fs::FileSystem`. See #13698 for the work to refactor `arrow_io_source` out of `datasource` |
| `include/cudf/io/arrow_io_source.cpp` | `buffer.h` <br> `filesystem/filesystem.h` <br> `result.h`  | uses `arrow::Buffer`, `arrow::fs::FileSystemFromUri`, |
| `src/io/utilities/datasource.cpp` | `io/memory.h` | to be solved by #15189 |

| Test file | Arrow include | Notes |
|---|---|---|
| `tests/interop/arrow_utils.hpp` | `util/bitmap_builders.h` for `arrow::internal::BytesToBits` | Also uses many arrow types such as: `arrow::Array`, `arrow:DictionaryArray`, `arrow::dictionary`, `arrow::Table`,  `arrow::Decimal128Builder`, `arrow::decimal`, `arrow::default_memory_pool`, `arrow::ListArray`, `arrow::list` , `arrow::Buffer`, `arrow::StringBuilder`, `arrow::StringArray` , `arrow::BooleanArray`, `arrow::BooleanBuilder` <br> needs research - can all of these references be migrated to nanoarrow? |
| `tests/io/arrow_io_source_test.cpp`  | `io/api.h`  <br> `filesystem/filesystem.h` <br> `filesystem/s3fs.h` <br> `util/config.h` | uses `arrow::fs::FileSystemFromUri`, `arrow::fs::EnsureS3Finalized` |
| `tests/io/json_test.cpp` | `io/api.h` | Uses `arrow::io::ReadableFile` as part of a test for reading from an `ArrowFileSource` |
| `tests/io/csv_test.cpp` | `io/api.h` | uses `arrow::io::ReadableFile` |
| `tests/quantiles/percentile_approx_test.cpp` | `util/tdigest.h` | uses `arrow::internal::TDigest`. presumably we could replace this with our own limited implementation |
",2024-02-29T17:13:26Z,0,0,Gregory Kimball,
346,[FEA] Add Parquet-to-Arrow dictionary transcoding to the parquet reader,"**Is your feature request related to a problem? Please describe.**
Using a parquet reader option, we could allow the user to specify columns that they would like to receive as dictionary-encoded in the output table. For the specified columns, the Parquet reader would transcode multiple Parquet dictionary-encoded column chunks into an Arrow dictionary-encoded column. 

**Describe the solution you'd like**
### Part 1 - Confirm correct and efficient dictionary processing in libcudf ###
1. Add benchmarks for dictionary `encode` and `decode` with axes including data type, cardinality and row count. Add checks that data is correctly round-tripped through dictionary encoding and decoding.
2. Expand unit testing when using dictionary types for reductions, join keys, aggregation keys, aggregation values and other operations. Include string and numeric types as dictionary values. Please note that although libcudf can represent dictionaries of lists (needs to be checked), in Parquet only leaf values can be dictionary-encoded.
3. Expand benchmarks for dictionary operations.  As of 24.04 we only have a [dictionary reduction](https://github.com/rapidsai/cudf/blob/branch-24.04/cpp/benchmarks/reduction/dictionary.cpp) benchmarks on `int32` and `float` value types. Benchmarks should include strings data type and axes for varying cardinality and row count.
4. Consider signed int for index type. Revisit the int types that can be used as indices. Revisit compatibility differences between libcudf dictionary and Arrow dictionary.
5. Consider dropping the sorted key requirement for improved python compatibility. We use natural order of index today and we could add a mapping layer to indexes to stop constraining the indices.

### Part 2 - Parquet-to-Arrow dictionary transcoding ###
1. Estimate the performance of transcoding Parquet dictionary-encoded column chunks into arrow dictionary-encoded columns. Each Parquet dictionary-encoded column chunk with begins with a dictionary page. To create an Arrow-compliant dictionary column, we need to merge the values from the dictionary page in each column chunk into a single set of values for the arrow dictionary-encoded column. Then to generate the indices data, we need to re-map the indices from each column chunk against the indices in the combined values. 
2. Please note that [PLAIN_DICTIONARY](https://parquet.apache.org/docs/file-format/data-pages/encodings/#dictionary-encoding-plain_dictionary--2-and-rle_dictionary--8) encoding is deprecated in Parquet 2.0. To support the new default [RLE_DICTIONARY](https://parquet.apache.org/docs/file-format/data-pages/encodings/#dictionary-encoding-plain_dictionary--2-and-rle_dictionary--8), we will need to add a conversion step from Parquet bit-packed indices into Arrow fixed-width indices.
3. The parquet format allows different encodings for each column chunk within a column. In the case of dictionaries, the Parquet specification describes cases where PLAIN encoding will be mixed with DICTIONARY encoding, ""If the dictionary grows too big, whether in size or number of distinct values, the encoding will fall back to the plain encoding"". To support this case we would need to add special handling.

**Describe alternatives you've considered**
Use `dictionary::encode` to encode target columns immediately after materialization by the Parquet reader. This approach will realize the downstream benefits of dictionary encoding, at the cost of additional work in Parquet decode and dictionary encode. We would benefit from sample queries and profiles that compare materialized column versus dictionary column processing in libcudf workflows. Such profiles could be used to estimate the performance improvement from adding Parquet-to-Arrow dictionary transcoding to the libcudf Parquet reader.

### Part 3 - Introduce run-end encoded type in libcudf, and then add Parquet-to-Arrow run-length/run-end transcoding
The Parquet format supports a [run-length encoding / bit-packing hybrid](https://parquet.apache.org/docs/file-format/data-pages/encodings/#run-length-encoding--bit-packing-hybrid-rle--3) and this could be transcoded into a [run-end encoded](https://arrow.apache.org/docs/format/Columnar.html#run-end-encoded-layout) Arrow type. To begin this project, we need to add run-end encoding as a new type to libcudf, introduce decode and encode functions, confirm correctness across libcudf APIs and audit for performance hotspots. A run-end encoded type in libcudf would allow us to support ""constant"" or ""scalar"" columns as requested in #15308. If libcudf supported a run-end encoded type, transcoding into this type from Parquet run-length encoded data would not be a zero-copy operation and would require converting the Parquet bit-packed ""lengths"" to Arrow fixed-width ""ends"". 

",2024-03-01T00:10:23Z,0,0,Gregory Kimball,
347,"[BUG] memcheck and racecheck errors in avro reader with `codec=""deflate""`","**Describe the bug**

```python
import cudf
import fastavro
import io

total_rows = num_rows = rows_per_block = 2048
total_bytes_per_block = rows_per_block * 7

records = [{""0"": f""{i:0>6}""} for i in range(total_rows)]
schema = {
    ""name"": ""root"",
    ""type"": ""record"",
    ""fields"": [
        {""name"": ""0"", ""type"": ""string""},
    ],
}

buffer = io.BytesIO()
fastavro.writer(buffer, schema, records, sync_interval=total_bytes_per_block, codec=""deflate"")
buffer.seek(0)

actual_df = cudf.read_avro(buffer, skiprows=0, num_rows=num_rows)
```

Extracted from `test_avro_reader_fastavro_integration.py::test_avro_reader_multiblock`.

Neither
```
compute-sanitizer --tool=memcheck python bug.py
```
nor
```
compute-sanitizer --tool=racecheck python bug.py
```

are clean.

Exemplar stack traces:

<details>
<summary> memcheck </summary>

```
========= COMPUTE-SANITIZER
========= Invalid __global__ read of size 1 bytes
=========     at 0x2080 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:807:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)
=========     by thread (32,0,0) in block (0,0,0)
=========     Address 0x7f6078604cb3 is out of bounds
=========     and is 2,356 bytes after the nearest allocation at 0x7f6078601600 of size 11,648 bytes
=========     Device Frame:/home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1109:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included) [0x6050]
=========     Saved host backtrace up to driver entry point at kernel launch time
=========     Host Frame: [0x332470]
=========                in /usr/lib/x86_64-linux-gnu/libcuda.so.1
=========     Host Frame: [0x14fb4]
=========                in /home/coder/.conda/envs/rapids/lib/libcudart.so.12
=========     Host Frame:cudaLaunchKernel [0x70aae]
=========                in /home/coder/.conda/envs/rapids/lib/libcudart.so.12
=========     Host Frame:/home/coder/.conda/envs/rapids/targets/x86_64-linux/include/cuda_runtime.h:216:cudaError cudaLaunchKernel<char>(char const*, dim3, dim3, void**, unsigned long, CUstream_st*) [0x12a5605]
=========                in /home/coder/cudf/cpp/build/release/libcudf.so
=========     Host Frame:/tmp/tmpxft_0003da43_00000000-6_gpuinflate.compute_90.cudafe1.stub.c:1:__device_stub__ZN4cudf2io14inflate_kernelILi128EEEvNS_11device_spanIKNS2_IKhLm18446744073709551615EEELm18446744073709551615EEENS2_IKNS2_IhLm18446744073709551615EEELm18446744073709551615EEENS2_INS0_18compression_resultELm18446744073709551615EEENS0_20gzip_header_includedE(cudf::device_span<cudf::device_span<unsigned char const, 18446744073709551615ul> const, 18446744073709551615ul>&, cudf::device_span<cudf::device_span<unsigned char, 18446744073709551615ul> const, 18446744073709551615ul>&, cudf::device_span<cudf::io::compression_result, 18446744073709551615ul>&, cudf::io::gzip_header_included) [0x12a4de6]
=========                in /home/coder/cudf/cpp/build/release/libcudf.so
=========     Host Frame:/tmp/tmpxft_0003da43_00000000-6_gpuinflate.compute_90.cudafe1.stub.c:4:void cudf::io::__wrapper__device_stub_inflate_kernel<128>(cudf::device_span<cudf::device_span<unsigned char const, 18446744073709551615ul> const, 18446744073709551615ul>&, cudf::device_span<cudf::device_span<unsigned char, 18446744073709551615ul> const, 18446744073709551615ul>&, cudf::device_span<cudf::io::compression_result, 18446744073709551615ul>&, cudf::io::gzip_header_included&) [0x12a4e1e]
=========                in /home/coder/cudf/cpp/build/release/libcudf.so
=========     Host Frame:/home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1145:void cudf::io::inflate_kernel<128>(cudf::device_span<cudf::device_span<unsigned char const, 18446744073709551615ul> const, 18446744073709551615ul>, cudf::device_span<cudf::device_span<unsigned char, 18446744073709551615ul> const, 18446744073709551615ul>, cudf::device_span<cudf::io::compression_result, 18446744073709551615ul>, cudf::io::gzip_header_included) [0x12a5598]
=========                in /home/coder/cudf/cpp/build/release/libcudf.so
=========     Host Frame:/home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1214:cudf::io::gpuinflate(cudf::device_span<cudf::device_span<unsigned char const, 18446744073709551615ul> const, 18446744073709551615ul>, cudf::device_span<cudf::device_span<unsigned char, 18446744073709551615ul> const, 18446744073709551615ul>, cudf::device_span<cudf::io::compression_result, 18446744073709551615ul>, cudf::io::gzip_header_included, rmm::cuda_stream_view) [0x12a49ef]
=========                in /home/coder/cudf/cpp/build/release/libcudf.so
=========     Host Frame:/home/coder/cudf/cpp/src/io/avro/reader_impl.cu:227:cudf::io::detail::avro::decompress_data(cudf::io::datasource&, cudf::io::detail::avro::metadata&, rmm::device_buffer const&, rmm::cuda_stream_view) [0x123db3c]
=========                in /home/coder/cudf/cpp/build/release/libcudf.so
=========     Host Frame:/home/coder/cudf/cpp/src/io/avro/reader_impl.cu:528:cudf::io::detail::avro::read_avro(std::unique_ptr<cudf::io::datasource, std::default_delete<cudf::io::datasource> >&&, cudf::io::avro_reader_options const&, rmm::cuda_stream_view, rmm::mr::device_memory_resource*) [0x123fa1f]
=========                in /home/coder/cudf/cpp/build/release/libcudf.so
=========     Host Frame:cudf::io::read_avro(cudf::io::avro_reader_options const&, rmm::mr::device_memory_resource*) [0x13019ee]
=========                in /home/coder/cudf/cpp/build/release/libcudf.so
=========     Host Frame: [0x2ba3c]
=========                in /home/coder/.conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/avro.cpython-310-x86_64-linux-gnu.so
=========     Host Frame: [0x2d29f]
=========                in /home/coder/.conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/avro.cpython-310-x86_64-linux-gnu.so
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/ceval.c:4181:_PyEval_EvalFrameDefault [0x139022]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Objects/call.c:342:_PyFunction_Vectorcall [0x1448cc]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/ceval.c:4231:_PyEval_EvalFrameDefault [0x1357dc]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/ceval.c:5067:_PyEval_Vector [0x1d7870]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/ceval.c:1135:PyEval_EvalCode [0x1d77b7]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:1292:run_eval_code_obj [0x207d1a]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:1313:run_mod [0x203123]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:1208:pyrun_file.cold [0x9a4d1]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:456:_PyRun_SimpleFileObject [0x1fd60e]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:90:_PyRun_AnyFileObject [0x1fd1a4]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Modules/main.c:670:Py_RunMain [0x1fa39b]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame:/usr/local/src/conda/python-3.10.13/Modules/main.c:1091:Py_BytesMain [0x1cae17]
=========                in /home/coder/.conda/envs/rapids/bin/python
=========     Host Frame: [0x29d90]
=========                in /usr/lib/x86_64-linux-gnu/libc.so.6
=========     Host Frame:__libc_start_main [0x29e40]
=========                in /usr/lib/x86_64-linux-gnu/libc.so.6
=========     Host Frame: [0x1cad11]
=========                in /home/coder/.conda/envs/rapids/bin/python
========= 
```

</details>

<details>
<summary> racecheck </summary>

```
========= COMPUTE-SANITIZER
========= Error: Race reported between Read access at 0xe00 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:789:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)
=========     and Write access at 0x1930 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:543:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [16132 hazards]
=========     and Write access at 0x5660 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:661:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [16156 hazards]
========= 
========= Error: Race reported between Write access at 0xd90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:957:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)
=========     and Read access at 0x33c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:590:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1144 hazards]
=========     and Read access at 0x5250 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:642:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [6592 hazards]
========= 
========= Error: Race reported between Read access at 0x810 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:954:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)
=========     and Write access at 0x59c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:665:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1032 hazards]
========= 
========= Error: Race reported between Read access at 0xa70 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:784:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)
=========     and Write access at 0x5930 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:663:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1028 hazards]
=========     and Write access at 0x5f90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:671:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [4 hazards]
========= 
========= Error: Race reported between Write access at 0x11c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:793:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)
=========     and Read access at 0xf90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:523:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [500 hazards]
=========     and Read access at 0x5dd0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:670:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [4 hazards]
========= 
========= Error: Race reported between Write access at 0xf60 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:962:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)
=========     and Read access at 0xdb0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:522:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [272 hazards]
========= 
========= Error: Race reported between Write access at 0x5d70 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1104:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included)
=========     and Read access at 0x5d0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:951:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int) [8 hazards]
========= 
========= Warning: Race reported between Read access at 0x3b0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:775:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)
=========     and Write access at 0x3000 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:826:cudf::io::process_symbols(cudf::io::inflate_state_s *, int) [8 hazards]
========= 
========= Warning: Race reported between Read access at 0x31a0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1068:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included)
=========     and Write access at 0x4900 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1081:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included) [4 hazards]
========= 
========= Error: Race reported between Read access at 0xe00 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:789:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)
=========     and Write access at 0x1930 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:543:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [16132 hazards]
=========     and Write access at 0x5660 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:661:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [16156 hazards]
========= 
========= Error: Race reported between Write access at 0xd90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:957:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)
=========     and Read access at 0x33c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:590:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1144 hazards]
=========     and Read access at 0x5250 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:642:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [6592 hazards]
========= 
========= Error: Race reported between Read access at 0x810 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:954:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)
=========     and Write access at 0x59c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:665:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1032 hazards]
========= 
========= Error: Race reported between Read access at 0xa70 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:784:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)
=========     and Write access at 0x5930 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:663:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1028 hazards]
=========     and Write access at 0x5f90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:671:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [4 hazards]
========= 
========= Error: Race reported between Write access at 0x11c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:793:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)
=========     and Read access at 0xf90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:523:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [500 hazards]
=========     and Read access at 0x5dd0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:670:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [4 hazards]
========= 
========= Error: Race reported between Write access at 0xf60 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:962:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)
=========     and Read access at 0xdb0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:522:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [272 hazards]
========= 
========= Error: Race reported between Write access at 0x5d70 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1104:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included)
=========     and Read access at 0x5d0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:951:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int) [8 hazards]
========= 
========= Warning: Race reported between Read access at 0x3b0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:775:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)
=========     and Write access at 0x3000 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:826:cudf::io::process_symbols(cudf::io::inflate_state_s *, int) [8 hazards]
========= 
========= Warning: Race reported between Read access at 0x31a0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1068:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included)
=========     and Write access at 0x4900 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1081:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included) [4 hazards]
========= 
========= RACECHECK SUMMARY: 18 hazards displayed (14 errors, 4 warnings)
```

</details>

I do not know if the racecheck warnings are as problematic as the memcheck ones, `gpuinflate.cu` is littered with `volatile` accesses to the inter-warp communication queue without (AFAICT) any synchronisation, but perhaps there are enough spin-waits that it is ""OK""?",2024-03-04T11:42:07Z,0,0,Lawrence Mitchell,
348,"[QST] Returning from multi-thread. TypeError: a bytes-like object is required, not 'dict'","When running my code with `cudf`, I got `TypeError: a bytes-like object is required, not 'dict'` in the multi-thread returning part.
1. Running the code without `-m cudf.pandas` option is *fine*.
2. It's *okay* if each multi-thread branch returns merely a scalar.
3. Program **CRUSHES** if a multi-thread branch returns a dataframe.

This is the code message:
```
concurrent.futures.process._RemoteTraceback:
'''
Traceback (most recent call last):
  File ""/usr/lib64/python3.9/concurrent/futures/process.py"", line 387, in wait_result_broken_or_wakeup
    result_item = result_reader.recv()
  File ""/usr/lib64/python3.9/multiprocessing/connection.py"", line 255, in recv
    return _ForkingPickler.loads(buf.getbuffer())
  File ""/usr/local/lib64/python3.9/site-packages/cudf/pandas/fast_slow_proxy.py"", line 742, in __setstate__
    unpickled_wrapped_obj = pickle.loads(state)
TypeError: a bytes-like object is required, not 'dict'
'''

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/usr/lib64/python3.9/runpy.py"", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/usr/lib64/python3.9/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""/usr/local/lib64/python3.9/site-packages/cudf/pandas/__main__.py"", line 91, in <module>
    main()
  File ""/usr/local/lib64/python3.9/site-packages/cudf/pandas/__main__.py"", line 87, in main
    runpy.run_path(args.args[0], run_name=""__main__"")
  File ""/usr/lib64/python3.9/runpy.py"", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File ""/usr/lib64/python3.9/runpy.py"", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File ""/usr/lib64/python3.9/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""clean_header.py"", line 48, in <module>
    main()
  File ""clean_header.py"", line 45, in main
    my_func()
  File ""clean_header.py"", line 39, in my_func
    for obj in r:
  File ""/usr/lib64/python3.9/concurrent/futures/process.py"", line 562, in _chain_from_iterable_of_lists
    for element in iterable:
  File ""/usr/lib64/python3.9/concurrent/futures/_base.py"", line 609, in result_iterator
    yield fs.pop().result()
  File ""/usr/lib64/python3.9/concurrent/futures/_base.py"", line 439, in result
    return self.__get_result()
  File ""/usr/lib64/python3.9/concurrent/futures/_base.py"", line 391, in __get_result
    raise self._exception
concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.
```


Here is my code.
```
from datetime import datetime, timedelta, date
import numpy as np
import pandas as pd
from random import randint
import swifter
import json, sys, os
from cudf.pandas.module_accelerator import disable_module_accelerator

from functools import partial
from concurrent.futures import ProcessPoolExecutor as Pool
from multiprocessing import set_start_method


def data_generation(nRows: int):
################## unimportant, for reproducing purpose ###################
# This function generates the dataframe obj, which has 5 columns, and the data are sorted by WorkingDay and Minute ascendingly
    my_df = pd.DataFrame(data={'WorkingDay': ['2019-01-02', '2018-01-02', '2019-05-02', '2020-01-02', '2021-01-02'], 'name': ['albert', 'alex', 'alice', 'ben', 'bob'], 'Minute': ['09:00:00', '09:20:00', '08:00:00', '07:00:00', '09:30:00'], 'aaa': np.random.rand(5), 'bbb': np.    random.rand(5)})
    my_df = pd.concat([my_df for i in range(int(nRows/5))], axis=0)
    my_df['WorkingDay'] = my_df['WorkingDay'].map(lambda x: (date(randint(2010,2020), randint(1,4), randint(1,5))).strftime('%Y-%m-%d'))
    my_df['Minute'] = np.random.permutation(my_df['Minute'].values)
    my_df = my_df.sort_values(by=['WorkingDay', 'Minute'], inplace=False).reset_index(drop=True,inplace=False)
    return my_df

def my_func_single(branchIndex: int):
    my_df = data_generation(20-5*branchIndex)
# data generated
#############################################################################
    # The multi-thread return is problematic
#############################################################################
    #return my_df.shape[0]
    return my_df


def my_func():
    set_start_method('spawn')
    my_func_partial = partial(my_func_single)
    with Pool(max_workers=2) as pool:
        r = pool.map(my_func_partial, range(4))
    for obj in r:
        #print('df has length: {}.'.format(obj))
        print('df has length: {}.'.format(obj.shape[0]))

def main():
    print('-------------------- program starts -----------------------')
    my_func()

if __name__ == '__main__':
    main()
```

Relevant dependencies:
```
cuda-python==12.4.0
cudf-cu12==24.4.0a516
cugraph-cu12==24.4.0a69
cuml-cu12==24.4.0a37
dask==2024.1.1
dask-cuda==24.4.0a11
dask-cudf-cu12==24.4.0a516
pylibcugraph-cu12==24.4.0a69
pylibraft-cu12==24.4.0a70
```
",2024-03-07T07:19:32Z,0,0,,
349,[FEA] Add shared memory hash map for low-cardinality aggregations,"**Is your feature request related to a problem? Please describe.**
libcudf aggregations show lower throughput when data cardinality is less than ~1000 distinct values. This is due to serializing atomic operations over a small range of global memory. We received some projections that use hash maps that begin in shared memory and then spill to global if they exceed a certain size. The projections indicate 2-10x speedup for cardinalities below 100.

![image](https://github.com/rapidsai/cudf/assets/12725111/f28d02c5-f107-4c4a-b44d-687094a0a7a8)
(Aggregation throughput data was collected for groupby max over 20M rows of int64 key and int64 payload, based on benchmarks introduced in https://github.com/rapidsai/cudf/pull/15134 and using A100 hardware. Projections were provided as speedup versus cardinality data and were applied to the A100 measured throughput to yield projected throughput.)

**Describe the solution you'd like**
We could provide an implementation that uses shared memory hash maps when cardinality is low. [Shared memory as storage](https://github.com/NVIDIA/cuCollections/blob/dev/examples/static_set/shared_memory_example.cu) is supported in [cuCollections](https://github.com/NVIDIA/cuCollections), so we could leverage this option to offer a higher throughput code path when cardinality is low.

As far as the API design, we could add an optional `cardinality` parameter to the `aggregate` API. When [hyperloglog](https://github.com/NVIDIA/cuCollections/pull/429) cardinality estimates are available in cuCollections, we may want to support cardinality estimates as well. Some open questions include:
* What is the throughput difference between hyperloglog and count distinct? We expect the memory footprint of hyperloglog to be much lower, but I don't believe throughput has had controlled measurements.
* If we accept cardinality estimates, what happens if the cardinality is underestimated and the shared memory hash map fails? 
* Does it make sense for column objects to track cardinality, or should the application layer track cardinality?


**Describe alternatives you've considered**
We aren't sure how common low cardinality aggregation keys are in customer workloads. Are there cases where cardinality will be known ahead of time, or will it always need to be computed or estimated before triggering the aggregation? Could we instrument NDS to log cardinality and row count before each aggregation node?

**Additional context**
We could also consider using shared memory hash maps for low-cardinality distinct-key joins. This optimization is mentioned in https://github.com/rapidsai/cudf/issues/14948.
",2024-03-08T22:50:19Z,0,0,Gregory Kimball,
350,DataFrame.pivot_table not supported in Cudf,"**Missing Pandas Feature Request**
A clear and concise summary of the pandas function(s) you'd like to be able run with cuDF.
DataFrame.pivot_table not supported in Cudf

**Profiler Output**
If you used the profiler in pandas accelerator mode, please provide the full output of your profiling report.
```
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Function                  ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ DataFrame.pivot_table     │ 0          │ 0.000       │ 0.000       │ 1          │ 0.076       │ 0.076       │
│ DataFrame.reset_index     │ 1          │ 0.003       │ 0.003       │ 0          │ 0.000       │ 0.000       │
│ merge                     │ 1          │ 1.164       │ 1.164       │ 0          │ 0.000       │ 0.000       │
│ DataFrame.drop_duplicates │ 1          │ 0.170       │ 0.170       │ 0          │ 0.000       │ 0.000       │
│ DataFrame                 │ 1          │ 0.000       │ 0.000       │ 0          │ 0.000       │ 0.000       │
│ DataFrame.__repr__        │ 1          │ 0.539       │ 0.539       │ 0          │ 0.000       │ 0.000       │
└───────────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘
```
Not all pandas operations ran on the GPU. The following functions required CPU fallback:

- DataFrame.pivot_table

**Additional context**
Add any other context, code examples, or references to existing implementations about the feature request here.
",2024-03-09T07:00:31Z,0,0,,
351,[FEA] Implement `__hash__` and `__eq__` for pylibcudf Aggregation objecs.,"libcudf `Aggregation` objects have implementations of hash and equality. We should expose these in pylibcudf so we can put the aggregation objects into dictionaries correctly.

",2024-03-11T18:27:02Z,1,0,Lawrence Mitchell,
352,[FEA] Accelerate conversion from `arrow::StringViewType` to `arrow::StringType` in libcudf interop,"
**Is your feature request related to a problem? Please describe.**
The Arrow 15 specification includes a definition of ""[arrow::StringViewType](https://arrow.apache.org/docs/cpp/api/datatype.html#classarrow_1_1_string_view_type)"" - an alternate representation of the ""[arrow::StringType](https://arrow.apache.org/docs/cpp/api/datatype.html#classarrow_1_1_string_type)"". You may find ""String view"" also referred to as [Umbra string](https://www.cidrdb.org/cidr2020/papers/p29-neumann-cidr20.pdf) or prefix string. 

A string view consists of two columns:
1. A column of 16 byte fixed-width elements. First 4 bytes contain the string size
* If size < 12, then the string is stored inline in the remaining 12 bytes (short string optimization)
* If size > 12, then the string is stored separately in the second column. Remaining 12 bytes are 8 bytes for pointer to the string + 4 bytes for the first 4 chars of the string
2. A column of characters storing the suffix strings

String view type enables some performance optimizations:
* ability to slice strings (e.g. `left(10)`) in place without a copy
* ability to replace with smaller strings (e.g. `replace(""aa"", ""a"")`) in place without a copy
* inlined strings can be written in any order and without knowing the column size
* better memory access patterns for the first 4 bytes (e.g. `startswith(""a"")`)

**Describe the solution you'd like**
Let's add interop support for string view in `from_arrow` with CUDA C++ code to accept string views and convert them to libcudf strings columns. We may also want to add string view compatibility to `to_arrow`, so we can hand off libcudf strings columns to host libraries that expect string views. We should be able to write CUDA C++ code to efficiently transform `arrow::StringViewType` buffers in to `arrow::StringType` buffers.

**Describe alternatives you've considered**
Force libcudf users to convert their string views into strings on the host before passing the data to the device.

**Additional context**
Velox supports a string view type ([ref1](https://facebookincubator.github.io/velox/develop/vectors.html#flat-vectors-scalar-types), [ref2](https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/)), [Polars has switched](https://pola.rs/posts/polars-string-type/) to a string view representation, and [DuckDB supports](https://15721.courses.cs.cmu.edu/spring2023/slides/22-duckdb.pdf) string view.

We may choose to investigate using string views in libcudf at some point, but for the foreseeable future string view refactoring will be lower priority than [supporting large strings](https://github.com/rapidsai/cudf/issues/13733) and [improving performance with long strings](https://github.com/rapidsai/cudf/issues/13048).",2024-03-13T23:40:41Z,0,0,Gregory Kimball,
353,[BUG] Empty DataFrame object `columns` property doesn't match pandas for `data=None` or `data={}`.,"**Describe the bug**

When constructing an empty dataframe where one does not explicitly specify the column names, pandas produces a `RangeIndex` for the `.columns` property.

In contrast, cudf produces an `Index(dtype=object)` if `data={}` or `data=None`.

**Steps/Code to reproduce bug**

```python
import cudf
import pandas as pd

for data in [{}, None]:
    columns = cudf.DataFrame(data=data).columns
    expect = pd.DataFrame(data=data).columns

    assert type(columns) == type(expect)
```

**Expected behavior**

Matching pandas. This works if `data` is an empty list-like object (e.g. `data=[]`) so it's probably just another condition to handle.",2024-03-22T11:45:37Z,0,0,Lawrence Mitchell,
354,[QST] How can the performance of chunked reading in Parquet be improved?,"**What is your question?**
![image](https://github.com/rapidsai/cudf/assets/36735914/08a2c7ce-226d-4230-b2a3-ddecb0c5b92c)

I am working on a project to improve the performance of reading parquet files using the libcudf library. As shown in the Nsight Systems screenshot, the decompress_page_data event consumes the most time in the read_chunk operation, taking 46.877ms and 41.987ms out of 123.117ms, respectively. I am trying to reduce this decompression time but have found limited material, documentation, or GitHub issues on the subject. Do you have any suggestions? I am also considering using stream technology to accelerate the process but am unsure where to begin. Attached is my code for your reference. Thank you.
[parquet_chuncked.txt](https://github.com/rapidsai/cudf/files/14726563/parquet_chuncked.txt)
",2024-03-22T17:44:35Z,0,0,Guangyu Meng,University of Notre Dame
355,[FEA] pandas DatetimeIndex.indexer_between_time,"I watched @shwina's GTC talk (https://register.nvidia.com/flow/nvidia/gtcs24/attendeeportaldigital/page/sessioncatalog/session/1695219773174001AmnA thanks Ashwin I really enjoyed it!)

**Is your feature request related to a problem? Please describe.**
No. I just noticed there wasn't an issue for [`DatetimeIndex.indexer_between_time`](https://github.com/pandas-dev/pandas/blob/main/pandas/core/indexes/datetimes.py#L764). I also enjoyed the user experience that `%%cudf.pandas.profile` points users to raise issues to highlight pandas API that falls back to CPU (https://github.com/rapidsai/cudf/blob/branch-24.06/python/cudf/cudf/pandas/profiler.py#L300).

**Describe the solution you'd like**
```
import pandas as pd
pd.date_range(""2023-01-01"", ""2023-01-02"", freq=""1h"").indexer_between_time(""09:00"", ""16:00"")
import cudf
cudf.date_range(""2023-01-01"", ""2023-01-02"", freq=""1h"").indexer_between_time(""09:00"", ""16:00"")
```

**Describe alternatives you've considered**
There may be a cudf work around in the meantime for a user who needs indexer_between_time that could be captured at https://docs.rapids.ai/api/cudf/stable/cudf_pandas/

**Additional context**
~~Could create a new issue template with the ""pandas"" label (https://github.com/rapidsai/cudf/issues?q=is%3Aopen+is%3Aissue+label%3Apandas) to be used at https://github.com/rapidsai/cudf/blob/branch-24.06/python/cudf/cudf/pandas/profiler.py#L297~~ fixed a bug at https://github.com/rapidsai/cudf/pull/15381
",2024-03-23T03:05:32Z,0,0,Ray Bell,DTN
356,"[BUG] In cudf.pandas mode, `.array` or `.values` don't actually return views to the underlying data","This seems a fundamental issue with the way cuDF is architected and possibly a `wontfix`, but it's important enough that we should consider solutions - and at the very least document the behaviour.

In pandas, `Series.values` (or `Series.array`) gives a reference to the underlying data as some kind of array-like object. Mutations to this object are reflected in the original `Series`:

```python

In [1]: import pandas as pd

In [2]: s = pd.Series([1, 2, pd.NA])

In [3]: a = s.array

In [4]: a
Out[4]:
<PandasArray>
[1, 2, <NA>]
Length: 3, dtype: object

In [5]: a[:2] = 3

In [6]: a
Out[6]:
<PandasArray>
[3, 3, <NA>]
Length: 3, dtype: object

In [7]: s
Out[7]:
0       3
1       3
2    <NA>
dtype: object
```

This doesn't always work when cudf.pandas is enabled:

```

In [1]: %load_ext cudf.pandas

In [2]: import pandas as pd

In [3]: s = pd.Series([1, 2, pd.NA])

In [4]: a = s.array  # this executes on CPU (because we don't support `.array` for null ints in cuDF)

In [5]: a
Out[5]:
<PandasArray>
[1.0, 2.0, nan]
Length: 3, dtype: float64

In [6]: s.max()  # this moves `s` from CPU to GPU, but `a` is still on CPU
Out[6]: 2.0

In [7]: a[:2] = 3  # this mutates `a`, but since `s` now lives on the GPU it doesn't see that mutation

In [8]: s  # `s` is unchanged
Out[8]:
0    1.0
1    2.0
2    NaN
dtype: float64

In [9]: a  # `a` is changed
Out[9]:
<PandasArray>
[3.0, 3.0, nan]
Length: 3, dtype: float64
```",2024-03-25T17:20:07Z,0,0,Ashwin Srinath,Voltron Data
357,[BUG] Array proxy in cudf.pandas don't include special casing for `ndarray.flat`,"The `arr.flat` attribute should return a `flatiter` object, but they currently return a generator. Unlike `flatiter`, generator objects cannot be written to:

```python
In [1]: %load_ext cudf.pandas

In [2]: import pandas as pd

In [3]: s = pd.Series([1,2 , 3])

In [4]: arr = s.values

In [5]: arr.flat
Out[5]: <generator object _maybe_wrap_result.<locals>.<genexpr> at 0x7f70a82cc310>
```

In contrast:

```python
import numpy as np

arr = np.arange(5)
print(type(arr.flat))
arr.flat[:3] = 100
print(arr)
<class 'numpy.flatiter'>
[100 100 100   3   4]
```

```python
import cupy as cp
arr = cp.arange(5)
print(type(arr.flat))
arr.flat[:3] = 100
print(arr)
<class 'cupy._indexing.iterate.flatiter'>
[100 100 100   3   4]
```",2024-03-25T19:06:52Z,0,0,Ashwin Srinath,Voltron Data
358,[FEA] Report the number of rows read per file in libcudf's Parquet reader ,"**Is your feature request related to a problem? Please describe.**
I wish libcudf's parquet reader reports the number of rows read per file.

Consider the following example, 
```c++
  std::vector<std::string> file_paths;  // defined elsewhere
  std::vector<std::string> column_names;  // defined elsewhere

  auto source  = cudf::io::source_info(file_paths);
  auto options = cudf::io::parquet_reader_options::builder(source);
  options.columns(column_names);
  auto result = cudf::io::read_parquet(options);
```

Here, `result` is of type [`table_with_metadata`](https://github.com/rapidsai/cudf/blob/branch-24.02/cpp/include/cudf/io/types.hpp#L249), but the metadata doesn't contain the number of rows read from each file. I wish libcudf can add this functionality.

**Describe the solution you'd like**
Report the number of rows read from each file in `table_with_metadata`.

**Describe alternatives you've considered**
I have tried `cudf::io::read_parquet_metadata` out-of-band, like the following snippet.

```c++
  std::vector<cudf::size_type> rows_per_file;
  rows_per_file.reserve(file_paths.size());

  for (auto const& file_path : file_paths) {
    auto file_source = cudf::io::source_info(file_path);
    auto metadata    = cudf::io::read_parquet_metadata(file_source);
    rows_per_file.push_back(metadata.num_rows());
  }
  result.rows_per_file = std::move(rows_per_file);
```

But this has nontrivial overhead in my use case. I believe we can get it for free as part of the Parquet reading process, since the Parquet reader needs to decode the file footers anyway.
",2024-03-26T06:34:07Z,0,0,,
359,[DOC] update CONTRIBUTING.md to mention devcontainers?,"**Suggested fix for documentation**
I learnt about the https://github.com/rapidsai/devcontainers from @dantegd's GTC talk (https://register.nvidia.com/flow/nvidia/gtcs24/attendeeportaldigital/page/sessioncatalog/session/1697766189600001T2p3) wonder if the build instructions in https://github.com/rapidsai/cudf/blob/branch-24.06/CONTRIBUTING.md could be updated to point to the devcontainers and how to use them.",2024-03-26T21:13:37Z,0,0,Ray Bell,DTN
360,[QST]Custom class with cuDF,"```
numba.core.errors.TypingError: Failed in cuda mode pipeline (step: nopython frontend)
Untyped global name 'Master10DH': Cannot determine Numba type of <class 'abc.ABCMeta'>

File ""ik_GPU.py"", line 9:
def ik(row):
    robot = Master10DH()
```
Hello, I encountered the following error, how can I fix it?",2024-04-03T11:26:31Z,0,0,,
361,[BUG] Unpickling objects with `pd.read_pickle()` doesn't work with cudf.pandas enabled,"**Describe the bug**
When `cudf.pandas` is enabled, we can pickle and unpickle objects using `pickle.dump/load` or `pickle.dumps/loads`. But if we choose to unpickle with `pd.read_pickle`, things go awry. Here's a minimal reproducer:

```python
import pandas as pd
from io import BytesIO
import pickle

pdf = pd.DataFrame({'a': [1.0, 2.0, None, 3.0]})

with open(""pickled_pdf.pkl"", ""wb"") as f:
    pickle.dump(pdf, f)

with open(""pickled_pdf.pkl"", ""rb"") as f:
    df = pd.read_pickle(f)

print(df)
```

<details>

```
In [1]: %load_ext cudf.pandas

In [2]: import pandas as pd

In [3]: from io import BytesIO
   ...: import pickle
   ...: 
   ...: pdf = pd.DataFrame({'a': [1.0, 2.0, None, 3.0]})
   ...: 
   ...: with open(""pickled_pdf.pkl"", ""wb"") as f:
   ...:     pickle.dump(pdf, f)
   ...: 
   ...: with open(""pickled_pdf.pkl"", ""rb"") as f:
   ...:     df = pd.read_pickle(f)
   ...: 
   ...: print(df)
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
File ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:888, in _fast_slow_function_call(func, *args, **kwargs)
    883 with nvtx.annotate(
    884     ""EXECUTE_FAST"",
    885     color=_CUDF_PANDAS_NVTX_COLORS[""EXECUTE_FAST""],
    886     domain=""cudf_pandas"",
    887 ):
--> 888     fast_args, fast_kwargs = _fast_arg(args), _fast_arg(kwargs)
    889     result = func(*fast_args, **fast_kwargs)

File ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:1007, in _fast_arg(arg)
   1006 seen: Set[int] = set()
-> 1007 return _transform_arg(arg, ""_fsproxy_fast"", seen)

File ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:934, in _transform_arg(arg, attribute_name, seen)
    932 if type(arg) is tuple:
    933     # Must come first to avoid infinite recursion
--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)
    935 elif hasattr(arg, ""__getnewargs_ex__""):
    936     # Partial implementation of to reconstruct with
    937     # transformed pieces
    938     # This handles scipy._lib._bunch._make_tuple_bunch

File ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:934, in <genexpr>(.0)
    932 if type(arg) is tuple:
    933     # Must come first to avoid infinite recursion
--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)
    935 elif hasattr(arg, ""__getnewargs_ex__""):
    936     # Partial implementation of to reconstruct with
    937     # transformed pieces
    938     # This handles scipy._lib._bunch._make_tuple_bunch

File ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:917, in _transform_arg(arg, attribute_name, seen)
    916 if isinstance(arg, (_FastSlowProxy, _FastSlowProxyMeta, _FunctionProxy)):
--> 917     typ = getattr(arg, attribute_name)
    918     if typ is _Unusable:

File ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:553, in _FastSlowProxy.__getattr__(self, name)
    550 if name.startswith(""_fsproxy""):
    551     # an AttributeError was raised when trying to evaluate
    552     # an internal attribute, we just need to propagate this
--> 553     _raise_attribute_error(self.__class__.__name__, name)
    554 if name in {
    555     ""_ipython_canary_method_should_not_exist_"",
    556     ""_ipython_display_"",
   (...)
    568     # This is somewhat delicate to the order in which IPython
    569     # implements special display fallbacks.

File ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:392, in _raise_attribute_error(obj, name)
    387 """"""
    388 Raise an AttributeError with a message that is consistent with
    389 the error raised by Python for a non-existent attribute on a
    390 proxy object.
    391 """"""
--> 392 raise AttributeError(f""'{obj}' object has no attribute '{name}'"")

AttributeError: 'function' object has no attribute '_fsproxy_fast'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-3-deda8b8b446c> in ?()
      8 
      9 with open(""pickled_pdf.pkl"", ""rb"") as f:
     10     df = pd.read_pickle(f)
     11 
---> 12 print(df)

~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py in ?(self, *args, **kwargs)
    836     def __call__(self, *args, **kwargs) -> Any:
--> 837         result, _ = _fast_slow_function_call(
    838             # We cannot directly call self here because we need it to be
    839             # converted into either the fast or slow object (by
    840             # _fast_slow_function_call) to avoid infinite recursion.

~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py in ?(func, *args, **kwargs)
    898             domain=""cudf_pandas"",
    899         ):
    900             slow_args, slow_kwargs = _slow_arg(args), _slow_arg(kwargs)
    901             with disable_module_accelerator():
--> 902                 result = func(*slow_args, **slow_kwargs)
    903     return _maybe_wrap_result(result, func, *args, **kwargs), fast

~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py in ?(fn, args, kwargs)
     29 def call_operator(fn, args, kwargs):
---> 30     return fn(*args, **kwargs)

~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/core/frame.py in ?(self)
   1199             self.info(buf=buf)
   1200             return buf.getvalue()
   1201 
   1202         repr_params = fmt.get_dataframe_repr_params()
-> 1203         return self.to_string(**repr_params)

~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/util/_decorators.py in ?(*args, **kwargs)
    329                     msg.format(arguments=_format_argument_list(allow_args)),
    330                     FutureWarning,
    331                     stacklevel=find_stack_level(),
    332                 )
--> 333             return func(*args, **kwargs)

~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/core/frame.py in ?(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)
   1361         """"""
   1362         from pandas import option_context
   1363 
   1364         with option_context(""display.max_colwidth"", max_colwidth):
-> 1365             formatter = fmt.DataFrameFormatter(
   1366                 self,
   1367                 columns=columns,
   1368                 col_space=col_space,

~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/io/formats/format.py in ?(self, frame, columns, col_space, header, index, na_rep, formatters, justify, float_format, sparsify, index_names, max_rows, min_rows, max_cols, show_dimensions, decimal, bold_rows, escape)
    443         bold_rows: bool = False,
    444         escape: bool = True,
    445     ) -> None:
    446         self.frame = frame
--> 447         self.columns = self._initialize_columns(columns)
    448         self.col_space = self._initialize_colspace(col_space)
    449         self.header = header
    450         self.index = index

~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/io/formats/format.py in ?(self, columns)
    552             cols = ensure_index(columns)
    553             self.frame = self.frame[cols]
    554             return cols
    555         else:
--> 556             return self.frame.columns

~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/core/generic.py in ?(self, name)
   6292             and name not in self._accessors
   6293             and self._info_axis._can_hold_identifiers_and_holds_name(name)
   6294         ):
   6295             return self[name]
-> 6296         return object.__getattribute__(self, name)

properties.pyx in ?()
---> 65 'Could not get source, probably due dynamically evaluated source code.'

~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/core/generic.py in ?(self, name)
   6292             and name not in self._accessors
   6293             and self._info_axis._can_hold_identifiers_and_holds_name(name)
   6294         ):
   6295             return self[name]
-> 6296         return object.__getattribute__(self, name)

AttributeError: 'DataFrame' object has no attribute '_mgr'
```
</details>
 
We can (and do) control what happens when objects are pickled and unpickled via the pickle protocol (`pickle.dump` and `pickle.load`) [here](https://github.com/rapidsai/cudf/blob/5192b608eeed4bda9317c657253c3a5630aa4c5d/python/cudf/cudf/pandas/fast_slow_proxy.py#L722-L741). 

And pandas' `read_pickle` does call the ""regular"" [`pickle.load` function](https://github.com/pandas-dev/pandas/blob/05ab1af783f6590b8a2d9fbea6d39793e88dfb04/pandas/io/pickle.py#L203). 

So what's going on?

When we call `pd.read_pickle` in `cudf.pandas` mode, that will first call `cudf.read_pickle` (doesn't exist) and then fall back to the real `pandas.read_pickle`. Importantly, during fallback, we [disable ourselves](https://github.com/rapidsai/cudf/blob/5192b608eeed4bda9317c657253c3a5630aa4c5d/python/cudf/cudf/pandas/fast_slow_proxy.py#L901). Which means that our special pickle protocol handling doesn't kick in and that messes everything up. 

### Solutions

The only solution I could think of is we vendor `pandas.read_pickle`, so we can keep ourselves enabled when it is called.",2024-04-03T20:24:39Z,0,0,Ashwin Srinath,Voltron Data
362,[BUG] Incorrect proxying of functions with no matching fast counterpart in cudf.pandas,"**Describe the bug**

Functions in the pandas source tree which do not have a matching counterpart in the cudf source tree are proxied with a `FunctionProxy` object whose `_fsproxy_fast` attribute is an `_Unusable` object.

Unfortunately, although accessing an `_Unusuable` object in a fast-slow chained method call fails, it does so too late and already provokes slow-to-fast and fast-to-slow copies. This ends up breaking the link between the fast and slow types inside a proxied object.

This raises its head particularly in the pandas test suite where there are functions that are used to parameterise over (for example) `iloc` vs `loc` indexing, like `pandas._testing.iloc`.

To see the problem consider the following:

```python
import cudf.pandas
cudf.pandas.install()

import pandas as pd

s = pd.Series(range(10))
s._fsproxy_state # => FAST
# pd._testing.iloc has no matching fast counterpart, so this function-call will provoke
# a fast to slow copy
indexer = pd._testing.iloc(s)
s._fsproxy_state # => SLOW
# We want setitem to keep the object as  slow,
# but this is a `_FastSlowAttribute` so it provokes (if it can) a slow-to-fast copy
getattr(indexer, ""__setitem__"")
s._fsproxy_state # => FAST
# Now we are in an inconsistent state.
```

In `_transform_arg` we have a carveout early exit if the fast or slow attribute we're asking for is  `_Unusable`, but not if it is an instance of `_Unusable`.

This patch helps a bit:
```patch
diff --git a/python/cudf/cudf/pandas/fast_slow_proxy.py b/python/cudf/cudf/pandas/fast_slow_proxy.py
index e811ba1351..9d07d236bb 100644
--- a/python/cudf/cudf/pandas/fast_slow_proxy.py
+++ b/python/cudf/cudf/pandas/fast_slow_proxy.py
@@ -915,7 +915,7 @@ def _transform_arg(
 
     if isinstance(arg, (_FastSlowProxy, _FastSlowProxyMeta, _FunctionProxy)):
         typ = getattr(arg, attribute_name)
-        if typ is _Unusable:
+        if typ is _Unusable or isinstance(typ, _Unusable):
             raise Exception(""Cannot transform _Unusable"")
         return typ
     elif isinstance(arg, types.ModuleType) and attribute_name in arg.__dict__:
```

But is observed to cause the pandas test suite run to take significantly longer (indicating, probably, more fast-to-slow transfers than necessary).

Note that this change works for `pd._testing.iloc` but _not_ `pd._testing.setitem` which is just the identity function, since wrapping the identity function produces a new function which is _not_ the identity.",2024-04-08T09:44:10Z,0,0,Lawrence Mitchell,
363,[BUG] cudf.read_parquet takes too much time(due to cudaMallocHost overhead etc.) to load the zstd compressed parquet files with few thousands to millions of rows,"**Describe the bug**
Performance improvement proposal for cudf parquet file reading efficiency.

**Steps/Code to reproduce bug**

```python
import pandas as pd

df = pd.DataFrame({'jnac': [None] * 1000})
df.to_parquet('/dev/shm/jnac.parquet', compression='ZSTD')

# cd to /dev/shm now

import cudf
import pandas
import pyarrow.parquet

import time

# not accurate timing, while the diff is so obvious which do not require more accurate timing temporrally

ts = time.time(); tb = cudf.read_parquet('/dev/shm/jnac.parquet'); te = time.time()
time.sleep(1)
ts = time.time(); tb = cudf.read_parquet('/dev/shm/jnac.parquet'); te = time.time()
print(te - ts)

ts = time.time(); tb = pandas.read_parquet('/dev/shm/jnac.parquet'); te = time.time()
time.sleep(1)
ts = time.time(); tb = pandas.read_parquet('/dev/shm/jnac.parquet'); te = time.time()
print(te - ts)

ts = time.time(); tb = pyarrow.parquet.read_table('/dev/shm/jnac.parquet'); te = time.time()
time.sleep(1)
ts = time.time(); tb = pyarrow.parquet.read_table('/dev/shm/jnac.parquet'); te = time.time()
print(te - ts)
```

**Expected behavior**

```python
>>> ts = time.time(); tb = cudf.read_parquet('jnac.parquet'); te = time.time()
>>> print(te - ts)
0.006829023361206055
>>>
>>> ts = time.time(); tb = pandas.read_parquet('jnac.parquet'); te = time.time()
>>> time.sleep(1)

>>> ts = time.time(); tb = pandas.read_parquet('jnac.parquet'); te = time.time()
>>> print(te - ts)
0.003950357437133789
>>>
>>> ts = time.time(); tb = pyarrow.parquet.read_table('jnac.parquet'); te = time.time()
>>> time.sleep(1)
>>> ts = time.time(); tb = pyarrow.parquet.read_table('jnac.parquet'); te = time.time()
>>> print(te - ts)
0.0013420581817626953
>>>

```

**Environment overview (please complete the following information)**
internal T4 node, py3.9, cudf 24.02.02


**Additional context**

It just takes too much time to process <NA> entries, especially for cudf when num rows is just 1K(similar latency cost for 10M rows NA though).
",2024-04-08T10:05:14Z,0,0,黄(Huáng)瓒(Zàn),Georgia Institute of Technology
364,"[FEA] cudf.pandas profiler should show time taken by other, non-pandas functions to run.","This is a bit different from https://github.com/rapidsai/cudf/issues/14499.

The `cudf.pandas` profiler only shows the time it takes for pandas functions and methods to run; but it doesn't report the time it takes for other functions and methods. It would be useful if the total time reported by the profiler matched up roughly with the actual total wall clock time of the program.

For example:

```
In [1]: %load_ext cudf.pandas

In [2]: import pandas as pd

In [3]: import time

In [4]: def fun1():
   ...:     time.sleep(5)
   ...:

In [5]: def fun2():
   ...:     s = pd.Series([1, 2, 3])
   ...:     s.max()
   ...:     s.min()
   ...:

In [6]: %%cudf.pandas.profile
   ...: fun1()
   ...: fun2()
   ...:
   ...:

                                   Total time elapsed: 6.345 seconds
                                 3 GPU function calls in 1.090 seconds
                                 0 CPU function calls in 0.000 seconds

                                                 Stats

┏━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Function   ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ Series     │ 1          │ 1.088       │ 1.088       │ 0          │ 0.000       │ 0.000       │
│ Series.max │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │
│ Series.min │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │
└────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘
``` 

It would be great if the result was something like:

```
                                   Total time elapsed: 6.345 seconds
                                 3 GPU function calls in 1.090 seconds
                                 0 CPU function calls in 0.000 seconds

                                                 Stats

┏━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Function   ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ Series     │ 1          │ 1.088       │ 1.088       │ 0          │ 0.000       │ 0.000       │
│ Series.max │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │
│ Series.min │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │
│ Others     │ -          │ -           │ -           │ -          │ 5.000       │ 5.000       │
└────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘
```",2024-04-08T13:17:03Z,0,0,Ashwin Srinath,Voltron Data
365,[FEA] Improve occupancy during hash table build,"**Is your feature request related to a problem? Please describe.**
cuco insert kernel has poor occupancy due to high register usage during hash table build operation executed by cuDF. If I disable some of the code paths for complex types(commenting out dict, string, list, struct, decimal) in https://github.com/rapidsai/cudf/blob/434df44d9fe1c94e8047bcc37266ae663eae8a8d/cpp/include/cudf/utilities/type_dispatcher.hpp#L456 the type dispatcher, then the register usage per thread drops from 75 -> 46 and leads to a significant occupancy bump. It seems that the insert kernel has to pay the cost of high register usage even for simpler types since the compiler has to account for all code paths.

I did some experiments by disabling different subsets of types, list has types I disable -> register count for insert kernel
- decimal -> 72
- struct -> 73
- list -> 73
- string -> 73
- dict -> 68
- struct, list -> 64
- list, decimal, struct -> 63
- dict, string, list, struct -> 58
- string, dict, struct, list, decimal -> 46

Here is the speedup I see on mixed semi join kernel by improving occupancy for int32 keys obtained by disabling complex types
![image](https://github.com/rapidsai/cudf/assets/23545205/553e66bc-0fce-4954-868b-cd8a7163eedf)

**Describe the solution you'd like**
Improve occupancy by disabling codepaths for complex types.

**Describe alternatives you've considered**
1. Add more template params to the hasher/comparator which allow us to separate codepaths for complex types and simpler types, or 
2. Add JIT compilation to only consider the types necessary for hasher/comparator for a row

**Additional context**
Add any other context, code examples, or references to existing implementations about the feature request here.
",2024-04-10T15:57:18Z,0,0,Tanmay Gujar,
366,[FEA] Allow groupby scan aggregations to return listified results,"**Is your feature request related to a problem? Please describe.**

To match the way scan aggregation results in groupby operations are returned in pandas, libcudf returns scan-based aggregations in the same shape as the input table (these are then optionally reordered to mimic pandas order).

For the cudf-polars executor, it would be useful to also have a mode where the result of a scan aggregation is collected, group-wise, into a list column. This would mean that both scan-like and reduction-like groupby aggregations always produce an output table with a number of rows equal to the number of unique group keys.

**Describe the solution you'd like**

For scan-only aggregations, this is relatively easy to achieve by taking the sorted grouped result and calling `make_lists_column` with the group offsets. When mixing scan and hash-based aggregations it is tricker (since those would spit things out in a different order and would then need a join). Ideally one the scan aggs have a ""collect as list"" option, then one would be able to do scan and reduce- aggs in the same call on the sorted table.

**Describe alternatives you've considered**

I can post-process the result (and then do a join if I have any hash-based aggs in addition).

**Additional context**

Right now, polars guarantees that although the order of groups in the result is implementation dependent, within a group, the rows show up in original dataframe order. I think this is also guaranteed by libcudf, since the sort-by-key before the aggregations is stable.
",2024-04-16T11:18:38Z,0,0,Lawrence Mitchell,
367,[FEA] Allow cudf::thread_pool to restrict the number of threads available.,"I have a benchmarking use case where it would be nice to be able to use a single thread pool across multiple benchmarks for ease of viewing in nsys.  Imagine a benchmark where one of your testing axes is the number of threads used to split up the work. Say, 2, 4 and 8 threads.  The way you would do this today is you would create a new `thread_pool` in each instance of the benchmark with the appropriate number of threads.  The problem with this is that each thread gets it's own line of data in nsys.  So you end up with 14 total threads that you have to expand and hunt down.  This gets worse if you have other axes.  You can very quickly get up into 64 or more threads, which is a bit of a headache to sort through.

Instead, it would be nice if we could create a thread pool and temporarily restrict the number of threads it would use for newly submitted jobs.   So what your benchmark could do is create a single global thread pool (say, 8 threads above). And then just set the thread count restriction in each benchmark.   So you would have a nice clean timeline with a tractable number of threads in nsys.

Alternately, a way to sub-allocate  out of an existing pool (temporarily funding one thread_pool with the threads from another)  would work as well.",2024-04-19T19:35:34Z,0,0,,
368,[FEA] Improve performance of strings matching in libcudf,"**Is your feature request related to a problem? Please describe.**
The issue documents a few performance ideas for the libcudf regular expression engine ([code pointer](https://github.com/rapidsai/cudf/tree/branch-24.06/cpp/src/strings/regex)) and strings APIs. In particular, these performance ideas came from investigation of multi-string pattern matching commonly used for IP addresses in DPUs. The DPU use case involves checking dozens (?) of string patterns against millions (?) of input strings, and most matches are negative.

| Idea | API scope | Initial scoping |
|---|---|---|
| Avoid regex and instead replace with strings contains or strings startswith/endswith whenever possible. | regex utilities | For now we encourage libcudf applications to add pattern inspection and avoid calling the regex engine if that is an important optimization in their use case. We may consider upstreaming a tool similar to the [regex parsing approach in Spark-RAPIDS](https://github.com/NVIDIA/spark-rapids/pull/10715) at some point. |
| Add a non-regex multi-string match function to the strings API, as a way to fused multiple string matches into a single kernel  |  strings | We have an investigation of this idea in #15536. Performance analysis is in progress |
| Use a shared memory Shift-Or approach to speed up strings contains.  | strings | Initial scoping suggests this method could deliver 3x throughput (~1000 GB/s on A100). However this optimization will have a larger memory footprint (256 bytes/thread) that could create other issues when integrated with libcudf. ([link to algorithm demonstration](https://www.educative.io/answers/shift-or-string-matching-algorithm)) |
| Fuse sequences of regex pattern characters into a single ""regex literal"" token | regex | After initial scoping, multi-character pattern tokens are unlikely to be compatible with the existing regex engine. Significant refactoring would be required and the benefits are uncertain. |
| ASCII-only strings `contains` | strings | There may be benefit to an ASCII-only implementation of string matching for some use cases. The potential performance benefit has not yet been evaluated. | 
| ASCII-only `match_re` | strings | There may be benefit to an ASCII-only implementation of regex pattern matching for some use cases. The potential performance benefit has not yet been evaluated. |
| [Sitaridi et al 2016](https://dl.acm.org/doi/pdf/10.1007/s00778-015-0409-y) suggests to use Knuth–Morris–Pratt (KMP) for string pattern matching | strings | Stores a partial match table that improves GPU L2 cache utilization |
| add aligned strings for vector loading | strings | add padding in the byte array, add sizes child column. always use aligned strings by default?  |
| prefix strings | strings | see Arrow (TBD) |  


**Describe the solution you'd like**
TBD

**Describe alternatives you've considered**
TBD

**Additional context**
Regex performance ideas have come out of collaboration between SM-based and DPU-based regular expression processing. For more information about DPU-based regex, please see the [NVIDIA Bluefield-2](https://docs.nvidia.com/networking/display/bluefielddpuosv385/regex+acceleration) docs.
",2024-04-29T18:29:30Z,0,0,Gregory Kimball,
369,[BUG] Enabling cudf.pandas leads to exception when using a Numpy array,"**Describe the bug**
When `cudf.pandas` is enabled then passing a Numpy array to `ExponentialSmoothing` from `statsmodels.tsa.holtwinters` involves the pandas accelerator (odd no?) and leads to an exception.

**Steps/Code to reproduce bug**

```python
import cudf.pandas
cudf.pandas.install()
import numpy as np
from statsmodels.tsa.holtwinters import ExponentialSmoothing
airpassengers = [
    112,
    118,
    132,
    129,
    121,
    135,
    148,
    148,
    136,
    119,
    104,
    118,
    115,
    126,
    141,
    135,
    125,
    149,
    170,
    170,
    158,
    133,
    114,
    140,
    145,
    150,
    178,
    163,
    172,
    178,
    199,
    199,
    184,
    162,
    146,
    166,
    171,
    180,
    193,
    181,
    183,
    218,
    230,
    242,
    209,
    191,
    172,
    194,
    196,
    196,
    236,
    235,
    229,
    243,
    264,
    272,
    237,
    211,
    180,
    201,
    204,
    188,
    235,
    227,
    234,
    264,
    302,
    293,
    259,
    229,
    203,
    229,
    242,
    233,
    267,
    269,
    270,
    315,
    364,
    347,
    312,
    274,
    237,
    278,
    284,
    277,
    317,
    313,
    318,
    374,
    413,
    405,
    355,
    306,
    271,
    306,
    315,
    301,
    356,
    348,
    355,
    422,
    465,
    467,
    404,
    347,
    305,
    336,
    340,
    318,
    362,
    348,
    363,
    435,
    491,
    505,
    404,
    359,
    310,
    337,
]
airpassengers = np.asarray(airpassengers, dtype=np.float64)

# this line leads to the traceback
ExponentialSmoothing(airpassengers, initialization_method='heuristic', seasonal='additive', seasonal_periods=12)
```

<details>
<summary>Full traceback</summary>

---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:888, in _fast_slow_function_call(func, *args, **kwargs)
    883 with nvtx.annotate(
    884     ""EXECUTE_FAST"",
    885     color=_CUDF_PANDAS_NVTX_COLORS[""EXECUTE_FAST""],
    886     domain=""cudf_pandas"",
    887 ):
--> 888     fast_args, fast_kwargs = _fast_arg(args), _fast_arg(kwargs)
    889     result = func(*fast_args, **fast_kwargs)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1007, in _fast_arg(arg)
   1006 seen: Set[int] = set()
-> 1007 return _transform_arg(arg, ""_fsproxy_fast"", seen)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:934, in _transform_arg(arg, attribute_name, seen)
    932 if type(arg) is tuple:
    933     # Must come first to avoid infinite recursion
--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)
    935 elif hasattr(arg, ""__getnewargs_ex__""):
    936     # Partial implementation of to reconstruct with
    937     # transformed pieces
    938     # This handles scipy._lib._bunch._make_tuple_bunch

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:934, in <genexpr>(.0)
    932 if type(arg) is tuple:
    933     # Must come first to avoid infinite recursion
--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)
    935 elif hasattr(arg, ""__getnewargs_ex__""):
    936     # Partial implementation of to reconstruct with
    937     # transformed pieces
    938     # This handles scipy._lib._bunch._make_tuple_bunch

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:917, in _transform_arg(arg, attribute_name, seen)
    916 if isinstance(arg, (_FastSlowProxy, _FastSlowProxyMeta, _FunctionProxy)):
--> 917     typ = getattr(arg, attribute_name)
    918     if typ is _Unusable:

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:528, in _FastSlowProxy._fsproxy_fast(self)
    523 """"""
    524 Returns the wrapped object. If the wrapped object is of ""slow""
    525 type, replaces it with the corresponding ""fast"" object before
    526 returning it.
    527 """"""
--> 528 self._fsproxy_wrapped = self._fsproxy_slow_to_fast()
    529 return self._fsproxy_wrapped

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)
    115 libnvtx_push_range(self.attributes, self.domain.handle)
--> 116 result = func(*args, **kwargs)
    117 libnvtx_pop_range(self.domain.handle)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:786, in _IntermediateProxy._fsproxy_slow_to_fast(self)
    785 func, args, kwargs = self._method_chain
--> 786 args, kwargs = _fast_arg(args), _fast_arg(kwargs)
    787 return func(*args, **kwargs)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1007, in _fast_arg(arg)
   1006 seen: Set[int] = set()
-> 1007 return _transform_arg(arg, ""_fsproxy_fast"", seen)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:934, in _transform_arg(arg, attribute_name, seen)
    932 if type(arg) is tuple:
    933     # Must come first to avoid infinite recursion
--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)
    935 elif hasattr(arg, ""__getnewargs_ex__""):
    936     # Partial implementation of to reconstruct with
    937     # transformed pieces
    938     # This handles scipy._lib._bunch._make_tuple_bunch

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:934, in <genexpr>(.0)
    932 if type(arg) is tuple:
    933     # Must come first to avoid infinite recursion
--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)
    935 elif hasattr(arg, ""__getnewargs_ex__""):
    936     # Partial implementation of to reconstruct with
    937     # transformed pieces
    938     # This handles scipy._lib._bunch._make_tuple_bunch

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:917, in _transform_arg(arg, attribute_name, seen)
    916 if isinstance(arg, (_FastSlowProxy, _FastSlowProxyMeta, _FunctionProxy)):
--> 917     typ = getattr(arg, attribute_name)
    918     if typ is _Unusable:

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:528, in _FastSlowProxy._fsproxy_fast(self)
    523 """"""
    524 Returns the wrapped object. If the wrapped object is of ""slow""
    525 type, replaces it with the corresponding ""fast"" object before
    526 returning it.
    527 """"""
--> 528 self._fsproxy_wrapped = self._fsproxy_slow_to_fast()
    529 return self._fsproxy_wrapped

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)
    115 libnvtx_push_range(self.attributes, self.domain.handle)
--> 116 result = func(*args, **kwargs)
    117 libnvtx_pop_range(self.domain.handle)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:787, in _IntermediateProxy._fsproxy_slow_to_fast(self)
    786 args, kwargs = _fast_arg(args), _fast_arg(kwargs)
--> 787 return func(*args, **kwargs)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:30, in call_operator(fn, args, kwargs)
     29 def call_operator(fn, args, kwargs):
---> 30     return fn(*args, **kwargs)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:76, in _Unusable.__call__(self, *args, **kwds)
     75 def __call__(self, *args: Any, **kwds: Any) -> Any:
---> 76     raise NotImplementedError(
     77         ""Fast implementation not available. ""
     78         ""Falling back to the slow implementation""
     79     )

NotImplementedError: Fast implementation not available. Falling back to the slow implementation

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
Cell In[1], line 130
    127 airpassengers = np.asarray(airpassengers, dtype=np.float64)
    129 # this line leads to the traceback
--> 130 ExponentialSmoothing(airpassengers, initialization_method='heuristic', seasonal='additive', seasonal_periods=12)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:837, in _CallableProxyMixin.__call__(self, *args, **kwargs)
    836 def __call__(self, *args, **kwargs) -> Any:
--> 837     result, _ = _fast_slow_function_call(
    838         # We cannot directly call self here because we need it to be
    839         # converted into either the fast or slow object (by
    840         # _fast_slow_function_call) to avoid infinite recursion.
    841         # TODO: When Python 3.11 is the minimum supported Python version
    842         # this can use operator.call
    843         call_operator,
    844         self,
    845         args,
    846         kwargs,
    847     )
    848     return result

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:902, in _fast_slow_function_call(func, *args, **kwargs)
    900         slow_args, slow_kwargs = _slow_arg(args), _slow_arg(kwargs)
    901         with disable_module_accelerator():
--> 902             result = func(*slow_args, **slow_kwargs)
    903 return _maybe_wrap_result(result, func, *args, **kwargs), fast

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:30, in call_operator(fn, args, kwargs)
     29 def call_operator(fn, args, kwargs):
---> 30     return fn(*args, **kwargs)

File /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/pandas/util/_decorators.py:213, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)
    211         raise TypeError(msg)
    212     kwargs[new_arg_name] = new_arg_value
--> 213 return func(*args, **kwargs)

TypeError: ExponentialSmoothing.__init__() missing 1 required positional argument: 'endog'

</details>

**Expected behavior**
No error

**Environment overview (please complete the following information)**
Setup cuml dev environment using a conda env

**Environment details**
Please run and paste the output of the `cudf/print_env.sh` script here, to gather any other relevant environment details

<details><summary>Click here to see environment details</summary><pre>

     **git***
     Not inside a git repository

     ***OS Information***
     DISTRIB_ID=Ubuntu
     DISTRIB_RELEASE=22.04
     DISTRIB_CODENAME=jammy
     DISTRIB_DESCRIPTION=""Ubuntu 22.04.2 LTS""
     PRETTY_NAME=""Ubuntu 22.04.2 LTS""
     NAME=""Ubuntu""
     VERSION_ID=""22.04""
     VERSION=""22.04.2 LTS (Jammy Jellyfish)""
     VERSION_CODENAME=jammy
     ID=ubuntu
     ID_LIKE=debian
     HOME_URL=""https://www.ubuntu.com/""
     SUPPORT_URL=""https://help.ubuntu.com/""
     BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
     PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
     UBUNTU_CODENAME=jammy
     Linux dt05 5.15.0-94-generic #104-Ubuntu SMP Tue Jan 9 15:25:40 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux

     ***GPU Information***
     Thu May  2 08:41:30 2024
     +---------------------------------------------------------------------------------------+
     | NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
     |-----------------------------------------+----------------------+----------------------+
     | GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
     | Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
     |                                         |                      |               MIG M. |
     |=========================================+======================+======================|
     |   0  Tesla T4                       On  | 00000000:3B:00.0 Off |                    0 |
     | N/A   36C    P8              15W /  70W |      2MiB / 15360MiB |      0%      Default |
     |                                         |                      |                  N/A |
     +-----------------------------------------+----------------------+----------------------+
     |   1  Tesla T4                       On  | 00000000:5E:00.0 Off |                    0 |
     | N/A   35C    P8              10W /  70W |      2MiB / 15360MiB |      0%      Default |
     |                                         |                      |                  N/A |
     +-----------------------------------------+----------------------+----------------------+
     |   2  Tesla T4                       On  | 00000000:AF:00.0 Off |                    0 |
     | N/A   29C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |
     |                                         |                      |                  N/A |
     +-----------------------------------------+----------------------+----------------------+
     |   3  Tesla T4                       On  | 00000000:D8:00.0 Off |                    0 |
     | N/A   29C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |
     |                                         |                      |                  N/A |
     +-----------------------------------------+----------------------+----------------------+

     +---------------------------------------------------------------------------------------+
     | Processes:                                                                            |
     |  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
     |        ID   ID                                                             Usage      |
     |=======================================================================================|
     |  No running processes found                                                           |
     +---------------------------------------------------------------------------------------+

     ***CPU***
     Architecture:                       x86_64
     CPU op-mode(s):                     32-bit, 64-bit
     Address sizes:                      46 bits physical, 48 bits virtual
     Byte Order:                         Little Endian
     CPU(s):                             64
     On-line CPU(s) list:                0-63
     Vendor ID:                          GenuineIntel
     Model name:                         Intel(R) Xeon(R) Gold 6130 CPU @ 2.10GHz
     CPU family:                         6
     Model:                              85
     Thread(s) per core:                 2
     Core(s) per socket:                 16
     Socket(s):                          2
     Stepping:                           4
     CPU max MHz:                        3700.0000
     CPU min MHz:                        1000.0000
     BogoMIPS:                           4200.00
     Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts pku ospke md_clear flush_l1d arch_capabilities
     Virtualization:                     VT-x
     L1d cache:                          1 MiB (32 instances)
     L1i cache:                          1 MiB (32 instances)
     L2 cache:                           32 MiB (32 instances)
     L3 cache:                           44 MiB (2 instances)
     NUMA node(s):                       2
     NUMA node0 CPU(s):                  0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62
     NUMA node1 CPU(s):                  1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63
     Vulnerability Gather data sampling: Mitigation; Microcode
     Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled
     Vulnerability L1tf:                 Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable
     Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT vulnerable
     Vulnerability Meltdown:             Mitigation; PTI
     Vulnerability Mmio stale data:      Mitigation; Clear CPU buffers; SMT vulnerable
     Vulnerability Retbleed:             Mitigation; IBRS
     Vulnerability Spec rstack overflow: Not affected
     Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp
     Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
     Vulnerability Spectre v2:           Mitigation; IBRS, IBPB conditional, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected
     Vulnerability Srbds:                Not affected
     Vulnerability Tsx async abort:      Mitigation; Clear CPU buffers; SMT vulnerable

     ***CMake***
     /nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin/cmake
     cmake version 3.29.2

     CMake suite maintained and supported by Kitware (kitware.com/cmake).

     ***g++***
     /nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin/g++
     g++ (conda-forge gcc 11.4.0-6) 11.4.0
     Copyright (C) 2021 Free Software Foundation, Inc.
     This is free software; see the source for copying conditions.  There is NO
     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


     ***nvcc***
     /nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin/nvcc
     nvcc: NVIDIA (R) Cuda compiler driver
     Copyright (c) 2005-2023 NVIDIA Corporation
     Built on Tue_Aug_15_22:02:13_PDT_2023
     Cuda compilation tools, release 12.2, V12.2.140
     Build cuda_12.2.r12.2/compiler.33191640_0

     ***Python***
     /nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin/python
     Python 3.11.9

     ***Environment Variables***
     PATH                            : /home/nfs/thead/.local/bin:/home/nfs/thead/.local/bin:/nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin:/nvme/1/thead/miniconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
     LD_LIBRARY_PATH                 :
     NUMBAPRO_NVVM                   :
     NUMBAPRO_LIBDEVICE              :
     CONDA_PREFIX                    : /nvme/1/thead/miniconda/envs/cuml-dev-24.06
     PYTHON_PATH                     :

     ***conda packages***
     /nvme/1/thead/miniconda/condabin/conda
     # packages in environment at /nvme/1/thead/miniconda/envs/cuml-dev-24.06:
     #
     # Name                    Version                   Build  Channel
     _libgcc_mutex             0.1                 conda_forge    conda-forge
     _openmp_mutex             4.5                       2_gnu    conda-forge
     _sysroot_linux-64_curr_repodata_hack 3                   h69a702a_14    conda-forge
     accessible-pygments       0.0.4              pyhd8ed1ab_0    conda-forge
     alabaster                 0.7.16             pyhd8ed1ab_0    conda-forge
     asttokens                 2.4.1              pyhd8ed1ab_0    conda-forge
     atk-1.0                   2.38.0               h04ea711_2    conda-forge
     attrs                     23.2.0             pyh71513ae_0    conda-forge
     aws-c-auth                0.7.18               he0b1f16_0    conda-forge
     aws-c-cal                 0.6.11               heb1d5e4_0    conda-forge
     aws-c-common              0.9.15               hd590300_0    conda-forge
     aws-c-compression         0.2.18               hce8ee76_3    conda-forge
     aws-c-event-stream        0.4.2                h01f5eca_8    conda-forge
     aws-c-http                0.8.1               hdb68c23_10    conda-forge
     aws-c-io                  0.14.7               hbfbeace_6    conda-forge
     aws-c-mqtt                0.10.4               h50844eb_0    conda-forge
     aws-c-s3                  0.5.7                h6be9164_2    conda-forge
     aws-c-sdkutils            0.1.15               hce8ee76_3    conda-forge
     aws-checksums             0.1.18               hce8ee76_3    conda-forge
     aws-crt-cpp               0.26.8               h2150271_2    conda-forge
     aws-sdk-cpp               1.11.267             hddb5a97_7    conda-forge
     babel                     2.14.0             pyhd8ed1ab_0    conda-forge
     backports.zoneinfo        0.2.1           py311h38be061_8    conda-forge
     beautifulsoup4            4.12.3             pyha770c72_0    conda-forge
     binutils                  2.40                 h4852527_0    conda-forge
     binutils_impl_linux-64    2.40                 ha885e6a_0    conda-forge
     binutils_linux-64         2.40                 hdade7a5_3    conda-forge
     bleach                    6.1.0              pyhd8ed1ab_0    conda-forge
     bokeh                     3.4.1              pyhd8ed1ab_0    conda-forge
     brotli                    1.1.0                hd590300_1    conda-forge
     brotli-bin                1.1.0                hd590300_1    conda-forge
     brotli-python             1.1.0           py311hb755f60_1    conda-forge
     bzip2                     1.0.8                hd590300_5    conda-forge
     c-ares                    1.28.1               hd590300_0    conda-forge
     c-compiler                1.5.2                h0b41bf4_0    conda-forge
     ca-certificates           2024.2.2             hbcca054_0    conda-forge
     cachetools                5.3.3              pyhd8ed1ab_0    conda-forge
     cairo                     1.18.0               h3faef2a_0    conda-forge
     certifi                   2024.2.2           pyhd8ed1ab_0    conda-forge
     charset-normalizer        3.3.2              pyhd8ed1ab_0    conda-forge
     click                     8.1.7           unix_pyh707e725_0    conda-forge
     cloudpickle               3.0.0              pyhd8ed1ab_0    conda-forge
     cmake                     3.29.2               hcfe8598_0    conda-forge
     colorama                  0.4.6              pyhd8ed1ab_0    conda-forge
     comm                      0.2.2              pyhd8ed1ab_0    conda-forge
     commonmark                0.9.1                      py_0    conda-forge
     contourpy                 1.2.1           py311h9547e67_0    conda-forge
     coverage                  7.5.0           py311h331c9d8_0    conda-forge
     cuda-cccl_linux-64        12.2.140             ha770c72_0    conda-forge
     cuda-crt-dev_linux-64     12.2.140             ha770c72_1    conda-forge
     cuda-crt-tools            12.2.140             ha770c72_1    conda-forge
     cuda-cudart               12.2.140             hd3aeb46_0    conda-forge
     cuda-cudart-dev           12.2.140             hd3aeb46_0    conda-forge
     cuda-cudart-dev_linux-64  12.2.140             h59595ed_0    conda-forge
     cuda-cudart-static        12.2.140             hd3aeb46_0    conda-forge
     cuda-cudart-static_linux-64 12.2.140             h59595ed_0    conda-forge
     cuda-cudart_linux-64      12.2.140             h59595ed_0    conda-forge
     cuda-driver-dev_linux-64  12.2.140             h59595ed_0    conda-forge
     cuda-nvcc                 12.2.140             hcdd1206_0    conda-forge
     cuda-nvcc-dev_linux-64    12.2.140             ha770c72_1    conda-forge
     cuda-nvcc-impl            12.2.140             hd3aeb46_1    conda-forge
     cuda-nvcc-tools           12.2.140             hd3aeb46_1    conda-forge
     cuda-nvcc_linux-64        12.2.140             h8a487aa_0    conda-forge
     cuda-nvrtc                12.2.140             hd3aeb46_0    conda-forge
     cuda-nvvm-dev_linux-64    12.2.140             ha770c72_1    conda-forge
     cuda-nvvm-impl            12.2.140             h59595ed_1    conda-forge
     cuda-nvvm-tools           12.2.140             h59595ed_1    conda-forge
     cuda-profiler-api         12.2.140             ha770c72_0    conda-forge
     cuda-python               12.4.0          py311h7f239a6_1    conda-forge
     cuda-version              12.2                 he2b69de_3    conda-forge
     cudf                      24.06.00a164    cuda12_py311_240430_gab5e3f3bc8_164    rapidsai-nightly
     cuml                      24.6.0                   pypi_0    pypi
     cupy                      13.1.0          py311hf829483_4    conda-forge
     cupy-core                 13.1.0          py311he1e6e68_4    conda-forge
     cxx-compiler              1.5.2                hf52228f_0    conda-forge
     cycler                    0.12.1             pyhd8ed1ab_0    conda-forge
     cython                    3.0.10          py311hb755f60_0    conda-forge
     cytoolz                   0.12.3          py311h459d7ec_0    conda-forge
     dask                      2024.4.3a240423  py_g5a588aee_1    dask/label/dev
     dask-core                 2024.4.3a240429 py_gb958ce2dc_9    dask/label/dev
     dask-cuda                 24.06.00a12     py311_240430_g85cbd00_12    rapidsai-nightly
     dask-cudf                 24.06.00a164    cuda12_py311_240430_gab5e3f3bc8_164    rapidsai-nightly
     dask-expr                 1.0.13a240425     py_g301c1a6_5    dask/label/dev
     dask-glm                  0.3.0                    pypi_0    pypi
     dask-ml                   2024.3.20          pyhd8ed1ab_0    conda-forge
     debugpy                   1.8.1           py311hb755f60_0    conda-forge
     decopatch                 1.4.10             pyhd8ed1ab_0    conda-forge
     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge
     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge
     distributed               2024.4.3a240423  py_g5a588aee_1    dask/label/dev
     dlpack                    0.8                  h59595ed_3    conda-forge
     docutils                  0.19            py311h38be061_1    conda-forge
     doxygen                   1.9.1                hb166930_1    conda-forge
     entrypoints               0.4                pyhd8ed1ab_0    conda-forge
     exceptiongroup            1.2.0              pyhd8ed1ab_2    conda-forge
     execnet                   2.1.1              pyhd8ed1ab_0    conda-forge
     executing                 2.0.1              pyhd8ed1ab_0    conda-forge
     expat                     2.6.2                h59595ed_0    conda-forge
     fastrlock                 0.8.2           py311hb755f60_2    conda-forge
     fmt                       10.2.1               h00ab1b0_0    conda-forge
     font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge
     font-ttf-inconsolata      3.000                h77eed37_0    conda-forge
     font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge
     font-ttf-ubuntu           0.83                 h77eed37_1    conda-forge
     fontconfig                2.14.2               h14ed4e7_0    conda-forge
     fonts-conda-ecosystem     1                             0    conda-forge
     fonts-conda-forge         1                             0    conda-forge
     fonttools                 4.51.0          py311h459d7ec_0    conda-forge
     freetype                  2.12.1               h267a509_2    conda-forge
     fribidi                   1.0.10               h36c2ea0_0    conda-forge
     fsspec                    2024.3.1           pyhca7485f_0    conda-forge
     future                    1.0.0              pyhd8ed1ab_0    conda-forge
     gcc                       11.4.0               h602e360_6    conda-forge
     gcc_impl_linux-64         11.4.0               h7abf839_6    conda-forge
     gcc_linux-64              11.4.0               h0f0c6b6_3    conda-forge
     gdk-pixbuf                2.42.11              hb9ae30d_0    conda-forge
     gflags                    2.2.2             he1b5a44_1004    conda-forge
     giflib                    5.2.2                hd590300_0    conda-forge
     glog                      0.7.0                hed5481d_0    conda-forge
     graphite2                 1.3.13            h59595ed_1003    conda-forge
     graphviz                  9.0.0                h78e8752_1    conda-forge
     gtk2                      2.24.33              h280cfa0_4    conda-forge
     gts                       0.7.6                h977cf35_4    conda-forge
     gxx                       11.4.0               h602e360_6    conda-forge
     gxx_impl_linux-64         11.4.0               h7abf839_6    conda-forge
     gxx_linux-64              11.4.0               h2730b16_3    conda-forge
     harfbuzz                  8.4.0                h3d44ed6_0    conda-forge
     hdbscan                   0.8.30          py311h1f0f07a_0    conda-forge
     hypothesis                6.100.2            pyha770c72_0    conda-forge
     icu                       73.2                 h59595ed_0    conda-forge
     idna                      3.7                pyhd8ed1ab_0    conda-forge
     imagesize                 1.4.1              pyhd8ed1ab_0    conda-forge
     importlib-metadata        7.1.0              pyha770c72_0    conda-forge
     importlib-resources       6.4.0              pyhd8ed1ab_0    conda-forge
     importlib_metadata        7.1.0                hd8ed1ab_0    conda-forge
     importlib_resources       6.4.0              pyhd8ed1ab_0    conda-forge
     iniconfig                 2.0.0              pyhd8ed1ab_0    conda-forge
     ipykernel                 6.29.3             pyhd33586a_0    conda-forge
     ipython                   8.22.2             pyh707e725_0    conda-forge
     jedi                      0.19.1             pyhd8ed1ab_0    conda-forge
     jinja2                    3.1.3              pyhd8ed1ab_0    conda-forge
     joblib                    1.4.0              pyhd8ed1ab_0    conda-forge
     jsonschema                4.21.1             pyhd8ed1ab_0    conda-forge
     jsonschema-specifications 2023.12.1          pyhd8ed1ab_0    conda-forge
     jupyter_client            8.6.1              pyhd8ed1ab_0    conda-forge
     jupyter_core              5.7.2           py311h38be061_0    conda-forge
     jupyterlab_pygments       0.3.0              pyhd8ed1ab_1    conda-forge
     kernel-headers_linux-64   3.10.0              h4a8ded7_14    conda-forge
     keyutils                  1.6.1                h166bdaf_0    conda-forge
     kiwisolver                1.4.5           py311h9547e67_1    conda-forge
     krb5                      1.21.2               h659d440_0    conda-forge
     lcms2                     2.16                 hb7c19ff_0    conda-forge
     ld_impl_linux-64          2.40                 h55db66e_0    conda-forge
     lerc                      4.0.0                h27087fc_0    conda-forge
     libabseil                 20240116.2      cxx17_h59595ed_0    conda-forge
     libarrow                  14.0.2          hefa796f_19_cpu    conda-forge
     libarrow-acero            14.0.2          hbabe93e_19_cpu    conda-forge
     libarrow-dataset          14.0.2          hbabe93e_19_cpu    conda-forge
     libarrow-flight           14.0.2          hc4f8a93_19_cpu    conda-forge
     libarrow-flight-sql       14.0.2          he4f5ca8_19_cpu    conda-forge
     libarrow-gandiva          14.0.2          hc1954e9_19_cpu    conda-forge
     libarrow-substrait        14.0.2          he4f5ca8_19_cpu    conda-forge
     libblas                   3.9.0           22_linux64_openblas    conda-forge
     libbrotlicommon           1.1.0                hd590300_1    conda-forge
     libbrotlidec              1.1.0                hd590300_1    conda-forge
     libbrotlienc              1.1.0                hd590300_1    conda-forge
     libcblas                  3.9.0           22_linux64_openblas    conda-forge
     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge
     libcublas                 12.2.5.6             hd3aeb46_0    conda-forge
     libcublas-dev             12.2.5.6             hd3aeb46_0    conda-forge
     libcudf                   24.06.00a164    cuda12_240430_gab5e3f3bc8_164    rapidsai-nightly
     libcufft                  11.0.8.103           hd3aeb46_0    conda-forge
     libcufft-dev              11.0.8.103           hd3aeb46_0    conda-forge
     libcufile                 1.7.2.10             hd3aeb46_0    conda-forge
     libcufile-dev             1.7.2.10             hd3aeb46_0    conda-forge
     libcumlprims              24.06.00a       cuda12_240429_g98a3699_7    rapidsai-nightly
     libcurand                 10.3.3.141           hd3aeb46_0    conda-forge
     libcurand-dev             10.3.3.141           hd3aeb46_0    conda-forge
     libcurl                   8.7.1                hca28451_0    conda-forge
     libcusolver               11.5.2.141           hd3aeb46_0    conda-forge
     libcusolver-dev           11.5.2.141           hd3aeb46_0    conda-forge
     libcusparse               12.1.2.141           hd3aeb46_0    conda-forge
     libcusparse-dev           12.1.2.141           hd3aeb46_0    conda-forge
     libdeflate                1.20                 hd590300_0    conda-forge
     libedit                   3.1.20191231         he28a2e2_2    conda-forge
     libev                     4.33                 hd590300_2    conda-forge
     libevent                  2.1.12               hf998b51_1    conda-forge
     libexpat                  2.6.2                h59595ed_0    conda-forge
     libffi                    3.4.2                h7f98852_5    conda-forge
     libgcc-devel_linux-64     11.4.0             hc2b0fca_106    conda-forge
     libgcc-ng                 13.2.0               hc881cc4_6    conda-forge
     libgd                     2.3.3                h119a65a_9    conda-forge
     libgfortran-ng            13.2.0               h69a702a_6    conda-forge
     libgfortran5              13.2.0               h43f5ff8_6    conda-forge
     libglib                   2.80.0               hf2295e7_6    conda-forge
     libgomp                   13.2.0               hc881cc4_6    conda-forge
     libgoogle-cloud           2.23.0               h9be4e54_1    conda-forge
     libgoogle-cloud-storage   2.23.0               hc7a4891_1    conda-forge
     libgrpc                   1.62.2               h15f2491_0    conda-forge
     libhwloc                  2.10.0          default_h2fb2949_1000    conda-forge
     libiconv                  1.17                 hd590300_2    conda-forge
     libjpeg-turbo             3.0.0                hd590300_1    conda-forge
     libkvikio                 24.06.00a       cuda12_240430_g7b0231c_11    rapidsai-nightly
     liblapack                 3.9.0           22_linux64_openblas    conda-forge
     libllvm14                 14.0.6               hcd5def8_4    conda-forge
     libllvm15                 15.0.7               hb3ce162_4    conda-forge
     libnghttp2                1.58.0               h47da74e_1    conda-forge
     libnl                     3.9.0                hd590300_0    conda-forge
     libnsl                    2.0.1                hd590300_0    conda-forge
     libnvjitlink              12.2.140             hd3aeb46_0    conda-forge
     libopenblas               0.3.27          pthreads_h413a1c8_0    conda-forge
     libparquet                14.0.2          hacf5a1f_19_cpu    conda-forge
     libpng                    1.6.43               h2797004_0    conda-forge
     libprotobuf               4.25.3               h08a7969_0    conda-forge
     libraft                   24.06.00a42     cuda12_240429_gd4d92ce9_42    rapidsai-nightly
     libraft-headers           24.06.00a42     cuda12_240429_gd4d92ce9_42    rapidsai-nightly
     libraft-headers-only      24.06.00a42     cuda12_240429_gd4d92ce9_42    rapidsai-nightly
     libre2-11                 2023.09.01           h5a48ba9_2    conda-forge
     librmm                    24.06.00a14     cuda12_240430_g9e6db746_14    rapidsai-nightly
     librsvg                   2.58.0               hadf69e7_1    conda-forge
     libsanitizer              11.4.0               hc2b0fca_6    conda-forge
     libsodium                 1.0.18               h36c2ea0_1    conda-forge
     libsqlite                 3.45.3               h2797004_0    conda-forge
     libssh2                   1.11.0               h0841786_0    conda-forge
     libstdcxx-devel_linux-64  11.4.0             hc2b0fca_106    conda-forge
     libstdcxx-ng              13.2.0               h95c4c6d_6    conda-forge
     libthrift                 0.19.0               hb90f79a_1    conda-forge
     libtiff                   4.6.0                h1dd3fc0_3    conda-forge
     libutf8proc               2.8.0                h166bdaf_0    conda-forge
     libuuid                   2.38.1               h0b41bf4_0    conda-forge
     libuv                     1.48.0               hd590300_0    conda-forge
     libwebp                   1.3.2                h658648e_1    conda-forge
     libwebp-base              1.3.2                hd590300_1    conda-forge
     libxcb                    1.15                 h0b41bf4_0    conda-forge
     libxcrypt                 4.4.36               hd590300_1    conda-forge
     libxml2                   2.12.6               h232c23b_2    conda-forge
     libzlib                   1.2.13               hd590300_5    conda-forge
     llvmlite                  0.42.0          py311ha6695c7_1    conda-forge
     locket                    1.0.0              pyhd8ed1ab_0    conda-forge
     lz4                       4.3.3           py311h38e4bf4_0    conda-forge
     lz4-c                     1.9.4                hcb278e6_0    conda-forge
     makefun                   1.15.2             pyhd8ed1ab_0    conda-forge
     markdown                  3.6                pyhd8ed1ab_0    conda-forge
     markdown-it-py            3.0.0              pyhd8ed1ab_0    conda-forge
     markupsafe                2.1.5           py311h459d7ec_0    conda-forge
     matplotlib-base           3.8.4           py311h54ef318_0    conda-forge
     matplotlib-inline         0.1.7              pyhd8ed1ab_0    conda-forge
     mdurl                     0.1.2              pyhd8ed1ab_0    conda-forge
     mistune                   3.0.2              pyhd8ed1ab_0    conda-forge
     msgpack-python            1.0.7           py311h9547e67_0    conda-forge
     multipledispatch          0.6.0                      py_0    conda-forge
     munkres                   1.1.4              pyh9f0ad1d_0    conda-forge
     nbclient                  0.10.0             pyhd8ed1ab_0    conda-forge
     nbconvert                 7.16.3               hd8ed1ab_1    conda-forge
     nbconvert-core            7.16.3             pyhd8ed1ab_1    conda-forge
     nbconvert-pandoc          7.16.3               hd8ed1ab_1    conda-forge
     nbformat                  5.10.4             pyhd8ed1ab_0    conda-forge
     nbsphinx                  0.9.3              pyhd8ed1ab_0    conda-forge
     nccl                      2.21.5.1             h3a97aeb_0    conda-forge
     ncurses                   6.4.20240210         h59595ed_0    conda-forge
     nest-asyncio              1.6.0              pyhd8ed1ab_0    conda-forge
     ninja                     1.12.0               h00ab1b0_0    conda-forge
     nltk                      3.8.1              pyhd8ed1ab_0    conda-forge
     numba                     0.59.1          py311h96b013e_0    conda-forge
     numpy                     1.26.4          py311h64a7726_0    conda-forge
     numpydoc                  1.7.0              pyhd8ed1ab_0    conda-forge
     nvcomp                    3.0.6                h10b603f_0    conda-forge
     nvtx                      0.2.10          py311h459d7ec_0    conda-forge
     openjpeg                  2.5.2                h488ebb8_0    conda-forge
     openssl                   3.2.1                hd590300_1    conda-forge
     orc                       2.0.0                h17fec99_1    conda-forge
     packaging                 24.0               pyhd8ed1ab_0    conda-forge
     pandas                    2.2.2           py311h320fe9a_0    conda-forge
     pandoc                    3.1.13               ha770c72_0    conda-forge
     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge
     pango                     1.52.2               ha41ecd1_0    conda-forge
     parso                     0.8.4              pyhd8ed1ab_0    conda-forge
     partd                     1.4.1              pyhd8ed1ab_0    conda-forge
     pathspec                  0.12.1             pyhd8ed1ab_0    conda-forge
     patsy                     0.5.6              pyhd8ed1ab_0    conda-forge
     pcre2                     10.43                hcad00b1_0    conda-forge
     pexpect                   4.9.0              pyhd8ed1ab_0    conda-forge
     pickleshare               0.7.5                   py_1003    conda-forge
     pillow                    10.3.0          py311h18e6fac_0    conda-forge
     pip                       24.0               pyhd8ed1ab_0    conda-forge
     pixman                    0.43.2               h59595ed_0    conda-forge
     pkgutil-resolve-name      1.3.10             pyhd8ed1ab_1    conda-forge
     platformdirs              4.2.1              pyhd8ed1ab_0    conda-forge
     pluggy                    1.5.0              pyhd8ed1ab_0    conda-forge
     prompt-toolkit            3.0.42             pyha770c72_0    conda-forge
     psutil                    5.9.8           py311h459d7ec_0    conda-forge
     pthread-stubs             0.4               h36c2ea0_1001    conda-forge
     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge
     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge
     py-cpuinfo                9.0.0              pyhd8ed1ab_0    conda-forge
     pyarrow                   14.0.2          py311hd5e4297_19_cpu    conda-forge
     pydata-sphinx-theme       0.15.2             pyhd8ed1ab_0    conda-forge
     pygments                  2.17.2             pyhd8ed1ab_0    conda-forge
     pylibraft                 24.06.00a42     cuda12_py311_240429_gd4d92ce9_42    rapidsai-nightly
     pynndescent               0.5.8              pyh1a96a4e_0    conda-forge
     pynvjitlink               0.2.2           py311hdaa3023_0    rapidsai
     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge
     pyparsing                 3.1.2              pyhd8ed1ab_0    conda-forge
     pysocks                   1.7.1              pyha2e5f31_6    conda-forge
     pytest                    7.4.4              pyhd8ed1ab_0    conda-forge
     pytest-benchmark          4.0.0              pyhd8ed1ab_0    conda-forge
     pytest-cases              3.8.5              pyhd8ed1ab_0    conda-forge
     pytest-cov                5.0.0              pyhd8ed1ab_0    conda-forge
     pytest-xdist              3.5.0              pyhd8ed1ab_0    conda-forge
     python                    3.11.9          hb806964_0_cpython    conda-forge
     python-dateutil           2.9.0              pyhd8ed1ab_0    conda-forge
     python-fastjsonschema     2.19.1             pyhd8ed1ab_0    conda-forge
     python-tzdata             2024.1             pyhd8ed1ab_0    conda-forge
     python_abi                3.11                    4_cp311    conda-forge
     pytz                      2024.1             pyhd8ed1ab_0    conda-forge
     pyyaml                    6.0.1           py311h459d7ec_1    conda-forge
     pyzmq                     26.0.2          py311h08a0b41_0    conda-forge
     raft-dask                 24.06.00a42     cuda12_py311_240429_gd4d92ce9_42    rapidsai-nightly
     rapids-dask-dependency    24.06.00a20                py_0    rapidsai-nightly
     rdma-core                 51.0                 hd3aeb46_0    conda-forge
     re2                       2023.09.01           h7f4b329_2    conda-forge
     readline                  8.2                  h8228510_1    conda-forge
     recommonmark              0.7.1              pyhd8ed1ab_0    conda-forge
     referencing               0.35.0             pyhd8ed1ab_0    conda-forge
     regex                     2024.4.28       py311h331c9d8_0    conda-forge
     requests                  2.31.0             pyhd8ed1ab_0    conda-forge
     rhash                     1.4.4                hd590300_0    conda-forge
     rich                      13.7.1             pyhd8ed1ab_0    conda-forge
     rmm                       24.06.00a14     cuda12_py311_240430_g9e6db746_14    rapidsai-nightly
     rpds-py                   0.18.0          py311h46250e7_0    conda-forge
     s2n                       1.4.12               h06160fa_0    conda-forge
     scikit-build-core         0.9.2              pyh4af843d_0    conda-forge
     scikit-learn              1.2.0           py311h67c5ca5_0    conda-forge
     scipy                     1.13.0          py311h64a7726_0    conda-forge
     seaborn                   0.13.2               hd8ed1ab_0    conda-forge
     seaborn-base              0.13.2             pyhd8ed1ab_0    conda-forge
     setuptools                69.5.1             pyhd8ed1ab_0    conda-forge
     six                       1.16.0             pyh6c4a22f_0    conda-forge
     snappy                    1.2.0                hdb0a2a9_1    conda-forge
     snowballstemmer           2.2.0              pyhd8ed1ab_0    conda-forge
     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge
     soupsieve                 2.5                pyhd8ed1ab_1    conda-forge
     sparse                    0.15.1             pyhd8ed1ab_1    conda-forge
     spdlog                    1.12.0               hd2e6256_2    conda-forge
     sphinx                    5.3.0              pyhd8ed1ab_0    conda-forge
     sphinx-copybutton         0.5.2              pyhd8ed1ab_0    conda-forge
     sphinx-markdown-tables    0.0.17             pyh6c4a22f_0    conda-forge
     sphinxcontrib-applehelp   1.0.8              pyhd8ed1ab_0    conda-forge
     sphinxcontrib-devhelp     1.0.6              pyhd8ed1ab_0    conda-forge
     sphinxcontrib-htmlhelp    2.0.5              pyhd8ed1ab_0    conda-forge
     sphinxcontrib-jsmath      1.0.1              pyhd8ed1ab_0    conda-forge
     sphinxcontrib-qthelp      1.0.7              pyhd8ed1ab_0    conda-forge
     sphinxcontrib-serializinghtml 1.1.10             pyhd8ed1ab_0    conda-forge
     stack_data                0.6.2              pyhd8ed1ab_0    conda-forge
     statsmodels               0.14.1          py311h1f0f07a_0    conda-forge
     sysroot_linux-64          2.17                h4a8ded7_14    conda-forge
     tabulate                  0.9.0              pyhd8ed1ab_1    conda-forge
     tbb                       2021.12.0            h00ab1b0_0    conda-forge
     tblib                     3.0.0              pyhd8ed1ab_0    conda-forge
     threadpoolctl             3.5.0              pyhc1e730c_0    conda-forge
     tinycss2                  1.3.0              pyhd8ed1ab_0    conda-forge
     tk                        8.6.13          noxft_h4845f30_101    conda-forge
     toml                      0.10.2             pyhd8ed1ab_0    conda-forge
     tomli                     2.0.1              pyhd8ed1ab_0    conda-forge
     toolz                     0.12.1             pyhd8ed1ab_0    conda-forge
     tornado                   6.4             py311h459d7ec_0    conda-forge
     tqdm                      4.66.2             pyhd8ed1ab_0    conda-forge
     traitlets                 5.14.3             pyhd8ed1ab_0    conda-forge
     treelite                  4.1.2           py311he8f9275_1    conda-forge
     typing-extensions         4.11.0               hd8ed1ab_0    conda-forge
     typing_extensions         4.11.0             pyha770c72_0    conda-forge
     tzdata                    2024a                h0c530f3_0    conda-forge
     ucx                       1.15.0               hda83522_8    conda-forge
     ucx-proc                  1.0.0                       gpu    rapidsai
     ucx-py                    0.38.00a4       py311_240430_g03c864b_4    rapidsai-nightly
     umap-learn                0.5.3           py311h38be061_1    conda-forge
     urllib3                   2.2.1              pyhd8ed1ab_0    conda-forge
     wcwidth                   0.2.13             pyhd8ed1ab_0    conda-forge
     webencodings              0.5.1              pyhd8ed1ab_2    conda-forge
     wheel                     0.43.0             pyhd8ed1ab_1    conda-forge
     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge
     xorg-libice               1.1.1                hd590300_0    conda-forge
     xorg-libsm                1.2.4                h7391055_0    conda-forge
     xorg-libx11               1.8.9                h8ee46fc_0    conda-forge
     xorg-libxau               1.0.11               hd590300_0    conda-forge
     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge
     xorg-libxext              1.3.4                h0b41bf4_2    conda-forge
     xorg-libxrender           0.9.11               hd590300_0    conda-forge
     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge
     xorg-xextproto            7.3.0             h0b41bf4_1003    conda-forge
     xorg-xproto               7.0.31            h7f98852_1007    conda-forge
     xyzservices               2024.4.0           pyhd8ed1ab_0    conda-forge
     xz                        5.2.6                h166bdaf_0    conda-forge
     yaml                      0.2.5                h7f98852_2    conda-forge
     zeromq                    4.3.5                h59595ed_1    conda-forge
     zict                      3.0.0              pyhd8ed1ab_0    conda-forge
     zipp                      3.17.0             pyhd8ed1ab_0    conda-forge
     zlib                      1.2.13               hd590300_5    conda-forge
     zstd                      1.5.5                hfc55251_0    conda-forge

</pre></details>

",2024-05-02T08:45:18Z,0,0,Tim Head,Nvidia 
370,[FEA] Concatenate dictionary of objects along axis=0,"Following up from https://github.com/rapidsai/cudf/issues/15115 and the implementation for `axis=1`.

We need to implement concatenation of dictionary objects along `axis=0`.

See important context from @shwina here https://github.com/rapidsai/cudf/issues/15115#issuecomment-1961179887",2024-05-04T00:56:15Z,0,0,,
371,[BUG] Concat `Index` behavior diverts from `pandas`,"As @wence- points out here https://github.com/rapidsai/cudf/pull/15623#discussion_r1586054947

We allow concatenating indexes whilst `pandas` does not.

Do we like this difference in behavior? Do we want parity? Would users be upset if we changed this behavior?",2024-05-04T04:31:14Z,0,0,,
372,[BUG] `test_concat` file instantiates GPU objects in the parametrize arguments,"As @bdice points out here: https://github.com/rapidsai/cudf/pull/15623#discussion_r1589362754

GPU object instantiation within the parametrize arguments results in the test suite being slower to launch. We should refactor tests as such: https://github.com/rapidsai/cudf/pull/15623/commits/b5b91166a7cb8e865e4c989e0a67f930fe643d63

Ideally, this refactor would occur across all test files with this associated issue.",2024-05-04T04:52:35Z,0,0,,
373,[QST] Recusively Generating AST Expressions (C++ libcudf),"I would like to implement a function that can generate AST expressions, for example, by recursively converting a different expression class, such as an Apache Arrow `arrow::compute::expression` [object](https://github.com/apache/arrow/blob/main/cpp/src/arrow/compute/expression.h), to a `cudf::ast::expression` [object](https://github.com/rapidsai/cudf/blob/branch-24.06/cpp/include/cudf/ast/expressions.hpp). 

Is this even possible? libcudf's AST expression classes only accept references that are owned by the caller function; this is a problem since we can not recurse anymore. Is there any way to do this, to implement functions that can generate AST expressions instead of hardcoding expressions in a caller?

",2024-05-04T16:10:19Z,0,0,Shriram Chandran,ETH Zürich
374,[FEA] Explicitly guarantee row group ordering in the parquet reader.,"From @devavret , the question came up as to whether we guarantee the relative ordering of row groups across multiple input files in the parquet reader.  That is, if you have two files `[f1, f2]` and the row groups within the files (in one column) are specified as `[[r0,r3], [r0,r1]]`, do we guarantee the output ordering would be  `[f1r0, f1r3, f2r0, f2r1]`

The code does in fact do this for both the explicitly specified case and the unspecified (empty user input / all row groups), but we don't make any guarantees about it.   Seems like a safe and easy thing to add.

https://github.com/rapidsai/cudf/blob/5d244dfc13f4db0b1e41ded3029942fec50c98f6/cpp/src/io/parquet/reader_impl_helpers.cpp#L663

",2024-05-07T21:27:02Z,0,0,,
375,[QST] aggregate function that operates on vector(array of numeric) data,"**What is your question?**
I am wondering if `cudf` has native or built-in support for aggregate function that run against vector data. Namley, text/image embeddings are stored in the column of csv/parquet file. And I'd like to run various aggregate functions such as `mean`, `max` and so on. All these operations are element-wise, namely, it returns the mean of all the values in same index and return an array with same lenght. What's more, I'd like to run K-Nearest-Neighbor search as well.

If not natively supported, how to achieve these operations with performance efficient?

example code:
```
import cudf
import numpy as np
import pandas as pd

# Sample DataFrame with Pandas to cuDF conversion
data = {
    'category': ['A', 'A', 'B', 'B'],
    'values': [np.array([1, 2, 3]), np.array([4, 5, 6]), np.array([7, 8, 9]), np.array([10, 11, 12])]
}
pdf = pd.DataFrame(data)
df = cudf.DataFrame.from_pandas(pdf)

result = df.groupby('category').agg({'values': ['sum', 'mean']})

print(result)

# Expected output
'''
category
A     [2.5, 3.5, 4.5]
B    [8.5, 9.5, 10.5]
Name: values, dtype: object
'''
```",2024-05-14T03:35:37Z,0,0,Rhett Ying,@aws
376,"[BUG] Data corruption and strange CUDA memory address errors at the same row index, despite manipulating data, when using `.stack()` on large, wide dataset","**Describe the bug**
Whenever I'm trying to use cudf,stack() on this large wide dataframe, at around the same index location, the data gets corrupted as you stack past that index until it fails to run, or just fails to run.  It happens at index 1159550.   go one index before 1159550, everything is fine. One or two after, you start to see issues or it fails.  Even if you change around the data a bit, it still fails. eventually.  When it fails, it returns `RuntimeError: parallel_for: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered`. 

Happens on both an A100 80GB and H100 running 24.04.  Completes successfully on pandas. Falls back to pandas and successfully completes on cudf.pandas.

**Steps/Code to reproduce bug**
This requires a dataset download, handled in the min repro, and a 32GB GPU or larger to test.

You can actually see the data getting corrupted at the incrementing runs at the end of the min repro, before it finally fails

```
!if [ ! -f ""job_skills.csv"" ]; then curl https://storage.googleapis.com/rapidsai/colab-data/job_skills.csv.gz -o job_skills.csv.gz; gunzip job_skills.csv.gz; else echo ""unzipped job data found""; fi
import cudf
skills = cudf.read_csv(""job_skills.csv"")

b = skills[""job_skills""].str.split("","", expand=True)
#print(b.iloc[1159550]) # incase you wanted to see what was on that index
print(b.iloc[1159550])
b2 = b[:1159549]
# b2 = b[:1159550] # Uncommenting this, it will fail
stacked_skills = b2.stack()
print(stacked_skills.head())

# this will also fail
# stacked_skills = b.stack().dropna()

# even if you change the dataframe a bit by moving up the indexes incrementally, it will not really change where it fails, as you can start to see the data start glitch
print(skills.count())
skills = skills.dropna()
print(skills.count())
b = skills[""job_skills""].str.split("","", expand=True)
print(b.iloc[1159550]) # in case you wanted to see what was on that index
b2 = b[:1159549]
stacked_skills = b2.stack()
print(1159549)
print(stacked_skills.head())
b2 = b[:1159550]
stacked_skills = b2.stack()
print(1159550)
print(stacked_skills.head()) # you can start to see data corruption or it just fails
b2 = b[:1159551]
stacked_skills = b2.stack()
print(1159551)
print(stacked_skills.head())
b2 = b[:1159552]
stacked_skills = b2.stack()
print(1159552)
print(stacked_skills.head())
b2 = b[:1159553]
stacked_skills = b2.stack()
print(1159553)
print(stacked_skills.head())
b2 = b[:1159554]
stacked_skills = b2.stack()
print(1159554)
print(stacked_skills.head()) # by here it should fail
```
Outputs:
```
0                         Anesthesiology
1                        Medical license
2                      BLS certification
3                       DEA registration
4       Controlled Substance Certificate
                     ...                
458                                 <NA>
459                                 <NA>
460                                 <NA>
461                                 <NA>
462                                 <NA>
Name: 1159550, Length: 463, dtype: object
0  0    Building Custodial Services
   1                       Cleaning
   2            Janitorial Services
   3             Materials Handling
   4                   Housekeeping
dtype: object
job_link      1296381
job_skills    1294346
dtype: int64
job_link      1294346
job_skills    1294346
dtype: int64
0      Project Management
1           Communication
2           Collaboration
3              Leadership
4          ProblemSolving
              ...        
458                  <NA>
459                  <NA>
460                  <NA>
461                  <NA>
462                  <NA>
Name: 1161237, Length: 463, dtype: object
1159549
0  0    Building Custodial Services
   1                       Cleaning
   2            Janitorial Services
   3             Materials Handling
   4                   Housekeeping
dtype: object
1159550
0  0     PCUeel Nurseendek Services
   1                       Cleaning
   2            Janitorial Services
   3             Materials Handling
   4                   Housekeeping
dtype: object
1159551
0  0     PCUeel Nursenndek Services
   1                       Cleaning
   2            Janitorial Services
   3             Materials Handling
   4                   Housekeeping
dtype: object
1159552
0  0     FoUd Safetyeg certificatio
   1                      nCleaning
   2            Janitorial Services
   3             Materials Handling
   4                   Housekeeping
dtype: object
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
Cell In[1], line 40
     38 print(stacked_skills.head())
     39 b2 = b[:1159553]
---> 40 stacked_skills = b2.stack()
     41 print(1159553)
     42 print(stacked_skills.head())

File /opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)
    113 @wraps(func)
    114 def inner(*args, **kwargs):
    115     libnvtx_push_range(self.attributes, self.domain.handle)
--> 116     result = func(*args, **kwargs)
    117     libnvtx_pop_range(self.domain.handle)
    118     return result

File /opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py:7079, in DataFrame.stack(self, level, dropna, future_stack)
   7073     # homogenize the dtypes of the columns
   7074     homogenized = [
   7075         col.astype(common_type) if col is not None else all_nulls()
   7076         for col in columns
   7077     ]
-> 7079     stacked.append(libcudf.reshape.interleave_columns(homogenized))
   7081 # Construct the resulting dataframe / series
   7082 if not has_unnamed_levels:

File /opt/conda/lib/python3.10/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)
     76 @wraps(func)
     77 def inner(*args, **kwds):
     78     with self._recreate_cm():
---> 79         return func(*args, **kwds)

File reshape.pyx:26, in cudf._lib.reshape.interleave_columns()

RuntimeError: parallel_for: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered
```

**Expected behavior**
This should just work, as it does in pandas, without ay data corruption
```
!if [ ! -f ""job_skills.csv"" ]; then curl https://storage.googleapis.com/rapidsai/colab-data/job_skills.csv.gz -o job_skills.csv.gz; gunzip job_skills.csv.gz; else echo ""unzipped job data found""; fi
import pandas as pd
skills = pd.read_csv(""job_skills.csv"")

b = skills[""job_skills""].str.split("","", expand=True)
print(b.iloc[1159550])
b2 = b # just to keep the copying similar.  it doesn't matter.
stacked_skills = b2.stack()
print(stacked_skills.head())
```
Outputs:
```
0                         Anesthesiology
1                        Medical license
2                      BLS certification
3                       DEA registration
4       Controlled Substance Certificate
                     ...                
458                                 None
459                                 None
460                                 None
461                                 None
462                                 None
Name: 1159550, Length: 463, dtype: object
0  0    Building Custodial Services
   1                       Cleaning
   2            Janitorial Services
   3             Materials Handling
   4                   Housekeeping
dtype: object
```

**Environment overview (please complete the following information)**
 - Environment location: Docker
 - Method of cuDF install: Docker
   - If method of install is [Docker], docker run --user root --gpus all --rm -it --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 9888:8888 -p 9787:8787 -p 9786:8786 -p 9999:9999 rapidsai/notebooks:24.04-cuda11.8-py3.10 jupyter-lab --notebook-dir=/home/rapids/notebooks --ip=0.0.0.0 --no-browser --NotebookApp.token='' --NotebookApp.allow_origin='*' --allow-root


**Environment details**
RAPIDS 24.04 cuda 11.8, py 3.9 and 3.10 Docker on ARM SBSA machines

**Additional context**
When running cudf.pandas, this will succeed, but at the costs of taking nearly 30-40% longer than pandas alone.  If and when it succeeds (by reducing it to the last row where it succeeds, it would be 50x+ faster.  I have not done a data integrity test just yet, to see if the corruption happens earlier.
@vyasr fyi.",2024-05-15T10:22:32Z,1,0,Taurean Dyer,
377,[FEA] Potential optimization:  Batched memset.,Under some situations in the Parquet reader (particularly the case with tables containing many columns or deeply nested column) we burn a decent amount of time doing `cudaMemset()` operations on output buffers. A good amount of this overhead seems to stem from the fact that we're simply launching many tiny kernels.  It might be useful to have a batched/multi memset kernel that takes a list of address/sizes/values as a single input and does all the work under a single kernel launch.  Similar to the Cub multi-buffer memcpy or `contiguous_split`.,2024-05-17T15:43:03Z,0,0,,
378,[ENH] Use `strict=True` argument to `zip` once py39 support is dropped,"In many places in the cudf code we zip two (or more) iterables together with the assumption/precondition that they are all of equal length. The pattern is (approximately):

```python
names: list[str]
columns: list[Column]
data: dict[str, Column] = dict(zip(names, columns))
```

This has, by design of zip, a potential problem lurking in that if the two inputs are _not_ of equal length, we only keep the first `min(len(names), len(columns))` objects.

To avoid check this at user-input boundaries we need to be careful to check (and then raise if not) that the inputs we are zipping _do_ have equal length. This is easy to forget.

[Python 3.10](https://docs.python.org/3/library/functions.html#zip) introduces a new keyword-argument to `zip`, `strict`, which can be used to assert that the inputs have the same length. We should consider using this across the code-base when no longer supporting Python 3.9.
",2024-05-23T09:59:08Z,0,0,Lawrence Mitchell,
379,[FEA] Better control over the output dtype in aggregations,"**Is your feature request related to a problem? Please describe.**

For the cudf-polars work, I'd like to match dtypes with polars where possible, preferably without casting the result of a libcudf call post-hoc if the interface in theory supports specifying an output type.

For whole-frame aggregations (`cudf::reduce`) although one is able to specify an output_dtype, this is not obeyed for a number of aggregations. Specifically:

- `MEDIAN` (always returns the datatype matching `double`)
- `NUNIQUE` (always returns the datatype matching `cudf::size_type`)
- `QUANTILE` (always returns the datatype matching `double`)


The same is true of many grouped aggregations.

**Describe the solution you'd like**

I'd like that aggregations could support output dtype as specified by the user.

**Describe alternatives you've considered**

post-hoc unary casting of the result, but this is yet another kernel launch, and produces more memory overhead.",2024-05-24T13:37:43Z,0,0,Lawrence Mitchell,
380,"For the overload of replace in libcudf where input/target/repl are columns, there isn't a maxrepl arg.","For the overload of replace in libcudf where input/target/repl are columns, there isn't a maxrepl arg.

We should probably support this in libcudf replace (eventually), otherwise we'll have some weirdness in pylibcudf where we'll have to raise for maxrepl despite accepting it as an argument.

_Originally posted by @lithomas1 in https://github.com/rapidsai/cudf/pull/15839#discussion_r1611981114_
            ",2024-05-24T16:46:09Z,0,0,Thomas Li,@pandas-dev
