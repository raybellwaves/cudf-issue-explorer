{"assignees":[],"author":{"id":"MDQ6VXNlcjIyNDg0NzY5","is_bot":false,"login":"FilippoSimini","name":"Filippo Simini"},"body":"Printing a `CategoricalIndex` with more than 200 elements results in the following error:\r\n\r\n```\r\nTypeError: Cannot interpret 'interval[float64, right]' as a data type\r\n```\r\n\r\nReproducer\r\n\r\n```\r\nimport cudf\r\nimport cupy\r\n\r\np = cudf.cut(cupy.arange(201), 3)\r\n\r\n# this works\r\nprint(p[:200])\r\n\r\n# this doesn't\r\nprint(p)\r\n```\r\n\r\nwith cudf version 23.04.01 and cupy version 11.6.0","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5bdqLt","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"This looks to be a bug in `cudf.core.column.concat_columns`, which does not preserve the correct dtype-data when concatenating `Interval` columns.\r\n\r\nA simpler reproducer:\r\n```python\r\nimport cudf\r\n\r\np = cudf.cut([1, 2, 3], 3)\r\np2 = cudf.concat([p, p])\r\n```\r\n\r\nWhat's going on? When categorical indices/columns are concatenated, we need to deduce the unique categories of the concatenated result. This is done like so:\r\n```\r\nunique_categories = cudf.core.column.concat_columns([p.categories, p.categories]).unique(preserve_order=True)\r\n```\r\nThese unique categories then have to be merged back with the result columns, which goes through the merge machinery. So far, all fine, _but_ `concat_columns` returns a new column of unique categories that has a different dtype than the inputs for `Interval` dtypes:\r\n\r\n```python\r\nimport pandas as pd\r\nimport cudf\r\nfrom cudf.core.column import concat_columns\r\n\r\ns = cudf.Series([pd.Interval(0.5, 1)]) # an interval series\r\n\r\nprint(s._column.dtype) # => interval[float64, right]\r\ny = concat_columns([s._column])\r\nprint(y.dtype) # => StructDtype({'0': dtype('float64'), '1': dtype('float64')})\r\n```\r\nSo some information has been lost, and when cudf then comes to merge the dtypes of the two columns it fails.\r\n\r\nAside: the reason you see this error when printing with 201 rows but not 200 is that if your dataframe is longer than a certain limit (by default 200 rows) we don't print the whole thing, but rather take a few rows from the start and the end and concatenate them together to show that. It is at the concatenation step that the bug occurs.\r\n\r\n","createdAt":"2023-05-04T10:26:44Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/13281#issuecomment-1534501613","viewerDidAuthor":false}],"createdAt":"2023-05-03T20:41:26Z","id":"I_kwDOBWUGps5lBFkt","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NTk=","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"MDU6TGFiZWwxMTM5NzQxMjEz","name":"cuDF (Python)","description":"Affects Python cuDF API.","color":"1d76db"}],"milestone":null,"number":13281,"projectCards":[],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[BUG] Error when printing large CategoricalIndex","updatedAt":"2023-05-04T10:26:45Z","url":"https://github.com/rapidsai/cudf/issues/13281"}
