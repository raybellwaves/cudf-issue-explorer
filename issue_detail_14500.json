{"assignees":[],"author":{"id":"MDQ6VXNlcjEyOTkwNjk1","is_bot":false,"login":"kolfild26","name":"Andrey Komrakov"},"body":"Hi,\r\nI'm trying to move from a basic pandas to cudf.pandas and I faced with the issue. It's not clear how cudf decides to use **CPU** or **GPU** in calculations.\r\nHere is the example when I have a dataframe with around 280kk rows and 9 columns.\r\nThe steps:\r\n1) I perform `.groupby.sum() `for the original df. I takes too much time and the profiler show that all calculations were on **CPU** not GPU.\r\n2) I cut df like `[:100000000]` so that there are 100kk rows left.\r\n3)  I perform `.groupby.sum() `for the modified df and... it takes 0.1 sec and the profiler says **GPU** was using for that.\r\n\r\nSo, here is some question.\r\n- what's the reason that 100kk df is being calculated on GPU and 280kk df on CPU? Hard to belive that the size is the reason.\r\n- If not the size then what's the criteria for that?\r\n\r\nThanks in advance.\r\np.s. I also tried `.sort_values()` and there were the same.\r\n\r\n```\r\nCOM_ORDER_LINE.shape\r\n(284125143, 9)\r\n```\r\n```\r\nCOM_ORDER_LINE.head()\r\n\r\nCODE | ORDER_CODE | VERSION_CODE | ID_WARE | QTY_ORDERED | CATALOG_PRICE | PRICE | TO_PAY | DISCOUNT_TOTAL\r\n10000006215177 | 10000006215175 | 10000006215176 | 1.787585e+11 | 1 | 3799.0 | 2659.0 | 2659.0 | 1140.0\r\n10000006215189 | 10000006215187 | 10000006215188 | 1.736505e+11 | 1 | 9999.0 | 6999.0 | 6999.0 | 3000.0\r\n10000006215364 | 10000006215362 | 10000006215363 | 1.736709e+11 | 1 | 1399.0 | 980.0 | 980.0 | 419.0\r\n```\r\n```\r\n%%cudf.pandas.profile\r\ndf=COM_ORDER_LINE.groupby(['ID_WARE'])['PRICE'].sum()\r\n```\r\n\r\n\r\n```\r\nTotal time elapsed: 31.764 seconds                                    \r\n                                          0 GPU function calls in 0.000 seconds                                   \r\n                                          3 CPU function calls in 23.186 seconds                                  \r\n                                                                                                                  \r\n                                                          Stats                                                   \r\n                                                                                                                  \r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\r\nâ”ƒ Function                     â”ƒ GPU ncalls â”ƒ GPU cumtime â”ƒ GPU percall â”ƒ CPU ncalls â”ƒ CPU cumtime â”ƒ CPU percall â”ƒ\r\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\r\nâ”‚ DataFrame.groupby            â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 2.929       â”‚ 2.929       â”‚\r\nâ”‚ DataFrameGroupBy.__getitem__ â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 2.915       â”‚ 2.915       â”‚\r\nâ”‚ SeriesGroupBy.sum            â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 17.341      â”‚ 17.341      â”‚\r\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\r\n\r\nNot all pandas operations ran on the GPU. The following functions required CPU fallback:\r\n\r\n- DataFrame.groupby\r\n- DataFrameGroupBy.__getitem__\r\n- SeriesGroupBy.sum\r\n```\r\n\r\n```\r\nCOM_ORDER_LINE_100KK = COM_ORDER_LINE[:100000000]\r\nCOM_ORDER_LINE_100KK.shape\r\n(100000000, 9)\r\n```\r\n\r\n```\r\n%%cudf.pandas.profile\r\ndf=COM_ORDER_LINE_100KK.groupby(['ID_WARE'])['PRICE'].sum()\r\n```\r\n\r\n```\r\nTotal time elapsed: 0.109 seconds                                     \r\n                                          3 GPU function calls in 0.082 seconds                                   \r\n                                          0 CPU function calls in 0.000 seconds                                   \r\n                                                                                                                  \r\n                                                          Stats                                                   \r\n                                                                                                                  \r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\r\nâ”ƒ Function                     â”ƒ GPU ncalls â”ƒ GPU cumtime â”ƒ GPU percall â”ƒ CPU ncalls â”ƒ CPU cumtime â”ƒ CPU percall â”ƒ\r\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\r\nâ”‚ DataFrame.groupby            â”‚ 1          â”‚ 0.000       â”‚ 0.000       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\r\nâ”‚ DataFrameGroupBy.__getitem__ â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\r\nâ”‚ SeriesGroupBy.sum            â”‚ 1          â”‚ 0.081       â”‚ 0.081       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\r\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\r\n```\r\n\r\n","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5s-t1e","author":{"login":"bdice"},"authorAssociation":"CONTRIBUTOR","body":"I suspect this is hitting an out-of-memory error on the GPU and falling back to the CPU. What GPU are you using?\r\n\r\nIf your columns are int64/float64 types, (284 million rows * 9 columns * 8 bytes per element) gives about 20 GB of memory consumption for the data alone, before the intermediate storage needed for the groupby computation and results.","createdAt":"2023-11-27T18:20:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1828379998","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5s_7rn","author":{"login":"kolfild26"},"authorAssociation":"NONE","body":"```\r\nCODE                int64\r\nORDER_CODE          int64\r\nVERSION_CODE        int64\r\nID_WARE           float64\r\nQTY_ORDERED         int64\r\nCATALOG_PRICE     float64\r\nPRICE             float64\r\nTO_PAY            float64\r\nDISCOUNT_TOTAL    float64\r\n```\r\nI played with the size, at some point it starts falling `DataFrame.groupby` back  the CPU and then `SeriesGroupBy.sum` too.\r\nBut the point it starts falling is around 110.000.000 that corresponds to ~7.4Gb.\r\nMy GPU is **Tesla V100-PCIE-32GB**\r\n\r\n                                                                                                                  \r\n```                                                                                                    \r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\r\nâ”ƒ Function                     â”ƒ GPU ncalls â”ƒ GPU cumtime â”ƒ GPU percall â”ƒ CPU ncalls â”ƒ CPU cumtime â”ƒ CPU percall â”ƒ\r\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\r\nâ”‚ DataFrame.groupby            â”‚ 1          â”‚ 0.000       â”‚ 0.000       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\r\nâ”‚ DataFrameGroupBy.__getitem__ â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\r\nâ”‚ SeriesGroupBy.sum            â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 20.493      â”‚ 20.493      â”‚\r\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\r\n```\r\n```\r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\r\nâ”ƒ Function                     â”ƒ GPU ncalls â”ƒ GPU cumtime â”ƒ GPU percall â”ƒ CPU ncalls â”ƒ CPU cumtime â”ƒ CPU percall â”ƒ\r\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\r\nâ”‚ DataFrame.groupby            â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 0.681       â”‚ 0.681       â”‚\r\nâ”‚ DataFrameGroupBy.__getitem__ â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 0.677       â”‚ 0.677       â”‚\r\nâ”‚ SeriesGroupBy.sum            â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 7.586       â”‚ 7.586       â”‚\r\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\r\n```\r\n","createdAt":"2023-11-27T22:05:59Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1828698855","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5s__fc","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"Thanks for exploring!\r\n\r\nJust curious, does it help to filter out just the `ID` and `PRICE` columns _before_ the groupby? If so, we might be missing out on some optimizations internally and that would be a bug:\r\n\r\n```python\r\ndf = df[[\"ID\", \"TOTAL\"]]\r\nresult = df.groupby(\"ID\").sum()\r\n```\r\n\r\nAt the same time, you can try turning cuDF's spilling on to spill unused data:\r\n\r\n```\r\nCUDF_SPILL=1 python -m cudf.pandas ...\r\n```\r\n","createdAt":"2023-11-27T22:17:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1828714460","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5tHxsz","author":{"login":"kolfild26"},"authorAssociation":"NONE","body":"@shwina\r\nThanks fro your updates. My answers are below.\r\n\r\n1ï¸âƒ£ \r\n> Just curious, does it help to filter out just the ID and PRICE columns before the groupby? If so, we might be missing out on some optimizations internally and that would be a bug:\r\n> \r\n> > df = df[[\"ID\", \"TOTAL\"]]\r\n> > result = df.groupby(\"ID\").sum()\r\n\r\nYes, that's what I see now. Filtering out two columns before the groupby fixes all. The groupby is again on the GPU.\r\n\r\n```\r\n%%cudf.pandas.profile\r\ndf=COM_ORDER_LINE.groupby(['ID_WARE'])['PRICE'].sum()\r\n                                                                                                                  \r\n                                            Total time elapsed: 27.720 seconds                                    \r\n                                          0 GPU function calls in 0.000 seconds                                   \r\n                                          3 CPU function calls in 20.844 seconds                                  \r\n                                                                                                                                                                                                                                        \r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\r\nâ”ƒ Function                     â”ƒ GPU ncalls â”ƒ GPU cumtime â”ƒ GPU percall â”ƒ CPU ncalls â”ƒ CPU cumtime â”ƒ CPU percall â”ƒ\r\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\r\nâ”‚ DataFrame.groupby            â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 2.359       â”‚ 2.359       â”‚\r\nâ”‚ DataFrameGroupBy.__getitem__ â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 2.334       â”‚ 2.334       â”‚\r\nâ”‚ SeriesGroupBy.sum            â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚ 1          â”‚ 16.152      â”‚ 16.152      â”‚\r\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\r\n```\r\n```\r\nCOM_ORDER_LINE_tmp=COM_ORDER_LINE[['ID_WARE', 'PRICE']]\r\n```\r\n```\r\n%%cudf.pandas.profile\r\ndf=COM_ORDER_LINE_tmp.groupby(['ID_WARE'])['PRICE'].sum()\r\n                                            Total time elapsed: 0.358 seconds                                     \r\n                                          3 GPU function calls in 0.329 seconds                                   \r\n                                          0 CPU function calls in 0.000 seconds                                   \r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\r\nâ”ƒ Function                     â”ƒ GPU ncalls â”ƒ GPU cumtime â”ƒ GPU percall â”ƒ CPU ncalls â”ƒ CPU cumtime â”ƒ CPU percall â”ƒ\r\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\r\nâ”‚ DataFrame.groupby            â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\r\nâ”‚ DataFrameGroupBy.__getitem__ â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\r\nâ”‚ SeriesGroupBy.sum            â”‚ 1          â”‚ 0.327       â”‚ 0.327       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\r\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\r\n```\r\n\r\n2ï¸âƒ£ \r\n```\r\nAt the same time, you can try turning cuDF's spilling on to spill unused data:\r\n```\r\n\r\nI also noticed that when I restart the machine, the first try after the restart is successfully being calculated on the GPU. Only once. Next run is falling back to the CPU again.\r\nSo, it looks like that the gpu memory really needs to be cleaned from unused data.\r\n\r\n```\r\nCUDF_SPILL=1 python -m cudf.pandas ...\r\n```\r\nIs there any way to switch on this option in the jupyter notebook? ","createdAt":"2023-11-28T21:11:59Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1830755123","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5tH7jU","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"> Filtering out two columns before the groupby fixes all.\r\n\r\nThanks! We'll investigate whether we can optimize things so that you don't have to do this filter, and report back here.\r\n\r\n> I also noticed that when I restart the machine, the first try after the restart is successfully being calculated on the GPU. Only once. Next run is falling back to the CPU again.\r\n\r\nAh, interesting. There are a few possibilities then:\r\n\r\n- We have a memory leak (this would be bad)\r\n- Some Python objects are caught in reference cycles and haven't been cleared. You can try running `gc.collect()` to release the memory associated with those objects and see if that helps with memory usage.\r\n\r\nCan you try the following:\r\n\r\n```Python\r\nimport gc\r\n\r\n# run groupby-sum for the first time\r\ngc.collect()\r\n# run groupby-sum for the second time\r\n```\r\n\r\nand let us know if that works?","createdAt":"2023-11-28T21:42:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1830795476","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5tIAfz","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"> Is there any way to switch on this option in the jupyter notebook?\r\n\r\nYes -- you can run jupyter notebook with:\r\n\r\n```\r\nCUDF_SPILL=1 jupyter notebook ...\r\n```","createdAt":"2023-11-28T21:54:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1830815731","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5tQGYX","author":{"login":"kolfild26"},"authorAssociation":"NONE","body":"`gc.collect()` doesn't change anything. \r\nNo need to fully restart(as I mentioned above) but just to recreate the conda env with rapids and cuda like:\r\n`conda create -n rapids-23.10 -c rapidsai -c conda-forge -c nvidia rapids=23.10 python=3.10 cuda-version=12.0`\r\nand the groupby() works out several times and then starts falling back to the CPU. The exact number of times before the falling is unpredictable, it might be 1 (as I said earlier) or 2-3, around.\r\nI've also tried the `sort_values()` and the `join() `operations. The same picture in there. There is a limit of the df size below which it's all on the GPU and above which it's  going to the CPU. The only thing that varies is the size. Each of that three operations has its own limit in my case. For the groupby and sort_values it's around ~100kk. For the join (_inner_ for instance) is to be ~10kk.\r\n\r\n> CUDF_SPILL=1\r\n\r\nI tried this and **periodically** I catch the warning:\r\n```\r\n[WARNING] RMM allocation of 2.12GiB bytes failed, spill-on-demand couldn't find any device memory to spill:\r\n<SpillManager spill_on_demand=True device_memory_limit=N/A | 7.38GiB spilled | 22.28GiB (100%) unspilled (unspillable)>\r\ntraceback\r\n```\r\nAnd, unfortunatelly _spilling_ doesn't help here too, no matter with or w/o this warning.","createdAt":"2023-11-30T00:58:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1832936983","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5tQHPU","author":{"login":"kolfild26"},"authorAssociation":"NONE","body":"`7.38GiB spilled | 22.28GiB (100%) unspilled (unspillable)`\r\nðŸ¤”  might this be the cause? Looks like it says that only 7,4Gb from 32Gb were available for that operation.","createdAt":"2023-11-30T01:03:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1832940500","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5tQK_C","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"Thanks for looking into it!\r\n\r\n> There is a limit of the df size below which it's all on the GPU and above which it's going to the CPU. The only thing that varies is the size. Each of that three operations has its own limit in my case. For the groupby and sort_values it's around ~100kk. For the join (inner for instance) is to be ~10kk.\r\n\r\nYeah this variability makes sense. The amount of intermediate memory required by a `join` operation can be very different from that required by `groupby` or `sort`.\r\n\r\nOn the `groupby` front, it does sound like we can optimize things so that you don't have to do a filter of the columns before `groupby`. \r\n\r\nI think you're essentially running up to the limitation that operations on larger data require more than the available GPU memory. While spilling can _sometimes_ help with that, it doesn't seem to in this particular situation. So the operations end up executing on CPU.\r\n\r\n--- \r\n\r\nTaking a step back, are you able to share what your workflow looks like? Perhaps we can provide more useful/specific suggestions if we can see the whole code. ","createdAt":"2023-11-30T01:22:45Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1832955842","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5teNIN","author":{"login":"kolfild26"},"authorAssociation":"NONE","body":"> are you able to share what your workflow looks like? Perhaps we can provide more useful/specific suggestions if we can see the whole code.\r\n\r\nI just started learning the cudf from exploring its boundaries. So, didn't apply it for the actual pipeline yet. But will definitely do this!\r\nWill raise an issue if I have any questions. Or I will update this one if it's relevant.\r\nThanks for your help.\r\n","createdAt":"2023-12-01T19:08:53Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/14500#issuecomment-1836634637","viewerDidAuthor":false}],"createdAt":"2023-11-27T18:14:30Z","id":"I_kwDOBWUGps53-Wnm","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjQ=","name":"question","description":"Further information is requested","color":"D4C5F9"},{"id":"MDU6TGFiZWwxMDEzOTg3Nzk5","name":"0 - Waiting on Author","description":"Waiting for author to respond to review","color":"ffb88c"},{"id":"MDU6TGFiZWwxMTM5NzQxMjEz","name":"cuDF (Python)","description":"Affects Python cuDF API.","color":"1d76db"}],"milestone":null,"number":14500,"projectCards":[],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[QST] cudf.pandas prefer using CPU over GPU in some cases","updatedAt":"2023-12-14T18:57:29Z","url":"https://github.com/rapidsai/cudf/issues/14500"}
