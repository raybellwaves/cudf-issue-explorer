{"assignees":[],"author":{"id":"MDQ6VXNlcjM0NDEzMjE=","is_bot":false,"login":"revans2","name":"Robert (Bobby) Evans"},"body":"**Describe the bug**\r\nThe parquet specification at https://github.com/apache/parquet-format/blob/master/LogicalTypes.md when talking about backwards compatibility in lists says that \r\n\r\n> If the repeated field is a group with one field and is named either array or uses the LIST-annotated group's name with _tuple appended then the repeated type is the element type and elements are required.\r\n\r\nThe examples given for these are.\r\n\r\n```\r\n// List<OneTuple<String>> (nullable list, non-null elements)\r\noptional group my_list (LIST) {\r\n  repeated group array {\r\n    required binary str (UTF8);\r\n  };\r\n}\r\n\r\n// List<OneTuple<String>> (nullable list, non-null elements)\r\noptional group my_list (LIST) {\r\n  repeated group my_list_tuple {\r\n    required binary str (UTF8);\r\n  };\r\n}\r\n```\r\n\r\nI implemented some tests based off of this and saw the CUDF is able to parse the data, but it is not returning the same types as Spark does, nor does it return what I would expect the examples to show.\r\n\r\nIn [files.zip](https://github.com/rapidsai/cudf/files/9913952/files.zip) there are two parquet files.\r\n\r\n`SPECIAL_ARRAY_LIST_TEST.parquet` has a footer schema of\r\n\r\n```\r\nmessage spark {\r\n  required group my_list (LIST) {\r\n    repeated group array {\r\n      required int32 item;\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nWhen I parse the data with CUDF I get back a table with types like `Table<LIST<INT32>>`, but Spark and expects the data to look like `Table<LIST<STRUCT<INT32>>>`.\r\n\r\nPandas appears to do the same thing, but I am not an expert on pandas to be 100% sure that it is the same thing.\r\n\r\n```python\r\n>>> pd.read_parquet(\"SPECIAL_ARRAY_LIST_TEST.parquet\")\r\n                      my_list\r\n0  [{'item': 0}, {'item': 1}]\r\n>>> pd.read_parquet(\"SPECIAL_ARRAY_LIST_TEST.parquet\").info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nRangeIndex: 1 entries, 0 to 0\r\nData columns (total 1 columns):\r\n #   Column   Non-Null Count  Dtype \r\n---  ------   --------------  ----- \r\n 0   my_list  1 non-null      object\r\ndtypes: object(1)\r\nmemory usage: 136.0+ bytes\r\n```\r\n\r\nThe other file is essentially the same, but it is using the `_tuple` special case instead of `array`.\r\n\r\n**Steps/Code to reproduce bug**\r\nTry to read the attached files in CUDF and see if they match the desired types/schema.\r\n\r\n**Expected behavior**\r\nThey should match, but it looks like they do not.\r\n\r\n**Additional context**\r\nThis is probably not super critical because it is an odd corner case that is not likely to be very common, but technically it is returning the wrong data.\r\n","closed":false,"closedAt":null,"comments":[],"createdAt":"2022-11-01T21:11:13Z","id":"I_kwDOBWUGps5VXDJY","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NTk=","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"}],"milestone":{"number":22,"title":"Parquet continuous improvement","description":"","dueOn":null},"number":12043,"projectCards":[{"project":{"name":"Bug Squashing"},"column":{"name":"Needs prioritizing"}},{"project":{"name":"v23.02 Release"},"column":{"name":"Issue-P1"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[BUG] Special case Parquet LIST names appear to be ignored","updatedAt":"2024-02-16T23:38:41Z","url":"https://github.com/rapidsai/cudf/issues/12043"}
