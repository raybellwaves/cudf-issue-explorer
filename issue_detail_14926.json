{"assignees":[],"author":{"id":"MDQ6VXNlcjU1NTA5NQ==","is_bot":false,"login":"zeroshade","name":"Matt Topol"},"body":"**Is your feature request related to a problem? Please describe.**\r\nI would like to generate Arrow IPC payloads from a `cudf::table` without copying the data off of the GPU device. Currently the `to_arrow` and `from_arrow` functions explicitly perform copies to and from the GPU device. There is not currently any efficient way to generate Arrow IPC payloads from libcudf without copying all of the data off of the device.\r\n\r\n**Describe the solution you'd like**\r\nIn addition to the existing `to_arrow` and `from_arrow` functions, we could have a `to_arrow_device_arr` function that populates an `ArrowDeviceArray` struct from a `cudf::table` or `cudf::column`. We'd also create a `from_arrow_device_arr` function that could construct a `cudf::table` / `cudf::column` from an `ArrowDeviceArray` that describes Arrow data which is already on the device. Once you have the `ArrowDeviceArray` struct, the Arrow C++ library itself can be used to generate the IPC payloads without needing to copy the data off the device. This would also increase the interoperability options that libcudf has, as anything which produces or consumes `ArrowDeviceArray` structs could hand data off to libcudf and vice versa.\r\n\r\n**Describe alternatives you've considered**\r\nAn alternative would be to implement Arrow IPC creating inside of the libcudf library, but I saw that this was explicitly removed from libcudf due to the requirement of linking against `libarrow_cuda.so`. (https://github.com/rapidsai/cudf/issues/10994). Implementing conversions to and from `ArrowDeviceArray` wouldn't require linking against `libarrow_cuda.so` at all and would provide an easy way to allow any consumers to create Arrow IPC payloads, or whatever else they want to do with the resulting Arrow data. Such as leveraging CUDA IPC with the data.\r\n\r\n**Additional context**\r\nWhen designing the `ArrowDeviceArray` struct, I created https://github.com/zeroshade/arrow-non-cpu as a POC which used Python numba to generate and operate on some GPU data before handing it off to libcudf, and then getting it back without copying off the device. Using `ArrowDeviceArray` as the way it handed the data off.\r\n\r\nMore recently I've been working on creating a protocol for sending Arrow IPC data that is located on GPUs across high-performance transports like UCX. To this end, I created a POC using libcudf to pass the data. As a result I have a partial implementation of the `to_arrow_device_arr` which can be found [here](https://github.com/zeroshade/cudf-flight-ucx/blob/main/to_arrow.cc). There's likely better ways than what I'm doing in there, but at least for my POC it was working.\r\n\r\nThe contribution guidelines say I should file this issue first for discussion rather than just submitting a PR, so that's where I'm at. I plan on trying to create a full implementation that I can contribute but wanted to have this discussion and get feedback here first. \r\n\r\nThanks for hearing me out everyone!\r\n","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5yL2oN","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"I don't think this requires new APIs to libcudf.\r\n\r\nThe `cudf::column` and `cudf::table` are [data-owning structs](https://github.com/rapidsai/cudf/blob/branch-24.04/cpp/doxygen/developer_guide/DEVELOPER_GUIDE.md#cudfcolumn) in libcudf.\r\nFor zero-copy you should be able wrap the arrow data in device memory with a `cudf::column_view` (and `cudf::table_view`) which are [non-owning data structures](https://github.com/rapidsai/cudf/blob/branch-24.04/cpp/doxygen/developer_guide/DEVELOPER_GUIDE.md#cudfcolumn_view).\r\n\r\nAll of the libcudf APIs accept `cudf::column_view` objects and so do not require an owning object so there should be no need to copy the arrow data in order to call a libcudf function.\r\n\r\nGenerally, libcudf APIs will return new `cudf::column` object since they are modifying or creating new column/table data. You can take ownership of this data (which should be in arrow format in device memory) using the `cudf::column::release()` method and then place the data in an appropriate arrow structure.","createdAt":"2024-01-29T22:48:25Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1915709965","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yMKlV","author":{"login":"zeroshade"},"authorAssociation":"CONTRIBUTOR","body":"> For zero-copy you should be able wrap the arrow data in device memory with a cudf::column_view (and cudf::table_view) which are [non-owning data structures](https://github.com/rapidsai/cudf/blob/branch-24.04/cpp/doxygen/developer_guide/DEVELOPER_GUIDE.md#cudfcolumn_view).\r\n\r\nThe issue is that it's not clear-cut how to perform that wrapping since `libcudf`'s memory representation still differs from Arrow in some cases, in addition to differences in how the buffers are handled (such as with string columns using children for their offsets/data and Arrow string the offsets and data buffers as plain buffers, not children). There's a significant amount of code required to correctly wrap `cudf::column_view`s around Arrow data in device memory (note the significant amount of code in https://github.com/rapidsai/cudf/blob/branch-24.04/cpp/src/interop/from_arrow.cu and https://github.com/rapidsai/cudf/blob/branch-24.04/cpp/src/interop/to_arrow.cu), which makes it worthwhile to have functions in libcudf itself to encapsulate this logic. Rather than have consumers replicate the logic in their own libraries.\r\n\r\n> You can take ownership of this data (which should be in arrow format in device memory) using the cudf::column::release() method and then place the data in an appropriate arrow structure.\r\n\r\nSure, but like I mentioned above it's not necessarily as simple as placing it in the appropriate arrow structure. It requires a significant amount of code to do it correctly and properly, and it makes sense for that to exist within libcudf. Particularly because it can then remain updated as libcudf adds support for more Arrow data types.","createdAt":"2024-01-30T00:00:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1915791701","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yRhqo","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Ok. That makes sense. This appears to be just a wrapper around the `cudf::column_view` [constructor](https://github.com/rapidsai/cudf/blob/57bbe94e995b9a0365276e4cb26853dce219e22a/cpp/include/cudf/column/column_view.hpp#L371-L377). But resolving the data-type and the other components needed for the parameters would involve significant code. And the reverse as well.","createdAt":"2024-01-30T15:25:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917196968","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yRnlt","author":{"login":"zeroshade"},"authorAssociation":"CONTRIBUTOR","body":"Before I go further working on it, could you take a look at my partial implementation in https://github.com/zeroshade/cudf-flight-ucx/blob/main/to_arrow.cc and let me know if you think that's a good direction to go in as opposed to a different approach? \r\n\r\nIf it's a good approach then i'll work on creating a PR for this","createdAt":"2024-01-30T15:30:12Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917221229","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5ySEkf","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Who owns the data after this call?\r\n\r\nI expected that this signature\r\n```\r\narrow::Status to_arrow_device_arr(std::shared_ptr<cudf::table> input,\r\n                                  struct ArrowDeviceArray* out,\r\n                                  rmm::cuda_stream_view stream)\r\n```\r\nwould be more like\r\n```\r\nstd::unique_ptr<struct struct ArrowDeviceArray> to_arrow_device_array(cudf::table_view const& input,\r\n                                                                      rmm::cuda_stream_view stream)\r\n```\r\nAnd throw an exception with an error message instead of returning a status.\r\n\r\nAlso, I don't understand what the `cudaEventRecord` objects are for and why they should be created here.\r\nIt seems a fragile piece of logic subject to fleeting changes in your arrow struct implementation.\r\nI wonder if Arrow could have an API to build an `ArrowDeviceArray` from simple native elements like pointers and integers similar to the parameters for `cudf::column_view` and `cudf::table_view` constructors.\r\n\r\n\r\n","createdAt":"2024-01-30T15:58:39Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917339935","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5ySpVa","author":{"login":"zeroshade"},"authorAssociation":"CONTRIBUTOR","body":"> Who owns the data after this call?\r\n\r\nTechnically the data has shared ownership. The `ArrowDeviceArray` maintains a reference to the passed in `std::shared_ptr<cudf::table>` to keep it alive until the release callback in the struct is called. Because the `ArrowDeviceArray` is intended to be a C ABI, it uses a release callback to control the lifetime of the underlying data.\r\n\r\nThe problem with this\r\n\r\n```\r\nstd::unique_ptr<struct ArrowDeviceArray> to_arrow_device_array(cudf::table_view const& input,\r\n                                                                      rmm::cuda_stream_view stream)\r\n```\r\n\r\nIs that because you're only passing in a `cudf::table_view` which doesn't own its data, there's no way to guarantee that the data stays alive until the release callback on the `ArrowDeviceArray` is called. We need to ensure that the underlying data stays valid and alive until the release callback is used. \r\n\r\nIf we don't like the idea of the shared ownership, then the interface could take a `cudf::table` and give the ownership to the `ArrowDeviceArray` entirely rather than sharing ownership.\r\n\r\n> Also, I don't understand what the cudaEventRecord objects are for and why they should be created here.\r\nIt seems a fragile piece of logic subject to fleeting changes in your arrow struct implementation.\r\n\r\nWe don't manually synchronize on the stream during the creation of the `ArrowDeviceArray`, instead we create an event and record it on the stream provided. The event is then part of the `ArrowDeviceArray` struct, so that a consumer can have their own stream wait on that event to synchronize before attempting to access the data. This lets the consumer of the struct choose when they synchronize, and on whatever stream they want to synchronize on. This allows the struct to be passed across C boundaries to different libraries and/or runtimes (such as python or Go or Rust etc.) and allow the consumer to synchronize the GPU however they want. @kkraus14 might be better able to explain the reasoning for the event in the struct than I.\r\n\r\nThat said, the `ArrowDeviceArray` struct is intended to be ABI stable and will not change. You can find the full definition, documentation and reasoning behind the structure of the `ArrowDeviceArray` here: https://arrow.apache.org/docs/format/CDeviceDataInterface.html\r\n\r\n> I wonder if Arrow could have an API to build an ArrowDeviceArray from simple native elements like pointers and integers similar to the parameters for cudf::column_view and cudf::table_view constructors.\r\n\r\nThat's exactly what the `ArrowDeviceArray` struct is. It's the collection of \"simple native elements like pointers and integers\" that describe the array and its children. Arrow provides APIs which take the struct and construct Arrow Arrays or RecordBatches from the struct (https://github.com/apache/arrow/blob/main/cpp/src/arrow/c/bridge.h#L232)\r\n\r\nIn this scenario: `arrow::Array` and `arrow::RecordBatch` are equivalent to `cudf::column` and `cudf::table`. `ArrowDeviceArray` is a struct used to encapsulate all of the pointers/length/null counts/etc. to zero-copy send the data across a C ABI boundary.","createdAt":"2024-01-30T16:59:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917490522","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yTG1f","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"Hey @davidwendt ðŸ˜ƒ\r\n\r\nThe CUDA event in the struct that @zeroshade mentioned is the responsibility of the producer of the struct. It should have all relevant work related to allocating and populating the memory that is being handed / shared to the struct captured so that a downstream user of the struct can wait on the event to guarantee that whatever stream they're working on doesn't cause a race condition with the relevant allocations / kernels that produced the memory.\r\n\r\nThe reason behind using a CUDA event as opposed to a CUDA stream is that often frameworks don't have a mechanism to share or extend the lifetime of their streams outside of their framework.\r\n\r\nAs far as the lifetime management of the actual memory, the struct's release callback is designed to be flexible to allow accommodating both owning and non-owning situations. I.E. if someone had a `cudf::column_view`, we could basically just have an empty release callback to have it function as a view as opposed to having any form of ownership. In the case of cudf having unique ownership in something like a `std::unique_ptr<cudf::column>`, then it would likely make sense to transfer ownership to the struct.","createdAt":"2024-01-30T18:07:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917611359","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yTRPv","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Hey Keith. Thanks but it seems this kind of Arrow-specific logic for an Arrow-specific struct does not belong in libcudf. It seems a bit fragile in that changing how Arrow manages objects would require changes in a non-Arrow repo (like cudf). For example, if in the future Arrow decided the `cudaEventCreate` was not sufficient and now relied on `cudaEventCreateWithFlags` instead, a new cudf PR would be required to make this compliant again.\r\n\r\nI was picturing more of a `arrow::ArrowArray::Make()` factory function that would handle these kinds of details. \r\nSomething like this perhaps (likely needs tweaking):\r\n```\r\nstd::unique_ptr<ArrowArray> Make( int length, int null_count, int offset, void* buffer, std::vector<ArrowArray> children);\r\n```\r\n(And similar one for `ArrowDeviceArray`)\r\nAnd this function would handle all the Arrow-specific things including the release mechanism and whatever CUDA objects it needs. It also allows the Arrow code complete control on how it is created and destroyed.\r\n\r\nThen the libcudf function could simply call this with the appropriate counts and device pointers.","createdAt":"2024-01-30T18:32:12Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917653999","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yTS-i","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"> Is that because you're only passing in a `cudf::table_view` which doesn't own its data, there's no way to guarantee that the data stays alive until the release callback on the `ArrowDeviceArray` is called. We need to ensure that the underlying data stays valid and alive until the release callback is used.\r\n\r\nGenerally, libcudf is based on accepting views that are non-owning as per our developer guidelines.\r\nhttps://github.com/rapidsai/cudf/blob/branch-24.04/cpp/doxygen/developer_guide/DEVELOPER_GUIDE.md#views-and-ownership\r\nThe caller must ensure proper ownership scope and lifetime.  This also provides a great deal of flexibility since there is no guarantee the original data is owned by a `cudf::table` in the first place.","createdAt":"2024-01-30T18:36:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917661090","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yTmAo","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> Thanks but it seems this kind of Arrow-specific logic for an Arrow-specific struct does not belong in libcudf. It seems a bit fragile in that changing how Arrow manages objects would require changes in a non-Arrow repo (like cudf).\r\n\r\nThis is Arrow format specific, but not Arrow library specific. Libcudf already has `to_arrow` and `from_arrow` functions to go from device memory in libcudf containers to host memory in arrow containers, so it's already been exposed to fragility in Arrow for years, but the memory layout and ABI has been stable for years.\r\n\r\nWhat is proposed here doesn't use Arrow containers and is designed to be a vendorable single header with a stable ABI so there really isn't additional exposure to Arrow that isn't already there.\r\n\r\n> I was picturing more of a `arrow::ArrowArray::Make()` factory function that would handle these kinds of details. Something like this perhaps (likely needs tweaking):\r\n> \r\n> ```\r\n> std::unique_ptr<ArrowArray> Make( int length, int null_count, int offset, void* buffer, std::vector<ArrowArray> children);\r\n> ```\r\n> \r\n> (And similar one for `ArrowDeviceArray`) And this function would handle all the Arrow-specific things including the release mechanism and whatever CUDA objects it needs. It also allows the Arrow code complete control on how it is created and destroyed.\r\n> \r\n> Then the libcudf function could simply call this with the appropriate counts and device pointers.\r\n\r\nIn theory something like this could be added as a free function in the vendorable header, but you'd need to handle all the nesting structure that columns can have where you'd ultimately end up likely recreating a healthy chunk of what this struct describes in itself. No matter what there's some translation that needs to happen from how libcudf organizes its device pointers into some type of interface, and that's basically what this struct is.","createdAt":"2024-01-30T19:27:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917739048","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yTr3V","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"Also, supporting this interface could be used to replace the existing `to_arrow` and `from_arrow` functions and remove the need to actually depend on the arrow library for supporting this functionality in the future. You could return host memory via this interface and there would be functions in the arrow library that could be called against the returned struct to get arrow containers similar to what the current `to_arrow` / `from_arrow` functions do.","createdAt":"2024-01-30T19:41:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917763029","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yY_e3","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"> In theory something like this could be added as a free function in the vendorable header, but you'd need to handle all the nesting structure that columns can have where you'd ultimately end up likely recreating a healthy chunk of what this struct describes in itself. No matter what there's some translation that needs to happen from how libcudf organizes its device pointers into some type of interface, and that's basically what this struct is.\r\n\r\nNo, I would not expect Arrow to unwind libcudf data structures. My suggestion leaves most of the proposed logic intact (type-dispatch, etc) but just replaces the pieces that create the [ArrowArray](https://github.com/zeroshade/cudf-flight-ucx/blob/07e8c30bb3c49e0011c991e124cc9dc750ffd0f8/to_arrow.cc#L512-L529) and [ArrowDeviceArray](https://github.com/zeroshade/cudf-flight-ucx/blob/07e8c30bb3c49e0011c991e124cc9dc750ffd0f8/to_arrow.cc#L560-L600) with factory functions implemented in the Arrow source.\r\n\r\nI will work on a counter-proposal.","createdAt":"2024-01-31T13:57:58Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1919154103","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yY_zI","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> I will work on a counter-proposal.\r\n\r\nThank you! We'll more than happily review and iterate on it with you! ðŸ˜ƒ","createdAt":"2024-01-31T13:58:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1919155400","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5ylmLB","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Ok, this is what I'm proposing for the 2 `Make` functions to go in the Arrow source.\r\nWe can name that whatever makes sense. And we can change the return type to be a `std::shared_ptr` if that helps too.\r\n\r\n```\r\nnamespace arrow {\r\n\r\n/// raw pointer and a function to free it\r\nusing OwningBuffer = std::pair<const void*, std::function<void()>>;\r\n\r\nnamespace {\r\n// generic object deleter functor for ArrowArray instances\r\nstruct DeleterFn {\r\n  std::vector<ArrowArray*> children;\r\n  std::vector<OwningBuffer> owners;\r\n  ~DeleterFn()\r\n  {\r\n    for (auto& c : children)\r\n      ArrowArrayRelease(c);\r\n    for (auto& o : owners)\r\n      std::invoke(o.second);\r\n  }\r\n};\r\n}  // namespace\r\n\r\nstd::unique_ptr<ArrowArray> MakeArrowArray(int64_t length,\r\n                                           int64_t null_count,\r\n                                           int64_t offset,\r\n                                           std::vector<OwningBuffer>&& data    = {},\r\n                                           std::vector<ArrowArray*>&& children = {},\r\n                                           ArrowArray&& dictionary             = {0})\r\n{\r\n  auto result = new ArrowArray{};\r\n  std::memset(result, 0, sizeof(ArrowArray));\r\n\r\n  const void** buffers = (const void**)(malloc(sizeof(void*) * data.size()));\r\n  std::transform(data.begin(), data.end(), buffers, [](auto& buffer) { return buffer.first; });\r\n\r\n  result->length     = length;\r\n  result->null_count = null_count;\r\n  result->offset     = offset;\r\n  result->n_buffers  = 2;\r\n  result->n_children = static_cast<int64_t>(children.size());\r\n  result->buffers    = buffers;\r\n  result->children   = children.data();\r\n  result->dictionary = dictionary.length == 0 ? nullptr : new ArrowArray(std::move(dictionary));\r\n  result->release    = [](struct ArrowArray* arr) {\r\n    free(arr->buffers);\r\n    auto d = static_cast<DeleterFn*>(arr->private_data);\r\n    delete d;\r\n    if (arr->dictionary) ArrowArrayRelease(arr->dictionary);\r\n    ArrowArrayMarkReleased(arr);\r\n  };\r\n  result->private_data = new DeleterFn{std::move(children), std::move(data)};\r\n  return std::unique_ptr<ArrowArray>(result);\r\n}\r\n\r\nstd::unique_ptr<ArrowDeviceArray> MakeDeviceArray(ArrowArray&& array)\r\n{\r\n  auto result = new ArrowDeviceArray{std::move(array)};\r\n  cudaEventCreate(reinterpret_cast<cudaEvent_t*>(&(result->sync_event)));\r\n  int dev_id = 0;\r\n  cudaGetDevice(&dev_id);\r\n  result->device_id   = dev_id;\r\n  result->device_type = ARROW_DEVICE_CUDA;\r\n  return std::unique_ptr<ArrowDeviceArray>(result);\r\n}\r\n}  // namespace arrow\r\n\r\n```\r\n\r\nThe `DeleterFn` can certainly go in a .cpp file along with the 2 function definitions. \r\nNo need for these to be declared and be defined in a header file.\r\nI believe this should work and all the appropriate objects are managed correctly but I've not tested it.\r\n\r\n","createdAt":"2024-02-01T23:15:52Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1922458305","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5ylo9S","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"I spent some time recoded each of the dispatch functions to use these `Make` factories.\r\nHere are few of them for reference.\r\n```\r\n  // handles most of the fixed-width types\r\n  std::unique_ptr<ArrowArray> operator()(cudf::column_view input, rmm::cuda_stream_view)\r\n  {\r\n    std::vector<arrow::OwningBuffer> data{{input.null_mask(), empty_fn}, {input.head(), empty_fn}};\r\n    return arrow::MakeArrowArray(input.size(), input.null_count(), input.offset(), std::move(data));\r\n  }\r\n\r\n```\r\n```\r\n// the bool specialization shows passing in a custom 'delete' function for freeing the device_buffer\r\ntemplate <>\r\nstd::unique_ptr<ArrowArray> dispatch_to_arrow::operator()<bool>(cudf::column_view input,\r\n                                                                rmm::cuda_stream_view stream)\r\n{\r\n  cudf::column_view view_without_offset =\r\n    input.offset() == 0 ? input\r\n                        : view_without_offset = cudf::column_view{input.type(), input.size() + input.offset(),\r\n                                                                  input.head(), input.null_mask(),  input.null_count()};\r\n  auto bitmask = std::get<0>(cudf::detail::bools_to_mask(\r\n    view_without_offset, stream, rmm::mr::get_current_device_resource()));\r\n\r\n  std::vector<arrow::OwningBuffer> data{{input.null_mask(), empty_fn}};\r\n  data.emplace_back(device_buffer_to_arrow(std::move(*bitmask.release())));\r\n  return arrow::MakeArrowArray(input.size(), input.null_count(), input.offset(), std::move(data));\r\n}\r\n...\r\nwhich uses this utility (to be included in the libcudf source along with these dispatch functions):\r\n...\r\n// utility to transfer a device_buffer to an OwningBuffer\r\narrow::OwningBuffer device_buffer_to_arrow(rmm::device_buffer&& buffer)\r\n{\r\n  auto dbuf    = new rmm::device_buffer(std::move(buffer));\r\n  auto deleter = [dbuf]() { delete dbuf; };\r\n  return arrow::OwningBuffer{dbuf->data(), deleter};\r\n}\r\n\r\n```\r\n```\r\n// the main public function that returns the new ArrowDeviceArray\r\nstd::unique_ptr<arrow::ArrowDeviceArray> to_arrow_device_array(table_view input_view,\r\n                                                               rmm::cuda_stream_view stream)\r\n{\r\n  std::vector<ArrowArray*> children;\r\n  for (auto& c : input_view) {\r\n    auto col = c.type().id() != cudf::type_id::EMPTY\r\n                 ? cudf::type_dispatcher(c.type(), detail::dispatch_to_arrow{}, c, stream)\r\n                 : detail::create_null_array(c.size());\r\n    children.emplace_back(col.release());\r\n  }\r\n  std::vector<arrow::OwningBuffer> data{{nullptr, detail::empty_fn}};\r\n  auto array =  arrow::MakeArrowArray(input_view.num_rows(), 0, 0, std::move(data), std::move(children));\r\n  return arrow::MakeDeviceArray(std::move(*array.release()));\r\n}\r\n...\r\nThe create_null_array() was copied from original the get_null_arr()\r\n...\r\nstd::unique_ptr<ArrowArray> create_null_array(int size)\r\n{\r\n  auto arr = std::make_shared<arrow::NullArray>(size);\r\n  auto out = new ArrowArray{};\r\n  ARROW_UNUSED(arrow::ExportArray(*arr, out));\r\n  return std::unique_ptr<ArrowArray>(out);\r\n}\r\n```\r\nLet me know if you want to see any of the other ones.\r\nI didn't realize how different each type is built into an `ArrowArray` but the `Make` function seems to handle them all.\r\nI was a bit surprised the type-id is not included in the structure.\r\n","createdAt":"2024-02-01T23:28:12Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1922469714","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yuTv4","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"I think we'd also want to look into [nanoarrow](https://github.com/apache/arrow-nanoarrow) (#13678) before we design any new structs ourselves. If I'm reading this discussion right it seems like there should be significant overlap given that nanoarrow has a [device-side extension](https://github.com/apache/arrow-nanoarrow/tree/main/extensions/nanoarrow_device#readme).","createdAt":"2024-02-02T21:44:25Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1924742136","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yxcTw","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> The `DeleterFn` can certainly go in a .cpp file along with the 2 function definitions.\r\n> No need for these to be declared and be defined in a header file.\r\n> I believe this should work and all the appropriate objects are managed correctly but I've not tested it.\r\n\r\nThis is unfortunately a C API as opposed to a CPP API. I imagine we could make this work regardless, but the bigger question is where would we expect this to live? If this lived in the main Arrow library then it eliminates the goal of being dependency free and requires linking libarrow which has a somewhat non-trivial dependency tree on its own. One of the goals of the interfaces is explicitly to avoid an explicit dependency on Arrow: https://arrow.apache.org/docs/format/CDeviceDataInterface.html#goals.\r\n\r\nWe could potentially implement something like this in nanoarrow as @vyasr mentioned above, but we'd probably need to take in the cuda event somewhere as opposed to having the make function create and record the event since the buffers coming in could potentially be on different streams or something of the like and I don't think there's a nice general way for something like nanoarrow to introspect and handle things properly. Additionally, the device and subsequent CUDA device extension in nanoarrow is quite new where there isn't interfaces for doing things like stream ordered memory management, stream ordered copying, etc. yet where I'm not sure how helpful it would be in the actual implementation here outside of providing the relevant definitions in headers for the Arrow C Device Data Interface.\r\n\r\n","createdAt":"2024-02-04T03:14:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1925563632","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zChYb","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Ok. The link was helpful background.\r\n\r\n> If this lived in the main Arrow library then it eliminates the goal of being dependency free and requires linking libarrow which has a somewhat non-trivial dependency tree on its own.\r\n\r\nSince `libcudf` is already linking to `libarrow.so`, I'd like to consider Arrow providing these functions as an alternative to hand building the struct elements as illustrated in the original proposal.\r\n\r\n","createdAt":"2024-02-06T15:23:50Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1930040859","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zCuz-","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> Since `libcudf` is already linking to `libarrow.so`\r\n\r\nMy understanding is that there is a desire for libcudf to no longer link against `libarrow.so`, where this proposal would enable a path to removing one of the key places it's used, in `to_arrow` and `from_arrow` as well as enabling handing GPU memory to other libraries that don't link to libcudf.\r\n\r\nI believe from some conversations with @beckernick that he's expressed that Arrow increasing major versions ~quarterly and libcudf being tied to a specific major version has caused some compatibility pain in working with other packages across the ecosystem.\r\n\r\n> I'd like to consider Arrow providing these functions as an alternative to hand building the struct elements as illustrated in the original proposal.\r\n\r\nI don't think this is particularly feasible. There's different ownership models / semantics that Arrow would need to capture / support here. I.E. shared ownership where someone would want to more or less stuff some shared_ptrs into the `private_data` struct member and handle them appropriately in the `release` callback.\r\n\r\nAdditionally, in your proposal above you'd still need to organize your buffers and child columns into a flattened structure, pass the device type, and create + record the CUDA event for synchronization yourself. It seems like the main difference would be moving handling the ownership semantics into Arrow as opposed to handling it in libcudf?","createdAt":"2024-02-06T15:50:11Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1930095870","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zDAGY","author":{"login":"bkietz"},"authorAssociation":"NONE","body":"> I'd like to consider Arrow providing these functions as an alternative to hand building the struct elements as illustrated in the original proposal.\r\n\r\nI'm not sure what the functions would look like if they lived in libarrow, since libarrow can't use definitions of libcudf classes like table_view. Could you sketch the signatures you were thinking of?","createdAt":"2024-02-06T16:08:54Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1930166680","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zDCF7","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"> > I'd like to consider Arrow providing these functions as an alternative to hand building the struct elements as illustrated in the original proposal.\r\n> \r\n> I'm not sure what the functions would look like if they lived in libarrow, since libarrow can't use definitions of libcudf classes like table_view. Could you sketch the signatures you were thinking of?\r\n\r\nhttps://github.com/rapidsai/cudf/issues/14926#issuecomment-1922458305","createdAt":"2024-02-06T16:10:29Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1930174843","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zFeV9","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"What version of Arrow includes `ArrowDeviceArray`? I don't see it in the version used by libcudf so upgrading may be a prerequisite for this work.\r\n\r\nI'm still puzzled by the lack of a type-id in these structures.\r\nWhat is your proposal for `from_arrow_device_array`? I believe it should be possible to build a `cudf::table_view/cudf::column_views` but only if the type-ids are available.\r\nBuilding a `cudf::table` does not look possible since `cudf::column` objects expect to own their data and for it to be stored in an `rmm::device_buffer` which is managed by RMM. [There is no mechanism for RMM to manage device memory that it has not allocated](https://github.com/rapidsai/rmm/issues/874).","createdAt":"2024-02-06T21:54:26Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1930814845","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zF_qk","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"> My understanding is that there is a desire for libcudf to no longer link against libarrow.so\r\n\r\n@kkraus14 you're right that we would eventually like to stop linking against libarrow if possible. \r\n\r\n> We could potentially implement something like this in nanoarrow as @vyasr mentioned above\r\n\r\nMy understanding is that nanoarrow was intended to provide essentially what we would need to decouple the existing Arrow interop functionality in libcudf from linkage to libarrow itself: a small, easily vendored library that provides an implementation of readers/writers of the Arrow C data interface so that various libraries could produce ABI-equivalent versions of Arrow data structures without linking. Do I have that right?\r\n\r\n> but [...] I don't think there's a nice general way for something like nanoarrow to introspect and handle things properly.\r\n\r\nAssuming my understanding of the goals of nanoarrow above is correct, is the main concern here leaking too much CUDA-specific information into the nanoarrow implementation, which would be a long-term issue? Or are you mostly concerned with the more short-term issue that \r\n\r\n> the device and subsequent CUDA device extension in nanoarrow is quite new where there isn't interfaces for doing things like stream ordered memory management, stream ordered copying, etc. yet \r\n\r\nIf it's the latter, then could it make sense to implement this kind of functionality in libcudf (or a separate but associated library) for now but eventually upstream it to nanoarrow?\r\n\r\nIf it's the former, then I'd like to better understand the inherent limitations you see in nanoarrow and see if we can find a path to upstream this. At a high level I think I understand your concerns but I would like to dig into the details a bit since IMHO something like this really ought to be within the long-term scope of nanoarrow if I've understood its intent properly. I think I agree that we'll always need _some_ functionality in cudf, but in an ideal world I would hope that we'd have something close to as simple as (very rough, not trying to be precise with types etc since I imagine all that could change in nanoarrow):\r\n```\r\nArrowDeviceArrayView to_arrow(column_view col) {\r\n    // Note that I'm constructing an ArrowDeviceArrayView, not an ArrowDeviceArray,\r\n    // because I assumed those were the intended semantics of that object.\r\n    // Since it's a view and not a copy stream-ordering concerns seem like they'd be obviated.\r\n    return ArrowDeviceArrayViewInit(col.data(), col.size());\r\n}\r\n```\r\nbut I really haven't looked into nanoarrow enough yet to understand where/why this would be problematic.","createdAt":"2024-02-06T23:38:57Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1930951332","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zGDe5","author":{"login":"zeroshade"},"authorAssociation":"CONTRIBUTOR","body":"The `ArrowDeviceArray` was introduced with arrow v13 or v14. You'll find it in the header file `<arrow/c/abi.h>` \r\n\r\n> I'm still puzzled by the lack of a type-id in these structures.\r\n\r\nThe type IDs are managed by a corresponding `ArrowSchema` object, also in the same header. They are separate to allow for a stream of batches of data with the same schema to not have to duplicate the type information for every batch of records. So libcudf would need two methods: one to fill in an `ArrowSchema` and it's children based on the type of a column/column_view or a table/table_view (a table is treated as a struct column whose fields are the columns of the table so everything is seamless).\r\n\r\nThe other issue I see with pushing this upstream is that the `ArrowDeviceArray` on the arrow side is supposed to be device agnostic. Any init function we provide would also need to have the device type passed in (we can't assume CUDA) which would also require the caller to pass in any synchronization event (if required). \r\n\r\nEssentially the only thing a helper function like what you are asking could do is be a wrapper around populating a C struct, which seems a little redundant and unnecessary. At least to me.\r\n\r\nNanoarrow could certainly be used to simplify the creating of the `ArrowArray` and `ArrowStruct` objects though. @paleolimbot could comment further on nanoarrow for this","createdAt":"2024-02-06T23:51:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1930966969","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zGjK0","author":{"login":"paleolimbot"},"authorAssociation":"NONE","body":"Very interesting read! No pressure to use nanoarrow's implementation for any of this...if it can't help, its source might be useful to review and/or it might give you another endpoint to test against.\r\n\r\nThe nanoarrow C library (without any CUDA integration) can definitely populate the `ArrowSchema` for you. It might look like:\r\n\r\n```c\r\n#include nanoarrow.hpp\r\n\r\nint export_column_schema(const cudf::column& col, ArrowSchema* out) {\r\n  nanoarrow::UniqueSchema tmp;\r\n  ArrowSchemInit(tmp.get());\r\n  // I imagine there is already a mapping to an Arrow type id somewhere in cudf, but for example...\r\n  NANOARROW_RETURN_NOT_OK(ArrowSchemaSetType(tmp.get(), NANOARROW_TYPE_INT32);\r\n  \r\n  ArrowSchemaMove(tmp.get(), out);\r\n  return NANOARROW_OK;\r\n}\r\n```\r\n\r\nThe nanoarrow C library (also without any CUDA integration) can also populate an `ArrowArray` for you. If you want export an `ArrowArray` that's actually non-owning (just pretending to be owning), you could do:\r\n\r\n```c\r\nint export_column_view_array(const cudf::column_view& col, ArrowArray* out) {\r\n  nanoarrow::UniqueArray tmp;\r\n  NANOARROW_RETURN_NOT_OK(ArrowArrayInitFromType(tmp.get(), NANOARROW_TYPE_INT32);\r\n  tmp->length = col.length;\r\n  // offset, null_count\r\n  tmp->buffers[1] = col.data_buffer_start_addr;\r\n  // If validity bitmaps are a thing in cudf: tmp->buffers[0] = col.validity_buffer;\r\n  \r\n  ArrowArrayMove(tmp.get(), out);\r\n  return NANOARROW_OK;\r\n}\r\n```\r\n\r\nIf you want to export an `ArrowArray` that fully conforms to the spec (i.e., it is safe to access buffer content until the consumer calls the release callback), you could also use nanoarrow but you would have to explode ownership to the buffer level, which it sounds like might involve some shared pointers or reference counting of some kind. Hypothetically:\r\n\r\n```c\r\nstatic void finalize_buffer(ArrowBufferAllocator* allocator, uint8_t* ptr, int64_t size) {\r\n  auto* shared_col = reinterpret_cast<std::shared_ptr<cuda::column>>(allocator->private_data);\r\n  delete shared_col;\r\n}\r\n\r\nint export_column_view_array(const std::shared_ptr<cuda::column> col, ArrowArray* out) {\r\n  nanoarrow::UniqueArray tmp;\r\n  NANOARROW_RETURN_NOT_OK(ArrowArrayInitFromType(tmp.get(), NANOARROW_TYPE_INT32);\r\n  tmp->length = col->length;\r\n  \r\n  ArrowBuffer* data_buffer = ArrowArrayBuffer(tmp.get(), 1);\r\n  ArrowBufferSetAllocator(\r\n    data_buffer, \r\n    ArrowBufferDeallocator(&finalize_buffer, new std::shared_ptr<cuda::column>(col));\r\n  data_buffer->data = col->data_buffer_start_addr;\r\n  \r\n  NANOARROW_RETURN_NOT_OK(ArrowArrayFinishBuilding(tmp.get(), nullptr. NANOARROW_VALIDATION_LEVEL_MINIMAL);\r\n  ArrowArrayMove(tmp.get(), out);\r\n  return NANOARROW_OK;\r\n}\r\n```\r\n\r\nThe only CUDA-specific part would be ensuring that the `cudaEvent_t` pointer in the `ArrowDeviceArray` struct is cleaned up when the outermost `ArrowArray`'s release callback is called.\r\n\r\n@vyasr is correct that there is an `ArrowArrayView` (and, in the work-in-progress device helpers, an `ArrowDeviceArrayView`). It sounds like this is the equivalent of your `cudf::column_view`; however, it's not ABI stable and so I'm not sure it will be all that useful to use as an interface.","createdAt":"2024-02-07T01:41:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1931096756","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5za0E1","author":{"login":"jrhemstad"},"authorAssociation":"CONTRIBUTOR","body":"I haven't read the full thread in detail, but here's my $0.02.\r\n\r\nAs far as I'm concerned, the whole reason for Arrow's existence and why RAPIDS built on it in the first place was to enable zero-copy data sharing with a common vocabulary for in-memory, columnar data. \r\n\r\nMy memory is hazy, but I believe the only reason the original `cudf::to/from_arrow` perform deep copies is because there wasn't yet a way to describe GPU memory with the Arrow data structures, so we had to always assume we had to make copies to/from host memory.\r\n\r\nNow it seems we have a zero-copy way to describe GPU memory with Arrow, so libcudf should _definitely_ enable that. \r\n\r\nIn my mind, this is equivalent to if you're a C++ library that has your own custom string type, you better provide a `std::string_view` conversion operator. ","createdAt":"2024-02-09T18:26:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":5}}],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1936408885","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zbHII","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"I agree with that, I just want to make sure that we're leveraging newer Arrow tools and concepts (the C Data Interface, nanoarrow, etc) to the maximum extent possible, which also means making sure that we understand exactly what those tools have to offer and whether there is missing functionality that we should be helping to implement. The questions I'm asking are focused on filling the gaps in my understanding. \r\n\r\n### Ownership\r\n\r\nThe questions around proper ownership are ultimately quite similar to, for instance, how cuDF Python works. All objects allocated by libcudf algorithms are immediately forced to relinquish their ownership to Python objects that maintain their lifetime, and downstream algorithms then operate on views anyway so it doesn't matter that libcudf no longer owns the memory. It seems to me then that the proper signature would be `ArrowDeviceArray to_arrow_device_array(unique_ptr<column> column)` in this context because an ownership transfer would indeed be the only way to get proper interop with other Arrow consumers that are expecting [a shared ownership model like Matt indicated above](https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917490522). On the flip side, for consuming arrow objects it seems like we'd want `cudf::column_view from_arrow_device_array(ArrowDeviceArray)` because we can only ever make a view since we cannot claim sole ownership of the data. \r\n\r\nAm I missing anything here? It seems like these are the only ways to provide semantics that are consistent with the goal of minimizing data copies while also producing objects that are consistent with the Arrow spec. There is a fundamental difference between the existing implementations in libcudf and the new ones we're proposing here because the host versions always require copies whereas we want the device ones to never(? or maybe sometimes, in which we'd need different versions of the APIs.) make copies.\r\n\r\n### Object Creation\r\n\r\nThis is where I was hoping that nanoarrow could help, and thanks to @paleolimbot we have [some good examples](https://github.com/rapidsai/cudf/issues/14926#issuecomment-1931096756). The example @zeroshade [linked above](https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917221229) looks like it's on the right track, and it seems like it could be written to use nanoarrow instead of arrow APIs based on the examples @paleolimbot showed above. If not, is there missing functionality that we should be helping to add? Creating those structures with nanoarrow seems like exactly what it's intended for and would allow the resulting library to have no direct dependency on libarrow, which would be nice and probably be a template for something we'd try to do with our existing Arrow host-data interop APIs eventually.\r\n\r\n### Where does the code live\r\n\r\nBased on the above I certainly think it makes sense for libcudf to own the logic for mapping our internal representation of Arrow data into Arrow's structs. What I would hope is that it would be possible to use nanoarrow to allocate the necessary Arrow structs and then ideally to use nanoarrow APIs to populate those structs within a libcudf-specific function that knows how to translate between our types and our groupings of (Arrow-compliant) data buffers into Arrow's types and Arrows structs. But Matt brings up a few points regarding that:\r\n\r\n> The other issue I see with pushing this upstream is that the ArrowDeviceArray on the arrow side is supposed to be device agnostic. Any init function we provide would also need to have the device type passed in (we can't assume CUDA) which would also require the caller to pass in any synchronization event (if required).\r\n\r\nI seem to recall discussions around Arrow device data also discussing this and designing for the need to pass around synchronization (CUDA) events. @kkraus14 can probably say more, but isn't Arrow already designing for this in some places? Are you thinking that it's just overkill in this context?\r\n\r\n> Essentially the only thing a helper function like what you are asking could do is be a wrapper around populating a C struct, which seems a little redundant and unnecessary. At least to me.\r\n> Nanoarrow could certainly be used to simplify the creating of the ArrowArray and ArrowStruct objects though. @paleolimbot could comment further on nanoarrow for this\r\n\r\nIt seems like using nanoarrow here would at least be helpful and not redundant as a way to protect against future non-ABI-breaking changes in the spec, e.g. if arrow arrays added fields at the end of the struct (that didn't change the alignment). And that also isn't all that different from what's outline in the example above. Maybe I'm exaggerating the likelihood of meaningful changes like this though and reaching for an external tool rather than adding this code to libcudf is unnecessarily complex.","createdAt":"2024-02-09T19:29:25Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1936486920","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zbTW6","author":{"login":"paleolimbot"},"authorAssociation":"NONE","body":"> If not, is there missing functionality that we should be helping to add?\r\n\r\nIf you do end up using nanoarrow and find that there is some missing functionality, feel free to open an issue! I'm happy to implement or coordinate implementing anything that helps, or to add anything that cudf had to implement themselves that would be useful to a wider audience.\r\n\r\n>  if arrow arrays added fields at the end of the struct\r\n\r\nI'm almost positive that we've stated that we won't do that...the main thing that I think nanoarrow can help you with is populating `ArrowSchema` and `ArrowArray` structs for nested things like structs and lists in a way that makes sure they're cleaned up. It's not hard to implement that, necessarily, but the details are fiddly.","createdAt":"2024-02-09T20:09:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1936537018","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zbVa4","author":{"login":"zeroshade"},"authorAssociation":"CONTRIBUTOR","body":"> `ArrowDeviceArray to_arrow_device_array(unique_ptr<column> column)` in this context because an ownership transfer would indeed be the only way to get proper interop with other Arrow consumers that are expecting [a shared ownership model like Matt indicated above](https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917490522.)\r\n\r\nThat signature should work fine. libcudf tends to use exceptions rather than explicit status returns right? As far as handling the shared ownership model, it's also possible for the `ArrowDeviceArray` that is constructed to have a no-op for its release callback meaning that no guarantee is provided that the returned `ArrowDeviceArray` keeps anything alive. So you could have two options, one that takes a `unique_ptr<column>` and guarantees it maintains the shared ownership and one that takes a `column_view` and leaves the responsibility on the consumer to maintain the lifetime as long as is necessary.\r\n\r\n> On the flip side, for consuming arrow objects it seems like we'd want `cudf::column_view from_arrow_device_array(ArrowDeviceArray)` because we can only ever make a view since we cannot claim sole ownership of the data.\r\n\r\nWell, not exactly. When you import from an `ArrowDeviceArray` you can claim sole ownership of the arrow data in terms of ensuring the release callback inside of the `ArrowArray` structs gets called upon destruction of the corresponding columns. Currently I don't think that `cudf::column_view` provides any way to provide anything custom in the destruction, but you could return an `unique_ptr<cudf::column>` with a custom deleter that calls the release callback?\r\n\r\n> There is a fundamental difference between the existing implementations in libcudf and the new ones we're proposing here because the host versions always require copies whereas we want the device ones to never(? or maybe sometimes, in which we'd need different versions of the APIs.) make copies.\r\n\r\nYou've got it exactly correct here.\r\n\r\n> It seems like using nanoarrow here would at least be helpful and not redundant as a way to protect against future non-ABI-breaking changes in the spec, e.g. if arrow arrays added fields at the end of the struct (that didn't change the alignment). And that also isn't all that different from what's outline in the example above. \r\n\r\nUsing nanoarrow should definitely be at least helpful for constructing the C structs. I can put together an example code sample if you'd like or I can just start working on a PR for libcudf using nanoarrow (remember that nanoarrow is intended to be vendored/embedded so that would be part of the PR)","createdAt":"2024-02-09T20:16:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1936545464","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zbmpV","author":{"login":"GregoryKimball"},"authorAssociation":"CONTRIBUTOR","body":"Thank you everyone for this discussion. It seems like we are directionally aligned with a few open questions. At this point I would encourage @zeroshade to prepare a draft PR. RAPIDS is interested in adding zero-copy interop via arrow, and the Awkward Array team is interested in testing the feature (see #14959).\r\n\r\nI see two areas where perhaps we should agree before @zeroshade kicks off a PR. Please share your thoughts if there are other areas.\r\n* Agree on including `nanoarrow` and using its interop utilities. I'm in favor of refactoring our interop module to use nanoarrow, especially if it gets us closer to dropping the libarrow dependency. Please share any concerns you may have about including nanoarrow.\r\n* Agree on the design for data lifetime and ownership. Since this is ultimately a performance project, would it be more valuable to build the `from` or the `to` first? In general, I would prefer to let the application layer manage data lifetime as much as possible. I'm used to reasoning about libcudf functions which almost always make a copy - so shared ownership is unfamiliar to me.","createdAt":"2024-02-09T21:17:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1936616021","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zcNMZ","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"I think we're directionally aligned enough on both of those points that a PR is the right idea at this point. @zeroshade if you want to start one up we can discuss the ways in which you handle ownership and use nanoarrow and figure out the right balance. Thank you!","createdAt":"2024-02-10T00:36:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":3}}],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1936773913","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zzYRU","author":{"login":"zeroshade"},"authorAssociation":"CONTRIBUTOR","body":"Hey everyone, i've put up a draft PR (linked above) which provides an initial pass at a `to_arrow_schema` function to generate an `ArrowSchema` struct and a first pass at creating an `ArrowDeviceArray` using nanoarrow which takes ownership of the data (it takes in a `cudf::table&` and calls `release()` on it embedding ownership of the individual buffers into the `ArrowArray` objects themselves.\r\n\r\nI haven't added any tests yet, and still need to implement string/list/struct/dictionary but I figured it would be good to at least get eyes on what I have so far for initial opinions and to make sure I'm going in a good direction before I get too deep.","createdAt":"2024-02-13T23:29:04Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"ROCKET","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-1942848596","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps54C59_","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"I've created #15370 as a sample of how we'd wrap this C++ API up for Python consumption. It's based on the ideas in https://github.com/apache/arrow/issues/38325 although no spec has been officially accepted there yet. It does reveal an issue that we knew we were going to hit anyway elsewhere, and that was discussed to some extent earlier in this issue, namely the concerns about shared ownership. @zeroshade started discussing that a bit more in https://github.com/rapidsai/cudf/issues/14926#issuecomment-1917490522.\r\n\r\nThe current API in #15047 is fine for C++ users who want to transfer ownership of a cudf table to a (set of) arrow arrays. With that API the arrow array becomes the primary owner. However, we also have (at least) a couple of important use cases where we cannot transfer ownership in that way:\r\n1. The legacy `to_arrow` implementation copies data from a cudf table to an arrow table, and `from_arrow` does the opposite. This is the standard method by which we have handled non-I/O interchange of host data in cudf. We would like to replace that implementation with a version that uses the C Data Interface because the current version uses the Arrow library directly and we would like to not have libcudf be so tightly coupled to libarrow (see #15193). To maintain the current interface, though, we need a way to call `to_arrow_device` such that the original owning cudf table does not lose ownership because the arrow device array created will just be an intermediate state from which we cudaMemcpy the data to host arrow buffers.\r\n2. In cudf Python (#15370) we do not use any of libcudf's owning types at all. All unique_ptrs produced by libcudf are immediately released and ownership is transferred to Python objects. The reason for this is that we need cudf to work seamlessly with other Python types (arrays exposing `__cuda_array_interface__` or `__dlpack_device__` for example) that allow us to view their data without copying it. Data from libcudf and data from other types need to be interchangeable once they have been ingested by cudf's initial translation layers. If we then want to take a column of data from the Python layer and convert it to an arrow device array for consumption by other APIs, we cannot have downstream consumers of that array try to release data that we could never really provide ownership of.\r\n\r\nThe way I see it, there are a few paths forward here but only one that really seems realistic. The options I see are:\r\n1. Exposing a second version of `to_arrow_device` that takes a `table_view` and creates an ArrowDeviceArray whose release callback is a no-op. This is the most flexible solution I can think of. It allows the array to then be passed around and used normally. The caveat is that ownership must be maintained by the creator of the original data. However, this is already consistent with libcudf's lifetime semantics (everything produces unique_ptrs and it is up to the caller to make sure that table_views point to valid data while in use). This solution solves both problems 1 and 2 above. In the Python case, we can ensure proper lifetimes are handled automatically by adding references to the original owning objects to the capsules we produce. A slightly more extensive version of this would be to define a function `template<typename Deleter> to_arrow_device(table_view, Deleter)` that accepts a deleter as a callable. Then the caller would be responsible for deciding how the data is deallocated, effectively passing the buck upstream one step. In practice we'd probably end up making the deleter to do nothing for the above two examples, but this approach would allow the user more control if there were smarter things that could be done or use cases beyond these two that I'm not considering.\r\n2. Exposing a second version of `to_arrow_device` that takes a `std::shared_ptr<table>` and creates an ArrowDeviceArray whose ownership is truly shared. This approach has the benefit of creating a truly shared ownership situation. At the C++ layer the cost of this approach is minimal from the viewpoint of libcudf because we would simply have to release a unique_ptr into a shared_ptr, and this would completely solve problem 1 above because the release callback would then just delete the shared_ptr it owned and rely on shared_ptr ref counting to ensure that the data is deleted when all references are gone. Unfortunately, I see no way for this approach to solve problem 2 above since at the Python layer we never even have a `table` to begin with.\r\n3. Wait to use this from Python until all the libraries we might want to interact with also support the arrow data interface. I don't see this as a good solution though since we'd like to be able to leverage this feature now given the downstream benefits we see. This solution would resolve problem 2 but still leaves the need for a solution to problem 1.\r\n4. Stop supporting as inputs Python types that don't expose the arrow capsule interface. This option isn't really viable. If we did it, it would also only solve problem 2.\r\n\r\nOf the above solutions 1 seems like the only really viable solution to me due to the need to solve both the Python and C++ use cases. \r\n\r\nWe could also completely throw in the towel on unifying the host and device code paths, and at that point the host code paths would become simpler to handle because those always require copies and there is no question of an ownership transfer so we could handle that separately. That essentially skips over any handling of proper 0-copy device data transfers in Python, though.","createdAt":"2024-03-21T23:18:18Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-2014027647","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps58rb26","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"From a next steps perspective I think we have the APIs we need for zero-copy (or near zero) Arrow device memory to and from cuDF. The `cudf::to_arrow_device()` APIs support both `cudf::column/table` #15047 (ownership is transferred) and `cudf::column_view/table_view` #15465 (data is wrapped). The `cudf::from_arrow_device()` APIs support wrapping Arrow device memory with `cudf::column_view/table_view` (#15458) objects as well. We don't have a need to also transfer ownership from an Arrow device memory into a `cudf::column/table` since all libcudf APIs accept only views.\r\n\r\nThis leaves the existing `cudf::to_arrow()` and `cudf::from_arrow()` APIs which handle host Arrow to device cudf and device cudf to host Arrow. Therefore, I think the only remaining task is to update these APIs to use the appropriate host Arrow structures/functions.","createdAt":"2024-05-02T21:37:37Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-2091761082","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps58rkEH","author":{"login":"zeroshade"},"authorAssociation":"CONTRIBUTOR","body":"I'm currently working on the host Arrow to device cudf function and should have a PR up early next week.","createdAt":"2024-05-02T21:47:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":2}}],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-2091794695","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5_Tvdn","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Just wanted to add this link here https://github.com/rapidsai/cudf/pull/15645#issuecomment-2135491432","createdAt":"2024-05-28T18:34:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-2135881575","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5_dvFx","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"Now that #15645 is merged, the last piece is a `to_arrow_host` function (as well as potentially addressing my comment that David linked above, which would be a very nice simplification of the code if it works as expected). @zeroshade do you see anything else left on here?","createdAt":"2024-05-30T01:20:57Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14926#issuecomment-2138501489","viewerDidAuthor":false}],"createdAt":"2024-01-29T21:39:04Z","id":"I_kwDOBWUGps59jl9w","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"}],"milestone":null,"number":14926,"projectCards":[],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] Produce and Consume ArrowDeviceArray struct from cudf::table / cudf::column","updatedAt":"2024-05-30T01:20:58Z","url":"https://github.com/rapidsai/cudf/issues/14926"}
