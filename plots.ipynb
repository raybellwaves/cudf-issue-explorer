{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from langchain_experimental.agents.agent_toolkits import (\n",
    "    create_pandas_dataframe_agent,\n",
    ")\n",
    "from langchain_openai import OpenAI as OpenAI_langchain\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "df_community = pd.read_parquet(\"all_poster_commenter_details.parquet\")\n",
    "df_issues = pd.read_parquet(\"external_issue_details_with_posters_min.parquet\")\n",
    "\n",
    "\n",
    "def chat_response(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": content}],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>n_body_reactions_thumbs_up</th>\n",
       "      <th>n_body_reactions_thumbs_down</th>\n",
       "      <th>author.name</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>[FEA] Support casting operations on nested types</td>\n",
       "      <td>**Is your feature request related to a problem...</td>\n",
       "      <td>2021-01-27 14:31:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kuhu Shukla</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>[FEA] Support FIRST_VALUE and LAST_VALUE in gr...</td>\n",
       "      <td>**Is your feature request related to a problem...</td>\n",
       "      <td>2021-01-27 21:56:45+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>William Malpica</td>\n",
       "      <td>Voltron Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[BUG] dask_cudf generates files it cannot read...</td>\n",
       "      <td>**Describe the bug**\\r\\n\\r\\nSomewhere between ...</td>\n",
       "      <td>2021-03-15 21:02:56+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Graphistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>[FEA][INTERNALS] A `ColumnMeta` type to repres...</td>\n",
       "      <td>When we roundtrip a `Frame` between Python and...</td>\n",
       "      <td>2021-03-18 22:07:35+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ashwin Srinath</td>\n",
       "      <td>Voltron Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[FEA] rolling correlation</td>\n",
       "      <td>**What is your question?**\\r\\nHow to calculate...</td>\n",
       "      <td>2021-03-22 14:11:38+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>[BUG] Data corruption and strange CUDA memory ...</td>\n",
       "      <td>**Describe the bug**\\r\\nWhenever I'm trying to...</td>\n",
       "      <td>2024-05-15 10:22:32+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Taurean Dyer</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>[FEA] Potential optimization:  Batched memset.</td>\n",
       "      <td>Under some situations in the Parquet reader (p...</td>\n",
       "      <td>2024-05-17 15:43:03+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>[ENH] Use `strict=True` argument to `zip` once...</td>\n",
       "      <td>In many places in the cudf code we zip two (or...</td>\n",
       "      <td>2024-05-23 09:59:08+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lawrence Mitchell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>[FEA] Better control over the output dtype in ...</td>\n",
       "      <td>**Is your feature request related to a problem...</td>\n",
       "      <td>2024-05-24 13:37:43+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lawrence Mitchell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>For the overload of replace in libcudf where i...</td>\n",
       "      <td>For the overload of replace in libcudf where i...</td>\n",
       "      <td>2024-05-24 16:46:09+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thomas Li</td>\n",
       "      <td>@pandas-dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "107   [FEA] Support casting operations on nested types   \n",
       "108  [FEA] Support FIRST_VALUE and LAST_VALUE in gr...   \n",
       "117  [BUG] dask_cudf generates files it cannot read...   \n",
       "118  [FEA][INTERNALS] A `ColumnMeta` type to repres...   \n",
       "120                          [FEA] rolling correlation   \n",
       "..                                                 ...   \n",
       "854  [BUG] Data corruption and strange CUDA memory ...   \n",
       "858     [FEA] Potential optimization:  Batched memset.   \n",
       "866  [ENH] Use `strict=True` argument to `zip` once...   \n",
       "869  [FEA] Better control over the output dtype in ...   \n",
       "870  For the overload of replace in libcudf where i...   \n",
       "\n",
       "                                                  body  \\\n",
       "107  **Is your feature request related to a problem...   \n",
       "108  **Is your feature request related to a problem...   \n",
       "117  **Describe the bug**\\r\\n\\r\\nSomewhere between ...   \n",
       "118  When we roundtrip a `Frame` between Python and...   \n",
       "120  **What is your question?**\\r\\nHow to calculate...   \n",
       "..                                                 ...   \n",
       "854  **Describe the bug**\\r\\nWhenever I'm trying to...   \n",
       "858  Under some situations in the Parquet reader (p...   \n",
       "866  In many places in the cudf code we zip two (or...   \n",
       "869  **Is your feature request related to a problem...   \n",
       "870  For the overload of replace in libcudf where i...   \n",
       "\n",
       "                    createdAt  n_body_reactions_thumbs_up  \\\n",
       "107 2021-01-27 14:31:06+00:00                           0   \n",
       "108 2021-01-27 21:56:45+00:00                           0   \n",
       "117 2021-03-15 21:02:56+00:00                           0   \n",
       "118 2021-03-18 22:07:35+00:00                           0   \n",
       "120 2021-03-22 14:11:38+00:00                           0   \n",
       "..                        ...                         ...   \n",
       "854 2024-05-15 10:22:32+00:00                           1   \n",
       "858 2024-05-17 15:43:03+00:00                           0   \n",
       "866 2024-05-23 09:59:08+00:00                           0   \n",
       "869 2024-05-24 13:37:43+00:00                           0   \n",
       "870 2024-05-24 16:46:09+00:00                           0   \n",
       "\n",
       "     n_body_reactions_thumbs_down        author.name       company  \n",
       "107                             0        Kuhu Shukla          None  \n",
       "108                             0    William Malpica  Voltron Data  \n",
       "117                             0               None    Graphistry  \n",
       "118                             0     Ashwin Srinath  Voltron Data  \n",
       "120                             0               None          None  \n",
       "..                            ...                ...           ...  \n",
       "854                             0       Taurean Dyer          None  \n",
       "858                             0               None          None  \n",
       "866                             0  Lawrence Mitchell          None  \n",
       "869                             0  Lawrence Mitchell          None  \n",
       "870                             0          Thomas Li   @pandas-dev  \n",
       "\n",
       "[341 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "external_users = df_community[df_community[\"is_nvidia_employee\"] == False]\n",
    "company_counts = external_users['company'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "company_counts.plot(\n",
    "    kind=\"bar\",\n",
    "    ax=ax,\n",
    "    xlabel=\"Company\",\n",
    "    ylabel=\"Count\",\n",
    "    title=\"Count of companies who post and comment on the cudf GitHub repo\",\n",
    ")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Halliburton is an American multinational corporation that provides services and products to the energy industry. They are primarily involved in providing services for oil and gas exploration, drilling, and production.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response(\"What type of company is Halliburton?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response(\"What type of company is Wallmart?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_community = gpd.GeoDataFrame(\n",
    "    df_community,\n",
    "    geometry=gpd.points_from_xy(df_community[\"location_lon\"], df_community[\"location_lat\"]),\n",
    "    crs=\"epsg:4326\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_0a2fefbd6bec22c5574a56cd470e000f {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    \n",
       "                    &lt;style&gt;\n",
       "                        .foliumtooltip {\n",
       "                            \n",
       "                        }\n",
       "                       .foliumtooltip table{\n",
       "                            margin: auto;\n",
       "                        }\n",
       "                        .foliumtooltip tr{\n",
       "                            text-align: left;\n",
       "                        }\n",
       "                        .foliumtooltip th{\n",
       "                            padding: 2px; padding-right: 8px;\n",
       "                        }\n",
       "                    &lt;/style&gt;\n",
       "            \n",
       "    \n",
       "    &lt;script src=&quot;https://code.jquery.com/ui/1.12.1/jquery-ui.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script&gt;$( function() {\n",
       "        $( &quot;.maplegend&quot; ).draggable({\n",
       "            start: function (event, ui) {\n",
       "                $(this).css({\n",
       "                    right: &quot;auto&quot;,\n",
       "                    top: &quot;auto&quot;,\n",
       "                    bottom: &quot;auto&quot;\n",
       "                });\n",
       "            }\n",
       "        });\n",
       "    });\n",
       "    &lt;/script&gt;\n",
       "    &lt;style type=&#x27;text/css&#x27;&gt;\n",
       "      .maplegend {\n",
       "        position: absolute;\n",
       "        z-index:9999;\n",
       "        background-color: rgba(255, 255, 255, .8);\n",
       "        border-radius: 5px;\n",
       "        box-shadow: 0 0 15px rgba(0,0,0,0.2);\n",
       "        padding: 10px;\n",
       "        font: 12px/14px Arial, Helvetica, sans-serif;\n",
       "        right: 10px;\n",
       "        bottom: 20px;\n",
       "      }\n",
       "      .maplegend .legend-title {\n",
       "        text-align: left;\n",
       "        margin-bottom: 5px;\n",
       "        font-weight: bold;\n",
       "        }\n",
       "      .maplegend .legend-scale ul {\n",
       "        margin: 0;\n",
       "        margin-bottom: 0px;\n",
       "        padding: 0;\n",
       "        float: left;\n",
       "        list-style: none;\n",
       "        }\n",
       "      .maplegend .legend-scale ul li {\n",
       "        list-style: none;\n",
       "        margin-left: 0;\n",
       "        line-height: 16px;\n",
       "        margin-bottom: 2px;\n",
       "        }\n",
       "      .maplegend ul.legend-labels li span {\n",
       "        display: block;\n",
       "        float: left;\n",
       "        height: 14px;\n",
       "        width: 14px;\n",
       "        margin-right: 5px;\n",
       "        margin-left: 0;\n",
       "        border: 0px solid #ccc;\n",
       "        }\n",
       "      .maplegend .legend-source {\n",
       "        color: #777;\n",
       "        clear: both;\n",
       "        }\n",
       "      .maplegend a {\n",
       "        color: #777;\n",
       "        }\n",
       "    &lt;/style&gt;\n",
       "    \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "    &lt;div id=&#x27;maplegend is_nvidia_employee&#x27; class=&#x27;maplegend&#x27;&gt;\n",
       "        &lt;div class=&#x27;legend-title&#x27;&gt;is_nvidia_employee&lt;/div&gt;\n",
       "        &lt;div class=&#x27;legend-scale&#x27;&gt;\n",
       "            &lt;ul class=&#x27;legend-labels&#x27;&gt;\n",
       "                &lt;li&gt;&lt;span style=&#x27;background:#440154&#x27;&gt;&lt;/span&gt;False&lt;/li&gt;\n",
       "                &lt;li&gt;&lt;span style=&#x27;background:#fde725&#x27;&gt;&lt;/span&gt;True&lt;/li&gt;\n",
       "            &lt;/ul&gt;\n",
       "        &lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_0a2fefbd6bec22c5574a56cd470e000f&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_0a2fefbd6bec22c5574a56cd470e000f = L.map(\n",
       "                &quot;map_0a2fefbd6bec22c5574a56cd470e000f&quot;,\n",
       "                {\n",
       "                    center: [10.811485050000002, 15.2217919],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 10,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "            L.control.scale().addTo(map_0a2fefbd6bec22c5574a56cd470e000f);\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_ca6c874b0b09c879e6619d78fa5c71c0 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_ca6c874b0b09c879e6619d78fa5c71c0.addTo(map_0a2fefbd6bec22c5574a56cd470e000f);\n",
       "        \n",
       "    \n",
       "            map_0a2fefbd6bec22c5574a56cd470e000f.fitBounds(\n",
       "                [[-37.8142454, -122.674194], [59.4372155, 153.1177778]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "        function geo_json_8dac8a1437d504ef90c372fd7751e842_styler(feature) {\n",
       "            switch(feature.id) {\n",
       "                case &quot;0&quot;: case &quot;2&quot;: case &quot;3&quot;: case &quot;4&quot;: case &quot;5&quot;: case &quot;7&quot;: case &quot;10&quot;: case &quot;11&quot;: case &quot;12&quot;: case &quot;14&quot;: case &quot;17&quot;: case &quot;19&quot;: case &quot;20&quot;: case &quot;21&quot;: case &quot;22&quot;: case &quot;23&quot;: case &quot;24&quot;: case &quot;26&quot;: case &quot;28&quot;: case &quot;29&quot;: case &quot;31&quot;: case &quot;32&quot;: case &quot;33&quot;: case &quot;34&quot;: case &quot;35&quot;: case &quot;37&quot;: case &quot;41&quot;: case &quot;42&quot;: case &quot;45&quot;: case &quot;53&quot;: case &quot;56&quot;: case &quot;57&quot;: case &quot;58&quot;: case &quot;59&quot;: case &quot;60&quot;: case &quot;62&quot;: case &quot;65&quot;: case &quot;68&quot;: case &quot;69&quot;: case &quot;71&quot;: case &quot;73&quot;: case &quot;74&quot;: case &quot;75&quot;: case &quot;78&quot;: case &quot;79&quot;: case &quot;84&quot;: case &quot;86&quot;: case &quot;87&quot;: case &quot;88&quot;: case &quot;89&quot;: case &quot;90&quot;: case &quot;91&quot;: case &quot;92&quot;: case &quot;93&quot;: case &quot;94&quot;: case &quot;95&quot;: case &quot;96&quot;: case &quot;97&quot;: case &quot;99&quot;: case &quot;100&quot;: case &quot;101&quot;: case &quot;102&quot;: case &quot;106&quot;: case &quot;107&quot;: case &quot;108&quot;: case &quot;111&quot;: case &quot;112&quot;: case &quot;113&quot;: case &quot;114&quot;: case &quot;116&quot;: case &quot;117&quot;: case &quot;118&quot;: case &quot;120&quot;: case &quot;121&quot;: case &quot;122&quot;: case &quot;123&quot;: case &quot;124&quot;: case &quot;125&quot;: case &quot;126&quot;: case &quot;128&quot;: case &quot;129&quot;: case &quot;130&quot;: case &quot;132&quot;: case &quot;133&quot;: case &quot;135&quot;: case &quot;136&quot;: case &quot;138&quot;: case &quot;140&quot;: case &quot;142&quot;: case &quot;145&quot;: case &quot;146&quot;: case &quot;148&quot;: case &quot;149&quot;: case &quot;150&quot;: case &quot;151&quot;: case &quot;152&quot;: case &quot;153&quot;: case &quot;154&quot;: case &quot;157&quot;: case &quot;160&quot;: case &quot;161&quot;: case &quot;162&quot;: case &quot;163&quot;: case &quot;164&quot;: case &quot;167&quot;: case &quot;168&quot;: case &quot;171&quot;: case &quot;172&quot;: case &quot;174&quot;: case &quot;175&quot;: case &quot;176&quot;: case &quot;178&quot;: case &quot;179&quot;: case &quot;180&quot;: case &quot;181&quot;: case &quot;182&quot;: case &quot;183&quot;: case &quot;185&quot;: case &quot;186&quot;: case &quot;187&quot;: case &quot;189&quot;: case &quot;190&quot;: case &quot;191&quot;: case &quot;192&quot;: case &quot;193&quot;: case &quot;194&quot;: case &quot;195&quot;: case &quot;196&quot;: case &quot;197&quot;: case &quot;198&quot;: case &quot;199&quot;: case &quot;200&quot;: case &quot;201&quot;: case &quot;204&quot;: case &quot;205&quot;: case &quot;207&quot;: case &quot;208&quot;: case &quot;209&quot;: case &quot;211&quot;: case &quot;212&quot;: case &quot;213&quot;: case &quot;214&quot;: case &quot;216&quot;: case &quot;218&quot;: case &quot;219&quot;: case &quot;220&quot;: case &quot;221&quot;: case &quot;222&quot;: case &quot;225&quot;: case &quot;226&quot;: case &quot;227&quot;: case &quot;228&quot;: case &quot;229&quot;: case &quot;230&quot;: case &quot;232&quot;: case &quot;233&quot;: case &quot;235&quot;: case &quot;236&quot;: case &quot;237&quot;: case &quot;238&quot;: case &quot;239&quot;: case &quot;240&quot;: case &quot;242&quot;: case &quot;243&quot;: case &quot;246&quot;: case &quot;247&quot;: \n",
       "                    return {&quot;color&quot;: &quot;#440154&quot;, &quot;fillColor&quot;: &quot;#440154&quot;, &quot;fillOpacity&quot;: 0.5, &quot;weight&quot;: 2};\n",
       "                default:\n",
       "                    return {&quot;color&quot;: &quot;#fde725&quot;, &quot;fillColor&quot;: &quot;#fde725&quot;, &quot;fillOpacity&quot;: 0.5, &quot;weight&quot;: 2};\n",
       "            }\n",
       "        }\n",
       "        function geo_json_8dac8a1437d504ef90c372fd7751e842_highlighter(feature) {\n",
       "            switch(feature.id) {\n",
       "                default:\n",
       "                    return {&quot;fillOpacity&quot;: 0.75};\n",
       "            }\n",
       "        }\n",
       "        function geo_json_8dac8a1437d504ef90c372fd7751e842_pointToLayer(feature, latlng) {\n",
       "            var opts = {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 2, &quot;stroke&quot;: true, &quot;weight&quot;: 3};\n",
       "            \n",
       "            let style = geo_json_8dac8a1437d504ef90c372fd7751e842_styler(feature)\n",
       "            Object.assign(opts, style)\n",
       "            \n",
       "            return new L.CircleMarker(latlng, opts)\n",
       "        }\n",
       "\n",
       "        function geo_json_8dac8a1437d504ef90c372fd7751e842_onEachFeature(feature, layer) {\n",
       "            layer.on({\n",
       "                mouseout: function(e) {\n",
       "                    if(typeof e.target.setStyle === &quot;function&quot;){\n",
       "                            geo_json_8dac8a1437d504ef90c372fd7751e842.resetStyle(e.target);\n",
       "                    }\n",
       "                },\n",
       "                mouseover: function(e) {\n",
       "                    if(typeof e.target.setStyle === &quot;function&quot;){\n",
       "                        const highlightStyle = geo_json_8dac8a1437d504ef90c372fd7751e842_highlighter(e.target.feature)\n",
       "                        e.target.setStyle(highlightStyle);\n",
       "                    }\n",
       "                },\n",
       "            });\n",
       "        };\n",
       "        var geo_json_8dac8a1437d504ef90c372fd7751e842 = L.geoJson(null, {\n",
       "                onEachFeature: geo_json_8dac8a1437d504ef90c372fd7751e842_onEachFeature,\n",
       "            \n",
       "                style: geo_json_8dac8a1437d504ef90c372fd7751e842_styler,\n",
       "                pointToLayer: geo_json_8dac8a1437d504ef90c372fd7751e842_pointToLayer,\n",
       "        });\n",
       "\n",
       "        function geo_json_8dac8a1437d504ef90c372fd7751e842_add (data) {\n",
       "            geo_json_8dac8a1437d504ef90c372fd7751e842\n",
       "                .addData(data);\n",
       "        }\n",
       "            geo_json_8dac8a1437d504ef90c372fd7751e842_add({&quot;bbox&quot;: [-122.674194, -37.8142454, 153.1177778, 59.4372155], &quot;features&quot;: [{&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Adam@adalogics.com&quot;, &quot;followers&quot;: 38.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;AdamKorcz&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-77.0365427, 38.8950368, -77.0365427, 38.8950368], &quot;geometry&quot;: {&quot;coordinates&quot;: [-77.0365427, 38.8950368], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;1&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 29.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;AjayThorve&quot;, &quot;name&quot;: &quot;Ajay Thorve&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [1.399492, 49.6902106, 1.399492, 49.6902106], &quot;geometry&quot;: {&quot;coordinates&quot;: [1.399492, 49.6902106], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;2&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;BassemKaroui&quot;, &quot;name&quot;: &quot;Bassem Karoui&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;3&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;ChrisJar&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;4&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Argonne National Laboratory&quot;, &quot;followers&quot;: 15.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;FilippoSimini&quot;, &quot;name&quot;: &quot;Filippo Simini&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.3558473, 37.7884969, -122.3558473, 37.7884969], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.3558473, 37.7884969], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;5&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 4.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;GregoryKimball&quot;, &quot;name&quot;: &quot;Gregory Kimball&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [121.4700152, 31.2312707, 121.4700152, 31.2312707], &quot;geometry&quot;: {&quot;coordinates&quot;: [121.4700152, 31.2312707], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;6&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@nvidia&quot;, &quot;followers&quot;: 7.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;HaoYang670&quot;, &quot;name&quot;: &quot;Remzi Yang&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;7&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Iroy30&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [116.3912972, 39.9057136, 116.3912972, 39.9057136], &quot;geometry&quot;: {&quot;coordinates&quot;: [116.3912972, 39.9057136], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;8&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 4.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;JacoCheung&quot;, &quot;name&quot;: &quot;Junzhang&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [139.6987107, 35.6645956, 139.6987107, 35.6645956], &quot;geometry&quot;: {&quot;coordinates&quot;: [139.6987107, 35.6645956], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;9&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 383.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;KazukiOnodera&quot;, &quot;name&quot;: &quot;Kazuki Onodera&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;10&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Kkrishnaa&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-0.9700664, 51.4564242, -0.9700664, 51.4564242], &quot;geometry&quot;: {&quot;coordinates&quot;: [-0.9700664, 51.4564242], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;11&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Quansight&quot;, &quot;followers&quot;: 409.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;MarcoGorelli&quot;, &quot;name&quot;: &quot;Marco Edward Gorelli&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;12&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;MikeChenfu&quot;, &quot;name&quot;: &quot;Cg Lai&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;13&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;NVnavkumar&quot;, &quot;name&quot;: &quot;Navin Kumar&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;14&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Nicholas-7&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [11.5753822, 48.1371079, 11.5753822, 48.1371079], &quot;geometry&quot;: {&quot;coordinates&quot;: [11.5753822, 48.1371079], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;15&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 32.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;Nyrio&quot;, &quot;name&quot;: &quot;Louis Sugy&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;16&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;OlivierNV&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;17&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Ploverain&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;18&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA @rapidsai&quot;, &quot;followers&quot;: 21.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;PointKernel&quot;, &quot;name&quot;: &quot;Yunsong Wang&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [121.4691024, 31.2323437, 121.4691024, 31.2323437], &quot;geometry&quot;: {&quot;coordinates&quot;: [121.4691024, 31.2323437], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;19&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@aws&quot;, &quot;followers&quot;: 8.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Rhett-Ying&quot;, &quot;name&quot;: &quot;Rhett Ying&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;20&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Rridley7&quot;, &quot;name&quot;: &quot;Rodney Ridley&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;21&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 5.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Salonijain27&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;22&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 7.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;ShashaankV&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;23&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;TravisHester&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [24.7453688, 59.4372155, 24.7453688, 59.4372155], &quot;geometry&quot;: {&quot;coordinates&quot;: [24.7453688, 59.4372155], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;24&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Ullar-Kask&quot;, &quot;name&quot;: &quot;\\u00dcllar Kask&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;25&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 24.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;VibhuJawa&quot;, &quot;name&quot;: &quot;Vibhu Jawa&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;26&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 9.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Vortexx2&quot;, &quot;name&quot;: &quot;Janmey Shukla&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-88.2430932, 40.1164841, -88.2430932, 40.1164841], &quot;geometry&quot;: {&quot;coordinates&quot;: [-88.2430932, 40.1164841], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;27&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 11.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;abellina&quot;, &quot;name&quot;: &quot;Alessandro Bellina&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;28&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 398.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;aerdem4&quot;, &quot;name&quot;: &quot;Ahmet Erdem&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.4193286, 37.7792588, -122.4193286, 37.7792588], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.4193286, 37.7792588], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;29&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;MIT&quot;, &quot;followers&quot;: 11.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;alecgunny&quot;, &quot;name&quot;: &quot;Alec Gunny&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-76.9382069, 39.5162401, -76.9382069, 39.5162401], &quot;geometry&quot;: {&quot;coordinates&quot;: [-76.9382069, 39.5162401], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;30&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 5.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;alexbarghi-nv&quot;, &quot;name&quot;: &quot;Alex Barghi&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;31&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 10.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;alextxu&quot;, &quot;name&quot;: &quot;Alex Xu&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;32&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;amanlai&quot;, &quot;name&quot;: &quot;Manlai Amar&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-88.4992659, 43.1116731, -88.4992659, 43.1116731], &quot;geometry&quot;: {&quot;coordinates&quot;: [-88.4992659, 43.1116731], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;33&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 66.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;andrewseidl&quot;, &quot;name&quot;: &quot;Andrew Seidl&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-105.05208, 39.9403995, -105.05208, 39.9403995], &quot;geometry&quot;: {&quot;coordinates&quot;: [-105.05208, 39.9403995], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;34&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@Apple&quot;, &quot;followers&quot;: 1208.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;andygrove&quot;, &quot;name&quot;: &quot;Andy Grove&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-71.5369607, -16.3988667, -71.5369607, -16.3988667], &quot;geometry&quot;: {&quot;coordinates&quot;: [-71.5369607, -16.3988667], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;35&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@voltrondata &quot;, &quot;followers&quot;: 61.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;aocsa&quot;, &quot;name&quot;: &quot;Alexander Ocsa&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;36&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 100.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;aroraakshit&quot;, &quot;name&quot;: &quot;Akshit Arora&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [8.2319736, 46.7985624, 8.2319736, 46.7985624], &quot;geometry&quot;: {&quot;coordinates&quot;: [8.2319736, 46.7985624], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;37&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;The \\u00c9cole polytechnique f\\u00e9d\\u00e9rale de Lausanne&quot;, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;arpan-das-astrophysics&quot;, &quot;name&quot;: &quot;Arpan Das&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;38&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 17.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;ayushdg&quot;, &quot;name&quot;: &quot;Ayush Dattagupta&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-94.5781416, 39.100105, -94.5781416, 39.100105], &quot;geometry&quot;: {&quot;coordinates&quot;: [-94.5781416, 39.100105], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;39&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA @rapidsai&quot;, &quot;followers&quot;: 154.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;bdice&quot;, &quot;name&quot;: &quot;Bradley Dice&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-100.445882, 39.7837304, -100.445882, 39.7837304], &quot;geometry&quot;: {&quot;coordinates&quot;: [-100.445882, 39.7837304], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;40&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 524.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;beckernick&quot;, &quot;name&quot;: &quot;Nick Becker&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [8.5410422, 47.3744489, 8.5410422, 47.3744489], &quot;geometry&quot;: {&quot;coordinates&quot;: [8.5410422, 47.3744489], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;41&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Nvidia &quot;, &quot;followers&quot;: 625.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;betatim&quot;, &quot;name&quot;: &quot;Tim Head&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;42&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;blue-cat-whale&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-87.6244212, 41.8755616, -87.6244212, 41.8755616], &quot;geometry&quot;: {&quot;coordinates&quot;: [-87.6244212, 41.8755616], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;43&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 9.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;brandon-b-miller&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.674194, 45.5202471, -122.674194, 45.5202471], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.674194, 45.5202471], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;44&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 538.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;bryevdv&quot;, &quot;name&quot;: &quot;Bryan Van de Ven&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.3558473, 37.7884969, -122.3558473, 37.7884969], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.3558473, 37.7884969], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;45&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Stanford&quot;, &quot;followers&quot;: 82.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;calebwin&quot;, &quot;name&quot;: &quot;Caleb Winston&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-74.0060152, 40.7127281, -74.0060152, 40.7127281], &quot;geometry&quot;: {&quot;coordinates&quot;: [-74.0060152, 40.7127281], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;46&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@rapidsai&quot;, &quot;followers&quot;: 22.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;charlesbluca&quot;, &quot;name&quot;: &quot;Charles Blackmon-Luca&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.4193286, 37.7792588, -122.4193286, 37.7792588], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.4193286, 37.7792588], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;47&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;chinmaychandak&quot;, &quot;name&quot;: &quot;Chinmay Chandak&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-79.3839347, 43.6534817, -79.3839347, 43.6534817], &quot;geometry&quot;: {&quot;coordinates&quot;: [-79.3839347, 43.6534817], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;48&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 1709.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;codereport&quot;, &quot;name&quot;: &quot;Conor Hoekstra&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-89.3837613, 43.074761, -89.3837613, 43.074761], &quot;geometry&quot;: {&quot;coordinates&quot;: [-89.3837613, 43.074761], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;49&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 43.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;csadorf&quot;, &quot;name&quot;: &quot;Simon Adorf&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-96.6705503, 33.1031744, -96.6705503, 33.1031744], &quot;geometry&quot;: {&quot;coordinates&quot;: [-96.6705503, 33.1031744], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;50&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 32.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;cwharris&quot;, &quot;name&quot;: &quot;Christopher Harris&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;51&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@Nvidia&quot;, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;dagardner-nv&quot;, &quot;name&quot;: &quot;David Gardner&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-78.9018053, 35.996653, -78.9018053, 35.996653], &quot;geometry&quot;: {&quot;coordinates&quot;: [-78.9018053, 35.996653], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;52&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 17.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;davidwendt&quot;, &quot;name&quot;: &quot;David Wendt&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;53&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;dawilliams-nvidia&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-100.445882, 39.7837304, -100.445882, 39.7837304], &quot;geometry&quot;: {&quot;coordinates&quot;: [-100.445882, 39.7837304], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;54&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 351.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;daxiongshu&quot;, &quot;name&quot;: &quot;Jiwei Liu&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-74.0060152, 40.7127281, -74.0060152, 40.7127281], &quot;geometry&quot;: {&quot;coordinates&quot;: [-74.0060152, 40.7127281], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;56&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 11.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;divyegala&quot;, &quot;name&quot;: &quot;Divye Gala&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;57&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;dominicshanshan&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.330062, 47.6038321, -122.330062, 47.6038321], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.330062, 47.6038321], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;58&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Voltron Data&quot;, &quot;followers&quot;: 178.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;drabastomek&quot;, &quot;name&quot;: &quot;Tomek Drabas&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-74.0060152, 40.7127281, -74.0060152, 40.7127281], &quot;geometry&quot;: {&quot;coordinates&quot;: [-74.0060152, 40.7127281], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;59&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 6.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;er-eis&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-97.7436995, 30.2711286, -97.7436995, 30.2711286], &quot;geometry&quot;: {&quot;coordinates&quot;: [-97.7436995, 30.2711286], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;60&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 100.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;eriknw&quot;, &quot;name&quot;: &quot;Erik Welch&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;61&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;esnvidia&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.768053, 37.6820583, -121.768053, 37.6820583], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.768053, 37.6820583], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;62&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@LLNL&quot;, &quot;followers&quot;: 8.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;etseidl&quot;, &quot;name&quot;: &quot;Ed Seidl&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [121.4691024, 31.2323437, 121.4691024, 31.2323437], &quot;geometry&quot;: {&quot;coordinates&quot;: [121.4691024, 31.2323437], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;63&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@Nvidia&quot;, &quot;followers&quot;: 4.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;firestarman&quot;, &quot;name&quot;: &quot;Liangcai Li&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-102.4107493, 34.2331373, -102.4107493, 34.2331373], &quot;geometry&quot;: {&quot;coordinates&quot;: [-102.4107493, 34.2331373], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;64&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA @rapidsai &quot;, &quot;followers&quot;: 26.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;galipremsagar&quot;, &quot;name&quot;: &quot;GALI PREM SAGAR&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;65&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;gaohao95&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.4193286, 37.7792588, -122.4193286, 37.7792588], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.4193286, 37.7792588], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;66&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 17.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;gerashegalov&quot;, &quot;name&quot;: &quot;Gera Shegalov&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;68&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 23.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;gucasbrg&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-43.2093727, -22.9110137, -43.2093727, -22.9110137], &quot;geometry&quot;: {&quot;coordinates&quot;: [-43.2093727, -22.9110137], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;69&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Globo.com&quot;, &quot;followers&quot;: 48.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;guedes-joaofelipe&quot;, &quot;name&quot;: &quot;Joao Felipe Guedes&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [153.1177778, -28.6483333, 153.1177778, -28.6483333], &quot;geometry&quot;: {&quot;coordinates&quot;: [153.1177778, -28.6483333], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;70&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 674.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;harrism&quot;, &quot;name&quot;: &quot;Mark Harris&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.4193286, 37.7792588, -122.4193286, 37.7792588], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.4193286, 37.7792588], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;71&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 4.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;henryzhangpku&quot;, &quot;name&quot;: &quot;Henry Zhang&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.3558473, 37.7884969, -122.3558473, 37.7884969], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.3558473, 37.7884969], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;72&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 8.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;hlinsen&quot;, &quot;name&quot;: &quot;Hugo Linsenmaier&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [0.7161146725194144, 51.54063195, 0.7161146725194144, 51.54063195], &quot;geometry&quot;: {&quot;coordinates&quot;: [0.7161146725194144, 51.54063195], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;73&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Hexegic&quot;, &quot;followers&quot;: 64.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;honno&quot;, &quot;name&quot;: &quot;Matthew Barber&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-82.5508407, 35.595363, -82.5508407, 35.595363], &quot;geometry&quot;: {&quot;coordinates&quot;: [-82.5508407, 35.595363], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;74&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 16.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;hyperbolic2346&quot;, &quot;name&quot;: &quot;Mike Wilson&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;75&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;infzo&quot;, &quot;name&quot;: &quot;Liu&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;76&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia Rapids&quot;, &quot;followers&quot;: 16.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;isVoid&quot;, &quot;name&quot;: &quot;Michael Wang&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-3.5269497, 50.7255794, -3.5269497, 50.7255794], &quot;geometry&quot;: {&quot;coordinates&quot;: [-3.5269497, 50.7255794], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;77&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@nvidia&quot;, &quot;followers&quot;: 390.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;jacobtomlinson&quot;, &quot;name&quot;: &quot;Jacob Tomlinson&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;78&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 245.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;jakirkham&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;79&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 232.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;jangorecki&quot;, &quot;name&quot;: &quot;Jan Gorecki&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-72.032366, 42.3788774, -72.032366, 42.3788774], &quot;geometry&quot;: {&quot;coordinates&quot;: [-72.032366, 42.3788774], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;80&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;jarmak-nv&quot;, &quot;name&quot;: &quot;Ben Jarmak&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-84.3902644, 33.7489924, -84.3902644, 33.7489924], &quot;geometry&quot;: {&quot;coordinates&quot;: [-84.3902644, 33.7489924], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;81&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 65.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;jdye64&quot;, &quot;name&quot;: &quot;Jeremy Dyer&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-88.2430932, 40.1164841, -88.2430932, 40.1164841], &quot;geometry&quot;: {&quot;coordinates&quot;: [-88.2430932, 40.1164841], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;82&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 32.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;jlowe&quot;, &quot;name&quot;: &quot;Jason Lowe&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-93.2654692, 44.9772995, -93.2654692, 44.9772995], &quot;geometry&quot;: {&quot;coordinates&quot;: [-93.2654692, 44.9772995], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;83&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 156.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;jrhemstad&quot;, &quot;name&quot;: &quot;Jake Hemstad&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;84&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 12.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;justkrismanohar&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-97.7436995, 30.2711286, -97.7436995, 30.2711286], &quot;geometry&quot;: {&quot;coordinates&quot;: [-97.7436995, 30.2711286], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;85&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 33.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;karthikeyann&quot;, &quot;name&quot;: &quot;Karthikeyan&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;86&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;kidman99&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;87&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;kijeungchoi&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;88&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@VoltronData&quot;, &quot;followers&quot;: 100.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;kkraus14&quot;, &quot;name&quot;: &quot;Keith Kraus&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;89&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Sportmaster Ltd.&quot;, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;kolfild26&quot;, &quot;name&quot;: &quot;Andrey Komrakov&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [6.959974, 50.938361, 6.959974, 50.938361], &quot;geometry&quot;: {&quot;coordinates&quot;: [6.959974, 50.938361], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;90&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;scieneers&quot;, &quot;followers&quot;: 29.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;krlng&quot;, &quot;name&quot;: &quot;Nico Kreiling&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;91&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;kuhushukla&quot;, &quot;name&quot;: &quot;Kuhu Shukla&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-83.0466403, 42.3315509, -83.0466403, 42.3315509], &quot;geometry&quot;: {&quot;coordinates&quot;: [-83.0466403, 42.3315509], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;92&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 122.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;lidavidm&quot;, &quot;name&quot;: &quot;David Li&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-76.9369189, 38.980666, -76.9369189, 38.980666], &quot;geometry&quot;: {&quot;coordinates&quot;: [-76.9369189, 38.980666], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;93&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@pandas-dev&quot;, &quot;followers&quot;: 42.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;lithomas1&quot;, &quot;name&quot;: &quot;Thomas Li&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;94&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;liuyangc1&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;95&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Graphistry&quot;, &quot;followers&quot;: 88.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;lmeyerov&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-79.3839347, 43.6534817, -79.3839347, 43.6534817], &quot;geometry&quot;: {&quot;coordinates&quot;: [-79.3839347, 43.6534817], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;96&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;loewenm&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [103.8194992, 1.357107, 103.8194992, 1.357107], &quot;geometry&quot;: {&quot;coordinates&quot;: [103.8194992, 1.357107], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;97&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 8.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;lvxhnat&quot;, &quot;name&quot;: &quot;Yi Kuang&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.036349, 37.3688301, -122.036349, 37.3688301], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.036349, 37.3688301], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;98&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 14.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;magnatelee&quot;, &quot;name&quot;: &quot;Wonchan Lee&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [11.5753822, 48.1371079, 11.5753822, 48.1371079], &quot;geometry&quot;: {&quot;coordinates&quot;: [11.5753822, 48.1371079], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;99&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 8.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;marcimarc1&quot;, &quot;name&quot;: &quot;Marc&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-0.14405508452768728, 51.4893335, -0.14405508452768728, 51.4893335], &quot;geometry&quot;: {&quot;coordinates&quot;: [-0.14405508452768728, 51.4893335], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;100&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Microsoft&quot;, &quot;followers&quot;: 320.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;marlenezw&quot;, &quot;name&quot;: &quot;Marlene &quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;101&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 37.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;mattf&quot;, &quot;name&quot;: &quot;Matthew Farrellee&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-79.3839347, 43.6534817, -79.3839347, 43.6534817], &quot;geometry&quot;: {&quot;coordinates&quot;: [-79.3839347, 43.6534817], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;102&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 6.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;mayankanand007&quot;, &quot;name&quot;: &quot;Mayank Anand&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;103&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 11.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;mhaseeb123&quot;, &quot;name&quot;: &quot;Muhammad Haseeb&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-3.7128413, 40.4318597, -3.7128413, 40.4318597], &quot;geometry&quot;: {&quot;coordinates&quot;: [-3.7128413, 40.4318597], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;104&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 59.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;miguelusque&quot;, &quot;name&quot;: &quot;Miguel Mart\\u00ednez&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;105&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;mjsamoht&quot;, &quot;name&quot;: &quot;Thomas Meier&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;106&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;mk1102&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;107&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 7.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;mlahir1&quot;, &quot;name&quot;: &quot;Lahir Marni&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-97.7436995, 30.2711286, -97.7436995, 30.2711286], &quot;geometry&quot;: {&quot;coordinates&quot;: [-97.7436995, 30.2711286], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;108&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@coiled &quot;, &quot;followers&quot;: 1778.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;mrocklin&quot;, &quot;name&quot;: &quot;Matthew Rocklin&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;109&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@rapidsai &quot;, &quot;followers&quot;: 134.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;mroeschke&quot;, &quot;name&quot;: &quot;Matthew Roeschke&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.890591, 37.3361663, -121.890591, 37.3361663], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.890591, 37.3361663], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;110&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 13.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;mythrocks&quot;, &quot;name&quot;: &quot;MithunR&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;111&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;nasiha0&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-100.445882, 39.7837304, -100.445882, 39.7837304], &quot;geometry&quot;: {&quot;coordinates&quot;: [-100.445882, 39.7837304], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;112&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;notwopr&quot;, &quot;name&quot;: &quot;David Choi&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;113&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;nurmanmus&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;114&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;nvdbaranec&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;115&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA \\u0026 Georgia Institute of Technology&quot;, &quot;followers&quot;: 18.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;ogreen&quot;, &quot;name&quot;: &quot;Oded Green&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-3.2765753, 54.7023545, -3.2765753, 54.7023545], &quot;geometry&quot;: {&quot;coordinates&quot;: [-3.2765753, 54.7023545], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;116&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 16.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;oliverholworthy&quot;, &quot;name&quot;: &quot;Oliver Holworthy&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-63.1653789, 45.1960403, -63.1653789, 45.1960403], &quot;geometry&quot;: {&quot;coordinates&quot;: [-63.1653789, 45.1960403], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;117&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@voltrondata&quot;, &quot;followers&quot;: 583.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;paleolimbot&quot;, &quot;name&quot;: &quot;Dewey Dunnington&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;118&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;parkerzf&quot;, &quot;name&quot;: &quot;zhao feng&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-83.0007065, 39.9622601, -83.0007065, 39.9622601], &quot;geometry&quot;: {&quot;coordinates&quot;: [-83.0007065, 39.9622601], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;119&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 377.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;paulhendricks&quot;, &quot;name&quot;: &quot;Paul Hendricks&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-0.14405508452768728, 51.4893335, -0.14405508452768728, 51.4893335], &quot;geometry&quot;: {&quot;coordinates&quot;: [-0.14405508452768728, 51.4893335], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;120&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;UCL&quot;, &quot;followers&quot;: 11.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;paulsbrookes&quot;, &quot;name&quot;: &quot;Paul Brookes&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [6.129799, 49.6112768, 6.129799, 49.6112768], &quot;geometry&quot;: {&quot;coordinates&quot;: [6.129799, 49.6112768], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;121&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Luxembourg Institute of Science and Technology&quot;, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;pbruneau&quot;, &quot;name&quot;: &quot;Pierrick Bruneau&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-84.3902644, 33.7489924, -84.3902644, 33.7489924], &quot;geometry&quot;: {&quot;coordinates&quot;: [-84.3902644, 33.7489924], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;122&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Georgia Institute of Technology&quot;, &quot;followers&quot;: 104.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;pmixer&quot;, &quot;name&quot;: &quot;\\u9ec4(Hu\\u00e1ng)\\u74d2(Z\\u00e0n)&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;123&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 12.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;pvnick&quot;, &quot;name&quot;: &quot;paul&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;124&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 145.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;quasiben&quot;, &quot;name&quot;: &quot;Benjamin Zaitlen&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;125&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 97.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;randerzander&quot;, &quot;name&quot;: &quot;Randy Gelhausen&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-76.9382069, 39.5162401, -76.9382069, 39.5162401], &quot;geometry&quot;: {&quot;coordinates&quot;: [-76.9382069, 39.5162401], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;126&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;DTN&quot;, &quot;followers&quot;: 135.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;raybellwaves&quot;, &quot;name&quot;: &quot;Ray Bell&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;127&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;razajafri&quot;, &quot;name&quot;: &quot;Raza Jafri&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.330062, 47.6038321, -122.330062, 47.6038321], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.330062, 47.6038321], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;128&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@wherobots&quot;, &quot;followers&quot;: 76.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;rbavery&quot;, &quot;name&quot;: &quot;Ryan Avery&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;129&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;reinzler&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;130&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 4.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;res-life&quot;, &quot;name&quot;: &quot;Chong Gao&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-88.2430932, 40.1164841, -88.2430932, 40.1164841], &quot;geometry&quot;: {&quot;coordinates&quot;: [-88.2430932, 40.1164841], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;131&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 143.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;revans2&quot;, &quot;name&quot;: &quot;Robert (Bobby) Evans&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;132&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 8.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;rgsl888prabhu&quot;, &quot;name&quot;: &quot;Ram (Ramakrishna Prabhu)&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-94.2088172, 36.3728538, -94.2088172, 36.3728538], &quot;geometry&quot;: {&quot;coordinates&quot;: [-94.2088172, 36.3728538], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;133&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Walmart&quot;, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;richardulrich&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-88.1479278, 41.7728699, -88.1479278, 41.7728699], &quot;geometry&quot;: {&quot;coordinates&quot;: [-88.1479278, 41.7728699], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;134&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 54.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;rjzamora&quot;, &quot;name&quot;: &quot;Richard (Rick) Zamora&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;135&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 9.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;rlratzel&quot;, &quot;name&quot;: &quot;Rick Ratzel&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;136&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 14.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;rnyak&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-73.754968, 42.6511674, -73.754968, 42.6511674], &quot;geometry&quot;: {&quot;coordinates&quot;: [-73.754968, 42.6511674], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;137&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 91.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;robertmaynard&quot;, &quot;name&quot;: &quot;Robert Maynard&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;138&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;rohanpaul14855&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;139&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 5.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;rwlee&quot;, &quot;name&quot;: &quot;Ryan Lee&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;140&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;sageslayers&quot;, &quot;name&quot;: &quot;Muhammad Rizky Ferlanda&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;141&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;sameerz&quot;, &quot;name&quot;: &quot;Sameer Raheja&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [15.3381061, 49.7439047, 15.3381061, 49.7439047], &quot;geometry&quot;: {&quot;coordinates&quot;: [15.3381061, 49.7439047], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;142&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Freelancer&quot;, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;sapcode&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;143&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 13.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;sarahyurick&quot;, &quot;name&quot;: &quot;Sarah Yurick&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;144&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 117.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;seberg&quot;, &quot;name&quot;: &quot;Sebastian Berg&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;145&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 6.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;shaneding&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [8.5410422, 47.3744489, 8.5410422, 47.3744489], &quot;geometry&quot;: {&quot;coordinates&quot;: [8.5410422, 47.3744489], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;146&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;ETH Z\\u00fcrich&quot;, &quot;followers&quot;: 11.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;shriramch&quot;, &quot;name&quot;: &quot;Shriram Chandran&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-121.6846349, 37.2333253, -121.6846349, 37.2333253], &quot;geometry&quot;: {&quot;coordinates&quot;: [-121.6846349, 37.2333253], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;147&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;shrshi&quot;, &quot;name&quot;: &quot;Shruti Shivakumar&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-79.3839347, 43.6534817, -79.3839347, 43.6534817], &quot;geometry&quot;: {&quot;coordinates&quot;: [-79.3839347, 43.6534817], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;148&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Voltron Data&quot;, &quot;followers&quot;: 114.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;shwina&quot;, &quot;name&quot;: &quot;Ashwin Srinath&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;149&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;sokol11&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;150&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 102.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;sperlingxx&quot;, &quot;name&quot;: &quot;Alfred Xu&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;151&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 6.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;stephenmm&quot;, &quot;name&quot;: &quot;stephenmm&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;152&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;stucash&quot;, &quot;name&quot;: &quot;QiuxiaoMu&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.3558473, 37.7884969, -122.3558473, 37.7884969], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.3558473, 37.7884969], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;153&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 13.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;taureandyernv&quot;, &quot;name&quot;: &quot;Taurean Dyer&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-74.0060152, 40.7127281, -74.0060152, 40.7127281], &quot;geometry&quot;: {&quot;coordinates&quot;: [-74.0060152, 40.7127281], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;154&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 10.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;tgujar&quot;, &quot;name&quot;: &quot;Tanmay Gujar&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-53.2, -10.3333333, -53.2, -10.3333333], &quot;geometry&quot;: {&quot;coordinates&quot;: [-53.2, -10.3333333], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;156&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 229.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;titericz&quot;, &quot;name&quot;: &quot;Gilberto Titericz Junior&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-117.162772, 32.7174202, -117.162772, 32.7174202], &quot;geometry&quot;: {&quot;coordinates&quot;: [-117.162772, 32.7174202], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;157&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;trevorsm7&quot;, &quot;name&quot;: &quot;Trevor Smith&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;158&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 144.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;trivialfis&quot;, &quot;name&quot;: &quot;Jiaming Yuan&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-100.445882, 39.7837304, -100.445882, 39.7837304], &quot;geometry&quot;: {&quot;coordinates&quot;: [-100.445882, 39.7837304], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;159&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot; GPU-Accelerating Apache Spark @Nvidia&quot;, &quot;followers&quot;: 109.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;ttnghia&quot;, &quot;name&quot;: &quot;Nghia Truong&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [105.4554789, 11.9940018, 105.4554789, 11.9940018], &quot;geometry&quot;: {&quot;coordinates&quot;: [105.4554789, 11.9940018], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;160&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;NJUPT&quot;, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;tx2002&quot;, &quot;name&quot;: &quot;TX&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [8.4034195, 49.0068705, 8.4034195, 49.0068705], &quot;geometry&quot;: {&quot;coordinates&quot;: [8.4034195, 49.0068705], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;161&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 15.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;upsj&quot;, &quot;name&quot;: &quot;Tobias Ribizel&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;162&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 10.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;usertoroot&quot;, &quot;name&quot;: &quot;Disper&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [10.4478313, 51.1638175, 10.4478313, 51.1638175], &quot;geometry&quot;: {&quot;coordinates&quot;: [10.4478313, 51.1638175], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;163&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;TriasDev&quot;, &quot;followers&quot;: 10.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;vaceslav&quot;, &quot;name&quot;: &quot;Slava&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;164&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;vivanov10&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;165&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 6.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;vuule&quot;, &quot;name&quot;: &quot;Vukasin Milovanovic&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.4193286, 37.7792588, -122.4193286, 37.7792588], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.4193286, 37.7792588], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;166&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@rapidsai&quot;, &quot;followers&quot;: 53.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;vyasr&quot;, &quot;name&quot;: &quot;Vyas Ramasubramani&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;167&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 7.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;wbo4958&quot;, &quot;name&quot;: &quot;Bobby Wang&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [104.999927, 35.000074, 104.999927, 35.000074], &quot;geometry&quot;: {&quot;coordinates&quot;: [104.999927, 35.000074], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;168&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 35.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;weedge&quot;, &quot;name&quot;: &quot;weedge&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [121.4691024, 31.2323437, 121.4691024, 31.2323437], &quot;geometry&quot;: {&quot;coordinates&quot;: [121.4691024, 31.2323437], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;170&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@Nvidia&quot;, &quot;followers&quot;: 14.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;wjxiz1992&quot;, &quot;name&quot;: &quot;Allen Xu&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;171&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Voltron Data&quot;, &quot;followers&quot;: 13.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;wmalpica&quot;, &quot;name&quot;: &quot;William Malpica&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;172&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;xhkong&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;173&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 20.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;yidong72&quot;, &quot;name&quot;: &quot;Yi Dong&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-73.4078968, 41.1175966, -73.4078968, 41.1175966], &quot;geometry&quot;: {&quot;coordinates&quot;: [-73.4078968, 41.1175966], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;174&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@voltrondata&quot;, &quot;followers&quot;: 57.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;zeroshade&quot;, &quot;name&quot;: &quot;Matt Topol&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [77.1716954, 28.6273928, 77.1716954, 28.6273928], &quot;geometry&quot;: {&quot;coordinates&quot;: [77.1716954, 28.6273928], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;175&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;ANIKET0956&quot;, &quot;name&quot;: &quot;aniket&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;176&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Ankitkurani1997&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;177&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@nvidia&quot;, &quot;followers&quot;: 18.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;BartleyR&quot;, &quot;name&quot;: &quot;Bartley Richardson&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [10.4478313, 51.1638175, 10.4478313, 51.1638175], &quot;geometry&quot;: {&quot;coordinates&quot;: [10.4478313, 51.1638175], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;178&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Meta&quot;, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Blonck&quot;, &quot;name&quot;: &quot;Martin Marenz&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [9.1896346, 45.4641943, 9.1896346, 45.4641943], &quot;geometry&quot;: {&quot;coordinates&quot;: [9.1896346, 45.4641943], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;179&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Ipazia SpA&quot;, &quot;followers&quot;: 54.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;CarloNicolini&quot;, &quot;name&quot;: &quot;Carlo Nicolini, PhD&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;180&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 4.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Christian8491&quot;, &quot;name&quot;: &quot;Christian C\\u00f3rdova&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;181&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;FelixGonzalez42&quot;, &quot;name&quot;: &quot;FAGH_42&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;182&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Franc-Z&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;183&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Haidow&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [8.5410422, 47.3744489, 8.5410422, 47.3744489], &quot;geometry&quot;: {&quot;coordinates&quot;: [8.5410422, 47.3744489], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;184&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 36.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;LutzCle&quot;, &quot;name&quot;: &quot;Clemens Lutz&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-74.0060152, 40.7127281, -74.0060152, 40.7127281], &quot;geometry&quot;: {&quot;coordinates&quot;: [-74.0060152, 40.7127281], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;185&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Slokie LLC&quot;, &quot;followers&quot;: 5.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;M00NSH0T&quot;, &quot;name&quot;: &quot;Kyle Archie&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-105.270545, 40.0149856, -105.270545, 40.0149856], &quot;geometry&quot;: {&quot;coordinates&quot;: [-105.270545, 40.0149856], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;186&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 10.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;MananDoshi1301&quot;, &quot;name&quot;: &quot;Manan Doshi&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;187&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;ManuGraiph&quot;, &quot;name&quot;: &quot;ManuGraiph&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;188&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA&quot;, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;Matt711&quot;, &quot;name&quot;: &quot;Matthew Murray&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;189&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Pavanmahaveer7&quot;, &quot;name&quot;: &quot;Pavanmahaveer Singara&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [140.077279, 36.0833265, 140.077279, 36.0833265], &quot;geometry&quot;: {&quot;coordinates&quot;: [140.077279, 36.0833265], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;190&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Tsukuba University&quot;, &quot;followers&quot;: 7.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Pedrexus&quot;, &quot;name&quot;: &quot;Pedro Valois&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-117.162772, 32.7174202, -117.162772, 32.7174202], &quot;geometry&quot;: {&quot;coordinates&quot;: [-117.162772, 32.7174202], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;191&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 5.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;ShahRishi&quot;, &quot;name&quot;: &quot;Rishi Shah&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;192&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;SteffenRoe&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-86.9080655, 40.4258686, -86.9080655, 40.4258686], &quot;geometry&quot;: {&quot;coordinates&quot;: [-86.9080655, 40.4258686], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;193&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 9.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;SurajAralihalli&quot;, &quot;name&quot;: &quot;Suraj Aralihalli&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [100.4935089, 13.7524938, 100.4935089, 13.7524938], &quot;geometry&quot;: {&quot;coordinates&quot;: [100.4935089, 13.7524938], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;194&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;-&quot;, &quot;followers&quot;: 16.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;Touutae-lab&quot;, &quot;name&quot;: &quot;Pantakan Kanprawet&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-75.6901106, 45.4208777, -75.6901106, 45.4208777], &quot;geometry&quot;: {&quot;coordinates&quot;: [-75.6901106, 45.4208777], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;195&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Improving Ottawa&quot;, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;ZelboK&quot;, &quot;name&quot;: &quot;Danial Javady&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-100.445882, 39.7837304, -100.445882, 39.7837304], &quot;geometry&quot;: {&quot;coordinates&quot;: [-100.445882, 39.7837304], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;196&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Esri&quot;, &quot;followers&quot;: 80.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;achapkowski&quot;, &quot;name&quot;: &quot;Andrew&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;197&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 19.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;adi-kmt&quot;, &quot;name&quot;: &quot;Adithya Kamath&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;198&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;anki-code&quot;, &quot;name&quot;: &quot;Andy Kipp&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-99.1331785, 19.4326296, -99.1331785, 19.4326296], &quot;geometry&quot;: {&quot;coordinates&quot;: [-99.1331785, 19.4326296], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;199&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Bumblebee&quot;, &quot;followers&quot;: 60.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;argenisleon&quot;, &quot;name&quot;: &quot;Argenis Leon&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;200&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;bdemirjian&quot;, &quot;name&quot;: &quot;Brad Demirjian&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;201&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@voltrondata &quot;, &quot;followers&quot;: 32.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;bkietz&quot;, &quot;name&quot;: &quot;Benjamin Kietzman&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-122.036349, 37.3688301, -122.036349, 37.3688301], &quot;geometry&quot;: {&quot;coordinates&quot;: [-122.036349, 37.3688301], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;202&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 785.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;brycelelbach&quot;, &quot;name&quot;: &quot;Bryce Adelstein Lelbach aka wash&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-79.3839347, 43.6534817, -79.3839347, 43.6534817], &quot;geometry&quot;: {&quot;coordinates&quot;: [-79.3839347, 43.6534817], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;203&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 1710.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;codereport&quot;, &quot;name&quot;: &quot;Conor Hoekstra&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-79.3839347, 43.6534817, -79.3839347, 43.6534817], &quot;geometry&quot;: {&quot;coordinates&quot;: [-79.3839347, 43.6534817], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;204&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;cpowr&quot;, &quot;name&quot;: &quot;Cemre Pehlivanoglu&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-117.162772, 32.7174202, -117.162772, 32.7174202], &quot;geometry&quot;: {&quot;coordinates&quot;: [-117.162772, 32.7174202], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;205&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 4.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;dlasusa&quot;, &quot;name&quot;: &quot;Dan&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-108.0037064, 43.9296783, -108.0037064, 43.9296783], &quot;geometry&quot;: {&quot;coordinates&quot;: [-108.0037064, 43.9296783], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;207&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Solo &quot;, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;drsxr&quot;, &quot;name&quot;: &quot;Stephen B&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;208&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;edwintyh&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [4.8320114, 45.7578137, 4.8320114, 45.7578137], &quot;geometry&quot;: {&quot;coordinates&quot;: [4.8320114, 45.7578137], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;209&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;eidalex&quot;, &quot;name&quot;: &quot;eidal&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [8.5410422, 47.3744489, 8.5410422, 47.3744489], &quot;geometry&quot;: {&quot;coordinates&quot;: [8.5410422, 47.3744489], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;210&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 11.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;elstehle&quot;, &quot;name&quot;: &quot;Elias Stehle&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;211&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;entelechie&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;212&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;espackman-nv&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [144.9631732, -37.8142454, 144.9631732, -37.8142454], &quot;geometry&quot;: {&quot;coordinates&quot;: [144.9631732, -37.8142454], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;213&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Energetiq&quot;, &quot;followers&quot;: 13.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;felixmccuaig&quot;, &quot;name&quot;: &quot;Felix&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [11.0480288, 46.3144754, 11.0480288, 46.3144754], &quot;geometry&quot;: {&quot;coordinates&quot;: [11.0480288, 46.3144754], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;214&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: null, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: null, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-3.2765753, 54.7023545, -3.2765753, 54.7023545], &quot;geometry&quot;: {&quot;coordinates&quot;: [-3.2765753, 54.7023545], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;215&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@nvidia&quot;, &quot;followers&quot;: 205.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;gmarkall&quot;, &quot;name&quot;: &quot;Graham Markall&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [13.3888599, 52.5170365, 13.3888599, 52.5170365], &quot;geometry&quot;: {&quot;coordinates&quot;: [13.3888599, 52.5170365], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;216&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;DFKI&quot;, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;grv1207&quot;, &quot;name&quot;: &quot;gaurav vashisth&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-118.242766, 34.0536909, -118.242766, 34.0536909], &quot;geometry&quot;: {&quot;coordinates&quot;: [-118.242766, 34.0536909], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;217&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 363.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;hcho3&quot;, &quot;name&quot;: &quot;Philip Hyunsu Cho&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-75.3490769, 40.0373323, -75.3490769, 40.0373323], &quot;geometry&quot;: {&quot;coordinates&quot;: [-75.3490769, 40.0373323], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;218&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Villanova University&quot;, &quot;followers&quot;: 2.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;imusa007&quot;, &quot;name&quot;: &quot;Rajib Khan&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;219&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;javy-kong&quot;, &quot;name&quot;: &quot;javy&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [153.0234991, -27.4689682, 153.0234991, -27.4689682], &quot;geometry&quot;: {&quot;coordinates&quot;: [153.0234991, -27.4689682], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;220&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;jl-massey&quot;, &quot;name&quot;: &quot;JL Massey&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;221&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Princeton, IRIS-HEP, PyHEP, Scikit-HEP&quot;, &quot;followers&quot;: 289.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;jpivarski&quot;, &quot;name&quot;: &quot;Jim Pivarski&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-89.423817, 43.0020919, -89.423817, 43.0020919], &quot;geometry&quot;: {&quot;coordinates&quot;: [-89.423817, 43.0020919], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;222&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Problem Solvers Guild \\u0026 Vitro Automotive&quot;, &quot;followers&quot;: 24.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;kevinbird15&quot;, &quot;name&quot;: &quot;Kevin Bird&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [10.3333283, 55.670249, 10.3333283, 55.670249], &quot;geometry&quot;: {&quot;coordinates&quot;: [10.3333283, 55.670249], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;224&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 28.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;madsbk&quot;, &quot;name&quot;: &quot;Mads R. B. Kristensen&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-102.0077097, 23.6585116, -102.0077097, 23.6585116], &quot;geometry&quot;: {&quot;coordinates&quot;: [-102.0077097, 23.6585116], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;225&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;marcodelmoral&quot;, &quot;name&quot;: &quot;Marco Julio Del Moral Argumedo&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-79.3839347, 43.6534817, -79.3839347, 43.6534817], &quot;geometry&quot;: {&quot;coordinates&quot;: [-79.3839347, 43.6534817], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;226&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Anaconda, inc.&quot;, &quot;followers&quot;: 393.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;martindurant&quot;, &quot;name&quot;: &quot;Martin Durant&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-84.0739102, 10.2735633, -84.0739102, 10.2735633], &quot;geometry&quot;: {&quot;coordinates&quot;: [-84.0739102, 10.2735633], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;227&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 20.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;maulberto3&quot;, &quot;name&quot;: &quot;Mauricio&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;228&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;medAli-ai&quot;, &quot;name&quot;: &quot;Mohamed Ali&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;229&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;meghmak13&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;230&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;mjshare&quot;, &quot;name&quot;: null}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-77.5645607, 39.1154506, -77.5645607, 39.1154506], &quot;geometry&quot;: {&quot;coordinates&quot;: [-77.5645607, 39.1154506], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;231&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 49.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;mmccarty&quot;, &quot;name&quot;: &quot;Mike McCarty&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-0.14405508452768728, 51.4893335, -0.14405508452768728, 51.4893335], &quot;geometry&quot;: {&quot;coordinates&quot;: [-0.14405508452768728, 51.4893335], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;232&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@UKPN-DSO&quot;, &quot;followers&quot;: 8.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;niltecedu&quot;, &quot;name&quot;: &quot;Nilesh Zagade&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;233&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;onacrame&quot;, &quot;name&quot;: &quot;ClubberLang&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;234&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA&quot;, &quot;followers&quot;: 46.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;pentschev&quot;, &quot;name&quot;: &quot;Peter Andreas Entschev&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;235&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;pmattione-nvidia&quot;, &quot;name&quot;: &quot;Paul Mattione&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;236&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;pretzelpy&quot;, &quot;name&quot;: &quot;Pretzel Py&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [78.6677428, 22.3511148, 78.6677428, 22.3511148], &quot;geometry&quot;: {&quot;coordinates&quot;: [78.6677428, 22.3511148], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;237&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 0.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;rafatsiddiqui9&quot;, &quot;name&quot;: &quot;Rafat Siddiqui&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;238&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;Halliburton | Landmark Brazil&quot;, &quot;followers&quot;: 11.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;rmozart&quot;, &quot;name&quot;: &quot;Reinaldo Mozart da Gama e Silva&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [113.2737934, 23.0634463, 113.2737934, 23.0634463], &quot;geometry&quot;: {&quot;coordinates&quot;: [113.2737934, 23.0634463], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;239&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 1.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;rouniuyizu&quot;, &quot;name&quot;: &quot;W&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-97.7436995, 30.2711286, -97.7436995, 30.2711286], &quot;geometry&quot;: {&quot;coordinates&quot;: [-97.7436995, 30.2711286], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;240&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 195.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;sklam&quot;, &quot;name&quot;: &quot;Siu Kwan Lam&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [10.4478313, 51.1638175, 10.4478313, 51.1638175], &quot;geometry&quot;: {&quot;coordinates&quot;: [10.4478313, 51.1638175], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;241&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;@NVIDIA @JGU-HPC &quot;, &quot;followers&quot;: 58.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;sleeepyjack&quot;, &quot;name&quot;: &quot;Daniel J\\u00fcnger&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;242&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;STE||AR GROUP&quot;, &quot;followers&quot;: 10.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;srinivasyadav18&quot;, &quot;name&quot;: &quot;Srinivas Yadav&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-86.7742984, 36.1622767, -86.7742984, 36.1622767], &quot;geometry&quot;: {&quot;coordinates&quot;: [-86.7742984, 36.1622767], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;243&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: null, &quot;followers&quot;: 3.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;stevemarin&quot;, &quot;name&quot;: &quot;Steve Marin&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [11.5753822, 48.1371079, 11.5753822, 48.1371079], &quot;geometry&quot;: {&quot;coordinates&quot;: [11.5753822, 48.1371079], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;244&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;Nvidia&quot;, &quot;followers&quot;: 51.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;teju85&quot;, &quot;name&quot;: &quot;Thejaswi. N. S&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [-97.7436995, 30.2711286, -97.7436995, 30.2711286], &quot;geometry&quot;: {&quot;coordinates&quot;: [-97.7436995, 30.2711286], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;245&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;company&quot;: &quot;NVIDIA, Inc&quot;, &quot;followers&quot;: 567.0, &quot;is_nvidia_employee&quot;: true, &quot;login&quot;: &quot;trxcllnt&quot;, &quot;name&quot;: &quot;Paul Taylor&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [7.540121, 44.933143, 7.540121, 44.933143], &quot;geometry&quot;: {&quot;coordinates&quot;: [7.540121, 44.933143], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;246&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;china&quot;, &quot;followers&quot;: 123.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;yanxiu0614&quot;, &quot;name&quot;: &quot;yanxiu&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [120.2052342, 30.2489634, 120.2052342, 30.2489634], &quot;geometry&quot;: {&quot;coordinates&quot;: [120.2052342, 30.2489634], &quot;type&quot;: &quot;Point&quot;}, &quot;id&quot;: &quot;247&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;company&quot;: &quot;@QUANTAXIS @BLEX\\u0026Capital&quot;, &quot;followers&quot;: 1487.0, &quot;is_nvidia_employee&quot;: false, &quot;login&quot;: &quot;yutiansut&quot;, &quot;name&quot;: &quot;Vincent yu&quot;}, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
       "\n",
       "        \n",
       "    \n",
       "    geo_json_8dac8a1437d504ef90c372fd7751e842.bindTooltip(\n",
       "    function(layer){\n",
       "    let div = L.DomUtil.create(&#x27;div&#x27;);\n",
       "    \n",
       "    let handleObject = feature=&gt;typeof(feature)==&#x27;object&#x27; ? JSON.stringify(feature) : feature;\n",
       "    let fields = [&quot;login&quot;, &quot;name&quot;, &quot;followers&quot;, &quot;company&quot;, &quot;is_nvidia_employee&quot;];\n",
       "    let aliases = [&quot;login&quot;, &quot;name&quot;, &quot;followers&quot;, &quot;company&quot;, &quot;is_nvidia_employee&quot;];\n",
       "    let table = &#x27;&lt;table&gt;&#x27; +\n",
       "        String(\n",
       "        fields.map(\n",
       "        (v,i)=&gt;\n",
       "        `&lt;tr&gt;\n",
       "            &lt;th&gt;${aliases[i]}&lt;/th&gt;\n",
       "            \n",
       "            &lt;td&gt;${handleObject(layer.feature.properties[v])}&lt;/td&gt;\n",
       "        &lt;/tr&gt;`).join(&#x27;&#x27;))\n",
       "    +&#x27;&lt;/table&gt;&#x27;;\n",
       "    div.innerHTML=table;\n",
       "    \n",
       "    return div\n",
       "    }\n",
       "    ,{&quot;className&quot;: &quot;foliumtooltip&quot;, &quot;sticky&quot;: true});\n",
       "                     \n",
       "    \n",
       "            geo_json_8dac8a1437d504ef90c372fd7751e842.addTo(map_0a2fefbd6bec22c5574a56cd470e000f);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1409495d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_community[[\"login\", \"name\", \"followers\", \"company\", \"is_nvidia_employee\", \"geometry\"]].explore(column=\"is_nvidia_employee\", cmap=\"viridis\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"having predicate pushdowns such as bloom filters work as in hive to skip over sections of data on disk during the read would enable better overall performance as the data would never have to be loaded to memory and then discarded if the predicate didn't match in the row group.\\r\\n\\r\\nsupport predicate pushdown similar to what is done with hive in read_orc, primary support for bloom filter but also for sorted data as well to enable only loading relevant data to query.\\r\\n\\r\\n\\r\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issues[df_issues[\"company\"] == \"Walmart\"][\"body\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The GitHub issue in the cudf repo discusses the potential benefits of implementing predicate pushdowns, specifically using bloom filters, similar to what is done in Hive. By implementing this feature, it would improve overall performance by skipping over sections of data on disk during reads, reducing the need to load unnecessary data into memory and then discarding it if the predicate doesn't match. The issue proposes adding support for predicate pushdowns in read_orc, focusing primarily on bloom filter support but also considering support for sorted data to only load relevant data for queries.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = (\n",
    "    \"Can you summarize this GitHub issue in the cudf repo? \"\n",
    "    f\"{df_issues[df_issues['company'] == 'Walmart']['body'].values[0]}\"\n",
    ")\n",
    "chat_response(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_issues = df_issues[df_issues[\"is_nvidia_employee\"] == False]\n",
    "external_issues = external_issues.drop(columns=[\"is_nvidia_employee\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(\"external_issue_details_with_posters_min.csv\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When converting floating point types to fixed point types, the casting operations are just blindly scaling the input values and then casting to integer without checking whether the scaled values are too big to be stored in the target integer types.\\r\\n\\r\\nProbably a more proper way to do casting here is to check for underflow/overflow and nullify the output accordingly.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issues[\"body\"].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_csv_agent(\n",
    "    OpenAI_langchain(temperature=0),\n",
    "    \"external_issue_details_with_posters_min.csv\",\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens, however you requested 14638 tokens (14382 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhow many rows are there?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain/chains/base.py:600\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    601\u001b[0m         _output_key\n\u001b[1;32m    602\u001b[0m     ]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    606\u001b[0m         _output_key\n\u001b[1;32m    607\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain/chains/base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    381\u001b[0m }\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain/agents/agent.py:1433\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1433\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1441\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1442\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1443\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain/agents/agent.py:1139\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1132\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1137\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1139\u001b[0m         [\n\u001b[1;32m   1140\u001b[0m             a\n\u001b[1;32m   1141\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1142\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1143\u001b[0m                 color_mapping,\n\u001b[1;32m   1144\u001b[0m                 inputs,\n\u001b[1;32m   1145\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1146\u001b[0m                 run_manager,\n\u001b[1;32m   1147\u001b[0m             )\n\u001b[1;32m   1148\u001b[0m         ]\n\u001b[1;32m   1149\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain/agents/agent.py:1139\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1132\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1137\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1139\u001b[0m         [\n\u001b[1;32m   1140\u001b[0m             a\n\u001b[1;32m   1141\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1142\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1143\u001b[0m                 color_mapping,\n\u001b[1;32m   1144\u001b[0m                 inputs,\n\u001b[1;32m   1145\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1146\u001b[0m                 run_manager,\n\u001b[1;32m   1147\u001b[0m             )\n\u001b[1;32m   1148\u001b[0m         ]\n\u001b[1;32m   1149\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain/agents/agent.py:1167\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain/agents/agent.py:398\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m             final_output \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/runnables/base.py:2769\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2763\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   2764\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2765\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   2766\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2767\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2768\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2769\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/runnables/base.py:2756\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   2751\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2752\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2753\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2754\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2755\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2756\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2757\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2758\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   2759\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2760\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2761\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/runnables/base.py:1772\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1772\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1774\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/runnables/base.py:2720\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2711\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2712\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   2713\u001b[0m         final_pipeline,\n\u001b[1;32m   2714\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2717\u001b[0m         ),\n\u001b[1;32m   2718\u001b[0m     )\n\u001b[0;32m-> 2720\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2721\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/runnables/base.py:1148\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m final: Input\n\u001b[1;32m   1146\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ichunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# The default implementation of transform is to buffer input and\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# then call stream.\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# It'll attempt to gather all input into a single chunk using\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# the `+` operator.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;66;03m# If the input is not addable, then we'll assume that we can\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;66;03m# only operate on the last chunk,\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;66;03m# and we'll iterate until we get to the last chunk.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1157\u001b[0m         final \u001b[38;5;241m=\u001b[39m ichunk\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/runnables/base.py:4638\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   4633\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4634\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   4635\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 4638\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   4639\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   4640\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4641\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   4642\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/runnables/base.py:1166\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1163\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1166\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/language_models/llms.py:458\u001b[0m, in \u001b[0;36mBaseLLM.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    452\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[1;32m    453\u001b[0m         e,\n\u001b[1;32m    454\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[1;32m    455\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    456\u001b[0m         ),\n\u001b[1;32m    457\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_core/language_models/llms.py:442\u001b[0m, in \u001b[0;36mBaseLLM.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m generation: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    443\u001b[0m         prompt, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    444\u001b[0m     ):\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/langchain_openai/llms/base.py:244\u001b[0m, in \u001b[0;36mBaseOpenAI._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sub_prompts(params, [prompt], stop)  \u001b[38;5;66;03m# this mutates params\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    246\u001b[0m         stream_resp \u001b[38;5;241m=\u001b[39m stream_resp\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/openai/resources/completions.py:528\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Completion \u001b[38;5;241m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_of\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_env/lib/python3.10/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens, however you requested 14638 tokens (14382 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "agent.run(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'df_head': '|    |   Unnamed: 0 | title                                | body                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | createdAt            |   n_body_reactions_thumbs_up |   n_body_reactions_thumbs_down | author.name      | company   |\\n|---:|-------------:|:-------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------|-----------------------------:|-------------------------------:|:-----------------|:----------|\\n|  0 |            0 | Support for windows?                 | I use Linux at work but at home I have windows and would like to be able to run it on my main machine with conda. Currently when I run:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 2017-07-01T05:54:03Z |                           43 |                              0 | stephenmm        | nan       |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | `conda env create --name pygdf_dev --file conda_environments/testing_py35.yml`                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | I am seeing this error:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ```                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      | NoPackagesFoundError: Package missing in current win-64 channels:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      |   - libgdf_cffi >=0.1.0a1.dev                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |                      |                              |                                |                  |           |\\n|    |              |                                      | ```                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | I am hoping that this could be easily added to the win-64 channels?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|  1 |            2 | Add clang-tidy for automatic linting | <!--                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 2018-08-29T18:00:18Z |                            0 |                              0 | Andrew Seidl     | nan       |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | Thanks for opening an issue! To help the libGDF team handle your information                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      | efficiently, please first ensure that there is no other issue present that                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                      |                              |                                |                  |           |\\n|    |              |                                      | already describes the issue you have                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      | (search at https://github.com/gpuopenanalytics/libgdf/issues?&q=is%3Aissue).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | If there is no issue present please jump to a section below and delete the                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                      |                              |                                |                  |           |\\n|    |              |                                      | irrelevant one depending on whether you are:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      |  * Making a feature request.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      |  * Reporting a bug.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | For more general \"how do I do X?\" type questions, please speak visit                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      | http://gpuopenanalytics.com/#/COMMUNITY for links to Slack and Google                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                      |                              |                                |                  |           |\\n|    |              |                                      | Groups.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | -->                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ## Feature request                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | In similar spirit of #117, would be good to start using [`clang-tidy`](https://clang.llvm.org/extra/clang-tidy/) as a linter on the codebase to catch some errors, style violations, etc.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | Arrow\\'s setup would be a good place to start, which includes a [CMake target](https://github.com/apache/arrow/blob/44c2fa7d7d4e7a1c1645c85f87d557c4fc510c33/cpp/CMakeLists.txt#L552-L560) to run the tool and a [custom version of `run-clang-tidy`](https://github.com/apache/arrow/blob/master/cpp/build-support/run-clang-tidy.sh) which supports ignoring some files.                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | <!--                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | Please include details of the feature you would like to see, why you would                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                      |                              |                                |                  |           |\\n|    |              |                                      | like to see it/the use case                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | -->                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|  2 |            3 | [BUG] Long import times              | **Describe the bug**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 2019-01-04T02:46:53Z |                            0 |                              0 | Matthew Rocklin  | @coiled   |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | It takes a few seconds to import cudf today                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | **Steps/Code to reproduce bug**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ```                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      | In [1]: import numpy, pandas                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | In [2]: %time import cudf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | CPU times: user 432 ms, sys: 132 ms, total: 564 ms                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                      |                              |                                |                  |           |\\n|    |              |                                      | Wall time: 2.44 s                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      | ```                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | <details>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ```                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      | **git***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | commit ab3f45857f641548f6d64d977908075d63c193bf (HEAD -> repr-html, mrocklin/repr-html)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |                      |                              |                                |                  |           |\\n|    |              |                                      | Author: Matthew Rocklin <mrocklin@gmail.com>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      | Date:   Thu Jan 3 17:35:10 2019 -0800                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      |     Test repr for both large and small dataframes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ***OS Information***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      | DGX_NAME=\"DGX Server\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                      |                              |                                |                  |           |\\n|    |              |                                      | DGX_PRETTY_NAME=\"NVIDIA DGX Server\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      | DGX_SWBUILD_DATE=\"2018-03-20\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |                      |                              |                                |                  |           |\\n|    |              |                                      | DGX_SWBUILD_VERSION=\"3.1.6\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      | DGX_COMMIT_ID=\"1b0f58ecbf989820ce745a9e4836e1de5eea6cfd\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | DGX_SERIAL_NUMBER=QTFCOU8310024                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | DGX_OTA_VERSION=\"3.1.7\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |                      |                              |                                |                  |           |\\n|    |              |                                      | DGX_OTA_DATE=\"Thu Sep 27 20:07:53 PDT 2018\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      | DISTRIB_ID=Ubuntu                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      | DISTRIB_RELEASE=16.04                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                      |                              |                                |                  |           |\\n|    |              |                                      | DISTRIB_CODENAME=xenial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |                      |                              |                                |                  |           |\\n|    |              |                                      | DISTRIB_DESCRIPTION=\"Ubuntu 16.04.5 LTS\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | NAME=\"Ubuntu\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |                      |                              |                                |                  |           |\\n|    |              |                                      | VERSION=\"16.04.5 LTS (Xenial Xerus)\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      | ID=ubuntu                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | ID_LIKE=debian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                      |                              |                                |                  |           |\\n|    |              |                                      | PRETTY_NAME=\"Ubuntu 16.04.5 LTS\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |                      |                              |                                |                  |           |\\n|    |              |                                      | VERSION_ID=\"16.04\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                      |                              |                                |                  |           |\\n|    |              |                                      | HOME_URL=\"http://www.ubuntu.com/\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      | SUPPORT_URL=\"http://help.ubuntu.com/\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                      |                              |                                |                  |           |\\n|    |              |                                      | BUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                      |                              |                                |                  |           |\\n|    |              |                                      | VERSION_CODENAME=xenial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |                      |                              |                                |                  |           |\\n|    |              |                                      | UBUNTU_CODENAME=xenial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                      |                              |                                |                  |           |\\n|    |              |                                      | Linux dgx16 4.4.0-135-generic #161-Ubuntu SMP Mon Aug 27 10:45:01 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ***GPU Information***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                      |                              |                                |                  |           |\\n|    |              |                                      | Thu Jan  3 18:42:10 2019                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | +-----------------------------------------------------------------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | NVIDIA-SMI 396.44                 Driver Version: 396.44                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |-------------------------------+----------------------+----------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |===============================+======================+======================|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | N/A   42C    P0    59W / 300W |   1085MiB / 32510MiB |      0%      Default |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-------------------------------+----------------------+----------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | N/A   43C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-------------------------------+----------------------+----------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | N/A   42C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-------------------------------+----------------------+----------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | N/A   41C    P0    47W / 300W |     11MiB / 32510MiB |      0%      Default |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-------------------------------+----------------------+----------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | N/A   42C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-------------------------------+----------------------+----------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | N/A   42C    P0    44W / 300W |     11MiB / 32510MiB |      0%      Default |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-------------------------------+----------------------+----------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | N/A   44C    P0    45W / 300W |     11MiB / 32510MiB |      0%      Default |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-------------------------------+----------------------+----------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | N/A   41C    P0    44W / 300W |     11MiB / 32510MiB |      0%      Default |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-------------------------------+----------------------+----------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-----------------------------------------------------------------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | | Processes:                                                       GPU Memory |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |  GPU       PID   Type   Process name                             Usage      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |=============================================================================|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |    0     64394      C   ...klin/miniconda/envs/cudf_dev/bin/python   644MiB |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | |    0     65545      C   ...klin/miniconda/envs/cudf_dev/bin/python   430MiB |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | +-----------------------------------------------------------------------------+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ***CPU***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | Architecture:          x86_64                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |                      |                              |                                |                  |           |\\n|    |              |                                      | CPU op-mode(s):        32-bit, 64-bit                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                      |                              |                                |                  |           |\\n|    |              |                                      | Byte Order:            Little Endian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      | CPU(s):                80                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | On-line CPU(s) list:   0-79                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      | Thread(s) per core:    2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | Core(s) per socket:    20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | Socket(s):             2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | NUMA node(s):          2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | Vendor ID:             GenuineIntel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      | CPU family:            6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | Model:                 79                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | Model name:            Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |                      |                              |                                |                  |           |\\n|    |              |                                      | Stepping:              1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | CPU MHz:               2030.789                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | CPU max MHz:           3600.0000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |                      |                              |                                |                  |           |\\n|    |              |                                      | CPU min MHz:           1200.0000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |                      |                              |                                |                  |           |\\n|    |              |                                      | BogoMIPS:              4391.76                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                      |                              |                                |                  |           |\\n|    |              |                                      | Virtualization:        VT-x                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      | L1d cache:             32K                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                      |                              |                                |                  |           |\\n|    |              |                                      | L1i cache:             32K                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                      |                              |                                |                  |           |\\n|    |              |                                      | L2 cache:              256K                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      | L3 cache:              51200K                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |                      |                              |                                |                  |           |\\n|    |              |                                      | NUMA node0 CPU(s):     0-19,40-59                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      | NUMA node1 CPU(s):     20-39,60-79                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                      |                              |                                |                  |           |\\n|    |              |                                      | Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt ssbd ibrs ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts flush_l1d |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ***CMake***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      | /home/nfs/mrocklin/miniconda/envs/cudf_dev/bin/cmake                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      | cmake version 3.13.2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | CMake suite maintained and supported by Kitware (kitware.com/cmake).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ***g++***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | /usr/bin/g++                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      | g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      | Copyright (C) 2015 Free Software Foundation, Inc.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      | This is free software; see the source for copying conditions.  There is NO                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                      |                              |                                |                  |           |\\n|    |              |                                      | warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ***nvcc***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ***Python***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      | /home/nfs/mrocklin/miniconda/envs/cudf_dev/bin/python                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                      |                              |                                |                  |           |\\n|    |              |                                      | Python 3.5.5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ***Environment Variables***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      | PATH                            : /home/nfs/mrocklin/miniconda/envs/cudf_dev/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/bin:/home/nfs/mrocklin/.local/bin:/home/nfs/mrocklin/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games                                                                                                                                                                                                                                                                                                                                                                           |                      |                              |                                |                  |           |\\n|    |              |                                      | LD_LIBRARY_PATH                 :                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      | NUMBAPRO_NVVM                   :                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      | NUMBAPRO_LIBDEVICE              :                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      | CONDA_PREFIX                    : /home/nfs/mrocklin/miniconda/envs/cudf_dev                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      | PYTHON_PATH                     :                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ***conda packages***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                      |                              |                                |                  |           |\\n|    |              |                                      | /home/nfs/mrocklin/miniconda/bin/conda                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                      |                              |                                |                  |           |\\n|    |              |                                      | # packages in environment at /home/nfs/mrocklin/miniconda/envs/cudf_dev:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | #                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                      |                              |                                |                  |           |\\n|    |              |                                      | # Name                    Version                   Build  Channel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                      |                              |                                |                  |           |\\n|    |              |                                      | alabaster                 0.7.12                     py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | arrow-cpp                 0.10.0           py35h70250a7_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | asn1crypto                0.24.0                   py35_3    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | atomicwrites              1.2.1                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | attrs                     18.2.0                     py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | babel                     2.6.0                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | backcall                  0.1.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | blas                      1.0                         mkl                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | bleach                    3.0.2                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | bokeh                     0.13.0                   py35_0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | boost                     1.67.0           py35h3e44d54_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | boost-cpp                 1.67.0               h3a22d5f_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | bzip2                     1.0.6                h470a237_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | ca-certificates           2018.03.07                    0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | certifi                   2018.8.24                py35_1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | cffi                      1.11.5           py35h5e8e0c9_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | chardet                   3.0.4                    py35_3    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | click                     7.0                        py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | cloudpickle               0.6.1                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | cmake                     3.13.2               h011004d_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | commonmark                0.5.4                      py_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | cryptography              2.3.1            py35hdffb7b8_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | cryptography-vectors      2.3.1                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | cudatoolkit               9.2                           0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | cudf                      0.4.0+385.g81a187d           <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      | curl                      7.63.0               h74213dd_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | cython                    0.28.5           py35hfc679d8_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | cytoolz                   0.9.0.1          py35h470a237_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | dask                      1.0.0+51.g2ca205b           <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                      |                              |                                |                  |           |\\n|    |              |                                      | dask-core                 1.0.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | dask-cuda                 0.0.0                     <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | dask-cudf                 0.0.1+222.g10a9f90.dirty           <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                      |                              |                                |                  |           |\\n|    |              |                                      | decorator                 4.3.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | distributed               1.23.2                   py35_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | distributed               1.25.1+10.ga0d0ed2           <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                      |                              |                                |                  |           |\\n|    |              |                                      | docutils                  0.14                     py35_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | entrypoints               0.2.3                    py35_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | expat                     2.2.5                hfc679d8_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | future                    0.16.0                   py35_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | gmp                       6.1.2                hfc679d8_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | heapdict                  1.0.0                 py35_1000    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | icu                       58.2                 hfc679d8_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | idna                      2.7                      py35_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | imagesize                 1.1.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | intel-openmp              2019.1                      144                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | ipykernel                 5.1.0              pyh24bf2e0_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | ipython                   7.0.1            py35h24bf2e0_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | ipython_genutils          0.2.0                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | jedi                      0.12.1                   py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | jinja2                    2.10                       py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | jsonschema                2.6.0                    py35_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | jupyter_client            5.2.4                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | jupyter_core              4.4.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | krb5                      1.16.2               hbb41f41_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | libcurl                   7.63.0               hbdb9355_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | libedit                   3.1.20170329         haf1bffa_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | libffi                    3.2.1                hfc679d8_5    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | libgcc-ng                 8.2.0                hdf63c60_1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | libgdf-cffi               0.4.0                     <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | libgfortran-ng            7.2.0                hdf63c60_3    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | librmm-cffi               0.4.0                     <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | libsodium                 1.0.16               h470a237_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | libssh2                   1.8.0                h5b517e9_3    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | libstdcxx-ng              8.2.0                hdf63c60_1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | libuv                     1.24.1               h470a237_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | llvmlite                  0.27.0           py35hf484d3e_0    numba                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                      |                              |                                |                  |           |\\n|    |              |                                      | Markdown                  2.6.11                    <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | markupsafe                1.0              py35h470a237_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | mistune                   0.8.3            py35h470a237_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | mkl                       2018.0.3                      1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | mkl_fft                   1.0.9                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | mkl_random                1.0.1                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | more-itertools            4.3.0                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | msgpack-python            0.5.6            py35h2d50403_3    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | nbconvert                 5.3.1                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | nbformat                  4.4.0                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | ncurses                   6.1                  hfc679d8_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | notebook                  5.7.0                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | numba                     0.42.0          np115py35hf484d3e_0    numba                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                      |                              |                                |                  |           |\\n|    |              |                                      | numpy                     1.15.2           py35h1d66e8a_0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | numpy-base                1.15.2           py35h81de0dd_0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | numpydoc                  0.8.0                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | nvstrings                 0.1.0            cuda9.2_py35_0    nvidia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      | openssl                   1.0.2p               h14c3975_0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | packaging                 18.0                       py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pandas                    0.20.3                   py35_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pandoc                    2.5                           0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pandocfilters             1.4.2                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | parquet-cpp               1.5.0.pre            h83d4a3d_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | parso                     0.3.1                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pathlib2                  2.3.2                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pexpect                   4.6.0                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pickleshare               0.7.5                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pip                       18.0                  py35_1001    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pluggy                    0.8.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | prometheus_client         0.5.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | prompt_toolkit            2.0.7                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | psutil                    5.4.7            py35h470a237_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | ptyprocess                0.6.0                 py35_1000    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | py                        1.7.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pyarrow                   0.10.0           py35hfc679d8_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pycparser                 2.19                       py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pygments                  2.3.1                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pyopenssl                 18.0.0                   py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pyparsing                 2.3.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pysocks                   1.6.8                    py35_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pytest                    4.0.2                     <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | pytest                    3.8.1                    py35_0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | python                    3.5.5                h5001a0f_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | python-dateutil           2.7.5                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pytz                      2018.7                     py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pyyaml                    3.13             py35h470a237_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | pyzmq                     17.1.2           py35hae99301_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | readline                  7.0                  haf1bffa_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | recommonmark              0.4.0                      py_2    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | requests                  2.19.1                   py35_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | rhash                     1.3.6                h470a237_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | send2trash                1.5.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | setuptools                40.4.3                   py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | simplegeneric             0.8.1                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | six                       1.11.0                   py35_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | snowballstemmer           1.2.1                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | sortedcontainers          2.1.0                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | sphinx                    1.8.1                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | sphinx-markdown-tables    0.0.9                     <pip>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                      |                              |                                |                  |           |\\n|    |              |                                      | sphinx_rtd_theme          0.4.2                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | sphinxcontrib-websupport  1.1.0                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | sqlite                    3.26.0               hb1c47c0_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | tblib                     1.3.2                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | terminado                 0.8.1                    py35_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | testpath                  0.3.1                    py35_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | tk                        8.6.9                ha92aebf_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | toolz                     0.9.0                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | tornado                   5.1.1            py35h470a237_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | traitlets                 4.3.2                    py35_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | urllib3                   1.23                     py35_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | wcwidth                   0.1.7                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | webencodings              0.5.1                      py_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | wheel                     0.32.0                py35_1000    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | xz                        5.2.4                h470a237_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | yaml                      0.1.7                h470a237_1    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | zeromq                    4.2.5                hfc679d8_6    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | zict                      0.1.3                      py_0    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | zlib                      1.2.11               h470a237_3    conda-forge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                      |                              |                                |                  |           |\\n|    |              |                                      | ```                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | </details>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                      |                              |                                |                  |           |\\n|  3 |            9 | [FEA] DatetimeIndex Frequency/TZ     | In Pandas, DatetimeIndexes can report back the frequency and timezone.  I think this would be useful/nice for cuDF but it\\'s not a high priority at all.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 2019-06-06T16:09:44Z |                            0 |                              0 | Benjamin Zaitlen | nan       |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | ```                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      | In [70]: pd.date_range(end=\\'1/1/2018\\', periods=8).freq                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                      |                              |                                |                  |           |\\n|    |              |                                      | Out[70]: <Day>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                      |                              |                                |                  |           |\\n|    |              |                                      | ```                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                      |                              |                                |                  |           |\\n|    |              |                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                      |                              |                                |                  |           |\\n|    |              |                                      | For more info on these extended dtypes: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#period-dtypes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |                      |                              |                                |                  |           |\\n|  4 |           11 | [FEA]Add merge_asof to cudf          | Please add merge_asof to cudf to match pandas merge_asof capabilities. Thanks!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | 2019-07-12T17:04:59Z |                            0 |                              0 | nan              | nan       |', 'tools': 'python_repl_ast - A Python shell. Use this to execute python commands. Input should be a valid python command. When using this tool, sometimes output is abbreviated - make sure it does not look abbreviated before using it in your answer.', 'tool_names': 'python_repl_ast'}, template='\\nYou are working with a pandas dataframe in Python. The name of the dataframe is `df`.\\nYou should use the tools below to answer the question posed of you:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\n\\nThis is the result of `print(df.head())`:\\n{df_head}\\n\\nBegin!\\nQuestion: {input}\\n{agent_scratchpad}')\n",
       "| RunnableBinding(bound=OpenAI(client=<openai.resources.completions.Completions object at 0x146675840>, async_client=<openai.resources.completions.AsyncCompletions object at 0x1468dbdf0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_organization='org-gW5fetDfRCugPniqD9lfqnqL', openai_proxy=''), kwargs={'stop': ['\\nObservation']})\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=['input'], return_keys_arg=['output'], stream_runnable=True), tools=[PythonAstREPLTool(locals={'df':      Unnamed: 0                                              title  \\\n",
       "0             0                              Support for windows?    \n",
       "1             2               Add clang-tidy for automatic linting   \n",
       "2             3                            [BUG] Long import times   \n",
       "3             9                   [FEA] DatetimeIndex Frequency/TZ   \n",
       "4            11                        [FEA]Add merge_asof to cudf   \n",
       "..          ...                                                ...   \n",
       "376         854  [BUG] Data corruption and strange CUDA memory ...   \n",
       "377         858     [FEA] Potential optimization:  Batched memset.   \n",
       "378         866  [ENH] Use `strict=True` argument to `zip` once...   \n",
       "379         869  [FEA] Better control over the output dtype in ...   \n",
       "380         870  For the overload of replace in libcudf where i...   \n",
       "\n",
       "                                                  body             createdAt  \\\n",
       "0    I use Linux at work but at home I have windows...  2017-07-01T05:54:03Z   \n",
       "1    <!--\\r\\n\\r\\nThanks for opening an issue! To he...  2018-08-29T18:00:18Z   \n",
       "2    **Describe the bug**\\r\\n\\r\\nIt takes a few sec...  2019-01-04T02:46:53Z   \n",
       "3    In Pandas, DatetimeIndexes can report back the...  2019-06-06T16:09:44Z   \n",
       "4    Please add merge_asof to cudf to match pandas ...  2019-07-12T17:04:59Z   \n",
       "..                                                 ...                   ...   \n",
       "376  **Describe the bug**\\r\\nWhenever I'm trying to...  2024-05-15T10:22:32Z   \n",
       "377  Under some situations in the Parquet reader (p...  2024-05-17T15:43:03Z   \n",
       "378  In many places in the cudf code we zip two (or...  2024-05-23T09:59:08Z   \n",
       "379  **Is your feature request related to a problem...  2024-05-24T13:37:43Z   \n",
       "380  For the overload of replace in libcudf where i...  2024-05-24T16:46:09Z   \n",
       "\n",
       "     n_body_reactions_thumbs_up  n_body_reactions_thumbs_down  \\\n",
       "0                            43                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "..                          ...                           ...   \n",
       "376                           1                             0   \n",
       "377                           0                             0   \n",
       "378                           0                             0   \n",
       "379                           0                             0   \n",
       "380                           0                             0   \n",
       "\n",
       "           author.name      company  \n",
       "0            stephenmm          NaN  \n",
       "1         Andrew Seidl          NaN  \n",
       "2      Matthew Rocklin     @coiled   \n",
       "3     Benjamin Zaitlen          NaN  \n",
       "4                  NaN          NaN  \n",
       "..                 ...          ...  \n",
       "376       Taurean Dyer          NaN  \n",
       "377                NaN          NaN  \n",
       "378  Lawrence Mitchell          NaN  \n",
       "379  Lawrence Mitchell          NaN  \n",
       "380          Thomas Li  @pandas-dev  \n",
       "\n",
       "[381 rows x 8 columns]})])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=': 0\\ntitle: Support for windows?\\nbody: I use Linux at work but at home I have windows and would like to be able to run it on my main machine with conda. Currently when I run:\\r\\n\\r\\n`conda env create --name pygdf_dev --file conda_environments/testing_py35.yml`\\r\\n\\r\\nI am seeing this error:\\r\\n\\r\\n```\\r\\nNoPackagesFoundError: Package missing in current win-64 channels:\\r\\n  - libgdf_cffi >=0.1.0a1.dev\\r\\n```\\r\\n\\r\\nI am hoping that this could be easily added to the win-64 channels?\\ncreatedAt: 2017-07-01T05:54:03Z\\nn_body_reactions_thumbs_up: 43\\nn_body_reactions_thumbs_down: 0\\nauthor.name: stephenmm\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 0}),\n",
       " Document(page_content=': 2\\ntitle: Add clang-tidy for automatic linting\\nbody: <!--\\r\\n\\r\\nThanks for opening an issue! To help the libGDF team handle your information\\r\\nefficiently, please first ensure that there is no other issue present that\\r\\nalready describes the issue you have\\r\\n(search at https://github.com/gpuopenanalytics/libgdf/issues?&q=is%3Aissue).\\r\\n\\r\\nIf there is no issue present please jump to a section below and delete the\\r\\nirrelevant one depending on whether you are:\\r\\n\\r\\n * Making a feature request.\\r\\n * Reporting a bug.\\r\\n\\r\\nFor more general \"how do I do X?\" type questions, please speak visit\\r\\nhttp://gpuopenanalytics.com/#/COMMUNITY for links to Slack and Google\\r\\nGroups.\\r\\n\\r\\n-->\\r\\n\\r\\n## Feature request\\r\\n\\r\\nIn similar spirit of #117, would be good to start using [`clang-tidy`](https://clang.llvm.org/extra/clang-tidy/) as a linter on the codebase to catch some errors, style violations, etc.\\r\\n\\r\\nArrow\\'s setup would be a good place to start, which includes a [CMake target](https://github.com/apache/arrow/blob/44c2fa7d7d4e7a1c1645c85f87d557c4fc510c33/cpp/CMakeLists.txt#L552-L560) to run the tool and a [custom version of `run-clang-tidy`](https://github.com/apache/arrow/blob/master/cpp/build-support/run-clang-tidy.sh) which supports ignoring some files.\\r\\n\\r\\n<!--\\r\\n\\r\\nPlease include details of the feature you would like to see, why you would\\r\\nlike to see it/the use case\\r\\n\\r\\n-->\\ncreatedAt: 2018-08-29T18:00:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Andrew Seidl\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 1}),\n",
       " Document(page_content=': 3\\ntitle: [BUG] Long import times\\nbody: **Describe the bug**\\r\\n\\r\\nIt takes a few seconds to import cudf today\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\n```\\r\\nIn [1]: import numpy, pandas\\r\\n\\r\\nIn [2]: %time import cudf\\r\\nCPU times: user 432 ms, sys: 132 ms, total: 564 ms\\r\\nWall time: 2.44 s\\r\\n```\\r\\n\\r\\n<details>\\r\\n\\r\\n```\\r\\n**git***\\r\\ncommit ab3f45857f641548f6d64d977908075d63c193bf (HEAD -> repr-html, mrocklin/repr-html)\\r\\nAuthor: Matthew Rocklin <mrocklin@gmail.com>\\r\\nDate:   Thu Jan 3 17:35:10 2019 -0800\\r\\n\\r\\n    Test repr for both large and small dataframes\\r\\n\\r\\n***OS Information***\\r\\nDGX_NAME=\"DGX Server\"\\r\\nDGX_PRETTY_NAME=\"NVIDIA DGX Server\"\\r\\nDGX_SWBUILD_DATE=\"2018-03-20\"\\r\\nDGX_SWBUILD_VERSION=\"3.1.6\"\\r\\nDGX_COMMIT_ID=\"1b0f58ecbf989820ce745a9e4836e1de5eea6cfd\"\\r\\nDGX_SERIAL_NUMBER=QTFCOU8310024\\r\\n\\r\\nDGX_OTA_VERSION=\"3.1.7\"\\r\\nDGX_OTA_DATE=\"Thu Sep 27 20:07:53 PDT 2018\"\\r\\nDISTRIB_ID=Ubuntu\\r\\nDISTRIB_RELEASE=16.04\\r\\nDISTRIB_CODENAME=xenial\\r\\nDISTRIB_DESCRIPTION=\"Ubuntu 16.04.5 LTS\"\\r\\nNAME=\"Ubuntu\"\\r\\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\\r\\nID=ubuntu\\r\\nID_LIKE=debian\\r\\nPRETTY_NAME=\"Ubuntu 16.04.5 LTS\"\\r\\nVERSION_ID=\"16.04\"\\r\\nHOME_URL=\"http://www.ubuntu.com/\"\\r\\nSUPPORT_URL=\"http://help.ubuntu.com/\"\\r\\nBUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\\r\\nVERSION_CODENAME=xenial\\r\\nUBUNTU_CODENAME=xenial\\r\\nLinux dgx16 4.4.0-135-generic #161-Ubuntu SMP Mon Aug 27 10:45:01 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\\r\\n\\r\\n***GPU Information***\\r\\nThu Jan  3 18:42:10 2019\\r\\n+-----------------------------------------------------------------------------+\\r\\n| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\\r\\n|-------------------------------+----------------------+----------------------+\\r\\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n|===============================+======================+======================|\\r\\n|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\\r\\n| N/A   42C    P0    59W / 300W |   1085MiB / 32510MiB |      0%      Default |\\r\\n+-------------------------------+----------------------+----------------------+\\r\\n|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\\r\\n| N/A   43C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |\\r\\n+-------------------------------+----------------------+----------------------+\\r\\n|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\\r\\n| N/A   42C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |\\r\\n+-------------------------------+----------------------+----------------------+\\r\\n|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\\r\\n| N/A   41C    P0    47W / 300W |     11MiB / 32510MiB |      0%      Default |\\r\\n+-------------------------------+----------------------+----------------------+\\r\\n|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\\r\\n| N/A   42C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |\\r\\n+-------------------------------+----------------------+----------------------+\\r\\n|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\\r\\n| N/A   42C    P0    44W / 300W |     11MiB / 32510MiB |      0%      Default |\\r\\n+-------------------------------+----------------------+----------------------+\\r\\n|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\\r\\n| N/A   44C    P0    45W / 300W |     11MiB / 32510MiB |      0%      Default |\\r\\n+-------------------------------+----------------------+----------------------+\\r\\n|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\\r\\n| N/A   41C    P0    44W / 300W |     11MiB / 32510MiB |      0%      Default |\\r\\n+-------------------------------+----------------------+----------------------+\\r\\n\\r\\n+-----------------------------------------------------------------------------+\\r\\n| Processes:                                                       GPU Memory |\\r\\n|  GPU       PID   Type   Process name                             Usage      |\\r\\n|=============================================================================|\\r\\n|    0     64394      C   ...klin/miniconda/envs/cudf_dev/bin/python   644MiB |\\r\\n|    0     65545      C   ...klin/miniconda/envs/cudf_dev/bin/python   430MiB |\\r\\n+-----------------------------------------------------------------------------+\\r\\n\\r\\n***CPU***\\r\\nArchitecture:          x86_64\\r\\nCPU op-mode(s):        32-bit, 64-bit\\r\\nByte Order:            Little Endian\\r\\nCPU(s):                80\\r\\nOn-line CPU(s) list:   0-79\\r\\nThread(s) per core:    2\\r\\nCore(s) per socket:    20\\r\\nSocket(s):             2\\r\\nNUMA node(s):          2\\r\\nVendor ID:             GenuineIntel\\r\\nCPU family:            6\\r\\nModel:                 79\\r\\nModel name:            Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz\\r\\nStepping:              1\\r\\nCPU MHz:               2030.789\\r\\nCPU max MHz:           3600.0000\\r\\nCPU min MHz:           1200.0000\\r\\nBogoMIPS:              4391.76\\r\\nVirtualization:        VT-x\\r\\nL1d cache:             32K\\r\\nL1i cache:             32K\\r\\nL2 cache:              256K\\r\\nL3 cache:              51200K\\r\\nNUMA node0 CPU(s):     0-19,40-59\\r\\nNUMA node1 CPU(s):     20-39,60-79\\r\\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt ssbd ibrs ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts flush_l1d\\r\\n\\r\\n***CMake***\\r\\n/home/nfs/mrocklin/miniconda/envs/cudf_dev/bin/cmake\\r\\ncmake version 3.13.2\\r\\n\\r\\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\\r\\n\\r\\n***g++***\\r\\n/usr/bin/g++\\r\\ng++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\\r\\nCopyright (C) 2015 Free Software Foundation, Inc.\\r\\nThis is free software; see the source for copying conditions.  There is NO\\r\\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n\\r\\n\\r\\n***nvcc***\\r\\n\\r\\n***Python***\\r\\n/home/nfs/mrocklin/miniconda/envs/cudf_dev/bin/python\\r\\nPython 3.5.5\\r\\n\\r\\n***Environment Variables***\\r\\nPATH                            : /home/nfs/mrocklin/miniconda/envs/cudf_dev/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/bin:/home/nfs/mrocklin/.local/bin:/home/nfs/mrocklin/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\\r\\nLD_LIBRARY_PATH                 :\\r\\nNUMBAPRO_NVVM                   :\\r\\nNUMBAPRO_LIBDEVICE              :\\r\\nCONDA_PREFIX                    : /home/nfs/mrocklin/miniconda/envs/cudf_dev\\r\\nPYTHON_PATH                     :\\r\\n\\r\\n***conda packages***\\r\\n/home/nfs/mrocklin/miniconda/bin/conda\\r\\n# packages in environment at /home/nfs/mrocklin/miniconda/envs/cudf_dev:\\r\\n#\\r\\n# Name                    Version                   Build  Channel\\r\\nalabaster                 0.7.12                     py_0    conda-forge\\r\\narrow-cpp                 0.10.0           py35h70250a7_0    conda-forge\\r\\nasn1crypto                0.24.0                   py35_3    conda-forge\\r\\natomicwrites              1.2.1                      py_0    conda-forge\\r\\nattrs                     18.2.0                     py_0    conda-forge\\r\\nbabel                     2.6.0                      py_1    conda-forge\\r\\nbackcall                  0.1.0                      py_0    conda-forge\\r\\nblas                      1.0                         mkl\\r\\nbleach                    3.0.2                      py_1    conda-forge\\r\\nbokeh                     0.13.0                   py35_0\\r\\nboost                     1.67.0           py35h3e44d54_0    conda-forge\\r\\nboost-cpp                 1.67.0               h3a22d5f_0    conda-forge\\r\\nbzip2                     1.0.6                h470a237_2    conda-forge\\r\\nca-certificates           2018.03.07                    0\\r\\ncertifi                   2018.8.24                py35_1\\r\\ncffi                      1.11.5           py35h5e8e0c9_1    conda-forge\\r\\nchardet                   3.0.4                    py35_3    conda-forge\\r\\nclick                     7.0                        py_0    conda-forge\\r\\ncloudpickle               0.6.1                      py_0    conda-forge\\r\\ncmake                     3.13.2               h011004d_0    conda-forge\\r\\ncommonmark                0.5.4                      py_2    conda-forge\\r\\ncryptography              2.3.1            py35hdffb7b8_0    conda-forge\\r\\ncryptography-vectors      2.3.1                    py35_0    conda-forge\\r\\ncudatoolkit               9.2                           0\\r\\ncudf                      0.4.0+385.g81a187d           <pip>\\r\\ncurl                      7.63.0               h74213dd_0    conda-forge\\r\\ncython                    0.28.5           py35hfc679d8_0    conda-forge\\r\\ncytoolz                   0.9.0.1          py35h470a237_0    conda-forge\\r\\ndask                      1.0.0+51.g2ca205b           <pip>\\r\\ndask-core                 1.0.0                      py_0    conda-forge\\r\\ndask-cuda                 0.0.0                     <pip>\\r\\ndask-cudf                 0.0.1+222.g10a9f90.dirty           <pip>\\r\\ndecorator                 4.3.0                      py_0    conda-forge\\r\\ndistributed               1.23.2                   py35_1    conda-forge\\r\\ndistributed               1.25.1+10.ga0d0ed2           <pip>\\r\\ndocutils                  0.14                     py35_1    conda-forge\\r\\nentrypoints               0.2.3                    py35_2    conda-forge\\r\\nexpat                     2.2.5                hfc679d8_2    conda-forge\\r\\nfuture                    0.16.0                   py35_2    conda-forge\\r\\ngmp                       6.1.2                hfc679d8_0    conda-forge\\r\\nheapdict                  1.0.0                 py35_1000    conda-forge\\r\\nicu                       58.2                 hfc679d8_0    conda-forge\\r\\nidna                      2.7                      py35_2    conda-forge\\r\\nimagesize                 1.1.0                      py_0    conda-forge\\r\\nintel-openmp              2019.1                      144\\r\\nipykernel                 5.1.0              pyh24bf2e0_0    conda-forge\\r\\nipython                   7.0.1            py35h24bf2e0_0    conda-forge\\r\\nipython_genutils          0.2.0                      py_1    conda-forge\\r\\njedi                      0.12.1                   py35_0    conda-forge\\r\\njinja2                    2.10                       py_1    conda-forge\\r\\njsonschema                2.6.0                    py35_2    conda-forge\\r\\njupyter_client            5.2.4                      py_0    conda-forge\\r\\njupyter_core              4.4.0                      py_0    conda-forge\\r\\nkrb5                      1.16.2               hbb41f41_0    conda-forge\\r\\nlibcurl                   7.63.0               hbdb9355_0    conda-forge\\r\\nlibedit                   3.1.20170329         haf1bffa_1    conda-forge\\r\\nlibffi                    3.2.1                hfc679d8_5    conda-forge\\r\\nlibgcc-ng                 8.2.0                hdf63c60_1\\r\\nlibgdf-cffi               0.4.0                     <pip>\\r\\nlibgfortran-ng            7.2.0                hdf63c60_3    conda-forge\\r\\nlibrmm-cffi               0.4.0                     <pip>\\r\\nlibsodium                 1.0.16               h470a237_1    conda-forge\\r\\nlibssh2                   1.8.0                h5b517e9_3    conda-forge\\r\\nlibstdcxx-ng              8.2.0                hdf63c60_1\\r\\nlibuv                     1.24.1               h470a237_0    conda-forge\\r\\nllvmlite                  0.27.0           py35hf484d3e_0    numba\\r\\nMarkdown                  2.6.11                    <pip>\\r\\nmarkupsafe                1.0              py35h470a237_1    conda-forge\\r\\nmistune                   0.8.3            py35h470a237_2    conda-forge\\r\\nmkl                       2018.0.3                      1\\r\\nmkl_fft                   1.0.9                    py35_0    conda-forge\\r\\nmkl_random                1.0.1                    py35_0    conda-forge\\r\\nmore-itertools            4.3.0                    py35_0    conda-forge\\r\\nmsgpack-python            0.5.6            py35h2d50403_3    conda-forge\\r\\nnbconvert                 5.3.1                      py_1    conda-forge\\r\\nnbformat                  4.4.0                      py_1    conda-forge\\r\\nncurses                   6.1                  hfc679d8_2    conda-forge\\r\\nnotebook                  5.7.0                    py35_0    conda-forge\\r\\nnumba                     0.42.0          np115py35hf484d3e_0    numba\\r\\nnumpy                     1.15.2           py35h1d66e8a_0\\r\\nnumpy-base                1.15.2           py35h81de0dd_0\\r\\nnumpydoc                  0.8.0                      py_1    conda-forge\\r\\nnvstrings                 0.1.0            cuda9.2_py35_0    nvidia\\r\\nopenssl                   1.0.2p               h14c3975_0\\r\\npackaging                 18.0                       py_0    conda-forge\\r\\npandas                    0.20.3                   py35_1    conda-forge\\r\\npandoc                    2.5                           0    conda-forge\\r\\npandocfilters             1.4.2                      py_1    conda-forge\\r\\nparquet-cpp               1.5.0.pre            h83d4a3d_0    conda-forge\\r\\nparso                     0.3.1                      py_0    conda-forge\\r\\npathlib2                  2.3.2                    py35_0    conda-forge\\r\\npexpect                   4.6.0                    py35_0    conda-forge\\r\\npickleshare               0.7.5                    py35_0    conda-forge\\r\\npip                       18.0                  py35_1001    conda-forge\\r\\npluggy                    0.8.0                      py_0    conda-forge\\r\\nprometheus_client         0.5.0                      py_0    conda-forge\\r\\nprompt_toolkit            2.0.7                      py_0    conda-forge\\r\\npsutil                    5.4.7            py35h470a237_1    conda-forge\\r\\nptyprocess                0.6.0                 py35_1000    conda-forge\\r\\npy                        1.7.0                      py_0    conda-forge\\r\\npyarrow                   0.10.0           py35hfc679d8_0    conda-forge\\r\\npycparser                 2.19                       py_0    conda-forge\\r\\npygments                  2.3.1                      py_0    conda-forge\\r\\npyopenssl                 18.0.0                   py35_0    conda-forge\\r\\npyparsing                 2.3.0                      py_0    conda-forge\\r\\npysocks                   1.6.8                    py35_2    conda-forge\\r\\npytest                    4.0.2                     <pip>\\r\\npytest                    3.8.1                    py35_0\\r\\npython                    3.5.5                h5001a0f_2    conda-forge\\r\\npython-dateutil           2.7.5                      py_0    conda-forge\\r\\npytz                      2018.7                     py_0    conda-forge\\r\\npyyaml                    3.13             py35h470a237_1    conda-forge\\r\\npyzmq                     17.1.2           py35hae99301_0    conda-forge\\r\\nreadline                  7.0                  haf1bffa_1    conda-forge\\r\\nrecommonmark              0.4.0                      py_2    conda-forge\\r\\nrequests                  2.19.1                   py35_1    conda-forge\\r\\nrhash                     1.3.6                h470a237_1    conda-forge\\r\\nsend2trash                1.5.0                      py_0    conda-forge\\r\\nsetuptools                40.4.3                   py35_0    conda-forge\\r\\nsimplegeneric             0.8.1                      py_1    conda-forge\\r\\nsix                       1.11.0                   py35_1    conda-forge\\r\\nsnowballstemmer           1.2.1                      py_1    conda-forge\\r\\nsortedcontainers          2.1.0                      py_0    conda-forge\\r\\nsphinx                    1.8.1                    py35_0    conda-forge\\r\\nsphinx-markdown-tables    0.0.9                     <pip>\\r\\nsphinx_rtd_theme          0.4.2                      py_0    conda-forge\\r\\nsphinxcontrib-websupport  1.1.0                      py_1    conda-forge\\r\\nsqlite                    3.26.0               hb1c47c0_0    conda-forge\\r\\ntblib                     1.3.2                      py_1    conda-forge\\r\\nterminado                 0.8.1                    py35_1    conda-forge\\r\\ntestpath                  0.3.1                    py35_1    conda-forge\\r\\ntk                        8.6.9                ha92aebf_0    conda-forge\\r\\ntoolz                     0.9.0                      py_1    conda-forge\\r\\ntornado                   5.1.1            py35h470a237_0    conda-forge\\r\\ntraitlets                 4.3.2                    py35_0    conda-forge\\r\\nurllib3                   1.23                     py35_1    conda-forge\\r\\nwcwidth                   0.1.7                      py_1    conda-forge\\r\\nwebencodings              0.5.1                      py_1    conda-forge\\r\\nwheel                     0.32.0                py35_1000    conda-forge\\r\\nxz                        5.2.4                h470a237_1    conda-forge\\r\\nyaml                      0.1.7                h470a237_1    conda-forge\\r\\nzeromq                    4.2.5                hfc679d8_6    conda-forge\\r\\nzict                      0.1.3                      py_0    conda-forge\\r\\nzlib                      1.2.11               h470a237_3    conda-forge\\r\\n```\\r\\n\\r\\n</details>\\ncreatedAt: 2019-01-04T02:46:53Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Rocklin\\ncompany: @coiled', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 2}),\n",
       " Document(page_content=\": 9\\ntitle: [FEA] DatetimeIndex Frequency/TZ\\nbody: In Pandas, DatetimeIndexes can report back the frequency and timezone.  I think this would be useful/nice for cuDF but it's not a high priority at all.  \\r\\n\\r\\n```\\r\\nIn [70]: pd.date_range(end='1/1/2018', periods=8).freq\\r\\nOut[70]: <Day>\\r\\n```\\r\\n\\r\\nFor more info on these extended dtypes: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#period-dtypes\\ncreatedAt: 2019-06-06T16:09:44Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Benjamin Zaitlen\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 3}),\n",
       " Document(page_content=': 11\\ntitle: [FEA]Add merge_asof to cudf\\nbody: Please add merge_asof to cudf to match pandas merge_asof capabilities. Thanks!\\ncreatedAt: 2019-07-12T17:04:59Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 4}),\n",
       " Document(page_content=': 15\\ntitle: Support callables in DataFrame.assign\\nbody: Value I am trying to compute is a range between two measure variables `v1, v2` within groups defined by `id2, id4` categories.\\r\\nThe following pandas/dask syntax could work\\r\\n```py\\r\\nans = x.groupby([\\'id2\\',\\'id4\\']).agg({\\'v1\\': \\'max\\', \\'v2\\': \\'min\\'}).assign(range_v1_v2=lambda x: x[\\'v1\\'] - x[\\'v2\\'])[[\\'range_v1_v2\\']]\\r\\n#  File \"pyarrow/array.pxi\", line 536, in pyarrow.lib.Array.from_pandas\\r\\n#  File \"pyarrow/array.pxi\", line 176, in pyarrow.lib.array\\r\\n#  File \"pyarrow/array.pxi\", line 85, in pyarrow.lib._ndarray_to_array\\r\\n#  File \"pyarrow/error.pxi\", line 81, in pyarrow.lib.check_status\\r\\n#pyarrow.lib.ArrowInvalid: Only 1D arrays accepted\\r\\n```\\r\\nreproducible example\\r\\n```py\\r\\nimport os\\r\\nimport gc\\r\\nimport cudf as cu\\r\\nver = cu.__version__\\r\\nprint(ver)\\r\\n#0.8.0+0.g8fa7bd3.dirty\\r\\nsrc_grp = \"G1_1e7_1e2_0_0.csv\"\\r\\nx = cu.read_csv(src_grp, skiprows=1,\\r\\n                names=[\\'id1\\',\\'id2\\',\\'id3\\',\\'id4\\',\\'id5\\',\\'id6\\',\\'v1\\',\\'v2\\',\\'v3\\'],\\r\\n                dtype=[\\'str\\',\\'str\\',\\'str\\',\\'int\\',\\'int\\',\\'int\\',\\'int\\',\\'int\\',\\'float\\'])\\r\\nans = x.groupby([\\'id2\\',\\'id4\\']).agg({\\'v1\\': \\'max\\', \\'v2\\': \\'min\\'}).assign(range_v1_v2=lambda x: x[\\'v1\\'] - x[\\'v2\\'])[[\\'range_v1_v2\\']]\\r\\n```\\r\\ngenerate data according to https://github.com/rapidsai/cudf/issues/2494\\ncreatedAt: 2019-08-15T09:19:19Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Jan Gorecki\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 5}),\n",
       " Document(page_content=': 21\\ntitle: [BUG]Cannot query dataframes with categorical columns\\nbody: **Describe the bug**\\r\\nif i do a simple query on a categorical column, i get an error stating that  `This error is usually caused by passing an argument of a type that is unsupported by the named function.`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nimport cudf\\r\\nimport pandas as pd\\r\\n\\r\\nfn = \\'test.csv\\'\\r\\nlines = \"\"\"id1,id2\\r\\n1,45\\r\\n2,3\\r\\n3, 7\\r\\n1, 25\\r\\n\"\"\"\\r\\nwith open(fn, \\'w\\') as fp:\\r\\n    fp.write(lines)\\r\\npdf = pd.read_csv(fn, header=0, dtype={\"id1\":\"category\", \"id2\":\"int32\"})\\r\\ncdf = cudf.read_csv(fn, header=0, dtype={\"id1\":\"int32\", \"id2\":\"int32\"}) #see #3960 for why i have to do this\\r\\ncdf[\\'id1\\'] = cdf[\\'id1\\'].astype(\"category\")\\r\\npdf.query(\"id1 == [\\'1\\'] and id2 == 45\")\\r\\ncdf.query(\"id1 == [\\'1\\'] and id2 == 45\")\\r\\n```\\r\\nThe cdf query outputs a rather large error\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nTypingError                               Traceback (most recent call last)\\r\\n<ipython-input-27-28a794912e6e> in <module>\\r\\n----> 1 cdf2.query(\"id1 == [\\'1\\'] and id2 == 45\")\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/dataframe.py in query(self, expr, local_dict)\\r\\n   2893         }\\r\\n   2894         # Run query\\r\\n-> 2895         boolmask = queryutils.query_execute(self, expr, callenv)\\r\\n   2896 \\r\\n   2897         selected = Series(boolmask)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/utils/queryutils.py in query_execute(df, expr, callenv)\\r\\n    223     # run kernel\\r\\n    224     args = [out] + colarrays + envargs\\r\\n--> 225     kernel.forall(nrows)(*args)\\r\\n    226     out_mask = applyutils.make_aggregate_nullmask(df, columns=columns)\\r\\n    227     if out_mask is not None:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in __call__(self, *args)\\r\\n    264     def __call__(self, *args):\\r\\n    265         if isinstance(self.kernel, AutoJitCUDAKernel):\\r\\n--> 266             kernel = self.kernel.specialize(*args)\\r\\n    267         else:\\r\\n    268             kernel = self.kernel\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in specialize(self, *args)\\r\\n    808         argtypes = tuple(\\r\\n    809             [self.typingctx.resolve_argument_type(a) for a in args])\\r\\n--> 810         kernel = self.compile(argtypes)\\r\\n    811         return kernel\\r\\n    812 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in compile(self, sig)\\r\\n    824                 self.targetoptions[\\'link\\'] = ()\\r\\n    825             kernel = compile_kernel(self.py_func, argtypes,\\r\\n--> 826                                     **self.targetoptions)\\r\\n    827             self.definitions[(cc, argtypes)] = kernel\\r\\n    828             if self.bind:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)\\r\\n     30         def _acquire_compile_lock(*args, **kwargs):\\r\\n     31             with self:\\r\\n---> 32                 return func(*args, **kwargs)\\r\\n     33         return _acquire_compile_lock\\r\\n     34 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in compile_kernel(pyfunc, args, link, debug, inline, fastmath, extensions, max_registers)\\r\\n     60 def compile_kernel(pyfunc, args, link, debug=False, inline=False,\\r\\n     61                    fastmath=False, extensions=[], max_registers=None):\\r\\n---> 62     cres = compile_cuda(pyfunc, types.void, args, debug=debug, inline=inline)\\r\\n     63     fname = cres.fndesc.llvm_func_name\\r\\n     64     lib, kernel = cres.target_context.prepare_cuda_kernel(cres.library, fname,\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)\\r\\n     30         def _acquire_compile_lock(*args, **kwargs):\\r\\n     31             with self:\\r\\n---> 32                 return func(*args, **kwargs)\\r\\n     33         return _acquire_compile_lock\\r\\n     34 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/cuda/compiler.py in compile_cuda(pyfunc, return_type, args, debug, inline)\\r\\n     49                                   return_type=return_type,\\r\\n     50                                   flags=flags,\\r\\n---> 51                                   locals={})\\r\\n     52 \\r\\n     53     library = cres.library\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\\r\\n    526     pipeline = pipeline_class(typingctx, targetctx, library,\\r\\n    527                               args, return_type, flags, locals)\\r\\n--> 528     return pipeline.compile_extra(func)\\r\\n    529 \\r\\n    530 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in compile_extra(self, func)\\r\\n    324         self.state.lifted = ()\\r\\n    325         self.state.lifted_from = None\\r\\n--> 326         return self._compile_bytecode()\\r\\n    327 \\r\\n    328     def compile_ir(self, func_ir, lifted=(), lifted_from=None):\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in _compile_bytecode(self)\\r\\n    383         \"\"\"\\r\\n    384         assert self.state.func_ir is None\\r\\n--> 385         return self._compile_core()\\r\\n    386 \\r\\n    387     def _compile_ir(self):\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in _compile_core(self)\\r\\n    363                 self.state.status.fail_reason = e\\r\\n    364                 if is_final_pipeline:\\r\\n--> 365                     raise e\\r\\n    366         else:\\r\\n    367             raise CompilerError(\"All available pipelines exhausted\")\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler.py in _compile_core(self)\\r\\n    354             res = None\\r\\n    355             try:\\r\\n--> 356                 pm.run(self.state)\\r\\n    357                 if self.state.cr is not None:\\r\\n    358                     break\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_machinery.py in run(self, state)\\r\\n    326                     (self.pipeline_name, pass_desc)\\r\\n    327                 patched_exception = self._patch_error(msg, e)\\r\\n--> 328                 raise patched_exception\\r\\n    329 \\r\\n    330     def dependency_analysis(self):\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_machinery.py in run(self, state)\\r\\n    317                 pass_inst = _pass_registry.get(pss).pass_inst\\r\\n    318                 if isinstance(pass_inst, CompilerPass):\\r\\n--> 319                     self._runPass(idx, pass_inst, state)\\r\\n    320                 else:\\r\\n    321                     raise BaseException(\"Legacy pass in use\")\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)\\r\\n     30         def _acquire_compile_lock(*args, **kwargs):\\r\\n     31             with self:\\r\\n---> 32                 return func(*args, **kwargs)\\r\\n     33         return _acquire_compile_lock\\r\\n     34 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_machinery.py in _runPass(self, index, pss, internal_state)\\r\\n    279             mutated |= check(pss.run_initialization, internal_state)\\r\\n    280         with SimpleTimer() as pass_time:\\r\\n--> 281             mutated |= check(pss.run_pass, internal_state)\\r\\n    282         with SimpleTimer() as finalize_time:\\r\\n    283             mutated |= check(pss.run_finalizer, internal_state)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/compiler_machinery.py in check(func, compiler_state)\\r\\n    266 \\r\\n    267         def check(func, compiler_state):\\r\\n--> 268             mangled = func(compiler_state)\\r\\n    269             if mangled not in (True, False):\\r\\n    270                 msg = (\"CompilerPass implementations should return True/False. \"\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typed_passes.py in run_pass(self, state)\\r\\n     92                 state.args,\\r\\n     93                 state.return_type,\\r\\n---> 94                 state.locals)\\r\\n     95             state.typemap = typemap\\r\\n     96             state.return_type = return_type\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals)\\r\\n     64 \\r\\n     65         infer.build_constraint()\\r\\n---> 66         infer.propagate()\\r\\n     67         typemap, restype, calltypes = infer.unify()\\r\\n     68 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typeinfer.py in propagate(self, raise_errors)\\r\\n    949                                   if isinstance(e, ForceLiteralArg)]\\r\\n    950                 if not force_lit_args:\\r\\n--> 951                     raise errors[0]\\r\\n    952                 else:\\r\\n    953                     raise reduce(operator.or_, force_lit_args)\\r\\n\\r\\nTypingError: Failed in nopython mode pipeline (step: nopython frontend)\\r\\nInvalid use of Function(<numba.cuda.compiler.DeviceFunctionTemplate object at 0x7f914147a320>) with argument(s) of type(s): (int32, int32)\\r\\n * parameterized\\r\\nIn definition 0:\\r\\n    TypingError: Failed in nopython mode pipeline (step: nopython frontend)\\r\\nInvalid use of Function(<built-in function eq>) with argument(s) of type(s): (int32, list(unicode_type))\\r\\nKnown signatures:\\r\\n * (bool, bool) -> bool\\r\\n * (int8, int8) -> bool\\r\\n * (int16, int16) -> bool\\r\\n * (int32, int32) -> bool\\r\\n * (int64, int64) -> bool\\r\\n * (uint8, uint8) -> bool\\r\\n * (uint16, uint16) -> bool\\r\\n * (uint32, uint32) -> bool\\r\\n * (uint64, uint64) -> bool\\r\\n * (float32, float32) -> bool\\r\\n * (float64, float64) -> bool\\r\\n * (complex64, complex64) -> bool\\r\\n * (complex128, complex128) -> bool\\r\\n * parameterized\\r\\nIn definition 0:\\r\\n    All templates rejected with literals.\\r\\nIn definition 1:\\r\\n    All templates rejected without literals.\\r\\nIn definition 2:\\r\\n    All templates rejected with literals.\\r\\nIn definition 3:\\r\\n    All templates rejected without literals.\\r\\nIn definition 4:\\r\\n    All templates rejected with literals.\\r\\nIn definition 5:\\r\\n    All templates rejected without literals.\\r\\nIn definition 6:\\r\\n    All templates rejected with literals.\\r\\nIn definition 7:\\r\\n    All templates rejected without literals.\\r\\nIn definition 8:\\r\\n    All templates rejected with literals.\\r\\nIn definition 9:\\r\\n    All templates rejected without literals.\\r\\nIn definition 10:\\r\\n    All templates rejected with literals.\\r\\nIn definition 11:\\r\\n    All templates rejected without literals.\\r\\nIn definition 12:\\r\\n    All templates rejected with literals.\\r\\nIn definition 13:\\r\\n    All templates rejected without literals.\\r\\nIn definition 14:\\r\\n    All templates rejected with literals.\\r\\nIn definition 15:\\r\\n    All templates rejected without literals.\\r\\nIn definition 16:\\r\\n    All templates rejected with literals.\\r\\nIn definition 17:\\r\\n    All templates rejected without literals.\\r\\nIn definition 18:\\r\\n    All templates rejected with literals.\\r\\nIn definition 19:\\r\\n    All templates rejected without literals.\\r\\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\\r\\n[1] During: typing of intrinsic-call at <string> (2)\\r\\n\\r\\nFile \"<string>\", line 2:\\r\\n<source missing, REPL/exec in use?>\\r\\n\\r\\n    raised from /opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typeinfer.py:951\\r\\nIn definition 1:\\r\\n    TypingError: Failed in nopython mode pipeline (step: nopython frontend)\\r\\nInvalid use of Function(<built-in function eq>) with argument(s) of type(s): (int32, list(unicode_type))\\r\\nKnown signatures:\\r\\n * (bool, bool) -> bool\\r\\n * (int8, int8) -> bool\\r\\n * (int16, int16) -> bool\\r\\n * (int32, int32) -> bool\\r\\n * (int64, int64) -> bool\\r\\n * (uint8, uint8) -> bool\\r\\n * (uint16, uint16) -> bool\\r\\n * (uint32, uint32) -> bool\\r\\n * (uint64, uint64) -> bool\\r\\n * (float32, float32) -> bool\\r\\n * (float64, float64) -> bool\\r\\n * (complex64, complex64) -> bool\\r\\n * (complex128, complex128) -> bool\\r\\n * parameterized\\r\\nIn definition 0:\\r\\n    All templates rejected with literals.\\r\\nIn definition 1:\\r\\n    All templates rejected without literals.\\r\\nIn definition 2:\\r\\n    All templates rejected with literals.\\r\\nIn definition 3:\\r\\n    All templates rejected without literals.\\r\\nIn definition 4:\\r\\n    All templates rejected with literals.\\r\\nIn definition 5:\\r\\n    All templates rejected without literals.\\r\\nIn definition 6:\\r\\n    All templates rejected with literals.\\r\\nIn definition 7:\\r\\n    All templates rejected without literals.\\r\\nIn definition 8:\\r\\n    All templates rejected with literals.\\r\\nIn definition 9:\\r\\n    All templates rejected without literals.\\r\\nIn definition 10:\\r\\n    All templates rejected with literals.\\r\\nIn definition 11:\\r\\n    All templates rejected without literals.\\r\\nIn definition 12:\\r\\n    All templates rejected with literals.\\r\\nIn definition 13:\\r\\n    All templates rejected without literals.\\r\\nIn definition 14:\\r\\n    All templates rejected with literals.\\r\\nIn definition 15:\\r\\n    All templates rejected without literals.\\r\\nIn definition 16:\\r\\n    All templates rejected with literals.\\r\\nIn definition 17:\\r\\n    All templates rejected without literals.\\r\\nIn definition 18:\\r\\n    All templates rejected with literals.\\r\\nIn definition 19:\\r\\n    All templates rejected without literals.\\r\\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\\r\\n[1] During: typing of intrinsic-call at <string> (2)\\r\\n\\r\\nFile \"<string>\", line 2:\\r\\n<source missing, REPL/exec in use?>\\r\\n\\r\\n    raised from /opt/conda/envs/rapids/lib/python3.7/site-packages/numba/typeinfer.py:951\\r\\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\\r\\n[1] During: resolving callee type: Function(<numba.cuda.compiler.DeviceFunctionTemplate object at 0x7f914147a320>)\\r\\n[2] During: typing of call at <string> (6)\\r\\n\\r\\n\\r\\nFile \"<string>\", line 6:\\r\\n<source missing, REPL/exec in use?>\\r\\n```\\r\\n**Expected behavior**\\r\\nI expect it to output similar to the `pdf.query`, `pdf.query(\"id1 == [\\'1\\'] and id2 == 45\")`\\r\\n\\r\\nid1 | id2\\r\\n-- | --\\r\\n1 | 45\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: [Docker]\\r\\n - Method of cuDF install: [Docker]\\r\\n\\r\\n**Additional context**\\r\\nConverting from cudf to pandas to do the query also inexplicitly fails\\r\\n```\\r\\ntdf = cdf.to_pandas()\\r\\ntdf[\\'id1\\']\\r\\n```\\r\\nwill output correctly with \\r\\n```\\r\\n0    1\\r\\n1    2\\r\\n2    3\\r\\n3    1\\r\\nName: id1, dtype: category\\r\\nCategories (3, int64): [1, 2, 3]\\r\\n```\\r\\nbut when you run the query...\\r\\n```\\r\\ntdf.query(\"id1 == [\\'1\\'] and id2 == 45\")\\r\\n```\\r\\nOutputs an empty table \\r\\n\\r\\n\\xa0 | id1 | id2\\r\\n-- | -- | --\\ncreatedAt: 2020-01-28T11:55:24Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Taurean Dyer\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 6}),\n",
       " Document(page_content=': 22\\ntitle: [FEA] Support nanValue Spark CSV parse option in cudf CSV reader\\nbody: _Description of the request:_ \\r\\nApache Spark CSV reader options include specifying values that should be interpreted as NaNs via `nanValue`.\\r\\nRefer to  [https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/DataFrameReader.html](url) \\r\\ncuDF CSV reader seems to lack an equivalent\\r\\n\\r\\n_Description of a possible solution_:\\r\\nIt would helpful to have a translation/support for that option in the cudf CSV reader options. (analogous to its na_values)\\ncreatedAt: 2020-01-29T22:12:37Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Kuhu Shukla\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 7}),\n",
       " Document(page_content=': 23\\ntitle: [BUG] expand_bits_to_bytes could be improved by returning ndarray of np.bool\\nbody: **Describe the bug**\\r\\n`expand_bits_to_bytes`, defined below, is a utility function for unit tests which unpacks a bitmask into a list of valids per element. As currently defined, this returns a `list` of `int` where 1 is valid and 0 is invalid. However, in every case where this is used, the caller converts the result to `ndarray` of `bool`. The input to the function is expected to be an `ndarray` anyway, so there could be some numpy transform which gives us the result as `ndarray` directly.\\r\\nhttps://github.com/rapidsai/cudf/blob/a831f11bdeb2cb8dfcc2f47ef69b596a2334c3d2/python/cudf/cudf/tests/utils.py#L36-L43\\r\\n\\r\\n**Expected behavior**\\r\\nRefactor `expand_bits_to_bytes` to return `ndarray` of `bool`. [unpackbits](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.unpackbits.html) looks like it would be useful here.\\ncreatedAt: 2020-02-20T03:05:49Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Trevor Smith\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 8}),\n",
       " Document(page_content=\": 28\\ntitle: [FEA] predicate push down such as bloom filters added to read_orc\\nbody: having predicate pushdowns such as bloom filters work as in hive to skip over sections of data on disk during the read would enable better overall performance as the data would never have to be loaded to memory and then discarded if the predicate didn't match in the row group.\\r\\n\\r\\nsupport predicate pushdown similar to what is done with hive in read_orc, primary support for bloom filter but also for sorted data as well to enable only loading relevant data to query.\\ncreatedAt: 2020-03-10T22:22:06Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: Walmart\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 9}),\n",
       " Document(page_content=\": 29\\ntitle: [FEA] Async, especially for heavier ops\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nWe are currently putting manual `await sleep(0)` points into our cudf code to enable use of cudf alongside Python async code in web server scenarios. Otherwise, cudf hangs our web server when it is used for handling requests. This gets worse as tasks get bigger, complicates having mixed CPU/GPU tasks, and unnecessarily forces architectural decisions like carefully separating processes and 2-level scheduling. \\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nSupport for Python3's async/await constructor. Part of the Python 2 -> 3 shift is native support for `async`, especially for IO (e.g., when handling web requests) and compute (e.g., compression tasks).  \\r\\n\\r\\nEx:\\r\\n\\r\\n```\\r\\n@route(/cluster/big/dataset/<datasetid>, method=POST)\\r\\nasync def cluster_big_dataset(dataset_id):\\r\\n    \\r\\n    df = await cudf.read_parquet(f'/files/{dataset_id}.parquet')\\r\\n    ...\\r\\n```\\r\\n\\r\\nThis would be great universally, but there's probably a ~top 10 list for most slow in practice: to/from I/O, groupby & merge, ... .\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\n* Going via Dask also supports this, but with way more overhead and complexity. \\r\\n\\r\\n* We currently use multiple Python processes to help with SLAs, but it's clearly avoidable.\\ncreatedAt: 2020-03-16T21:44:13Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: Graphistry\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 10}),\n",
       " Document(page_content=\": 31\\ntitle: [FEA] dask-cudf groupby with quantile and median methods\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nI'd like to calculate median and/or quantile on a column after groupbying a dask-cudf data frame. \\r\\n\\r\\n**EDIT** 5/10/2024: median is now implemented\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nI want the following code to work and generate correct results:\\r\\n\\r\\n```\\r\\ncdf =cudf.DataFrame({'id4': 4*list(range(6)), 'id5': 4*list(reversed(range(6))), 'v3': 6*list(range(4))})\\r\\nddf = dcu.from_cudf(cdf, npartitions= 1)\\r\\n\\r\\nddf.dtypes\\r\\nid4    int64\\r\\nid5    int64\\r\\nv3     int64\\r\\ndtype: object\\r\\n\\r\\nddf.head()\\r\\n\\r\\n        id4   id5     v3\\r\\n\\r\\n0\\t0\\t5\\t0\\r\\n1\\t1\\t4\\t1\\r\\n2\\t2\\t3\\t2\\r\\n3\\t3\\t2\\t3\\r\\n4\\t4\\t1\\t0\\r\\n\\r\\n#these groupby operations do not work\\r\\nans = ddf.groupby(['id4', 'id5'])[['v3']].median().compute()\\r\\n\\r\\nOR \\r\\n\\r\\nans = ddf.groupby(['id4', 'id5'])[['v3']].quantile(q=0.5).compute()\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nI am using Rapids 0.13 nightly release in conda env, with dask 2.12.0 version.\\ncreatedAt: 2020-03-26T16:49:09Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 11}),\n",
       " Document(page_content=\": 36\\ntitle: [FEA] Snappy Compressed CSV Not Implemented\\nbody: read_csv doesn't support snappy compression. As a workaround we use snappy-python to uncompress csv files and then load using cudf.\\ncreatedAt: 2020-05-08T14:57:47Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lahir Marni\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 12}),\n",
       " Document(page_content=': 39\\ntitle: [FEA] cuDF doesn’t support custom class objects as columns\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\ncuDF doesn’t support custom class objects as columns\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nAdd support for custom class objects to be used as columns\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nUse strings instead\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nPandas sample\\r\\n```python\\r\\n\\r\\nimport pandas as pd\\r\\n\\r\\nclass Header:\\r\\n    def __init__(self, name):\\r\\n        self.name = name\\r\\n\\r\\npd.DataFrame({Header(\"name\"): [1, 2, 3]})\\r\\n```\\r\\n\\r\\ncuDF sample\\r\\n```python\\r\\nimport cudf as pd\\r\\n\\r\\npd.DataFrame({Header(\"name\"): [1, 2, 3]})\\r\\n# TypeError: __setitem__ on type <class \\'__main__.Header\\'> is not supported\\r\\n\\r\\n```\\r\\n\\r\\nTraceback:\\r\\n```python\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\n\\r\\n~/miniconda3/envs/rapids14/lib/python3.7/site-packages/cudf/core/dataframe.py in __setitem__(self, arg, value)\\r\\n    616         else:\\r\\n    617             msg = \"__setitem__ on type {!r} is not supported\"\\r\\n--> 618             raise TypeError(msg.format(type(arg)))\\r\\n    619 \\r\\n    620     def __delitem__(self, name):\\r\\n\\r\\nTypeError: __setitem__ on type <class \\'__main__.Header\\'> is not supported\\r\\n       \\r\\n```\\ncreatedAt: 2020-06-23T07:19:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 13}),\n",
       " Document(page_content=\": 40\\ntitle: [FEA] cuDF doesn't work out of the box with `NamedTuple` when constructing a `DataFrame`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\ncuDF doesn't work out of the box with `NamedTuple` when constructing a `DataFrame`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nAdd support for `NamedTuple`\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\nFirst, create a `NamedTuple` object:\\r\\n\\r\\n```python\\r\\nfrom typing import NamedTuple, Optional, List\\r\\nclass ModelPrediction(NamedTuple):\\r\\n    suspicious: Optional[bool]\\r\\n    confidence: Optional[float]\\r\\n    prediction: Optional[List[float]]\\r\\n\\r\\noutputs = [ModelPrediction(suspicious=True, confidence=0.1, prediction=60), ModelPrediction(suspicious=False, confidence=0.6, prediction=40), ModelPrediction(suspicious=True, confidence=0.8, prediction=30)]\\r\\n```\\r\\n\\r\\ncuDF workaround:\\r\\n```python\\r\\nimport cudf as pd\\r\\npd.DataFrame(list(iter(outputs)), columns=ModelPrediction.__annotations__.keys())\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nPandas works out of the box:\\r\\n```python\\r\\nimport pandas as pd\\r\\npd.DataFrame(iter(outputs))\\r\\n```\\r\\n\\r\\nwhile cuDF produces a DataFrame with column names missing:\\r\\n```python\\r\\nimport cudf as pd\\r\\npd.DataFrame(list(iter(outputs))) # column names missing\\r\\n\\r\\n```\\r\\n\\r\\nOutput:\\r\\n```\\r\\nsuspicious\\tconfidence\\tprediction\\r\\n0\\tTrue\\t0.1\\t60\\r\\n1\\tFalse\\t0.6\\t40\\r\\n2\\tTrue\\t0.8\\t30\\r\\n```\\ncreatedAt: 2020-06-23T07:22:34Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 14}),\n",
       " Document(page_content=': 41\\ntitle: [FEA] `fillna()` doesn\\'t accept axis keyword\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\n`fillna()` doesn\\'t accept axis keyword\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nAdd support for the `axis` keyword\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\n\\r\\nIn our use case `axis` keyword was redundant, it worked without it\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nPandas showcase:\\r\\n```python\\r\\n\\r\\nimport pandas as pd\\r\\n\\r\\ndata = pd.DataFrame(\\r\\n   data=([[None, None, 100, 1000, 10000], [2, 20, 200, 2000, 20000]]), columns=[\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\']\\r\\n)\\r\\n\\r\\ndata1 = pd.DataFrame(\\r\\n   data=([[3, 33], [2, 22]]), columns=[\\'a\\', \\'b\\']\\r\\n)\\r\\ndata.fillna(data1, axis=1)\\r\\n```\\r\\n\\r\\ncuDF showcase:\\r\\n```python\\r\\nimport cudf as pd\\r\\n\\r\\ndata = pd.DataFrame(\\r\\n   data=([[None, None, 100, 1000, 10000], [2, 20, 200, 2000, 20000]]), columns=[\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\']\\r\\n)\\r\\n\\r\\ndata1 = pd.DataFrame(\\r\\n   data=([[3, 33], [2, 22]]), columns=[\\'a\\', \\'b\\']\\r\\n)\\r\\ndata.fillna(data1, axis=1) # the axis keyword is not supported\\r\\n\\r\\n```\\r\\n\\r\\nTraceback:\\r\\n```python\\r\\n---------------------------------------------------------------------------\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\n<ipython-input-9-3b5ff28bd8cb> in <module>\\r\\n      9    data=([[3, 33], [2, 22]]), columns=[\\'a\\', \\'b\\']\\r\\n     10 )\\r\\n---> 11 data.fillna(data1, axis=1) # the axis keyword is not supported\\r\\n\\r\\n~/miniconda3/envs/rapids14/lib/python3.7/site-packages/cudf/core/dataframe.py in fillna(self, value, method, axis, inplace, limit)\\r\\n   3815                 axis=axis,\\r\\n   3816                 inplace=inplace,\\r\\n-> 3817                 limit=limit,\\r\\n   3818             )\\r\\n   3819 \\r\\n\\r\\n~/miniconda3/envs/rapids14/lib/python3.7/site-packages/cudf/core/series.py in fillna(self, value, method, axis, inplace, limit)\\r\\n   1605             raise NotImplementedError(\"The limit keyword is not supported\")\\r\\n   1606         if axis:\\r\\n-> 1607             raise NotImplementedError(\"The axis keyword is not supported\")\\r\\n   1608 \\r\\n   1609         data = self._column.fillna(value)\\r\\n\\r\\nNotImplementedError: The axis keyword is not supported\\r\\n    ```\\ncreatedAt: 2020-06-23T07:26:33Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 15}),\n",
       " Document(page_content=\": 44\\ntitle: [FEA] Hash values in nested columns\\nbody: Hashing categorical features to a fixed number of bins is a common preprocessing operation, particularly for tabular deep learning models where memory requirements scale with the number of bins. For extension of CuDF to nested columns, it would be helpful if calls to `Series.hash_values` hashed the values *in* each element's list and not the list itself. This would allow categorical hashing to extend to multi-hot categorical features.\\r\\n\\r\\nAs an example:\\r\\n```\\r\\ndf = cudf.DataFrame({'a': [[0, 1, 2], [3, 4], [], [5], [6, 7, 8, 9]]})\\r\\ndf['a'].hash_values()\\r\\n\\r\\n# not sure what this representation will\\r\\n# print like but some like this\\r\\n[[ 29140149,  -247539971,  1683430573],  [1098043756,  1851360991], [],\\r\\n        [100260016],   [154726282, -1778135556, -1793932552,   246633392]]\\r\\n\\r\\ndf['a'].hash_values() % 4\\r\\n[[1, 1, 1], [0, 3], [], [0], [2, 0, 0, 0]]\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nNecessary for extension of [NVTabular HashBucket op](https://github.com/NVIDIA/NVTabular/blob/9f8216a89d565e00d8356ffef62f4437f3e2dee3/nvtabular/ops.py#L498) to multi-hot categorical data\\ncreatedAt: 2020-07-06T13:43:29Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Alec Gunny\\ncompany: MIT\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 16}),\n",
       " Document(page_content=': 45\\ntitle: [ENH] Identify opportunities for making properties cached in cuDF\\nbody: Wherever possible, cache properties using [`cached_property`](https://github.com/rapidsai/cudf/blob/branch-0.15/python/cudf/cudf/utils/utils.py#L310) to avoid computing them every time they are needed.\\ncreatedAt: 2020-07-15T12:27:36Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 17}),\n",
       " Document(page_content=\": 47\\ntitle: [FEA] Rolling slope calculation with groupby\\nbody: Hello.\\r\\n\\r\\nI would like to calculate the rolling slope of y_value over x_value using cuML LinearRegression.\\r\\n\\r\\nSample data (cuDF dataframe):\\r\\n```\\r\\n| date       | x_value | y_value |\\r\\n| ------     | ------  |  ----   |\\r\\n| 2020-01-01 | 900     | 10      |\\r\\n| 2020-01-01 | 905     | 15      |\\r\\n| 2020-01-01 | 910     | 15      |\\r\\n| 2020-01-01 | 915     | 15      |\\r\\n| 2020-01-02 | 900     | 30      |\\r\\n| 2020-01-02 | 905     | 40      |\\r\\n| 2020-01-02 | 910     | 50      |\\r\\n| ------     | ------  | ------  |\\r\\n```\\r\\nA simple function to use LinearRegression:\\r\\n```\\r\\ndef RollingOLS(x, y):\\r\\n    lr = LinearRegression(fit_intercept = True, normalize = False, algorithm = 'svd')\\r\\n    reg = lr.fit(x, y)\\r\\n    \\r\\n    return reg.coef_\\r\\n```\\r\\n\\r\\nWhat I would like to do:\\r\\n```\\r\\ndata.groupby('date').rolling(2).apply(RollingOLS, x=x_value, y=y_value)\\r\\n```\\r\\n\\r\\nHowever, I am getting an error: ```NotImplementedError: Handling UDF with null values is not yet supported```. Is there any way to overcome this error? Thank you.\\ncreatedAt: 2020-08-02T16:43:06Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 18}),\n",
       " Document(page_content=\": 49\\ntitle: [FEA] Make java test utlities for Lists and nested types user-friendly and less verbose\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nAdd test utilities to make complex type testing simpler and readable.\\r\\n\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nWe need some modifications to fromLists and getList methods in cudf java to auto detect number of elements, assert when numRows and data size may not line up and make `DataType` more palatable in terms of verbosity.\\ncreatedAt: 2020-08-07T21:20:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Kuhu Shukla\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 19}),\n",
       " Document(page_content=': 50\\ntitle: [FEA] Pass `cudaStreamPerThread` to numba/CuPy kernels\\nbody: Memory allocations should already use PTDS since both numba and CuPy allocate memory using RMM. Kernels on the other hand, may explicitly need to be passed the `cudaStreamPerThread` stream handle.\\r\\n\\r\\ncc: @jakirkham @kkraus14\\ncreatedAt: 2020-08-11T13:45:41Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 20}),\n",
       " Document(page_content=': 52\\ntitle: [FEA] Profiling duplicate reading of metadata\\nbody: The row-group-level filtered reading for Parquet that is introduced by #5843 creates an issue of duplicate metadata (metadata is stored in the footers of Parquet files) reading in the case when filters are specified. Arrow is used to read metadata and select a subset of data to read given user-provided filters [4] . Information about this subset is then passed to libcudf which reads in the subset [5]. The issue is that metadata gets read twice - first when Arrow reads metadata to do filtering and second when libcudf reads data.\\r\\n\\r\\nThis issue was initially raised here [1].\\r\\n\\r\\n# What to profile\\r\\n\\r\\n- [ ] Perf penalty of reading metadata using Arrow for filtering in the same vein as [2] but with datasets of varying # of files\\r\\n- [ ] Perf penalty of parsing metadata buffer [3] as fraction of total time Arrow spends reading metadata\\r\\n\\r\\n# What to determine\\r\\n\\r\\n- [ ] Determine whether or not perf penalty of the additional reading of metadata using Arrow is significant\\r\\n- [ ] Determine whether the duplicate reading should be resolved by passing metadata struct (steps to implement [6]) or metadata buffer (which is then parsed into metadata struct in libcudf) (steps to implement [7]) from Arrow `Dataset` to libcudf reader functions\\r\\n\\r\\n# Relevant discussion/code\\r\\n\\r\\n[1] https://github.com/rapidsai/cudf/pull/5843#discussion_r467191621\\r\\n[2] https://github.com/rapidsai/cudf/pull/5843#issuecomment-673566456\\r\\n[3] https://github.com/apache/arrow/blob/2e6009621011d7df43882aa883905b84d1647018/cpp/src/parquet/file_reader.cc#L532\\r\\n[4] https://github.com/rapidsai/cudf/pull/5843/files#diff-deac873508aaa12ca2e7c0a2c9035230R316\\r\\n[5] https://github.com/rapidsai/cudf/pull/5843/files#diff-deac873508aaa12ca2e7c0a2c9035230R359-R375\\r\\n[6] https://github.com/rapidsai/cudf/pull/5843#issuecomment-674437264\\r\\n[7] https://github.com/rapidsai/cudf/pull/5843#issuecomment-674437709\\ncreatedAt: 2020-08-17T19:09:26Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Caleb Winston\\ncompany: Stanford', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 21}),\n",
       " Document(page_content=\": 55\\ntitle: [FEA] Filtering/reading statistics of ORC data with legacy TimestampStatistics\\nbody: The ORC statistics reading introduced in #6142 and stats-based ORC filtering in #6116 do not support the legacy version of `TimestampStatistics` in the ORC format. This legacy version uses time that is adjusted to the local timezone that the ORC data was written in. Fortunately, the local timezone is contained in ORC metadata so it is possible for us to support this version.\\r\\n\\r\\nI'm creating this issue mainly to see if there is a need for this (user/workflow). If there is, the necessary changes would involve an interface between cuDF and libcudf for getting `writerTimezone` from each `StripeFooter`. This `writerTimezone` would be used to decode `minimum` and `maximum` into Python datetimes.\\ncreatedAt: 2020-09-04T19:15:28Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Caleb Winston\\ncompany: Stanford\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 22}),\n",
       " Document(page_content=': 56\\ntitle: [FEA] Nth element support in dask cudf\\nbody: Requesting `nth` support in dask cudf after groupby.\\r\\nex. \\r\\n```\\r\\nfrom cudf import DataFrame\\r\\nimport dask_cudf\\r\\ndf = DataFrame()\\r\\ndf[\\'key\\'] = [1, 1, 1, 1, 2, 2, 2]\\r\\ndf[\\'val_0\\']= [13, 15, 20, 27, 60, 17, 90]\\r\\ndf[\\'val_1\\'] = [5, 1, 4, 9, 2, 7, 8]\\r\\nmeta_format = DataFrame()\\r\\nddf = dask_cudf.from_cudf(df, npartitions=1)\\r\\ngroups = ddf.groupby([\\'key\\']).nth(0)\\r\\n```\\r\\nCurrently it fails with :\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nKeyError                                  Traceback (most recent call last)\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/dask/dataframe/groupby.py in __getattr__(self, key)\\r\\n   1749         try:\\r\\n-> 1750             return self[key]\\r\\n   1751         except KeyError as e:\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/dask/dataframe/groupby.py in __getitem__(self, key)\\r\\n   1735         # error is raised from pandas\\r\\n-> 1736         g._meta = g._meta[key]\\r\\n   1737         return g\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in __getitem__(self, key)\\r\\n    623     def __getitem__(self, key):\\r\\n--> 624         return self.obj[key].groupby(self.grouping, dropna=self._dropna)\\r\\n    625\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/dataframe.py in __getitem__(self, arg)\\r\\n    640         if is_scalar(arg) or isinstance(arg, tuple):\\r\\n--> 641             return self._get_columns_by_label(arg, downcast=True)\\r\\n    642\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/frame.py in _get_columns_by_label(self, labels, downcast)\\r\\n    466         \"\"\"\\r\\n--> 467         new_data = self._data.select_by_label(labels)\\r\\n    468         if downcast:\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/column_accessor.py in select_by_label(self, key)\\r\\n    216                     return self._select_by_label_with_wildcard(key)\\r\\n--> 217             return self._select_by_label_grouped(key)\\r\\n    218\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/column_accessor.py in _select_by_label_grouped(self, key)\\r\\n    264     def _select_by_label_grouped(self, key):\\r\\n--> 265         result = self._grouped_data[key]\\r\\n    266         if isinstance(result, cudf.core.column.ColumnBase):\\r\\n\\r\\nKeyError: \\'nth\\'\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nAttributeError                            Traceback (most recent call last)\\r\\n<ipython-input-2-9e488bd207ec> in <module>\\r\\n      7 meta_format = DataFrame()\\r\\n      8 ddf = dask_cudf.from_cudf(df, npartitions=1)\\r\\n----> 9 groups = ddf.groupby([\\'key\\']).nth(1)\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/dask/dataframe/groupby.py in __getattr__(self, key)\\r\\n   1750             return self[key]\\r\\n   1751         except KeyError as e:\\r\\n-> 1752             raise AttributeError(e) from e\\r\\n   1753\\r\\n   1754     @derived_from(pd.core.groupby.DataFrameGroupBy)\\r\\n\\r\\nAttributeError: \\'nth\\'\\r\\n```\\r\\nOnce this functionality is implemented it should return a dask cudf dataframe that would contain the first row of each groupby\\r\\n\\r\\n```\\r\\n     val_0  val_1\\r\\nkey\\r\\n1       13      5\\r\\n2       60      2\\r\\n\\r\\n```\\ncreatedAt: 2020-09-08T18:19:17Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 23}),\n",
       " Document(page_content=': 62\\ntitle: [FEA] Improve readability of thread id based branching\\nbody: Improve readability of thread id based branches by giving them more descriptive names.\\r\\n\\r\\n#### e.g.\\r\\n```c++\\r\\nif (!t) // is actually a t == 0\\r\\n```\\r\\n#### and\\r\\nhttps://github.com/rapidsai/cudf/blob/57ef76927373d7260b6a0eda781e59a4c563d36e/cpp/src/io/statistics/column_stats.cu#L285\\r\\nIs actually a `lane_id == 0`\\r\\nAs demonstrated in https://github.com/rapidsai/cudf/issues/6241#issuecomment-693125331, prefer cooperative groups for this.\\r\\n\\r\\n\\r\\n#### and\\r\\nhttps://github.com/rapidsai/cudf/blob/85cd56dfb3449140f18c7cef3a3be01ac976fd14/cpp/src/io/parquet/page_enc.cu#L1256\\r\\nis actually ~`t < 32`~ `lane_id == 31`. (~I think this might be an oversight,~ ignore as it might be fixed in #6238 ).\\ncreatedAt: 2020-09-15T18:12:23Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Devavret Makkar\\ncompany: @VoltronData', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 24}),\n",
       " Document(page_content=': 64\\ntitle: [BUG] Rolling window\\'s apply function throws `TypingError`\\nbody: On running the apply function for `rolling` and trying to analyze array or any other variable type other than a single value I get the following error:\\r\\n`TypingError: Failed in nopython mode pipeline (step: nopython frontend)`\\r\\n\\r\\nCode to reproduce the error:\\r\\n```\\r\\nimport cudf\\r\\nimport numpy as np\\r\\nimport math\\r\\ndef groll_sort(x):\\r\\n    t = x.median() #np.median(x.values)\\r\\n    return t\\r\\ndf = cudf.DataFrame()\\r\\ndf[\\'a\\'] = (0.25, 0.3, 0.5,1,3,1,-1,3,-2)\\r\\nrolling = df.rolling(window=3).apply(groll_sort)\\r\\nprint(rolling)\\r\\n```\\r\\nNote: I also tried using `t = np.median(x.values)` in the function\\r\\nOn running the above code i get the following error:\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nTypingError                               Traceback (most recent call last)\\r\\n<ipython-input-6-99e3758f2d02> in <module>\\r\\n      7 df = cudf.DataFrame()\\r\\n      8 df[\\'a\\'] = (0.25, 0.3, 0.5,1,3,1,-1,3,-2)\\r\\n----> 9 rolling = df.rolling(window=3).apply(groll_sort)\\r\\n     10 print(rolling)\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/window/rolling.py in apply(self, func, *args, **kwargs)\\r\\n    276                 \"Handling UDF with null values is not yet supported\"\\r\\n    277             )\\r\\n--> 278         return self._apply_agg(func)\\r\\n    279\\r\\n    280     def _normalize(self):\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/window/rolling.py in _apply_agg(self, agg_name)\\r\\n    236             return self._apply_agg_series(self.obj, agg_name)\\r\\n    237         else:\\r\\n--> 238             return self._apply_agg_dataframe(self.obj, agg_name)\\r\\n    239\\r\\n    240     def sum(self):\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/window/rolling.py in _apply_agg_dataframe(self, df, agg_name)\\r\\n    225         result_df = cudf.DataFrame({})\\r\\n    226         for i, col_name in enumerate(df.columns):\\r\\n--> 227             result_col = self._apply_agg_series(df[col_name], agg_name)\\r\\n    228             result_df.insert(i, col_name, result_col)\\r\\n    229         result_df.index = df.index\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/core/window/rolling.py in _apply_agg_series(self, sr, agg_name)\\r\\n    201     def _apply_agg_series(self, sr, agg_name):\\r\\n    202         if isinstance(self.window, int):\\r\\n--> 203             result_col = libcudf.rolling.rolling(\\r\\n    204                 sr._column,\\r\\n    205                 None,\\r\\n\\r\\ncudf/_lib/rolling.pyx in cudf._lib.rolling.rolling()\\r\\n\\r\\ncudf/_lib/aggregation.pyx in cudf._lib.aggregation.make_aggregation()\\r\\n\\r\\ncudf/_lib/aggregation.pyx in cudf._lib.aggregation._AggregationFactory.from_udf()\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/cudf/utils/cudautils.py in compile_udf(udf, type_signature)\\r\\n    287     \"\"\"\\r\\n    288     decorated_udf = cuda.jit(udf, device=True)\\r\\n--> 289     compiled = decorated_udf.compile(type_signature)\\r\\n    290     ptx_code = decorated_udf.inspect_ptx(type_signature).decode(\"utf-8\")\\r\\n    291     output_type = numpy_support.as_dtype(compiled.signature.return_type)\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/cuda/compiler.py in compile(self, args)\\r\\n    162         \"\"\"\\r\\n    163         if args not in self._compileinfos:\\r\\n--> 164             cres = compile_cuda(self.py_func, None, args, debug=self.debug,\\r\\n    165                                 inline=self.inline)\\r\\n    166             first_definition = not self._compileinfos\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)\\r\\n     30         def _acquire_compile_lock(*args, **kwargs):\\r\\n     31             with self:\\r\\n---> 32                 return func(*args, **kwargs)\\r\\n     33         return _acquire_compile_lock\\r\\n     34\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/cuda/compiler.py in compile_cuda(pyfunc, return_type, args, debug, inline)\\r\\n     36         flags.set(\\'forceinline\\')\\r\\n     37     # Run compilation pipeline\\r\\n---> 38     cres = compiler.compile_extra(typingctx=typingctx,\\r\\n     39                                   targetctx=targetctx,\\r\\n     40                                   func=pyfunc,\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\\r\\n    601     pipeline = pipeline_class(typingctx, targetctx, library,\\r\\n    602                               args, return_type, flags, locals)\\r\\n--> 603     return pipeline.compile_extra(func)\\r\\n    604\\r\\n    605\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func)\\r\\n    337         self.state.lifted = ()\\r\\n    338         self.state.lifted_from = None\\r\\n--> 339         return self._compile_bytecode()\\r\\n    340\\r\\n    341     def compile_ir(self, func_ir, lifted=(), lifted_from=None):\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self)\\r\\n    399         \"\"\"\\r\\n    400         assert self.state.func_ir is None\\r\\n--> 401         return self._compile_core()\\r\\n    402\\r\\n    403     def _compile_ir(self):\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self)\\r\\n    379                 self.state.status.fail_reason = e\\r\\n    380                 if is_final_pipeline:\\r\\n--> 381                     raise e\\r\\n    382         else:\\r\\n    383             raise CompilerError(\"All available pipelines exhausted\")\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self)\\r\\n    370             res = None\\r\\n    371             try:\\r\\n--> 372                 pm.run(self.state)\\r\\n    373                 if self.state.cr is not None:\\r\\n    374                     break\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state)\\r\\n    339                     (self.pipeline_name, pass_desc)\\r\\n    340                 patched_exception = self._patch_error(msg, e)\\r\\n--> 341                 raise patched_exception\\r\\n    342\\r\\n    343     def dependency_analysis(self):\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state)\\r\\n    330                 pass_inst = _pass_registry.get(pss).pass_inst\\r\\n    331                 if isinstance(pass_inst, CompilerPass):\\r\\n--> 332                     self._runPass(idx, pass_inst, state)\\r\\n    333                 else:\\r\\n    334                     raise BaseException(\"Legacy pass in use\")\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)\\r\\n     30         def _acquire_compile_lock(*args, **kwargs):\\r\\n     31             with self:\\r\\n---> 32                 return func(*args, **kwargs)\\r\\n     33         return _acquire_compile_lock\\r\\n     34\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state)\\r\\n    289             mutated |= check(pss.run_initialization, internal_state)\\r\\n    290         with SimpleTimer() as pass_time:\\r\\n--> 291             mutated |= check(pss.run_pass, internal_state)\\r\\n    292         with SimpleTimer() as finalize_time:\\r\\n    293             mutated |= check(pss.run_finalizer, internal_state)\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state)\\r\\n    262\\r\\n    263         def check(func, compiler_state):\\r\\n--> 264             mangled = func(compiler_state)\\r\\n    265             if mangled not in (True, False):\\r\\n    266                 msg = (\"CompilerPass implementations should return True/False. \"\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state)\\r\\n     90                               % (state.func_id.func_name,)):\\r\\n     91             # Type inference\\r\\n---> 92             typemap, return_type, calltypes = type_inference_stage(\\r\\n     93                 state.typingctx,\\r\\n     94                 state.func_ir,\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors)\\r\\n     68\\r\\n     69         infer.build_constraint()\\r\\n---> 70         infer.propagate(raise_errors=raise_errors)\\r\\n     71         typemap, restype, calltypes = infer.unify(raise_errors=raise_errors)\\r\\n     72\\r\\n\\r\\n~/miniconda3/envs/branch15/lib/python3.8/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors)\\r\\n    992                                   if isinstance(e, ForceLiteralArg)]\\r\\n    993                 if not force_lit_args:\\r\\n--> 994                     raise errors[0]\\r\\n    995                 else:\\r\\n    996                     raise reduce(operator.or_, force_lit_args)\\r\\n\\r\\nTypingError: Failed in nopython mode pipeline (step: nopython frontend)\\r\\nUnknown attribute \\'median\\' of type array(float64, 1d, A)\\r\\n\\r\\nFile \"<ipython-input-6-99e3758f2d02>\", line 5:\\r\\ndef groll_sort(x):\\r\\n    t = x.median() #np.median(x.values)\\r\\n    ^\\r\\n\\r\\nDuring: typing of get attribute at <ipython-input-6-99e3758f2d02> (5)\\r\\n\\r\\nFile \"<ipython-input-6-99e3758f2d02>\", line 5:\\r\\ndef groll_sort(x):\\r\\n    t = x.median() #np.median(x.values)\\r\\n```\\r\\n\\r\\nThe same code runs on pandas and gives the following output:\\r\\nI/P:\\r\\n```\\r\\nimport pandas\\r\\nimport numpy as np\\r\\ndef groll_sort(x):\\r\\n    t = x.median()\\r\\n    return t\\r\\ndf = pandas.DataFrame()\\r\\ndf[\\'a\\'] = (0.25, 0.3, 0.5,1,3,1,-1,3,-2)\\r\\nrolling = df.rolling(window=3).apply(groll_sort)\\r\\nprint(rolling)\\r\\n```\\r\\nO/P:\\r\\n```\\r\\n     a\\r\\n0  NaN\\r\\n1  NaN\\r\\n2  0.3\\r\\n3  0.5\\r\\n4  1.0\\r\\n5  1.0\\r\\n6  1.0\\r\\n7  1.0\\r\\n8 -1.0\\r\\n```\\ncreatedAt: 2020-09-18T20:42:53Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 25}),\n",
       " Document(page_content=': 65\\ntitle: [FEA] rolling median()\\nbody: Use case: Run a sliding window robust z-score as part of standard EEG preprocessing step. Point is to denoise a non-stationary signal. This is a general outlier detection procedure that could have value outside EEG. \\r\\n\\r\\n(There was a previous request last year but seems to have stalled: https://github.com/rapidsai/cudf/issues/2135)\\r\\n\\r\\nThe robust z-score uses the **median** for the first (expectation) and second (variance, standard deviation) moments. This is instead of the average. \\r\\n\\r\\nCurrent operation takes about 30 minutes for 10^7x20 element data frame in pandas. cuDF could bring this down to seconds. \\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nLike to have a median() agg added to rolling or UDF for apply. \\r\\n\\r\\nFor robust z the function is:\\r\\n\\r\\n$$z_i = \\\\kappa\\\\frac{x_i-median(x)}{median(absolute\\\\{(x_i-median(x))\\\\})}$$\\r\\n$$\\\\text{where } \\\\kappa\\\\textrm{ := scaling factor}$$\\r\\n$$x \\\\subseteq X \\\\text{, }X\\\\text{ column vector in DF} $$\\r\\n\\r\\n\\r\\nSo, some possible solution to get the sliding robust z once we have the median working with apply are: 1) run the median twice (once of the original and then again on the median absolute values of the substracted residuals), and 2) right a custom UDF once the median function solution is known. \\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nI have tried writing a UDF but the issue is the **sort()** needed for the median calculation. I tried a numba nopython pandas rolling.apply solution. This works if I copy the windowed array (x2 = x.copy()). It spits out an error when run with cuDF. I believe it\\'s a memory and/or broadcasting issue (I\\'ve seen two kinds of errors). If I don\\'t copy then the pandas numba code sorts the original array and propagates this corrupt data back to the original DF.   \\r\\n\\r\\n**Additional context**\\r\\nHere is an example of the numba solution that works (this is for example to test on cuDF, of course pandas has a rolling median() agg). \\r\\n\\r\\n>code\\r\\n\\r\\n```\\r\\n@nb.jit(nopython=True)\\r\\ndef udf_median(x):\\r\\n  ##version 0\\r\\n  #mu = np.median(x)\\r\\n  ##version 1\\r\\n  x2 = x.copy()\\r\\n  x2.sort()\\r\\n  n = len(x2)\\r\\n  k = int(n/2) \\r\\n  if n%2 == 0:\\r\\n    mu = (x2[k]+x2[k+1])/2\\r\\n  else:\\r\\n    mu = x2[k]\\r\\n  return mu\\r\\n\\r\\n\\r\\n\\r\\ndf = pd.DataFrame()\\r\\ndf[\\'a\\'] = (-5,-3,-1,0.2,-2)\\r\\ndf[\\'b\\'] = (5,-3,1,-0.2,-2)\\r\\nprint(\\'original df\\')\\r\\nprint(df)\\r\\nrolling = df.rolling(window=3,axis=0)\\r\\nprint(\"panda call\\\\nwin=3 rolling median\")\\r\\nprint(rolling.apply(udf_median, engine=\\'numba\\', raw=True))\\r\\nprint(\\'df after rolling call - if copy is not done, then corrupted original df\\')\\r\\nprint(df)\\r\\n\\r\\nprint(\"\\\\ncuDF call\")\\r\\ndf = cudf.DataFrame()\\r\\ndf[\\'a\\'] = (-5,-3,-1,0.2,-2)\\r\\ndf[\\'b\\'] = (5,-3,1,-0.2,-2)\\r\\nrolling = df.rolling(window=3,axis=0)\\r\\nprint(rolling.apply(udf_median))\\r\\n\\r\\n```\\r\\n\\r\\n>output\\r\\noriginal df\\r\\n     a    b\\r\\n0 -5.0  5.0\\r\\n1 -3.0 -3.0\\r\\n2 -1.0  1.0\\r\\n3  0.2 -0.2\\r\\n4 -2.0 -2.0\\r\\npanda call\\r\\nwin=3 rolling median\\r\\n     a    b\\r\\n0  NaN  NaN\\r\\n1  NaN  NaN\\r\\n2 -3.0  1.0\\r\\n3 -1.0 -0.2\\r\\n4 -1.0 -0.2\\r\\ndf after rolling call - if copy is not done, then corrupted original df\\r\\n(in this case the df is intact due to the copy function, comment that out to see the error)\\r\\n     a    b\\r\\n0 -5.0  5.0\\r\\n1 -3.0 -3.0\\r\\n2 -1.0  1.0\\r\\n3  0.2 -0.2\\r\\n4 -2.0 -2.0\\r\\n\\r\\ncuDF call\\r\\n\\r\\nRuntimeError                              Traceback (most recent call last)\\r\\n/usr/local/lib/python3.6/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs)\\r\\n    744     try:\\r\\n--> 745         yield\\r\\n    746     except NumbaError as e:\\r\\n\\r\\n40 frames\\r\\nRuntimeError: NRT required but not enabled\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nLoweringError                             Traceback (most recent call last)\\r\\ncudf/_lib/rolling.pyx in cudf._lib.rolling.rolling()\\r\\n\\r\\ncudf/_lib/aggregation.pyx in cudf._lib.aggregation.make_aggregation()\\r\\n\\r\\ncudf/_lib/aggregation.pyx in cudf._lib.aggregation._AggregationFactory.from_udf()\\r\\n\\r\\n/usr/local/lib/python3.6/site-packages/numba/core/utils.py in reraise(tp, value, tb)\\r\\n     79     if value.__traceback__ is not tb:\\r\\n     80         raise value.with_traceback(tb)\\r\\n---> 81     raise value\\r\\n     82 \\r\\n     83 \\r\\n\\r\\nLoweringError: Failed in nopython mode pipeline (step: nopython mode backend)\\r\\nNRT required but not enabled\\r\\n\\r\\nFile \"<ipython-input-16-2c1e7f32fcdd>\", line 6:\\r\\ndef udf_median(x):\\r\\n    <source elided>\\r\\n  ##version 1\\r\\n  x2 = x.copy()\\r\\n  ^\\r\\n\\r\\nDuring: lowering \"$0.3 = call $0.2(func=$0.2, args=[], kws=(), vararg=None)\" at <ipython-input-16-2c1e7f32fcdd> (6)\\ncreatedAt: 2020-09-20T04:50:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 26}),\n",
       " Document(page_content=\": 66\\ntitle: [FEA] Improve escape character and quotation character parsing in Json and CSV reader.\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nAs of now, csv and json reader are post processing occurrences of escape character and quotation character once it parses complete string.\\r\\nhttps://github.com/rapidsai/cudf/blob/76e2e155ce6fe2194a2bb41aeca93b48a39a55c2/cpp/src/io/csv/reader_impl.cu#L375\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nWe might be able to handle skipping/leaving those character while copying the data.\\ncreatedAt: 2020-09-23T14:41:02Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ram (Ramakrishna Prabhu)\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 27}),\n",
       " Document(page_content=': 71\\ntitle: [BUG] `cudf.read_json` is incorrectly parsing TimeStamp typed columns\\nbody: **Describe the bug**\\r\\n`cudf.read_json` is failing to parse DateTime64 typed columns correctly when expected dtype is provided. \\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\n>>> import cudf\\r\\n>>> import pandas as pd\\r\\n>>> pdf = pd.DataFrame({\"a\":[45461150050, 55414521000, 4544624522000, 4546345758000, 45445254600]}, dtype=\\'datetime64[ms]\\')\\r\\n>>> pdf\\r\\n                        a\\r\\n0 1970-01-01 00:00:45.461\\r\\n1 1970-01-01 00:00:55.414\\r\\n2 1970-01-01 01:15:44.624\\r\\n3 1970-01-01 01:15:46.345\\r\\n4 1970-01-01 00:00:45.445\\r\\n>>> buffer = pdf.to_json(compression=\\'infer\\', lines=True, orient=\"records\")\\r\\n>>> buffer\\r\\n\\'{\"a\":45461}\\\\n{\"a\":55414}\\\\n{\"a\":4544624}\\\\n{\"a\":4546345}\\\\n{\"a\":45445}\\'\\r\\n>>> df = cudf.read_json(buffer, ompression=\\'infer\\', lines=True, orient=\"records\", dtype=[\\'timestamp[ms]\\'])\\r\\n>>> df\\r\\n                        a\\r\\n0 1969-12-31 23:59:59.999\\r\\n1 1969-12-31 23:59:59.999\\r\\n2 1969-12-31 23:59:59.999\\r\\n3 1969-12-31 23:59:59.999\\r\\n4 1969-12-31 23:59:59.999\\r\\n```\\r\\nIf `dtype` isn\\'t specified, and if we cast the resulting int64 column, we get expected result\\r\\n```\\r\\n>>> expected_df = cudf.read_json(buffer, ompression=\\'infer\\', lines=True, orient=\"records\")\\r\\n>>> expected_df[\\'a\\'] = expected_df[\\'a\\'].astype(\\'datetime64[ms]\\')\\r\\n>>> expected_df\\r\\n                        a\\r\\n0 1970-01-01 00:00:45.461\\r\\n1 1970-01-01 00:00:55.414\\r\\n2 1970-01-01 01:15:44.624\\r\\n3 1970-01-01 01:15:46.345\\r\\n4 1970-01-01 00:00:45.445\\r\\n>>> \\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n`cudf.read_json` should handle dtype arguement.\\r\\n```\\r\\n>>> df = cudf.read_json(buffer, ompression=\\'infer\\', lines=True, orient=\"records\", dtype=[\\'timestamp[ms]\\'])\\r\\n>>> df\\r\\n\\r\\n                        a\\r\\n0 1970-01-01 00:00:45.461\\r\\n1 1970-01-01 00:00:55.414\\r\\n2 1970-01-01 01:15:44.624\\r\\n3 1970-01-01 01:15:46.345\\r\\n4 1970-01-01 00:00:45.445\\r\\n>>> \\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Bare-metal\\r\\n - Method of cuDF install: conda\\ncreatedAt: 2020-09-30T22:49:03Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ram (Ramakrishna Prabhu)\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 28}),\n",
       " Document(page_content=\": 74\\ntitle: [FEA] Java host string columns should match list columns\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThe way we construct and layout strings and lists are different but essentially have similar functionality/usage, adding complexity around host side construction/deconstruction. This should be commonized.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nStrings can be represented as lists maybe.\\ncreatedAt: 2020-10-12T13:08:04Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Kuhu Shukla\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 29}),\n",
       " Document(page_content=\": 77\\ntitle: [BUG] Reading JSON file saved from Series fails\\nbody: **Describe the bug**\\r\\nReading a JSON file created from a Series `.to_json(path, orient='records', lines=True)` call leads to a `Input data is not a valid JSON file` when trying to read with `.read_json(path, orient='records', lines=True)` (with or without `engine='cudf'` parameter).\\r\\n\\r\\n**NOTE**: this is only a problem when saving Series in this format -- DataFrame objects are saved properly.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\ncudf.Series([1,2,3,4,5]).to_json('sample.json', lines=True, orient='records')\\r\\n\\r\\ncudf.read_json('sample.json', lines=True, orient='records')\\r\\n```\\r\\n\\r\\nThe output file looks as follows:\\r\\n\\r\\n```\\r\\n1\\r\\n2\\r\\n3\\r\\n4\\r\\n5\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nThe file is read back properly and produces a valid `cudf.Series` object. \\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Docker\\r\\n - Method of cuDF install: Docker\\r\\n   - RAPIDS v 0.16 pull from nightly.\\ncreatedAt: 2020-10-12T22:07:00Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Tomek Drabas\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 30}),\n",
       " Document(page_content=\": 79\\ntitle: [FEA] Add java/JNI support for substring() with non-literals parameters\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nWe currently support only literals as params to substring method, using the newly added `slice_strings` we should be able to support non-literals. \\r\\n\\r\\n**Describe the solution you'd like**\\r\\nRequires jni and java side bindings\\ncreatedAt: 2020-10-20T13:26:29Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Kuhu Shukla\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 31}),\n",
       " Document(page_content=': 88\\ntitle: [FEA] Support objects with default values in Series.map\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nI\\'d like for cuDF to support \\'defaultdict\\' like objects in the Series.map method. There is currently a NotImplementedError which contrasts from the Pandas implementation of Series.map\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nAn implementation of Series.map that converts values that are not found in the dict to a default value, if the dict has a default value (e.g. defaultdict).\\r\\n\\r\\n**Additional context**\\r\\nWith Pandas an example of this looks like\\r\\n```\\r\\n>>>p1 = pd.Series([\\'cat\\', \\'dog\\', np.nan, \\'rabbit\\'])\\r\\n>>>from collections import defaultdict\\r\\n>>>t = defaultdict(lambda: \\'bird\\')\\r\\n>>> t[\\'cat\\'] = \\'kitten\\'\\r\\n>>> t[\\'dog\\'] = \\'puppy\\'\\r\\n>>> p1.map(t)\\r\\n0    kitten\\r\\n1     puppy\\r\\n2      bird\\r\\n3      bird\\r\\ndtype: object\\r\\n```\\r\\nWith cuDF currently we get the following\\r\\n```\\r\\n>>> s = cudf.Series([\\'cat\\', \\'dog\\', np.nan, \\'rabbit\\'])\\r\\n>>>s.map(t)\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \"/home/nfs/mmhangami/marlene/rapids/cudf/python/cudf/cudf/core/series.py\", line 878, in map\\r\\n    \"default values in dicts are currently not supported.\"\\r\\nNotImplementedError: default values in dicts are currently not supported.\\r\\n```\\r\\n\\r\\nfor additional context see [pandas.Series.map](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) and PR #6459\\ncreatedAt: 2020-11-10T11:44:49Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Marlene\\ncompany: Microsoft', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 32}),\n",
       " Document(page_content=\": 89\\ntitle: [FEA]Coalesce(), find the first non-null value, no equivalent function in RAPIDS\\nbody: I want to create a new column, which is the first non-null value of several columns, I used the function [coalesce()](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/coalesce) in dplyr to achieve that by simply run ` data %>% mutate(d = coalesce(a, b, c))`, in Dask CPU, I run below code to achieve that\\r\\n```\\r\\nd = {'a': [1, 2, 3, None, 5, 1, None, None, None, None, 3, None, 5, 6, 7], \\\\\\r\\n     'b': [1, 2, 3, 200, 5, 1, 200, None, 400, None, 3, None, 5, 6, 7], \\\\\\r\\n     'c': [1, 2, 3, None, 5, 1, 300, 300, None, 600, 3, 300, 5, 6, 7]} \\r\\n\\r\\ndf2 = pd.DataFrame(d)\\r\\n\\r\\nddf2 = dd.from_pandas(df2,npartitions=50)\\r\\nddf2['d'] = ddf2['a'].copy().fillna(ddf2['b']).fillna(ddf2['c'])\\r\\nddf2.compute()\\r\\n```\\r\\nHowever, in dask cuDF, when I am trying to use the fillna() to acheive my intent, I got the error message\\r\\n```\\r\\nd = {'id': ['a', 'a','a','a','a','b','b','b','b','b','c','c','c','c','c'], \\\\\\r\\n     'time': ['1', '2', '4', '3', '5', '1', '2', '3', '4', '5','1', '2', '3', '4', '5'], \\\\\\r\\n     'a': [1, 2, 3, None, 5, 1, None, None, None, None, 3, None, 5, 6, 7], \\\\\\r\\n     'b': [1, 2, 3, 200, 5, 1, 200, None, 400, None, 3, None, 5, 6, 7], \\\\\\r\\n     'c': [1, 2, 3, None, 5, 1, 300, 300, None, 600, 3, 300, 5, 6, 7]} \\r\\n\\r\\ndf = pd.DataFrame(data=d)\\r\\ngdf = cudf.DataFrame.from_pandas(df)\\r\\n\\r\\nddf = dask_cudf.from_cudf(gdf, npartitions=4)\\r\\n\\r\\nddf['d'] = ddf['a'].copy().fillna(ddf['b']).fillna(ddf['c'])\\r\\nddf.compute()\\r\\n```\\r\\nerror message: `RuntimeError: cuDF failure at: /opt/conda/envs/rapids/conda-bld/libcudf_1598487636199/work/cpp/src/replace/replace.cu:804: Column size mismatch`\\r\\n\\r\\nSo I am wondering if there are functions that allows me to get the first non-null value from several columns in cuDF or if we can add that.\\ncreatedAt: 2020-11-12T21:16:22Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 33}),\n",
       " Document(page_content=': 90\\ntitle: [BUG] Bools written by cuIO ORC writer don\\'t match when read by pyarrow/pyorc\\nbody: When writing a large dataframe with bool column using cuIO ORC writer, the result of reading the file back using pyarrow does not match the input dataframe. However when reading back from cudf\\'s ORC reader it matches.\\r\\n\\r\\n```python\\r\\nimport pandas as pd\\r\\nimport numpy as np\\r\\nimport pyarrow as pa\\r\\nimport pyorc\\r\\nimport cudf\\r\\n\\r\\nnp.random.seed(0)\\r\\nfrom cudf._lib.null_mask import bitmask_allocation_size_bytes\\r\\n\\r\\ndef random_bitmask(size):\\r\\n    sz = bitmask_allocation_size_bytes(size)\\r\\n    data = np.random.randint(0, 255, dtype=\"u1\", size=sz)\\r\\n    return data.view(\"i1\")\\r\\n\\r\\nsize = 6000000\\r\\narr = np.random.randint(low=0, high=2, size=size).astype(np.bool)\\r\\ns = cudf.Series.from_masked_array(arr, random_bitmask(size))\\r\\ngdf = cudf.DataFrame({\"col_bool\": s})\\r\\n\\r\\n# write with cuIO\\r\\nfname = \"brokenbool.orc\"\\r\\ngdf.to_orc(fname)\\r\\n\\r\\n# read with pyarrow\\r\\npdf = pa.orc.ORCFile(fname).read().to_pandas()\\r\\n\\r\\n# the sum doesn\\'t match\\r\\nprint(gdf.col_bool.sum(), pdf.col_bool.sum())\\r\\n\\r\\n# read with pyorc\\r\\nfile = open(fname, \\'rb\\')\\r\\ndata = pyorc.Reader(file).read()\\r\\npdf = pd.DataFrame(data, columns=[\"col_bool\"])\\r\\n\\r\\n# sum matches pyarrow but not original df\\r\\nprint(gdf.col_bool.sum(), pdf.col_bool.sum())\\r\\n\\r\\n# reading with cuIO gives the correct result\\r\\nprint(gdf.col_bool.sum(), cudf.read_orc(fname).col_bool.sum())\\r\\n```\\r\\n\\r\\nNote that this doesn\\'t occur when there are no nulls in the input.\\ncreatedAt: 2020-11-13T08:17:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Devavret Makkar\\ncompany: @VoltronData', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 34}),\n",
       " Document(page_content=': 91\\ntitle: [FEA] Decimal constructor for boxed unscaled values\\nbody: As mentioned in conversation of #6770, it is good to have a decimal constructor for boxed unscaled values, which working with `ColumnVector.build`.\\ncreatedAt: 2020-11-18T01:54:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Alfred Xu\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 35}),\n",
       " Document(page_content=': 92\\ntitle: [FEA] Add factory methods for ColumnVector creation in cudf java\\nbody: As a follow on to https://github.com/rapidsai/cudf/pull/6751, we plan to move towards factory methods to create ColumnVector instances.\\ncreatedAt: 2020-11-18T15:22:04Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Kuhu Shukla\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 36}),\n",
       " Document(page_content=': 94\\ntitle: [BUG] arrow data: Categorical categories must be unique\\nbody: **Describe the bug**\\r\\n\\r\\nI switched from using csv format to feather format and getting and error for the same dataset. Error is being raised during printing. Sorry for not having minimal example but python is not my native language.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\nGenerate data in csv and feather\\r\\n```sh\\r\\nRscript -e \\'install.packages(c(\"data.table\",\"arrow\"))\\'\\r\\nwget https://raw.githubusercontent.com/h2oai/db-benchmark/629755352248c9538fbd924e56356e5592f268be/_data/groupby-datagen.R\\r\\nRscript groupby-datagen.R 1e7 1e2 0 0\\r\\nRscript -e \\'arrow::write_feather(data.table::fread(\"G1_1e7_1e2_0_0.csv\", stringsAsFactors=TRUE, data.table=FALSE), \"G1_1e7_1e2_0_0.feather\")\\'\\r\\n```\\r\\n\\r\\ncudf using csv\\r\\n```py\\r\\nimport cudf as cu\\r\\nx = cu.read_csv(\"G1_1e7_1e2_0_0.csv\", header=0, dtype=[\\'str\\',\\'str\\',\\'str\\',\\'int32\\',\\'int32\\',\\'int32\\',\\'int32\\',\\'int32\\',\\'float64\\'])\\r\\nx[\\'id1\\'] = x[\\'id1\\'].astype(\\'category\\')\\r\\nx[\\'id2\\'] = x[\\'id2\\'].astype(\\'category\\')\\r\\nx[\\'id3\\'] = x[\\'id3\\'].astype(\\'category\\')\\r\\nans = x.groupby([\\'id1\\'],as_index=False).agg({\\'v1\\':\\'sum\\'})\\r\\nprint(ans.head(3), flush=True)\\r\\n```\\r\\n```\\r\\n     id1      v1\\r\\n0  id001  299542\\r\\n1  id002  300933\\r\\n2  id003  301968\\r\\n```\\r\\n\\r\\ncudf using feather\\r\\n```py\\r\\nimport cudf as cu\\r\\nx = cu.io.feather.read_feather(\"data/G1_1e7_1e2_0_0.feather\")\\r\\n#/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/io/feather.py:15: UserWarning: Using CPU via PyArrow to read #feather \\r\\n#dataset, this may be GPU accelerated in the future\\r\\n#  warnings.warn(\\r\\nans = x.groupby([\\'id1\\'],as_index=False).agg({\\'v1\\':\\'sum\\'})\\r\\nprint(ans.head(3), flush=True)\\r\\n```\\r\\n```\\r\\nTraceback (most recent call last):\\r\\n  File \"./cudf/groupby-cudf.py\", line 58, in <module>\\r\\n    print(ans.head(3), flush=True)\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py\", line 1025, in __str__\\r\\n    return self.to_string()\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py\", line 1022, in to_string\\r\\n    return self.__repr__()\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py\", line 1272, in __repr__\\r\\n    return self._clean_renderable_dataframe(output)\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py\", line 1151, in _clean_renderable_dataframe\\r\\n    output = output.to_pandas().to_string(\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/dataframe.py\", line 4861, in to_pandas\\r\\n    out_data[i] = self._data[col_key].to_pandas(index=out_index)\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/cudf/core/column/categorical.py\", line 935, in to_pandas\\r\\n    data = pd.Categorical.from_codes(\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/arrays/categorical.py\", line 606, in from_codes\\r\\n    dtype = CategoricalDtype._from_values_or_dtype(\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py\", line 277, in _from_values_or_dtype\\r\\n    dtype = CategoricalDtype(categories, ordered)\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py\", line 164, in __init__\\r\\n    self._finalize(categories, ordered, fastpath=False)\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py\", line 318, in _finalize\\r\\n    categories = self.validate_categories(categories, fastpath=fastpath)\\r\\n  File \"/home/jan/anaconda3/envs/cudf/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py\", line 495, in validate_categories\\r\\n    raise ValueError(\"Categorical categories must be unique\")\\r\\nValueError: Categorical categories must be unique\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nPrinting `ans` should not raise error for feather source data, same as it doesn\\'t for csv data.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n\\r\\nbare-metal\\r\\ncudf installed from conda\\r\\n\\r\\n**Environment details**\\r\\n\\r\\n```\\r\\ncudf/print_env.sh\\r\\n#Traceback (most recent call last):\\r\\n#  File \"<stdin>\", line 1, in <module>\\r\\n#NameError: name \\'cudf\\' is not defined\\r\\n```\\r\\n\\r\\ncudf 0.16\\r\\narrow 2.0.0\\ncreatedAt: 2020-11-21T09:00:14Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Jan Gorecki\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 37}),\n",
       " Document(page_content=': 96\\ntitle: [FEA] Add function \"to_julian_date()\"  to cuDF\\nbody: \\'DatetimeIndex\\' object has no attribute \\'to_julian_date\\', would be good if it could do as pandas:\\r\\njulianday = pd.DatetimeIndex(df[\\'mydatetime\\']).to_julian_date()\\ncreatedAt: 2020-12-06T21:16:16Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 38}),\n",
       " Document(page_content=\": 107\\ntitle: [FEA] Support casting operations on nested types\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nCurrently we support `castTo` on primitive data types. This request is to extend this functionality/operator to nested types like lists, structs, and list of structs.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nOne should be able to call a cudf function to cast an `array(floats)` for example to an `array(doubles)`. We should also allow other valid casts that we support today to nested type category.\\ncreatedAt: 2021-01-27T14:31:06Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Kuhu Shukla\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 39}),\n",
       " Document(page_content=\": 108\\ntitle: [FEA] Support FIRST_VALUE and LAST_VALUE in grouped_rolling_window\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nLike ROW_NUMBER, which supported in PR 4881, FIRST_VALUE is widely used window function in sql. So, we want to provide it for BlazingSQL. FIRST_VALUE and LAST_VALUE are fairly trivial where there are no partitions to worry about, but if you have multiple groups or partitions, for the case of `grouped_rolling_window`, then its not so trivial, and we would want native support for that aggregator in cudf.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nImplementation of the aggregation for FIRST_VALUE and LAST_VALUE, especially for `grouped_rolling_window`\\ncreatedAt: 2021-01-27T21:56:45Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: William Malpica\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 40}),\n",
       " Document(page_content=': 117\\ntitle: [BUG] dask_cudf generates files it cannot read back\\nbody: **Describe the bug**\\r\\n\\r\\nSomewhere between `dgdf = dask_cudf.read_csv(..)` and `dgdf.to_parquet()`, the generated files are written in a way that `cudf.read_parquet` and `dask_cudf.read_parquet` will fail to read the data back.\\r\\n\\r\\nException:  `cuDF failure at: /opt/conda/envs/rapids/conda-bld/libcudf_1607621803079/work/cpp/src/io/parquet/reader_impl.cu:371: All sources must have the same schemas`\\r\\n\\r\\n\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\nMay need to fix paths:\\r\\n\\r\\nDownload:\\r\\n\\r\\n```bash\\r\\ncurl -O /tmp/logs.csv.gz \"https://s3.amazonaws.com/botsdataset/botsv1/csv-by-sourcetype/botsv1.WinEventLog%3ASecurity.csv.gz\"\\r\\n(cd /tmp && gunzip logs.csv.gz)\\r\\n```\\r\\n\\r\\nConvert:\\r\\n```python\\r\\nwith dask.distributed.Client(ADDRESS):\\r\\n  dgdf = dask_cudf.read_csv(\\'/tmp/logs.csv\\')\\r\\n  dgdf.to_parquet(\\r\\n       \\'/tmp/logs.parquet\\',\\r\\n        compression=\\'snappy\\',\\r\\n        write_index=False,\\r\\n        index=False)\\r\\n```\\r\\n\\r\\nTest: Unexpectedly throws exn\\r\\n```python\\r\\ncudf.read_parquet(\\'/tmp/logs.parquet\\')\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nThe converted file to read back with matching dtypes... but throws an exn\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\nRAPIDS 0.18 (conda) in docker (ubuntu); A100\\'s\\r\\n\\r\\n**Additional context**\\r\\n\\r\\n* Variants where we set `schema`, `dtypes`,  and `use_pandas_metadata` also fail\\r\\n* Also seeing failures when doing dask_cudf.read_parquet, and doing an intermediate repartition\\ncreatedAt: 2021-03-15T21:02:56Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: Graphistry', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 41}),\n",
       " Document(page_content=': 118\\ntitle: [FEA][INTERNALS] A `ColumnMeta` type to represent the column metadata of a `Frame`\\nbody: When we roundtrip a `Frame` between Python and libcudf, we potentially lose a bunch of metadata:\\r\\n\\r\\n1. Names of columns\\r\\n2. Whether the columns have multiple levels (i.e., the Frame has a MultiIndex as its columns(\\r\\n3. The level names\\r\\n\\r\\n## The problem\\r\\n\\r\\nlibcudf functions return a `unique_ptr<cudf::table>`, we  convert that `table` into a  `Frame` in the function [from_unique_ptr](https://github.com/rapidsai/cudf/blob/ec5364c2fc0a3c63583e648ec90efa8d3b5675bc/python/cudf/cudf/_lib/table.pyx#L82). Here, we pass the column names (1), but not the multiindex (2) or level_names (3) metadata.\\r\\n\\r\\nThis can lead to surprising behaviour in many situations. For example, consider the `loc` call below where we lose the `multiindex` part of our metadata:\\r\\n\\r\\n```python\\r\\nIn [10]: df\\r\\nOut[10]:\\r\\n    a       b\\r\\n  sum min max min\\r\\na\\r\\n2   4   2   5   4\\r\\n1   3   1   3   1\\r\\n\\r\\nIn [11]: df.loc[[2, 2, 1, 1], :]\\r\\nOut[11]:\\r\\n   (a, sum)  (a, min)  (b, max)  (b, min)\\r\\na\\r\\n2         4         2         5         4\\r\\n2         4         2         5         4\\r\\n1         3         1         3         1\\r\\n1         3         1         3         1\\r\\n\\r\\nIn [12]: df.to_pandas().loc[[2, 2, 1, 1], :]\\r\\nOut[12]:\\r\\n    a       b\\r\\n  sum min max min\\r\\na\\r\\n2   4   2   5   4\\r\\n2   4   2   5   4\\r\\n1   3   1   3   1\\r\\n1   3   1   3   1\\r\\n```\\r\\n\\r\\n## Proposed solution\\r\\n\\r\\nWe could introduce an internal `ColumnMeta` type:\\r\\n\\r\\n```python\\r\\nclass ColumnMeta:\\r\\n    names: Tuple[Any]\\r\\n    multiindex: bool\\r\\n    level_names: Optional[Tuple[Any]]\\r\\n```\\r\\n\\r\\nwhich could be a property of `Frame` objects for convenience:\\r\\n\\r\\n```python\\r\\nclass Frame:\\r\\n    @cached_property\\r\\n    def _column_meta(self):\\r\\n         ...\\r\\n```\\r\\n\\r\\nNow, instead of passing just the column names and index names to `from_unique_ptr`, we could pass the full metadata for both:\\r\\n\\r\\n```python\\r\\ncdef Table from_unique_ptr(\\r\\n    unique_ptr[table] c_tbl,\\r\\n    ColumnMeta data_meta,\\r\\n    ColumnMeta index_meta=None\\r\\n):\\r\\n```\\r\\n\\r\\nand it would construct the resulting `Frame` with the correct column metadata.\\r\\n\\r\\n--\\r\\n\\r\\nWith this, a typical Python wrapper around a libcudf API would be:\\r\\n\\r\\n```python\\r\\ndef py_func(Table foo, ...):\\r\\n    cdef table_view c_input = foo.view()\\r\\n    cdef unique_ptr[table] c_result\\r\\n    with nogil:\\r\\n        c_result = cpp_func(c_input)\\r\\n    return Table.from_unique_ptr(c_result, foo._column_meta, foo.index._column_meta)\\r\\n```\\ncreatedAt: 2021-03-18T22:07:35Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 42}),\n",
       " Document(page_content=': 120\\ntitle: [FEA] rolling correlation\\nbody: **What is your question?**\\r\\nHow to calculate rolling correlation between two cuDF columns?\\ncreatedAt: 2021-03-22T14:11:38Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 43}),\n",
       " Document(page_content=': 121\\ntitle: [FEA] Mixed precision Decimal math support in cudf Python\\nbody: Using recent cudf nightly conda package (0.19.0a+250.g8632ca0da3):\\r\\n\\r\\n**Int & Decimal Addition**:\\r\\n```\\r\\nimport cudf\\r\\nfrom cudf.core.dtypes import Decimal64Dtype\\r\\n\\r\\ndf = cudf.DataFrame({\\'val\\': [0.01, 0.02, 0.03]})\\r\\n\\r\\ndf[\\'dec_val\\'] = df[\\'val\\'].astype(Decimal64Dtype(7,2))\\r\\ndf[\\'dec_val\\'] + 1\\r\\n```\\r\\n**Result**:\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nAttributeError                            Traceback (most recent call last)\\r\\n<ipython-input-8-d4f1761193b6> in <module>\\r\\n----> 1 df[\\'val\\'] + 1\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/series.py in __add__(self, other)\\r\\n   1600 \\r\\n   1601     def __add__(self, other):\\r\\n-> 1602         return self._binaryop(other, \"add\")\\r\\n   1603 \\r\\n   1604     def radd(self, other, fill_value=None, axis=0):\\r\\n\\r\\n/conda/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     73         def inner(*args, **kwds):\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n     77 \\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/series.py in _binaryop(self, other, fn, fill_value, reflect, can_reindex)\\r\\n   1515         else:\\r\\n   1516             lhs, rhs = self, other\\r\\n-> 1517         rhs = self._normalize_binop_value(rhs)\\r\\n   1518 \\r\\n   1519         if fn == \"truediv\":\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/series.py in _normalize_binop_value(self, other)\\r\\n   2307             return cudf.Scalar(other, dtype=self.dtype)\\r\\n   2308         else:\\r\\n-> 2309             return self._column.normalize_binop_value(other)\\r\\n   2310 \\r\\n   2311     def eq(self, other, fill_value=None, axis=0):\\r\\n\\r\\nAttributeError: \\'DecimalColumn\\' object has no attribute \\'normalize_binop_value\\'\\r\\n```\\r\\n\\r\\n**Workaround**:\\r\\n```\\r\\nimport cudf\\r\\nfrom cudf.core.dtypes import Decimal64Dtype\\r\\n\\r\\ndf = cudf.DataFrame({\\'val\\': [0.01, 0.02, 0.03]})\\r\\n\\r\\ndf[\\'dec_val\\'] = df[\\'val\\'].astype(Decimal64Dtype(7,2))\\r\\ndf[\\'ones\\'] = 1.00\\r\\ndf[\\'dec_val\\'] + df[\\'ones\\'].astype(Decimal64Dtype(7,0))\\r\\n```\\r\\n```\\r\\n0    1.01\\r\\n1    1.02\\r\\n2    1.03\\r\\ndtype: decimal\\r\\n```\\r\\n\\r\\n**Decimal & Float Multiplication**:\\r\\n```\\r\\nimport cudf\\r\\nfrom cudf.core.dtypes import Decimal64Dtype\\r\\n\\r\\ndf = cudf.DataFrame({\\'val\\': [0.01, 0.02, 0.03]})\\r\\n\\r\\ndf[\\'dec_val\\'] = df[\\'val\\'].astype(Decimal64Dtype(7,2))\\r\\ndf[\\'val\\'] * df[\\'dec_val\\']\\r\\n```\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\n<ipython-input-13-4680a31be74b> in <module>\\r\\n----> 1 df[\\'val\\'] * df[\\'dec_val\\']\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/series.py in __mul__(self, other)\\r\\n   1799 \\r\\n   1800     def __mul__(self, other):\\r\\n-> 1801         return self._binaryop(other, \"mul\")\\r\\n   1802 \\r\\n   1803     def rmul(self, other, fill_value=None, axis=0):\\r\\n\\r\\n/conda/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     73         def inner(*args, **kwds):\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n     77 \\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/series.py in _binaryop(self, other, fn, fill_value, reflect, can_reindex)\\r\\n   1542                     rhs = rhs.fillna(fill_value)\\r\\n   1543 \\r\\n-> 1544         outcol = lhs._column.binary_operator(fn, rhs, reflect=reflect)\\r\\n   1545         result = lhs._copy_construct(data=outcol, name=result_name)\\r\\n   1546         return result\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/column/numerical.py in binary_operator(self, binop, rhs, reflect)\\r\\n    108             ):\\r\\n    109                 msg = \"{!r} operator not supported between {} and {}\"\\r\\n--> 110                 raise TypeError(msg.format(binop, type(self), type(rhs)))\\r\\n    111             out_dtype = np.result_type(self.dtype, rhs.dtype)\\r\\n    112             if binop in [\"mod\", \"floordiv\"]:\\r\\n\\r\\nTypeError: \\'mul\\' operator not supported between <class \\'cudf.core.column.numerical.NumericalColumn\\'> and <class \\'cudf.core.column.decimal.DecimalColumn\\'\\r\\n```\\r\\n\\r\\n**Workaround**:\\r\\n```\\r\\nimport cudf\\r\\nfrom cudf.core.dtypes import Decimal64Dtype\\r\\n\\r\\ndf = cudf.DataFrame({\\'val\\': [0.01, 0.02, 0.03]})\\r\\n\\r\\ndf[\\'dec_val\\'] = df[\\'val\\'].astype(Decimal64Dtype(7,2))\\r\\ndf[\\'dec_val\\'] * df[\\'val\\'].astype(Decimal64Dtype(7, 2))\\r\\n```\\r\\n```\\r\\n0    0.0001\\r\\n1    0.0004\\r\\n2    0.0009\\r\\ndtype: decimal\\r\\n```\\ncreatedAt: 2021-03-23T14:36:45Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Randy Gelhausen\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 44}),\n",
       " Document(page_content=': 123\\ntitle: [FEA] Support list types in \"to_csv\"\\nbody: **Example**:\\r\\n```\\r\\nimport cudf\\r\\n\\r\\ndf = cudf.DataFrame({\\'id\\': [0, 1], \\'list_col\\': [[0, 0], [1, 1]]})\\r\\ndf.to_csv(\\'test.csv\\')\\r\\n```\\r\\n**Result**:\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\n<ipython-input-11-781fe2a14f27> in <module>\\r\\n      1 df = cudf.DataFrame({\\'id\\': [0, 1], \\'list_col\\': [[0, 0], [1, 1]]})\\r\\n----> 2 df.to_csv(\\'test.csv\\')\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/dataframe.py in to_csv(self, path_or_buf, sep, na_rep, columns, header, index, line_terminator, chunksize, encoding, compression, **kwargs)\\r\\n   7366         from cudf.io import csv as csv\\r\\n   7367 \\r\\n-> 7368         return csv.to_csv(\\r\\n   7369             self,\\r\\n   7370             path_or_buf=path_or_buf,\\r\\n\\r\\n/conda/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     73         def inner(*args, **kwds):\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n     77 \\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/io/csv.py in to_csv(df, path_or_buf, sep, na_rep, columns, header, index, line_terminator, chunksize, encoding, compression, **kwargs)\\r\\n    157     for col in df._data.columns:\\r\\n    158         if isinstance(col, cudf.core.column.ListColumn):\\r\\n--> 159             raise NotImplementedError(\\r\\n    160                 \"Writing to csv format is not yet supported with \"\\r\\n    161                 \"list columns.\"\\r\\n\\r\\nNotImplementedError: Writing to csv format is not yet supported with list columns.\\r\\n```\\r\\n\\r\\nPandas does this by wrapping a stringified representation of each row\\'s list `quotechar`:\\r\\n```\\r\\nimport pandas as pd\\r\\n\\r\\ndf = pd.DataFrame({\\'id\\': [0, 1], \\'list_col\\': [[0, 0], [1, 1]]})\\r\\ndf.to_csv(\\'test.csv\\')\\r\\n```\\r\\ntest.csv:\\r\\n```\\r\\n,id,list_col\\r\\n0,0,\"[0, 0]\"\\r\\n1,1,\"[1, 1]\"\\r\\n```\\ncreatedAt: 2021-03-24T15:55:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Randy Gelhausen\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 45}),\n",
       " Document(page_content=': 124\\ntitle: [FEA] dask_cudf cross-partition type coercions\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nIt\\'s been frustrating adapting cudf -> dask_cudf kernels in two basic areas around cross-partition type mismatches:\\r\\n\\r\\n* ingest: loading json, csv, etc. that vary in column types across partitions: existence, nans, int vs float, etc. When the code writer isn\\'t the user -- so a library, piece of software, a UI, this is common and you can\\'t just workaround by specifying dtypes ahead of time\\r\\n\\r\\n* compute: when doing data cleaning (ex: date inference) or some algs, it\\'s unclear what `meta` should be ahead of time, only after you actually do the calc. dask will sample the first df... which is often wrong\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\ndask_cudf ingest operators: an auto-coercion flag (\"when columns are in conflict across partitions, coerce to the closest common type, like float or str\")\\r\\n\\r\\ndask_cudf map, concat, etc: same thing\\r\\n\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\n\\r\\nIt may also be possible to make each operator smarter via sampling or other tricks. dask core and some cudf io seems to be experimenting here.\\r\\n\\r\\nI like explicit flags b/c of their predictability/reliability, and uniformity... but ultimately, whatever work :)\\r\\n\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nBy default, I\\'m guessing this issue will be ignored & deprioritized ;-)\\r\\n\\r\\nBefore doing that, it may be worth polling dask_cudf users -- not devs -- how they feel about this ;-) my bet is people spend a surprising % of their time on a few issues around here, well before actual perf\\ncreatedAt: 2021-03-26T21:18:23Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: Graphistry', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 46}),\n",
       " Document(page_content=': 128\\ntitle: [FEA] Groupby support with Decimal column as key column\\nbody: ```\\r\\nimport cudf\\r\\nfrom cudf.core.dtypes import Decimal64Dtype\\r\\n\\r\\ndf = cudf.DataFrame({\\'id\\': [0, 1, 2]})\\r\\n\\r\\ndf[\\'id_dec\\'] = df[\\'id\\'].astype(Decimal64Dtype(7,2))\\r\\n\\r\\n#works\\r\\ndf.groupby(\\'id\\').count()\\r\\n\\r\\n# fails\\r\\ndf.groupby(\\'id_dec\\').count()\\r\\n```\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nRecursionError                            Traceback (most recent call last)\\r\\n<ipython-input-6-a16bdd01391b> in <module>\\r\\n----> 1 df.groupby(\\'id_dec\\').count()\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in _agg_func_name_with_args(self, func_name, *args, **kwargs)\\r\\n    605 \\r\\n    606     func.__name__ = func_name\\r\\n--> 607     return self.agg(func)\\r\\n    608 \\r\\n    609 \\r\\n\\r\\n/conda/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     73         def inner(*args, **kwds):\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n     77 \\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in agg(self, func)\\r\\n    163         # a Float64Index, while Pandas returns an Int64Index\\r\\n    164         # (GH: 6945)\\r\\n--> 165         result = self._groupby.aggregate(self.obj, normalized_aggs)\\r\\n    166 \\r\\n    167         result = cudf.DataFrame._from_table(result)\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/utils/utils.py in __get__(self, instance, cls)\\r\\n    276             return self\\r\\n    277         else:\\r\\n--> 278             value = self.func(instance)\\r\\n    279             setattr(instance, self.func.__name__, value)\\r\\n    280             return value\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in _groupby(self)\\r\\n    102     @cached_property\\r\\n    103     def _groupby(self):\\r\\n--> 104         return libgroupby.GroupBy(self.grouping.keys, dropna=self._dropna)\\r\\n    105 \\r\\n    106     @annotate(\"GROUPBY_AGG\", domain=\"cudf_python\")\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/groupby/groupby.py in keys(self)\\r\\n    887             )\\r\\n    888         else:\\r\\n--> 889             return cudf.core.index.as_index(\\r\\n    890                 self._key_columns[0], name=self.names[0]\\r\\n    891             )\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/index.py in as_index(arbitrary, **kwargs)\\r\\n   2866     elif isinstance(arbitrary, range):\\r\\n   2867         return RangeIndex(arbitrary, **kwargs)\\r\\n-> 2868     return as_index(\\r\\n   2869         column.as_column(arbitrary, dtype=kwargs.get(\"dtype\", None)), **kwargs\\r\\n   2870     )\\r\\n\\r\\n... last 1 frames repeated, from the frame below ...\\r\\n\\r\\n/conda/lib/python3.8/site-packages/cudf/core/index.py in as_index(arbitrary, **kwargs)\\r\\n   2866     elif isinstance(arbitrary, range):\\r\\n   2867         return RangeIndex(arbitrary, **kwargs)\\r\\n-> 2868     return as_index(\\r\\n   2869         column.as_column(arbitrary, dtype=kwargs.get(\"dtype\", None)), **kwargs\\r\\n   2870     )\\r\\n\\r\\nRecursionError: maximum recursion depth exceeded in comparison\\r\\n```\\ncreatedAt: 2021-04-01T22:08:37Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Randy Gelhausen\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 47}),\n",
       " Document(page_content=\": 130\\ntitle: [DOC] Rolling window apply with constant parameters.\\nbody: ## Report incorrect documentation\\r\\n\\r\\n**Location of incorrect documentation**\\r\\n https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.window.rolling.Rolling.apply.html?highlight=apply#pandas.core.[…]olling.apply\\r\\n\\r\\n**Describe the problems or issues found in the documentation**\\r\\nIs the rolling apply fully implemented? `args` and `kwargs` seem to be ignored, or I am doing it wrong. I searched far and wide for examples of how to add a constant parameter for this function (like decay rate) but I have not found it. \\r\\n\\r\\nLooking at the implementation in Github https://github.com/rapidsai/cudf/blob/c929ba1fe85c152d6e8b4c868cd36f0802dafa51/python/cudf/cudf/core/window/rolling.py#L254 it also does not become directly clear how to use it. `args` and `kwargs` are not referenced.\\r\\n\\r\\n**Steps taken to verify documentation is incorrect**\\r\\nList any steps you have taken:\\r\\nLooked at the source code and examples.\\r\\n\\r\\n**Suggested fix for documentation**\\r\\nDetail proposed changes to fix the documentation if you have any.\\r\\nGive an example usage of the rolling apply with a constant parameter (for example, decay rate).\\r\\n---\\r\\n\\r\\n## Report needed documentation\\r\\n\\r\\n**Report needed documentation**\\r\\nA lot of rolling functions will have some kind of configuration parameters that are required. It should be possible to pass them.\\r\\n\\r\\n**Describe the documentation you'd like**\\r\\nEither documentation giving examples for this use case should be added, or if the feature is forgotten, the feature should be completed.\\r\\n\\r\\n**Steps taken to search for needed documentation**\\r\\nList any steps you have taken:\\r\\n- Google\\r\\n- https://pandas.pydata.org/pandas-docs/stable/user_guide/window.html#rolling-window\\r\\n- https://docs.rapids.ai/api/cudf/stable/api.html?highlight=apply#cudf.core.window.Rolling.apply\\ncreatedAt: 2021-04-04T12:48:14Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Disper\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 48}),\n",
       " Document(page_content=': 131\\ntitle: [FEA] Support string concatenation of a Series and something array-like into a Series\\nbody: I’d like for cuDF to support concatenating a series and something array-like into a series similarly to how Pandas functions.\\r\\n\\r\\n# Example:\\r\\n```\\r\\ncudfArray = cudf.concat([cudfSeriesB, cudfSeries], axis=1)\\r\\ncudfSeries\\r\\ncudfArray\\r\\ncudfSeries.str.cat(cudfArray, na_rep=\"-\")\\r\\n```\\r\\n\\r\\n# Result:\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/column.py in as_column(arbitrary, nan_as_null, dtype, length)\\r\\n   1950             data = as_column(\\r\\n-> 1951                 memoryview(arbitrary), dtype=dtype, nan_as_null=nan_as_null\\r\\n   1952             )\\r\\n\\r\\nTypeError: memoryview: a bytes-like object is required, not \\'DataFrame\\'\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nTypeError                                 Traceback (most recent call last)\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/column.py in as_column(arbitrary, nan_as_null, dtype, length)\\r\\n   1987                         if nan_as_null is None\\r\\n-> 1988                         else nan_as_null,\\r\\n   1989                     ),\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/array.pxi in pyarrow.lib.array()\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/error.pxi in pyarrow.lib.check_status()\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/dataframe.py in __arrow_array__(self, type)\\r\\n   1018         raise TypeError(\\r\\n-> 1019             \"Implicit conversion to a host PyArrow Table via __arrow_array__ \"\\r\\n   1020             \"is not allowed, To explicitly construct a PyArrow Table, \"\\r\\n\\r\\nTypeError: Implicit conversion to a host PyArrow Table via __arrow_array__ is not allowed, To explicitly construct a PyArrow Table, consider using .to_arrow()\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nTypeError                                 Traceback (most recent call last)\\r\\n<ipython-input-64-9046cb089696> in <module>\\r\\n      2 cudfSeries\\r\\n      3 cudfArray\\r\\n----> 4 cudfSeries.str.cat(cudfArray, na_rep=\"-\")\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/string.py in cat(self, others, sep, na_rep)\\r\\n    441             )\\r\\n    442         else:\\r\\n--> 443             other_cols = _get_cols_list(self._parent, others)\\r\\n    444             all_cols = [self._column] + other_cols\\r\\n    445             data = cpp_concatenate(\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/string.py in _get_cols_list(parent_obj, others)\\r\\n   5198             others = others.reindex(parent_index)\\r\\n   5199 \\r\\n-> 5200         return [column.as_column(others, dtype=\"str\")]\\r\\n   5201     else:\\r\\n   5202         raise TypeError(\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/column/column.py in as_column(arbitrary, nan_as_null, dtype, length)\\r\\n   1996                     data = as_column(sr, nan_as_null=nan_as_null, dtype=dtype)\\r\\n   1997                 elif np_type == np.str_:\\r\\n-> 1998                     sr = pd.Series(arbitrary, dtype=\"str\")\\r\\n   1999                     data = as_column(sr, nan_as_null=nan_as_null)\\r\\n   2000                 else:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath)\\r\\n    325                     data = data.copy()\\r\\n    326             else:\\r\\n--> 327                 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)\\r\\n    328 \\r\\n    329                 data = SingleBlockManager.from_array(data, index)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure)\\r\\n    461         subarr = construct_1d_arraylike_from_scalar(data, len(index), dtype)\\r\\n    462     else:\\r\\n--> 463         subarr = _try_cast(data, dtype, copy, raise_cast_failure)\\r\\n    464 \\r\\n    465     # scalar like, GH\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/construction.py in _try_cast(arr, dtype, copy, raise_cast_failure)\\r\\n    566             subarr = construct_1d_object_array_from_listlike(subarr)\\r\\n    567         elif not is_extension_array_dtype(subarr):\\r\\n--> 568             subarr = construct_1d_ndarray_preserving_na(subarr, dtype, copy=copy)\\r\\n    569     except OutOfBoundsDatetime:\\r\\n    570         # in case of out of bound datetime64 -> always raise\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/dtypes/cast.py in construct_1d_ndarray_preserving_na(values, dtype, copy)\\r\\n   1621 \\r\\n   1622     if dtype is not None and dtype.kind == \"U\":\\r\\n-> 1623         subarr = lib.ensure_string_array(values, convert_na_value=False, copy=copy)\\r\\n   1624     else:\\r\\n   1625         subarr = np.array(values, dtype=dtype, copy=copy)\\r\\n\\r\\npandas/_libs/lib.pyx in pandas._libs.lib.ensure_string_array()\\r\\n\\r\\npandas/_libs/lib.pyx in pandas._libs.lib.ensure_string_array()\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/numpy/core/_asarray.py in asarray(a, dtype, order)\\r\\n     81 \\r\\n     82     \"\"\"\\r\\n---> 83     return array(a, dtype, copy=False, order=order)\\r\\n     84 \\r\\n     85 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/dataframe.py in __array__(self, dtype)\\r\\n   1009     def __array__(self, dtype=None):\\r\\n   1010         raise TypeError(\\r\\n-> 1011             \"Implicit conversion to a host NumPy array via __array__ is not \"\\r\\n   1012             \"allowed, To explicitly construct a GPU matrix, consider using \"\\r\\n   1013             \".as_gpu_matrix()\\\\nTo explicitly construct a host \"\\r\\n\\r\\nTypeError: Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .as_gpu_matrix()\\r\\nTo explicitly construct a host matrix, consider using .as_matrix()\\r\\n```\\r\\n\\r\\n**Pandas does this by Concatenating a series and something array-like (dataframe) into a series.:**\\r\\n \\r\\n```\\r\\npandasArray = pd.concat([pandasSeriesB, pandasSeries], axis=1)\\r\\npandasSeries\\r\\npandasArray\\r\\npandasSeries.str.cat(pandasArray, na_rep=\"-\")\\r\\n\\r\\n```\\r\\n**A cudf workaround was found doing the following:**\\r\\n\\r\\n```\\r\\ncudfArray = cudf.concat([cudfSeriesB, cudfSeries], axis=1)\\r\\nprint(cudfSeries)\\r\\nprint(cudfArray)\\r\\nprint(cudfSeriesB)\\r\\n#cudfArray = cudfArray.as_matrix()\\r\\ncudfArray[1].str.cat(cudfArray[0], na_rep=\"-\").str.cat(cudfSeries, na_rep=\"-\")\\r\\n```\\ncreatedAt: 2021-04-08T01:26:40Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 49}),\n",
       " Document(page_content=': 132\\ntitle: [FEA] Support an “extractall” method\\nbody: I’d like for cuDF to support an “extractall” method similarly to how Pandas functions\\r\\n\\r\\n# Example:\\r\\n\\r\\n```\\r\\ncudfSeries = cudf.Series([\"a1a2\", \"b1\", \"c1\"], index=[\"A\", \"B\", \"C\"], dtype=\"str\")\\r\\ncudfSeries\\r\\ncudf_two_groups = \"(?P<letter>[a-z])(?P<digit>[0-9])\"\\r\\ncudfSeries.str.extract(cudf_two_groups, expand=True)\\r\\ncudfSeries.str.extractall(cudf_two_groups)\\r\\n```\\r\\n \\r\\n# Result:\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nAttributeError                            Traceback (most recent call last)\\r\\n<ipython-input-76-e32113055d25> in <module>\\r\\n----> 1 cudfSeries.str.extractall(cudf_two_groups)\\r\\n \\r\\nAttributeError: \\'StringMethods\\' object has no attribute \\'extractall\\'\\r\\n```\\r\\n \\r\\n\\r\\n**Pandas does this by extracting using ‘extractall’ is always a DataFrame with a MultiIndex on its rows. The last level of the MultiIndex is named match and indicates the order in the subject.:**\\r\\n \\r\\npandasSeries = pd.Series([\"a1a2\", \"b1\", \"c1\"], index=[\"A\", \"B\", \"C\"], dtype=\"string\")\\r\\npandasSeries\\r\\npandas_two_groups = \"(?P<letter>[a-z])(?P<digit>[0-9])\"\\r\\npandasSeries.str.extract(pandas_two_groups, expand=True)\\r\\npandasSeries.str.extractall(pandas_two_groups)\\r\\n\\r\\n# Output\\r\\n\\r\\n```\\r\\n\\t   letter   digit\\r\\n    match\\t\\t\\r\\n_________________________\\r\\nA\\t0\\ta\\t1\\r\\n1\\ta\\t2\\r\\nB\\t0\\tb\\t1\\r\\nC\\t0\\tc\\t1\\r\\n```\\ncreatedAt: 2021-04-08T07:30:21Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 50}),\n",
       " Document(page_content=': 133\\ntitle: [FEA] Support `cudf::replace_nulls` on structs\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nI am working on supporting join on StructType in spark-rapids.  And I found an unsupported error while testing FullOuterJoin, which caused by `cudf::replace_nulls` on StructType.  Here is the [link](https://github.com/rapidsai/cudf/blob/branch-0.20/java/src/main/native/src/TableJni.cpp#L1696) of error code piece.\\ncreatedAt: 2021-04-13T14:18:04Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Alfred Xu\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 51}),\n",
       " Document(page_content=\": 136\\ntitle: [FEA] Support lists as groupby keys\\nbody: I'd like to be able to use lists as keys in a groupby:\\r\\n```\\r\\nimport cudf\\r\\n\\r\\ndf = cudf.DataFrame({\\r\\n    'id': [0, 1],\\r\\n    'id_lst': [[0, 0], [1, 1]],\\r\\n    'val': [0, 1]\\r\\n})\\r\\n\\r\\ndf.groupby(['id', 'id_lst']).val.sum()\\r\\n```\\r\\nResult:\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\n~/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath)\\r\\n    339             try:\\r\\n--> 340                 codes, categories = factorize(values, sort=True)\\r\\n    341             except TypeError as err:\\r\\n\\r\\n~/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/algorithms.py in factorize(values, sort, na_sentinel, size_hint)\\r\\n    721 \\r\\n--> 722         codes, uniques = factorize_array(\\r\\n    723             values, na_sentinel=na_sentinel, size_hint=size_hint, na_value=na_value\\r\\n\\r\\n~/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/algorithms.py in factorize_array(values, na_sentinel, size_hint, na_value, mask)\\r\\n    527     table = hash_klass(size_hint or len(values))\\r\\n--> 528     uniques, codes = table.factorize(\\r\\n    529         values, na_sentinel=na_sentinel, na_value=na_value, mask=mask\\r\\n\\r\\npandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.factorize()\\r\\n\\r\\npandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable._unique()\\r\\n\\r\\nTypeError: unhashable type: 'numpy.ndarray'\\r\\n```\\r\\n\\r\\nOne workaround is once [string list concatenation](https://github.com/rapidsai/cudf/pull/7929) merges, converting `id_lst` to a tokenized string and using the string representation as the grouping key.\\ncreatedAt: 2021-04-22T18:26:08Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Randy Gelhausen\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 52}),\n",
       " Document(page_content=': 141\\ntitle: Concatenated rows exceeds size_type range after merge operation[BUG]\\nbody: **Describe the bug**\\r\\nHi Guys,  I got an error about `Total number of concatenated rows exceeds size_type range` after  doing an`inner join` on two `dask_cudf` dfs. It seems that some partitions contains a large number of rows. However, the code works good when I `concat` these two dfs.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nIn my understanding, the rows in q2 should be larger than q1 .\\r\\n```\\r\\n# setup\\r\\nc = LocalCUDACluster( device_memory_limit=0.8, rmm_managed_memory=True, jit_unspill=True)\\r\\nc = Client(c)\\r\\n\\r\\n# 40G data\\r\\na = dask_cudf.read_orc(\\'a/*.orc\\')\\r\\n# 4G data\\r\\nb = dask_cudf.read_orc(\\'b/*.orc\\')\\r\\n\\r\\n# Works good\\r\\nq2 = dask_cudf.concat([a,b])\\r\\nq2.map_partitions(len).compute()\\r\\n\\r\\n0        307200\\r\\n1        291840\\r\\n2        337920\\r\\n3        261120\\r\\n4        256000\\r\\n          ...  \\r\\n21529    100525\\r\\n21530     94142\\r\\n21531     86762\\r\\n21532     94782\\r\\n21533     12502\\r\\nLength: 21534, dtype: int64\\r\\n\\r\\n# Errors with concatenated rows exceeds size_type range\\r\\nq1 = a.merge(b, on=[\\'a\\'],how=\\'inner\\' )\\r\\nlength_partition = q1.map_partitions(len)\\r\\nlength_partition.compute()\\r\\n\\r\\n---------------------------------------------------------------------------\\r\\nRuntimeError                              Traceback (most recent call last)\\r\\n<ipython-input-8-efedf1b4ef97> in <module>\\r\\n      1 length_partition = q1.map_partitions(len)\\r\\n----> 2 length_partition.compute()\\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/dask/base.py in compute(self, **kwargs)\\r\\n    282         dask.base.compute\\r\\n    283         \"\"\"\\r\\n--> 284         (result,) = compute(self, traverse=False, **kwargs)\\r\\n    285         return result\\r\\n    286 \\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/dask/base.py in compute(*args, **kwargs)\\r\\n    564         postcomputes.append(x.__dask_postcompute__())\\r\\n    565 \\r\\n--> 566     results = schedule(dsk, keys, **kwargs)\\r\\n    567     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\\r\\n    568 \\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py in get(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\\r\\n   2664                     should_rejoin = False\\r\\n   2665             try:\\r\\n-> 2666                 results = self.gather(packed, asynchronous=asynchronous, direct=direct)\\r\\n   2667             finally:\\r\\n   2668                 for f in futures.values():\\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py in gather(self, futures, errors, direct, asynchronous)\\r\\n   1979                 direct=direct,\\r\\n   1980                 local_worker=local_worker,\\r\\n-> 1981                 asynchronous=asynchronous,\\r\\n   1982             )\\r\\n   1983 \\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py in sync(self, func, asynchronous, callback_timeout, *args, **kwargs)\\r\\n    842         else:\\r\\n    843             return sync(\\r\\n--> 844                 self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\\r\\n    845             )\\r\\n    846 \\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/distributed/utils.py in sync(loop, func, callback_timeout, *args, **kwargs)\\r\\n    351     if error[0]:\\r\\n    352         typ, exc, tb = error[0]\\r\\n--> 353         raise exc.with_traceback(tb)\\r\\n    354     else:\\r\\n    355         return result[0]\\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/distributed/utils.py in f()\\r\\n    334             if callback_timeout is not None:\\r\\n    335                 future = asyncio.wait_for(future, callback_timeout)\\r\\n--> 336             result[0] = yield future\\r\\n    337         except Exception as exc:\\r\\n    338             error[0] = sys.exc_info()\\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/tornado/gen.py in run(self)\\r\\n    760 \\r\\n    761                     try:\\r\\n--> 762                         value = future.result()\\r\\n    763                     except Exception:\\r\\n    764                         exc_info = sys.exc_info()\\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py in _gather(self, futures, errors, direct, local_worker)\\r\\n   1838                             exc = CancelledError(key)\\r\\n   1839                         else:\\r\\n-> 1840                             raise exception.with_traceback(traceback)\\r\\n   1841                         raise exc\\r\\n   1842                     if errors == \"skip\":\\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/core.py in _concat()\\r\\n    101         args[0]\\r\\n    102         if not args2\\r\\n--> 103         else methods.concat(args2, uniform=True, ignore_index=ignore_index)\\r\\n    104     )\\r\\n    105 \\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/methods.py in concat()\\r\\n    434             filter_warning=filter_warning,\\r\\n    435             ignore_index=ignore_index,\\r\\n--> 436             **kwargs\\r\\n    437         )\\r\\n    438 \\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/dask_cuda/proxy_object.py in wrapper()\\r\\n    708         args = [unproxy(d) for d in args]\\r\\n    709         kwargs = {k: unproxy(v) for k, v in kwargs.items()}\\r\\n--> 710         return func(*args, **kwargs)\\r\\n    711 \\r\\n    712     return wrapper\\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/methods.py in concat()\\r\\n    434             filter_warning=filter_warning,\\r\\n    435             ignore_index=ignore_index,\\r\\n--> 436             **kwargs\\r\\n    437         )\\r\\n    438 \\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/dask_cudf/backends.py in concat_cudf()\\r\\n    223         )\\r\\n    224 \\r\\n--> 225     return cudf.concat(dfs, axis=axis, ignore_index=ignore_index)\\r\\n    226 \\r\\n    227 \\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/reshape.py in concat()\\r\\n    370                 ignore_index=ignore_index,\\r\\n    371                 # Explicitly cast rather than relying on None being falsy.\\r\\n--> 372                 sort=bool(sort),\\r\\n    373             )\\r\\n    374         return result\\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/contextlib.py in inner()\\r\\n     72         def inner(*args, **kwds):\\r\\n     73             with self._recreate_cm():\\r\\n---> 74                 return func(*args, **kwds)\\r\\n     75         return inner\\r\\n     76 \\r\\n\\r\\n/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/frame.py in _concat()\\r\\n    454         # Concatenate the Tables\\r\\n    455         out = cls._from_table(\\r\\n--> 456             libcudf.concat.concat_tables(tables, ignore_index=ignore_index)\\r\\n    457         )\\r\\n    458 \\r\\n\\r\\ncudf/_lib/concat.pyx in cudf._lib.concat.concat_tables()\\r\\n\\r\\ncudf/_lib/concat.pyx in cudf._lib.concat.concat_tables()\\r\\n\\r\\nRuntimeError: cuDF failure at: ../src/copying/concatenate.cu:364: Total number of concatenated rows exceeds size_type range\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\n\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Docker\\r\\n - Method of cuDF install: conda\\ncreatedAt: 2021-05-07T15:42:19Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Cg Lai\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 53}),\n",
       " Document(page_content=': 143\\ntitle: [BUG] map_partitions() potentially resulting in unexpected index\\nbody: **Describe the bug**\\r\\nWhen using map_partitions() on a `dask_cudf` dataframe we can potentially get an unexpected index. This does not affect `.compute()` by default as it reconstructs a global index.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nimport cudf\\r\\nimport dask_cudf\\r\\ns = cudf.Series([\"ab\", \"cd\", \"ef\", \"gh\", \"ij\"])\\r\\nds = dask_cudf.from_cudf(s, 2)\\r\\nprint(ds.compute())\\r\\nprint(ds.map_partitions(lambda x: x.str.character_tokenize(), meta=ds._meta).compute())\\r\\n```\\r\\nThis prints\\r\\n```\\r\\n0    ab\\r\\n1    cd\\r\\n2    ef\\r\\n3    gh\\r\\n4    ij\\r\\ndtype: object\\r\\n0    a\\r\\n1    b\\r\\n2    c\\r\\n3    d\\r\\n4    e\\r\\n5    f\\r\\n0    g\\r\\n1    h\\r\\n2    i\\r\\n3    j\\r\\ndtype: object\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nWould love to discuss what the expected output would be, but below is what I would expect.\\r\\n```\\r\\n0    ab\\r\\n1    cd\\r\\n2    ef\\r\\n3    gh\\r\\n4    ij\\r\\ndtype: object\\r\\n0    a\\r\\n1    b\\r\\n2    c\\r\\n3    d\\r\\n4    e\\r\\n5    f\\r\\n6    g\\r\\n7    h\\r\\n8    i\\r\\n9    j\\r\\ndtype: object\\r\\n```\\r\\n**Environment details**\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n     \\r\\n     **git***\\r\\n     commit 512e485c41f0b9aa2261430ba426fa8c05c98c2a (HEAD -> list-accessor, origin/list-accessor)\\r\\n     Merge: bf68778b78 5f9dade58a\\r\\n     Author: Shane Ding <shane200195@gmail.com>\\r\\n     Date:   Fri May 7 14:33:32 2021 +0000\\r\\n     \\r\\n     Merge branch \\'branch-0.20\\' of https://github.com/rapidsai/cudf into list-accessor\\r\\n     **git submodules***\\r\\n     \\r\\n     ***OS Information***\\r\\n     DGX_NAME=\"DGX Server\"\\r\\n     DGX_PRETTY_NAME=\"NVIDIA DGX Server\"\\r\\n     DGX_SWBUILD_DATE=\"2019-12-02\"\\r\\n     DGX_SWBUILD_VERSION=\"4.3.0\"\\r\\n     DGX_COMMIT_ID=\"3015363\"\\r\\n     DGX_PLATFORM=\"DGX Server for DGX-1\"\\r\\n     DGX_SERIAL_NUMBER=\"QTFCOU9270061\"\\r\\n     DISTRIB_ID=Ubuntu\\r\\n     DISTRIB_RELEASE=18.04\\r\\n     DISTRIB_CODENAME=bionic\\r\\n     DISTRIB_DESCRIPTION=\"Ubuntu 18.04.3 LTS\"\\r\\n     NAME=\"Ubuntu\"\\r\\n     VERSION=\"18.04.3 LTS (Bionic Beaver)\"\\r\\n     ID=ubuntu\\r\\n     ID_LIKE=debian\\r\\n     PRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\\r\\n     VERSION_ID=\"18.04\"\\r\\n     HOME_URL=\"https://www.ubuntu.com/\"\\r\\n     SUPPORT_URL=\"https://help.ubuntu.com/\"\\r\\n     BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\\r\\n     PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\\r\\n     VERSION_CODENAME=bionic\\r\\n     UBUNTU_CODENAME=bionic\\r\\n     Linux rl-dgx-r11-u30-rapids-dgx103 4.15.0-55-generic #60-Ubuntu SMP Tue Jul 2 18:22:20 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\\r\\n     \\r\\n     ***GPU Information***\\r\\n     Mon May 10 17:20:28 2021\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\\r\\n     |-------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                               |                      |               MIG M. |\\r\\n     |===============================+======================+======================|\\r\\n     |   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\\r\\n     | N/A   35C    P0    48W / 163W |    718MiB / 32510MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\\r\\n     | N/A   33C    P0    42W / 163W |      3MiB / 32510MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\\r\\n     | N/A   34C    P0    44W / 163W |      3MiB / 32510MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\\r\\n     | N/A   31C    P0    43W / 163W |      3MiB / 32510MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\\r\\n     | N/A   36C    P0    43W / 163W |      3MiB / 32510MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\\r\\n     | N/A   35C    P0    43W / 163W |      3MiB / 32510MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\\r\\n     | N/A   37C    P0    41W / 163W |      3MiB / 32510MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\\r\\n     | N/A   34C    P0    42W / 163W |      3MiB / 32510MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     \\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | Processes:                                                                  |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n     |        ID   ID                                                   Usage      |\\r\\n     |=============================================================================|\\r\\n     |    0   N/A  N/A     44033      C   .../envs/cudf_dev/bin/python      715MiB |\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     \\r\\n     ***CPU***\\r\\n     Architecture:        x86_64\\r\\n     CPU op-mode(s):      32-bit, 64-bit\\r\\n     Byte Order:          Little Endian\\r\\n     CPU(s):              80\\r\\n     On-line CPU(s) list: 0-79\\r\\n     Thread(s) per core:  2\\r\\n     Core(s) per socket:  20\\r\\n     Socket(s):           2\\r\\n     NUMA node(s):        2\\r\\n     Vendor ID:           GenuineIntel\\r\\n     CPU family:          6\\r\\n     Model:               79\\r\\n     Model name:          Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz\\r\\n     Stepping:            1\\r\\n     CPU MHz:             1967.306\\r\\n     CPU max MHz:         3600.0000\\r\\n     CPU min MHz:         1200.0000\\r\\n     BogoMIPS:            4390.35\\r\\n     Virtualization:      VT-x\\r\\n     L1d cache:           32K\\r\\n     L1i cache:           32K\\r\\n     L2 cache:            256K\\r\\n     L3 cache:            51200K\\r\\n     NUMA node0 CPU(s):   0-19,40-59\\r\\n     NUMA node1 CPU(s):   20-39,60-79\\r\\n     Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap intel_pt xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts md_clear flush_l1d\\r\\n     \\r\\n     ***CMake***\\r\\n     /raid/sding/miniconda3/envs/cudf_dev/bin/cmake\\r\\n     cmake version 3.18.5\\r\\n     \\r\\n     CMake suite maintained and supported by Kitware (kitware.com/cmake).\\r\\n     \\r\\n     ***g++***\\r\\n     /usr/bin/g++\\r\\n     g++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\\r\\n     Copyright (C) 2017 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n     \\r\\n     \\r\\n     ***nvcc***\\r\\n     /usr/local/cuda/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2021 NVIDIA Corporation\\r\\n     Built on Sun_Feb_14_21:12:58_PST_2021\\r\\n     Cuda compilation tools, release 11.2, V11.2.152\\r\\n     Build cuda_11.2.r11.2/compiler.29618528_0\\r\\n     \\r\\n     ***Python***\\r\\n     /raid/sding/miniconda3/envs/cudf_dev/bin/python\\r\\n     Python 3.8.8\\r\\n     \\r\\n     ***Environment Variables***\\r\\n     PATH                            : /home/u00u97shnnb9gHdDUD357/.vscode-server/bin/3c4e3df9e89829dce27b7b5c24508306b151f30d/bin:/raid/sding/miniconda3/envs/cudf_dev/bin:/raid/sding/miniconda3/condabin:/home/u00u97shnnb9gHdDUD357/.vscode-server/bin/3c4e3df9e89829dce27b7b5c24508306b151f30d/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin:/usr/local/cuda/bin\\r\\n     LD_LIBRARY_PATH                 :\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /raid/sding/miniconda3/envs/cudf_dev\\r\\n     PYTHON_PATH                     :\\r\\n     \\r\\n     ***conda packages***\\r\\n     /raid/sding/miniconda3/condabin/conda\\r\\n     # packages in environment at /raid/sding/miniconda3/envs/cudf_dev:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                       1_gnu    conda-forge\\r\\n     abseil-cpp                20210324.0           h9c3ff4c_0    conda-forge\\r\\n     alabaster                 0.7.12                     py_0    conda-forge\\r\\n     apipkg                    1.5                        py_0    conda-forge\\r\\n     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge\\r\\n     argon2-cffi               20.1.0           py38h497a2fe_2    conda-forge\\r\\n     arrow-cpp                 1.0.1           py38h27527b3_37_cuda    conda-forge\\r\\n     arrow-cpp-proc            3.0.0                      cuda    conda-forge\\r\\n     async_generator           1.10                       py_0    conda-forge\\r\\n     attrs                     20.3.0             pyhd3deb0d_0    conda-forge\\r\\n     aws-c-cal                 0.5.6                hd8e7a0d_1    conda-forge\\r\\n     aws-c-common              0.5.10               h7f98852_0    conda-forge\\r\\n     aws-c-event-stream        0.2.7                he3525c2_3    conda-forge\\r\\n     aws-c-io                  0.9.11               hd6868ff_1    conda-forge\\r\\n     aws-checksums             0.1.11               h8a473d3_5    conda-forge\\r\\n     aws-sdk-cpp               1.8.186              h2f913a8_1    conda-forge\\r\\n     babel                     2.9.1              pyh44b312d_0    conda-forge\\r\\n     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\\r\\n     backports                 1.0                        py_2    conda-forge\\r\\n     backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\\r\\n     black                     19.10b0                    py_4    conda-forge\\r\\n     bleach                    3.3.0              pyh44b312d_0    conda-forge\\r\\n     bokeh                     2.3.1            py38h578d9bd_0    conda-forge\\r\\n     boost-cpp                 1.76.0               hc6e9bd1_0    conda-forge\\r\\n     brotli                    1.0.9                h9c3ff4c_4    conda-forge\\r\\n     brotlipy                  0.7.0           py38h497a2fe_1001    conda-forge\\r\\n     bzip2                     1.0.8                h7f98852_4    conda-forge\\r\\n     c-ares                    1.17.1               h7f98852_1    conda-forge\\r\\n     ca-certificates           2020.12.5            ha878542_0    conda-forge\\r\\n     cachetools                4.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     certifi                   2020.12.5        py38h578d9bd_1    conda-forge\\r\\n     cffi                      1.14.5           py38ha65f79e_0    conda-forge\\r\\n     cfgv                      3.2.0                      py_0    conda-forge\\r\\n     chardet                   4.0.0            py38h578d9bd_1    conda-forge\\r\\n     clang                     8.0.1                hc9558a2_2    conda-forge\\r\\n     clang-tools               8.0.1                hc9558a2_2    conda-forge\\r\\n     clangxx                   8.0.1                         2    conda-forge\\r\\n     click                     7.1.2              pyh9f0ad1d_0    conda-forge\\r\\n     cloudpickle               1.6.0                      py_0    conda-forge\\r\\n     cmake                     3.18.5               h1f3970d_0    rapidsai-nightly\\r\\n     cmake_setuptools          0.1.3                      py_0    rapidsai\\r\\n     colorama                  0.4.4              pyh9f0ad1d_0    conda-forge\\r\\n     commonmark                0.9.1                      py_0    conda-forge\\r\\n     cryptography              3.4.7            py38ha5dfef3_0    conda-forge\\r\\n     cudatoolkit               11.0.221             h6bb024c_0    nvidia\\r\\n     cudf                      0.20.0a0+260.gd56428abfc          pypi_0    pypi\\r\\n     cudnn                     8.0.0                cuda11.0_0    nvidia\\r\\n     cupy                      8.0.0            py38hb7c6141_0    rapidsai\\r\\n     cython                    0.29.23          py38h709712a_0    conda-forge\\r\\n     cytoolz                   0.11.0           py38h497a2fe_3    conda-forge\\r\\n     dask                      2021.4.1+17.gc3993fd9          pypi_0    pypi\\r\\n     dask-cudf                 0.20.0a0+280.g611cabd5ba.dirty          pypi_0    pypi\\r\\n     dataclasses               0.8                pyhc8e2a94_1    conda-forge\\r\\n     decorator                 5.0.7              pyhd8ed1ab_0    conda-forge\\r\\n     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     distlib                   0.3.1              pyh9f0ad1d_0    conda-forge\\r\\n     distributed               2021.4.1+12.g1ee22c84          pypi_0    pypi\\r\\n     dlpack                    0.3                  he1b5a44_1    conda-forge\\r\\n     docutils                  0.16             py38h578d9bd_3    conda-forge\\r\\n     double-conversion         3.1.5                h9c3ff4c_2    conda-forge\\r\\n     editdistance-s            1.0.0            py38h1fd1430_1    conda-forge\\r\\n     entrypoints               0.3             pyhd8ed1ab_1003    conda-forge\\r\\n     execnet                   1.8.0              pyh44b312d_0    conda-forge\\r\\n     expat                     2.2.10               h9c3ff4c_0    conda-forge\\r\\n     fastavro                  1.4.0            py38h497a2fe_0    conda-forge\\r\\n     fastrlock                 0.6              py38h709712a_0    conda-forge\\r\\n     filelock                  3.0.12             pyh9f0ad1d_0    conda-forge\\r\\n     flake8                    3.8.3                      py_1    conda-forge\\r\\n     flatbuffers               1.12.0               h58526e2_0    conda-forge\\r\\n     freetype                  2.10.4               h0708190_1    conda-forge\\r\\n     fsspec                    2021.4.0           pyhd8ed1ab_0    conda-forge\\r\\n     future                    0.18.2           py38h578d9bd_3    conda-forge\\r\\n     gflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\n     glog                      0.4.0                h49b9bf7_3    conda-forge\\r\\n     gmp                       6.2.1                h58526e2_0    conda-forge\\r\\n     grpc-cpp                  1.37.1               h36de60a_0    conda-forge\\r\\n     heapdict                  1.0.1                      py_0    conda-forge\\r\\n     hypothesis                6.10.1             pyhd8ed1ab_0    conda-forge\\r\\n     icu                       68.1                 h58526e2_0    conda-forge\\r\\n     identify                  2.2.4              pyhd8ed1ab_0    conda-forge\\r\\n     idna                      2.10               pyh9f0ad1d_0    conda-forge\\r\\n     imagesize                 1.2.0                      py_0    conda-forge\\r\\n     importlib-metadata        4.0.1            py38h578d9bd_0    conda-forge\\r\\n     iniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge\\r\\n     ipykernel                 5.5.3            py38hd0cf306_0    conda-forge\\r\\n     ipython                   7.23.0           py38hd0cf306_0    conda-forge\\r\\n     ipython_genutils          0.2.0                      py_1    conda-forge\\r\\n     isort                     5.0.7            py38h32f6830_0    conda-forge\\r\\n     jedi                      0.18.0           py38h578d9bd_2    conda-forge\\r\\n     jinja2                    2.11.3             pyh44b312d_0    conda-forge\\r\\n     joblib                    1.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     jpeg                      9d                   h36c2ea0_0    conda-forge\\r\\n     jsonschema                3.2.0              pyhd8ed1ab_3    conda-forge\\r\\n     jupyter_client            6.1.12             pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_core              4.7.1            py38h578d9bd_0    conda-forge\\r\\n     jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\\r\\n     krb5                      1.17.2               h926e7f8_0    conda-forge\\r\\n     lcms2                     2.12                 hddcbb42_0    conda-forge\\r\\n     ld_impl_linux-64          2.35.1               hea4e1c9_2    conda-forge\\r\\n     libblas                   3.9.0                9_openblas    conda-forge\\r\\n     libcblas                  3.9.0                9_openblas    conda-forge\\r\\n     libcurl                   7.76.1               hc4aaa36_1    conda-forge\\r\\n     libedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\n     libev                     4.33                 h516909a_1    conda-forge\\r\\n     libevent                  2.1.10               hcdb4288_3    conda-forge\\r\\n     libffi                    3.3                  h58526e2_2    conda-forge\\r\\n     libgcc-ng                 9.3.0               h2828fa1_19    conda-forge\\r\\n     libgfortran-ng            9.3.0               hff62375_19    conda-forge\\r\\n     libgfortran5              9.3.0               hff62375_19    conda-forge\\r\\n     libgomp                   9.3.0               h2828fa1_19    conda-forge\\r\\n     liblapack                 3.9.0                9_openblas    conda-forge\\r\\n     libllvm10                 10.0.1               he513fc3_3    conda-forge\\r\\n     libllvm8                  8.0.1                hc9558a2_0    conda-forge\\r\\n     libnghttp2                1.43.0               h812cca2_0    conda-forge\\r\\n     libopenblas               0.3.15          pthreads_h8fe5266_0    conda-forge\\r\\n     libpng                    1.6.37               h21135ba_2    conda-forge\\r\\n     libprotobuf               3.15.8               h780b84a_0    conda-forge\\r\\n     librmm                    0.20.0a210505   cuda11.0_g9aaa7bc_26    rapidsai-nightly\\r\\n     libsodium                 1.0.18               h36c2ea0_1    conda-forge\\r\\n     libssh2                   1.9.0                ha56f1ee_6    conda-forge\\r\\n     libstdcxx-ng              9.3.0               h6de172a_19    conda-forge\\r\\n     libthrift                 0.14.1               he6d91bd_1    conda-forge\\r\\n     libtiff                   4.2.0                hdc55705_1    conda-forge\\r\\n     libutf8proc               2.6.1                h7f98852_0    conda-forge\\r\\n     libuv                     1.41.0               h7f98852_0    conda-forge\\r\\n     libwebp-base              1.2.0                h7f98852_2    conda-forge\\r\\n     llvmlite                  0.36.0           py38h4630a5e_0    conda-forge\\r\\n     locket                    0.2.0                      py_2    conda-forge\\r\\n     lz4-c                     1.9.3                h9c3ff4c_0    conda-forge\\r\\n     markdown                  3.3.4              pyhd8ed1ab_0    conda-forge\\r\\n     markupsafe                1.1.1            py38h497a2fe_3    conda-forge\\r\\n     matplotlib-inline         0.1.2              pyhd8ed1ab_2    conda-forge\\r\\n     mccabe                    0.6.1                      py_1    conda-forge\\r\\n     mimesis                   4.0.0              pyh9f0ad1d_0    conda-forge\\r\\n     mistune                   0.8.4           py38h497a2fe_1003    conda-forge\\r\\n     more-itertools            8.7.0              pyhd8ed1ab_1    conda-forge\\r\\n     msgpack-python            1.0.2            py38h1fd1430_1    conda-forge\\r\\n     mypy                      0.782                      py_0    conda-forge\\r\\n     mypy_extensions           0.4.3            py38h578d9bd_3    conda-forge\\r\\n     nbclient                  0.5.3              pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert                 6.0.7            py38h578d9bd_3    conda-forge\\r\\n     nbformat                  5.1.3              pyhd8ed1ab_0    conda-forge\\r\\n     nbsphinx                  0.8.4              pyhd8ed1ab_0    conda-forge\\r\\n     nccl                      2.7.8.1            h4962215_100    nvidia\\r\\n     ncurses                   6.2                  h58526e2_4    conda-forge\\r\\n     nest-asyncio              1.5.1              pyhd8ed1ab_0    conda-forge\\r\\n     nodeenv                   1.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     notebook                  6.3.0              pyha770c72_1    conda-forge\\r\\n     numba                     0.53.1           py38h0e12cce_0    conda-forge\\r\\n     numpy                     1.20.2           py38h9894fe3_0    conda-forge\\r\\n     numpydoc                  1.1.0                      py_1    conda-forge\\r\\n     nvtx                      0.2.3            py38h497a2fe_0    conda-forge\\r\\n     olefile                   0.46               pyh9f0ad1d_1    conda-forge\\r\\n     openjpeg                  2.4.0                hf7af979_0    conda-forge\\r\\n     openssl                   1.1.1k               h7f98852_0    conda-forge\\r\\n     orc                       1.6.7                heec2584_1    conda-forge\\r\\n     packaging                 20.9               pyh44b312d_0    conda-forge\\r\\n     pandas                    1.2.4            py38h1abd341_0    conda-forge\\r\\n     pandoc                    1.19.2                        0    conda-forge\\r\\n     pandocfilters             1.4.2                      py_1    conda-forge\\r\\n     parquet-cpp               1.5.1                         2    conda-forge\\r\\n     parso                     0.8.2              pyhd8ed1ab_0    conda-forge\\r\\n     partd                     1.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     pathspec                  0.8.1              pyhd3deb0d_0    conda-forge\\r\\n     pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\\r\\n     pickleshare               0.7.5                   py_1003    conda-forge\\r\\n     pillow                    8.1.2            py38ha0e1e83_1    conda-forge\\r\\n     pip                       21.1.1             pyhd8ed1ab_0    conda-forge\\r\\n     pluggy                    0.13.1           py38h578d9bd_4    conda-forge\\r\\n     pre-commit                2.12.1           py38h578d9bd_0    conda-forge\\r\\n     pre_commit                2.12.1               hd8ed1ab_0    conda-forge\\r\\n     prometheus_client         0.10.1             pyhd8ed1ab_0    conda-forge\\r\\n     prompt-toolkit            3.0.18             pyha770c72_0    conda-forge\\r\\n     protobuf                  3.15.8           py38h709712a_0    conda-forge\\r\\n     psutil                    5.8.0            py38h497a2fe_1    conda-forge\\r\\n     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\\r\\n     py                        1.10.0             pyhd3deb0d_0    conda-forge\\r\\n     py-cpuinfo                8.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     pyarrow                   1.0.1           py38hb53058b_37_cuda    conda-forge\\r\\n     pycodestyle               2.6.0              pyh9f0ad1d_0    conda-forge\\r\\n     pycparser                 2.20               pyh9f0ad1d_2    conda-forge\\r\\n     pyflakes                  2.2.0              pyh9f0ad1d_0    conda-forge\\r\\n     pygments                  2.8.1              pyhd8ed1ab_0    conda-forge\\r\\n     pyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyorc                     0.4.0                    pypi_0    pypi\\r\\n     pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\\r\\n     pyrsistent                0.17.3           py38h497a2fe_2    conda-forge\\r\\n     pysocks                   1.7.1            py38h578d9bd_3    conda-forge\\r\\n     pytest                    6.2.4            py38h578d9bd_0    conda-forge\\r\\n     pytest-benchmark          3.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     pytest-forked             1.3.0              pyhd3deb0d_0    conda-forge\\r\\n     pytest-xdist              2.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     python                    3.8.8           hffdb5ce_0_cpython    conda-forge\\r\\n     python-dateutil           2.8.1                      py_0    conda-forge\\r\\n     python_abi                3.8                      1_cp38    conda-forge\\r\\n     pytz                      2021.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyyaml                    5.4.1            py38h497a2fe_0    conda-forge\\r\\n     pyzmq                     22.0.3           py38h2035c66_1    conda-forge\\r\\n     rapidjson                 1.1.0             he1b5a44_1002    conda-forge\\r\\n     re2                       2021.04.01           h9c3ff4c_0    conda-forge\\r\\n     readline                  8.1                  h46c0cb4_0    conda-forge\\r\\n     recommonmark              0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     regex                     2021.4.4         py38h497a2fe_0    conda-forge\\r\\n     requests                  2.25.1             pyhd3deb0d_0    conda-forge\\r\\n     rhash                     1.4.1                h7f98852_0    conda-forge\\r\\n     rmm                       0.20.0a210505   cuda_11.0_py38_g9aaa7bc_26    rapidsai-nightly\\r\\n     s2n                       1.0.5                h9b69904_0    conda-forge\\r\\n     sacremoses                0.0.43             pyh9f0ad1d_0    conda-forge\\r\\n     send2trash                1.5.0                      py_0    conda-forge\\r\\n     setuptools                49.6.0           py38h578d9bd_3    conda-forge\\r\\n     six                       1.15.0             pyh9f0ad1d_0    conda-forge\\r\\n     snappy                    1.1.8                he1b5a44_3    conda-forge\\r\\n     snowballstemmer           2.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     sortedcontainers          2.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     spdlog                    1.7.0                hc9558a2_2    conda-forge\\r\\n     sphinx                    3.5.4              pyh44b312d_0    conda-forge\\r\\n     sphinx-copybutton         0.3.1              pyhd8ed1ab_0    conda-forge\\r\\n     sphinx-markdown-tables    0.0.15             pyhd3deb0d_0    conda-forge\\r\\n     sphinx_rtd_theme          0.5.2              pyhd8ed1ab_1    conda-forge\\r\\n     sphinxcontrib-applehelp   1.0.2                      py_0    conda-forge\\r\\n     sphinxcontrib-devhelp     1.0.2                      py_0    conda-forge\\r\\n     sphinxcontrib-htmlhelp    1.0.3                      py_0    conda-forge\\r\\n     sphinxcontrib-jsmath      1.0.1                      py_0    conda-forge\\r\\n     sphinxcontrib-qthelp      1.0.3                      py_0    conda-forge\\r\\n     sphinxcontrib-serializinghtml 1.1.4                      py_0    conda-forge\\r\\n     sphinxcontrib-websupport  1.2.4              pyh9f0ad1d_0    conda-forge\\r\\n     sqlite                    3.35.5               h74cdb3f_0    conda-forge\\r\\n     streamz                   0.6.2              pyh44b312d_0    conda-forge\\r\\n     tblib                     1.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     terminado                 0.9.4            py38h578d9bd_0    conda-forge\\r\\n     testpath                  0.4.4                      py_0    conda-forge\\r\\n     tk                        8.6.10               h21135ba_1    conda-forge\\r\\n     tokenizers                0.10.1           py38hb63a372_0    conda-forge\\r\\n     toml                      0.10.2             pyhd8ed1ab_0    conda-forge\\r\\n     toolz                     0.11.1                     py_0    conda-forge\\r\\n     tornado                   6.1              py38h497a2fe_1    conda-forge\\r\\n     tqdm                      4.60.0             pyhd8ed1ab_0    conda-forge\\r\\n     traitlets                 5.0.5                      py_0    conda-forge\\r\\n     transformers              4.5.1              pyhd8ed1ab_1    conda-forge\\r\\n     typed-ast                 1.4.3            py38h497a2fe_0    conda-forge\\r\\n     typing_extensions         3.7.4.3                    py_0    conda-forge\\r\\n     unknown                   0.0.0                     dev_0    <develop>\\r\\n     urllib3                   1.26.4             pyhd8ed1ab_0    conda-forge\\r\\n     virtualenv                20.4.4           py38h578d9bd_0    conda-forge\\r\\n     wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\\r\\n     webencodings              0.5.1                      py_1    conda-forge\\r\\n     wheel                     0.36.2             pyhd3deb0d_0    conda-forge\\r\\n     xz                        5.2.5                h516909a_1    conda-forge\\r\\n     yaml                      0.2.5                h516909a_0    conda-forge\\r\\n     zeromq                    4.3.4                h9c3ff4c_0    conda-forge\\r\\n     zict                      2.0.0                      py_0    conda-forge\\r\\n     zipp                      3.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     zlib                      1.2.11            h516909a_1010    conda-forge\\r\\n     zstd                      1.4.9                ha95c52a_0    conda-forge\\ncreatedAt: 2021-05-10T17:27:36Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 54}),\n",
       " Document(page_content=\": 147\\ntitle: [FEA] Add support for limit to Series.fillna\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nIt is not currently possible to limit the number of missing values filled consecutively using `fillna`.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nSupport for a limit argument similar to how pandas does it.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nWriting a clunkier version of fillna that keeps track of the number of missing values filled.\\r\\n\\r\\n**Additional context**\\r\\nExample:\\r\\n```python\\r\\nimport cudf\\r\\nsr = cudf.Series([1, 2, None, None, 5])\\r\\nsr.fillna(method='pad', limit=1)\\r\\n```\\r\\nShould return:\\r\\n```\\r\\n0    1\\r\\n1    2\\r\\n2    2\\r\\n3    <NA>\\r\\n4    5\\r\\ndtype: int64\\r\\n```\\r\\nBut throws a NotImplementedError instead\\ncreatedAt: 2021-05-20T21:55:04Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 55}),\n",
       " Document(page_content=': 148\\ntitle: [FEA] Add decimal support to Dask cuDF parquet reader\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nI wish I could use the Dask cuDF parquet reader to read parquet files with decimal columns.\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nCurrently\\r\\n```\\r\\nimport cudf\\r\\nimport dask_cudf\\r\\nfrom cudf.core.dtypes import Decimal64Dtype\\r\\nfrom decimal import Decimal\\r\\n\\r\\ndf = cudf.DataFrame({\"val\":[Decimal(\"3.5\"), Decimal(\"4.3\")]}, dtype=Decimal64Dtype(5,2))\\r\\ndf.to_parquet(\"test.parquet\")\\r\\n\\r\\ndask_df = dask_cudf.read_parquet(\"test.parquet\")\\r\\ndask_df.dtypes\\r\\n```\\r\\nreturns\\r\\n```\\r\\nval    object\\r\\ndtype: object\\r\\n```\\r\\nWhereas using cudf\\r\\n```\\r\\ndf = cudf.read_parquet(\"test.parquet\")\\r\\ndf.dtypes\\r\\n```\\r\\nreturns\\r\\n```\\r\\nval    decimal\\r\\ndtype: object\\r\\n```\\ncreatedAt: 2021-05-21T04:54:30Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 56}),\n",
       " Document(page_content=': 154\\ntitle: [BUG] MultiIndex loc expects an iterable when passed Timestamp\\nbody: **Describe the bug**\\r\\ncuDF DataFrames indexed by a Timestamp range can be accessed using `.loc[]` without any problem. However, if the cuDF DataFrame is indexed with a MultiIndex with timestamps as the first key, `.loc[]` fails, when doing so causes no issue with pandas.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nThe [following gist](https://gist.github.com/pbruneau/689242cf5c79ce9185aa7fa3bb1f2e89) holds a self-contained example. The last line of the code fails with error: `TypeError: \\'Timestamp\\' object is not iterable`\\r\\n\\r\\n**Expected behavior**\\r\\nI would expect the pandas and cuDF snippets to behave similarly. \\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Docker\\r\\n - Method of cuDF install: Docker\\r\\n   - docker pull rapidsai/rapidsai:0.18-cuda10.1-runtime-ubuntu18.04-py3.7\\r\\n   - docker run -d -p 10000:8888 -p 10001:8787 -p 10002:8786 --privileged=true --gpus all --name test -t test\\r\\n\\r\\n**Environment details**\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n     \\r\\n     **git***\\r\\n     commit 2cda39b34197c60614186ec51106d8254e5f7b05 (grafted, HEAD, origin/branch-0.16)\\r\\n     Author: Ray Douglass <3107146+raydouglass@users.noreply.github.com>\\r\\n     Date:   Wed Oct 21 10:31:49 2020 -0400\\r\\n     \\r\\n     Update CHANGELOG.md\\r\\n     **git submodules***\\r\\n     \\r\\n     ***OS Information***\\r\\n     DISTRIB_ID=Ubuntu\\r\\n     DISTRIB_RELEASE=18.04\\r\\n     DISTRIB_CODENAME=bionic\\r\\n     DISTRIB_DESCRIPTION=\"Ubuntu 18.04.5 LTS\"\\r\\n     NAME=\"Ubuntu\"\\r\\n     VERSION=\"18.04.5 LTS (Bionic Beaver)\"\\r\\n     ID=ubuntu\\r\\n     ID_LIKE=debian\\r\\n     PRETTY_NAME=\"Ubuntu 18.04.5 LTS\"\\r\\n     VERSION_ID=\"18.04\"\\r\\n     HOME_URL=\"https://www.ubuntu.com/\"\\r\\n     SUPPORT_URL=\"https://help.ubuntu.com/\"\\r\\n     BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\\r\\n     PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\\r\\n     VERSION_CODENAME=bionic\\r\\n     UBUNTU_CODENAME=bionic\\r\\n     Linux fe1b5c84b917 4.15.0-143-generic #147-Ubuntu SMP Wed Apr 14 16:10:11 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\\r\\n     \\r\\n     ***GPU Information***\\r\\n     Tue Jun 22 15:01:51 2021\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\\r\\n     |-------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                               |                      |               MIG M. |\\r\\n     |===============================+======================+======================|\\r\\n     |   0  GeForce GTX 1080    On   | 00000000:05:00.0 Off |                  N/A |\\r\\n     | 28%   43C    P8     7W / 180W |   1504MiB /  8114MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     \\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | Processes:                                                                  |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n     |        ID   ID                                                   Usage      |\\r\\n     |=============================================================================|\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     \\r\\n     ***CPU***\\r\\n     Architecture:        x86_64\\r\\n     CPU op-mode(s):      32-bit, 64-bit\\r\\n     Byte Order:          Little Endian\\r\\n     CPU(s):              12\\r\\n     On-line CPU(s) list: 0-11\\r\\n     Thread(s) per core:  2\\r\\n     Core(s) per socket:  6\\r\\n     Socket(s):           1\\r\\n     NUMA node(s):        1\\r\\n     Vendor ID:           GenuineIntel\\r\\n     CPU family:          6\\r\\n     Model:               79\\r\\n     Model name:          Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz\\r\\n     Stepping:            1\\r\\n     CPU MHz:             1200.861\\r\\n     CPU max MHz:         3800.0000\\r\\n     CPU min MHz:         1200.0000\\r\\n     BogoMIPS:            6800.53\\r\\n     Virtualization:      VT-x\\r\\n     L1d cache:           32K\\r\\n     L1i cache:           32K\\r\\n     L2 cache:            256K\\r\\n     L3 cache:            15360K\\r\\n     NUMA node0 CPU(s):   0-11\\r\\n     Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap intel_pt xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts md_clear flush_l1d\\r\\n     \\r\\n     ***CMake***\\r\\n     \\r\\n     ***g++***\\r\\n     \\r\\n     ***nvcc***\\r\\n     \\r\\n     ***Python***\\r\\n     /opt/conda/envs/rapids/bin/python\\r\\n     Python 3.7.10\\r\\n     \\r\\n     ***Environment Variables***\\r\\n     PATH                            : /opt/conda/envs/rapids/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\r\\n     LD_LIBRARY_PATH                 : /usr/local/nvidia/lib:/usr/local/nvidia/lib64\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /opt/conda/envs/rapids\\r\\n     PYTHON_PATH                     :\\r\\n     \\r\\n     ***conda packages***\\r\\n     /opt/conda/condabin/conda\\r\\n     # packages in environment at /opt/conda/envs/rapids:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                       1_gnu    conda-forge\\r\\n     abseil-cpp                20200225.2           he1b5a44_2    conda-forge\\r\\n     aiobotocore               1.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     aiohttp                   3.7.4            py37h5e8e339_0    conda-forge\\r\\n     aioitertools              0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge\\r\\n     argon2-cffi               20.1.0           py37h5e8e339_2    conda-forge\\r\\n     arrow-cpp                 1.0.1           py37h2318771_14_cuda    conda-forge\\r\\n     arrow-cpp-proc            3.0.0                      cuda    conda-forge\\r\\n     async-timeout             3.0.1                   py_1000    conda-forge\\r\\n     async_generator           1.10                       py_0    conda-forge\\r\\n     attrs                     20.3.0             pyhd3deb0d_0    conda-forge\\r\\n     aws-c-common              0.4.59               h36c2ea0_1    conda-forge\\r\\n     aws-c-event-stream        0.1.6                had2084c_6    conda-forge\\r\\n     aws-checksums             0.1.10               h4e93380_0    conda-forge\\r\\n     aws-sdk-cpp               1.8.63               h9b98462_0    conda-forge\\r\\n     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\\r\\n     backports                 1.0                        py_2    conda-forge\\r\\n     backports.functools_lru_cache 1.6.1                      py_0    conda-forge\\r\\n     blas                      2.14                   openblas    conda-forge\\r\\n     blazingsql                0.18.0                   pypi_0    pypi\\r\\n     bleach                    3.3.0              pyh44b312d_0    conda-forge\\r\\n     bokeh                     2.2.3            py37h89c1867_0    conda-forge\\r\\n     boost                     1.72.0           py37h48f8a5e_1    conda-forge\\r\\n     boost-cpp                 1.72.0               h9d3c048_4    conda-forge\\r\\n     botocore                  1.19.52            pyhd8ed1ab_0    conda-forge\\r\\n     brotli                    1.0.9                h9c3ff4c_4    conda-forge\\r\\n     brotlipy                  0.7.0           py37h5e8e339_1001    conda-forge\\r\\n     bzip2                     1.0.8                h7f98852_4    conda-forge\\r\\n     c-ares                    1.17.1               h36c2ea0_0    conda-forge\\r\\n     ca-certificates           2020.12.5            ha878542_0    conda-forge\\r\\n     cairo                     1.16.0            h6cf1ce9_1008    conda-forge\\r\\n     certifi                   2020.12.5        py37h89c1867_1    conda-forge\\r\\n     cffi                      1.14.5           py37hc58025e_0    conda-forge\\r\\n     cfitsio                   3.470                h2e3daa1_7    conda-forge\\r\\n     cftime                    1.5.0                    pypi_0    pypi\\r\\n     chardet                   4.0.0            py37h89c1867_1    conda-forge\\r\\n     click                     7.1.2              pyh9f0ad1d_0    conda-forge\\r\\n     click-plugins             1.1.1                      py_0    conda-forge\\r\\n     cligj                     0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     cloudpickle               1.6.0                      py_0    conda-forge\\r\\n     colorcet                  2.0.6              pyhd8ed1ab_0    conda-forge\\r\\n     convertdate               2.3.2                    pypi_0    pypi\\r\\n     cryptography              3.4.4            py37hf1a17b8_0    conda-forge\\r\\n     cudatoolkit               10.1.243             h036e899_8    nvidia\\r\\n     cudf                      0.18.0          cuda_10.1_py37_g20778e5ddb_0    rapidsai\\r\\n     cudf_kafka                0.18.0          py37_g20778e5ddb_0    rapidsai\\r\\n     cudnn                     7.6.0                cuda10.1_0    nvidia\\r\\n     cugraph                   0.18.0          py37_g65ec965f_0    rapidsai\\r\\n     cuml                      0.18.0          cuda10.1_py37_gb5f59e005_0    rapidsai\\r\\n     cupy                      8.0.0            py37h0632833_0    conda-forge\\r\\n     curl                      7.71.1               he644dc0_8    conda-forge\\r\\n     cusignal                  0.18.0          py38_g42899d2_0    rapidsai\\r\\n     cuspatial                 0.18.0a210212   py37_g3045c48_21    rapidsai-nightly\\r\\n     custreamz                 0.18.0          py37_g20778e5ddb_0    rapidsai\\r\\n     cuxfilter                 0.18.0          py37_gac6f488_0    rapidsai\\r\\n     cycler                    0.10.0                     py_2    conda-forge\\r\\n     cyrus-sasl                2.1.27               h3274739_1    conda-forge\\r\\n     cython                    0.29.22          py37hcd2ae1e_0    conda-forge\\r\\n     cytoolz                   0.11.0           py37h5e8e339_3    conda-forge\\r\\n     dask                      2021.2.0           pyhd8ed1ab_0    conda-forge\\r\\n     dask-core                 2021.2.0           pyhd8ed1ab_0    conda-forge\\r\\n     dask-cuda                 0.18.0                   py37_0    rapidsai\\r\\n     dask-cudf                 0.18.0          py37_g20778e5ddb_0    rapidsai\\r\\n     dask-glm                  0.2.0                      py_1    conda-forge\\r\\n     dask-labextension         4.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     dask-ml                   1.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     datashader                0.11.1             pyh9f0ad1d_0    conda-forge\\r\\n     datashape                 0.5.4                      py_1    conda-forge\\r\\n     decorator                 4.4.2                      py_0    conda-forge\\r\\n     defusedxml                0.6.0                      py_0    conda-forge\\r\\n     distlib                   0.3.2                    pypi_0    pypi\\r\\n     distributed               2021.2.0         py37h89c1867_0    conda-forge\\r\\n     dlpack                    0.3                  he1b5a44_1    conda-forge\\r\\n     ecmwf-api-client          1.6.1                    pypi_0    pypi\\r\\n     entrypoints               0.3             pyhd8ed1ab_1003    conda-forge\\r\\n     ephem                     4.0.0.2                  pypi_0    pypi\\r\\n     expat                     2.2.10               h9c3ff4c_0    conda-forge\\r\\n     fa2                       0.3.5            py37h8f50634_0    conda-forge\\r\\n     faiss-proc                1.0.0                      cuda    conda-forge\\r\\n     fastavro                  1.3.4            py37h5e8e339_0    conda-forge\\r\\n     fastrlock                 0.5              py37hcd2ae1e_2    conda-forge\\r\\n     filelock                  3.0.12                   pypi_0    pypi\\r\\n     filterpy                  1.4.5                      py_1    conda-forge\\r\\n     fiona                     1.8.18           py37h527b4ca_0    conda-forge\\r\\n     flask                     2.0.1                    pypi_0    pypi\\r\\n     flask-wtf                 0.15.1                   pypi_0    pypi\\r\\n     fontconfig                2.13.1            hba837de_1004    conda-forge\\r\\n     freetype                  2.10.4               h0708190_1    conda-forge\\r\\n     freexl                    1.0.6                h7f98852_0    conda-forge\\r\\n     fsspec                    0.8.7              pyhd8ed1ab_0    conda-forge\\r\\n     future                    0.18.2           py37h89c1867_3    conda-forge\\r\\n     gdal                      3.1.4            py37h2ec2946_2    conda-forge\\r\\n     geopandas                 0.8.1                      py_0    conda-forge\\r\\n     geos                      3.8.1                he1b5a44_0    conda-forge\\r\\n     geotiff                   1.6.0                h5d11630_3    conda-forge\\r\\n     gettext                   0.19.8.1          h0b5b191_1005    conda-forge\\r\\n     gflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\n     giflib                    5.2.1                h36c2ea0_2    conda-forge\\r\\n     git                       2.30.1          pl5320h6697202_1    conda-forge\\r\\n     glog                      0.4.0                h49b9bf7_3    conda-forge\\r\\n     gluonts                   0.7.6                    pypi_0    pypi\\r\\n     google-cloud-cpp          1.16.0               he4a878c_2    conda-forge\\r\\n     google-cloud-cpp-common   0.25.0               he83eced_7    conda-forge\\r\\n     googleapis-cpp            0.10.0               h6b1abdc_4    conda-forge\\r\\n     gpuci-tools               0.3.1                         0    gpuci\\r\\n     greenlet                  1.0.0            py37hcd2ae1e_0    conda-forge\\r\\n     grpc-cpp                  1.32.0               h7997a97_1    conda-forge\\r\\n     gunicorn                  20.1.0                   pypi_0    pypi\\r\\n     hdf4                      4.2.13            h10796ff_1004    conda-forge\\r\\n     hdf5                      1.10.6          nompi_h7c3c948_1111    conda-forge\\r\\n     heapdict                  1.0.1                      py_0    conda-forge\\r\\n     hijri-converter           2.1.2                    pypi_0    pypi\\r\\n     holidays                  0.11.1                   pypi_0    pypi\\r\\n     holoviews                 1.14.2             pyhd8ed1ab_0    conda-forge\\r\\n     icu                       68.1                 h58526e2_0    conda-forge\\r\\n     idna                      2.10               pyh9f0ad1d_0    conda-forge\\r\\n     importlib-metadata        3.7.0            py37h89c1867_0    conda-forge\\r\\n     importlib_metadata        3.7.0                hd8ed1ab_0    conda-forge\\r\\n     iniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge\\r\\n     ipykernel                 5.5.0            py37h888b3d9_1    conda-forge\\r\\n     ipython                   7.15.0           py37hc8dfbb8_0    conda-forge\\r\\n     ipython_genutils          0.2.0                      py_1    conda-forge\\r\\n     ipywidgets                7.6.3              pyhd3deb0d_0    conda-forge\\r\\n     itsdangerous              2.0.1                    pypi_0    pypi\\r\\n     jedi                      0.17.2           py37h89c1867_1    conda-forge\\r\\n     jinja2                    3.0.1                    pypi_0    pypi\\r\\n     jmespath                  0.10.0             pyh9f0ad1d_0    conda-forge\\r\\n     joblib                    1.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     jpeg                      9d                   h36c2ea0_0    conda-forge\\r\\n     jpype1                    1.2.1            py37h2527ec5_0    conda-forge\\r\\n     json-c                    0.13.1            hbfbb72e_1002    conda-forge\\r\\n     json5                     0.9.5              pyh9f0ad1d_0    conda-forge\\r\\n     jsonschema                3.2.0                      py_2    conda-forge\\r\\n     jupyter-server-proxy      1.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_client            6.1.11             pyhd8ed1ab_1    conda-forge\\r\\n     jupyter_core              4.7.1            py37h89c1867_0    conda-forge\\r\\n     jupyterlab                2.1.5                      py_0    conda-forge\\r\\n     jupyterlab-nvdashboard    0.1.11200212              py_12    rapidsai-nightly\\r\\n     jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\\r\\n     jupyterlab_server         1.2.0                      py_0    conda-forge\\r\\n     jupyterlab_widgets        1.0.0              pyhd8ed1ab_1    conda-forge\\r\\n     kealib                    1.4.14               hcc255d8_2    conda-forge\\r\\n     kiwisolver                1.3.1            py37h2527ec5_1    conda-forge\\r\\n     korean-lunar-calendar     0.2.1                    pypi_0    pypi\\r\\n     krb5                      1.17.2               h926e7f8_0    conda-forge\\r\\n     lcms2                     2.12                 hddcbb42_0    conda-forge\\r\\n     ld_impl_linux-64          2.35.1               hea4e1c9_2    conda-forge\\r\\n     libblas                   3.8.0               14_openblas    conda-forge\\r\\n     libcblas                  3.8.0               14_openblas    conda-forge\\r\\n     libcrc32c                 1.1.1                h9c3ff4c_2    conda-forge\\r\\n     libcudf                   0.18.1          cuda10.1_g999be56c80_0    rapidsai\\r\\n     libcudf_kafka             0.18.0a210226   g1544474166_254    rapidsai-nightly\\r\\n     libcugraph                0.18.0          cuda10.1_g65ec965f_0    rapidsai\\r\\n     libcuml                   0.18.0          cuda10.1_gb5f59e005_0    rapidsai\\r\\n     libcumlprims              0.18.0a210211   cuda10.1_gff080f3_0    rapidsai-nightly\\r\\n     libcurl                   7.71.1               hcdd3856_8    conda-forge\\r\\n     libcuspatial              0.18.0          cuda10.1_gf4da460_0    rapidsai\\r\\n     libdap4                   3.20.6               hd7c4107_1    conda-forge\\r\\n     libedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\n     libev                     4.33                 h516909a_1    conda-forge\\r\\n     libevent                  2.1.10               hcdb4288_3    conda-forge\\r\\n     libfaiss                  1.6.3           he68dc02_3_cuda    conda-forge\\r\\n     libffi                    3.3                  h58526e2_2    conda-forge\\r\\n     libgcc-ng                 9.3.0               h2828fa1_18    conda-forge\\r\\n     libgcrypt                 1.9.2                h7f98852_0    conda-forge\\r\\n     libgdal                   3.1.4                h02eeb80_2    conda-forge\\r\\n     libgfortran-ng            7.5.0               h14aa051_18    conda-forge\\r\\n     libgfortran4              7.5.0               h14aa051_18    conda-forge\\r\\n     libglib                   2.68.0               h3e27bee_2    conda-forge\\r\\n     libgomp                   9.3.0               h2828fa1_18    conda-forge\\r\\n     libgpg-error              1.42                 h9c3ff4c_0    conda-forge\\r\\n     libgsasl                  1.8.0                         2    conda-forge\\r\\n     libhwloc                  2.3.0                h5e5b7d1_1    conda-forge\\r\\n     libiconv                  1.16                 h516909a_0    conda-forge\\r\\n     libkml                    1.3.0             hd79254b_1012    conda-forge\\r\\n     liblapack                 3.8.0               14_openblas    conda-forge\\r\\n     liblapacke                3.8.0               14_openblas    conda-forge\\r\\n     libllvm10                 10.0.1               he513fc3_3    conda-forge\\r\\n     libnetcdf                 4.7.4           nompi_h56d31a8_107    conda-forge\\r\\n     libnghttp2                1.43.0               h812cca2_0    conda-forge\\r\\n     libntlm                   1.4               h7f98852_1002    conda-forge\\r\\n     libopenblas               0.3.7                h5ec1e0e_6    conda-forge\\r\\n     libpng                    1.6.37               h21135ba_2    conda-forge\\r\\n     libpq                     12.3                 h255efa7_3    conda-forge\\r\\n     libprotobuf               3.13.0.1             h8b12597_0    conda-forge\\r\\n     librdkafka                1.5.3                h54cafa9_0    conda-forge\\r\\n     librmm                    0.18.0          cuda10.1_ga4ee6b7_0    rapidsai\\r\\n     librttopo                 1.1.0                hb271727_4    conda-forge\\r\\n     libsodium                 1.0.18               h36c2ea0_1    conda-forge\\r\\n     libspatialindex           1.9.3                h9c3ff4c_3    conda-forge\\r\\n     libspatialite             5.0.1                h6ec7341_0    conda-forge\\r\\n     libssh2                   1.9.0                hab1572f_5    conda-forge\\r\\n     libstdcxx-ng              9.3.0               h6de172a_18    conda-forge\\r\\n     libthrift                 0.13.0               h5aa387f_6    conda-forge\\r\\n     libtiff                   4.2.0                hdc55705_0    conda-forge\\r\\n     libutf8proc               2.6.1                h7f98852_0    conda-forge\\r\\n     libuuid                   2.32.1            h7f98852_1000    conda-forge\\r\\n     libuv                     1.41.0               h7f98852_0    conda-forge\\r\\n     libwebp                   1.2.0                h3452ae3_0    conda-forge\\r\\n     libwebp-base              1.2.0                h7f98852_0    conda-forge\\r\\n     libxcb                    1.13              h7f98852_1003    conda-forge\\r\\n     libxgboost                1.3.3dev.rapidsai0.18      cuda10.1_0    rapidsai-nightly\\r\\n     libxml2                   2.9.10               h72842e0_3    conda-forge\\r\\n     line-profiler             3.3.0                    pypi_0    pypi\\r\\n     llvmlite                  0.35.0           py37h9d7f4d0_1    conda-forge\\r\\n     locket                    0.2.0                      py_2    conda-forge\\r\\n     lz4-c                     1.9.2                he1b5a44_3    conda-forge\\r\\n     markdown                  3.3.4              pyhd8ed1ab_0    conda-forge\\r\\n     markupsafe                2.0.1                    pypi_0    pypi\\r\\n     matplotlib-base           3.3.4            py37h0c9df89_0    conda-forge\\r\\n     mistune                   0.8.4           py37h5e8e339_1003    conda-forge\\r\\n     more-itertools            8.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     msgpack-python            1.0.2            py37h2527ec5_1    conda-forge\\r\\n     multidict                 5.1.0            py37h5e8e339_1    conda-forge\\r\\n     multipledispatch          0.6.0                      py_0    conda-forge\\r\\n     munch                     2.5.0                      py_0    conda-forge\\r\\n     mxnet-cu101               1.8.0                    pypi_0    pypi\\r\\n     nbclient                  0.5.3              pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert                 6.0.7            py37h89c1867_3    conda-forge\\r\\n     nbformat                  5.1.2              pyhd8ed1ab_1    conda-forge\\r\\n     nccl                      2.8.4.1              h8b44402_3    conda-forge\\r\\n     ncurses                   6.2                  h58526e2_4    conda-forge\\r\\n     nest-asyncio              1.4.3              pyhd8ed1ab_0    conda-forge\\r\\n     netcdf4                   1.5.6                    pypi_0    pypi\\r\\n     netifaces                 0.10.9          py37h5e8e339_1003    conda-forge\\r\\n     networkx                  2.5                        py_0    conda-forge\\r\\n     nodejs                    14.15.4              h92b4a50_1    conda-forge\\r\\n     notebook                  6.2.0            py37h89c1867_0    conda-forge\\r\\n     numba                     0.52.0           py37hdc94413_0    conda-forge\\r\\n     numpy                     1.19.5           py37haa41c4c_1    conda-forge\\r\\n     nvtx                      0.2.3            py37h5e8e339_0    conda-forge\\r\\n     olefile                   0.46               pyh9f0ad1d_1    conda-forge\\r\\n     openjdk                   11.0.1            h516909a_1016    conda-forge\\r\\n     openjpeg                  2.4.0                hf7af979_0    conda-forge\\r\\n     openssl                   1.1.1k               h7f98852_0    conda-forge\\r\\n     orc                       1.6.5                hd3605a7_0    conda-forge\\r\\n     packaging                 20.9               pyh44b312d_0    conda-forge\\r\\n     pandas                    1.1.5            py37hdc94413_0    conda-forge\\r\\n     pandoc                    2.11.4               h7f98852_0    conda-forge\\r\\n     pandocfilters             1.4.2                      py_1    conda-forge\\r\\n     panel                     0.10.3             pyhd8ed1ab_0    conda-forge\\r\\n     param                     1.10.1             pyhd3deb0d_0    conda-forge\\r\\n     parquet-cpp               1.5.1                         2    conda-forge\\r\\n     parso                     0.7.1              pyh9f0ad1d_0    conda-forge\\r\\n     partd                     1.1.0                      py_0    conda-forge\\r\\n     patsy                     0.5.1                      py_0    conda-forge\\r\\n     pcre                      8.44                 he1b5a44_0    conda-forge\\r\\n     perl                      5.32.0               h36c2ea0_0    conda-forge\\r\\n     pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\\r\\n     pickle5                   0.0.11           py37h8f50634_0    conda-forge\\r\\n     pickleshare               0.7.5                   py_1003    conda-forge\\r\\n     pillow                    8.1.1            py37h4600e1f_0    conda-forge\\r\\n     pip                       21.0.1             pyhd8ed1ab_0    conda-forge\\r\\n     pipenv                    2021.5.29                pypi_0    pypi\\r\\n     pixman                    0.40.0               h36c2ea0_0    conda-forge\\r\\n     pluggy                    0.13.1           py37h89c1867_4    conda-forge\\r\\n     poppler                   0.89.0               h2de54a5_5    conda-forge\\r\\n     poppler-data              0.4.10                        0    conda-forge\\r\\n     postgresql                12.3                 hc2f5b80_3    conda-forge\\r\\n     proj                      7.1.1                h966b41f_3    conda-forge\\r\\n     prometheus_client         0.9.0              pyhd3deb0d_0    conda-forge\\r\\n     prompt-toolkit            3.0.16             pyha770c72_0    conda-forge\\r\\n     protobuf                  3.13.0.1         py37h745909e_1    conda-forge\\r\\n     psutil                    5.8.0            py37h5e8e339_1    conda-forge\\r\\n     pthread-stubs             0.4               h36c2ea0_1001    conda-forge\\r\\n     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\\r\\n     pvlib                     0.8.1                    pypi_0    pypi\\r\\n     py                        1.10.0             pyhd3deb0d_0    conda-forge\\r\\n     py-xgboost                1.3.3dev.rapidsai0.18  cuda10.1py37_0    rapidsai-nightly\\r\\n     pyarrow                   1.0.1           py37hbeecfa9_14_cuda    conda-forge\\r\\n     pycparser                 2.20               pyh9f0ad1d_2    conda-forge\\r\\n     pyct                      0.4.6                      py_0    conda-forge\\r\\n     pyct-core                 0.4.6                      py_0    conda-forge\\r\\n     pydantic                  1.8.2                    pypi_0    pypi\\r\\n     pydeck                    0.5.0              pyh9f0ad1d_0    conda-forge\\r\\n     pyee                      7.0.4              pyh9f0ad1d_0    conda-forge\\r\\n     pyephem                   9.99                     pypi_0    pypi\\r\\n     pygments                  2.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     pyhive                    0.6.3              pyhd3deb0d_0    conda-forge\\r\\n     pymeeus                   0.5.11                   pypi_0    pypi\\r\\n     pynndescent               0.5.2              pyh44b312d_0    conda-forge\\r\\n     pynvml                    8.0.4                      py_1    conda-forge\\r\\n     pyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\\r\\n     pyppeteer                 0.2.2                      py_1    conda-forge\\r\\n     pyproj                    2.6.1.post1      py37h6415a23_3    conda-forge\\r\\n     pyrsistent                0.17.3           py37h5e8e339_2    conda-forge\\r\\n     pysocks                   1.7.1            py37h89c1867_3    conda-forge\\r\\n     pytest                    6.2.2            py37h89c1867_0    conda-forge\\r\\n     python                    3.7.10          hffdb5ce_100_cpython    conda-forge\\r\\n     python-confluent-kafka    1.5.0            py37h8f50634_0    conda-forge\\r\\n     python-dateutil           2.8.1                      py_0    conda-forge\\r\\n     python-graphviz           0.8.4                    pypi_0    pypi\\r\\n     python_abi                3.7                     1_cp37m    conda-forge\\r\\n     pytz                      2021.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyviz_comms               2.0.1              pyhd3deb0d_0    conda-forge\\r\\n     pyyaml                    5.4.1            py37h5e8e339_0    conda-forge\\r\\n     pyzmq                     22.0.3           py37h336d617_1    conda-forge\\r\\n     rapids                    0.18.0a210302   cuda10.1_py37_g58c5d18_220    rapidsai-nightly\\r\\n     rapids-blazing            0.18.0a210302   cuda10.1_py37_g58c5d18_220    rapidsai-nightly\\r\\n     rapids-xgboost            0.18.0a210302   cuda10.1_py37_g58c5d18_220    rapidsai-nightly\\r\\n     re2                       2020.10.01           he1b5a44_0    conda-forge\\r\\n     readline                  8.0                  he28a2e2_2    conda-forge\\r\\n     requests                  2.25.1             pyhd3deb0d_0    conda-forge\\r\\n     rmm                       0.18.0          cuda_10.1_py37_ga4ee6b7_0    rapidsai\\r\\n     rtree                     0.9.7            py37h0b55af0_1    conda-forge\\r\\n     s2n                       1.0.0                h9b69904_0    conda-forge\\r\\n     s3fs                      0.5.2              pyhd8ed1ab_0    conda-forge\\r\\n     sasl                      0.2.1           py37h3340039_1002    conda-forge\\r\\n     scikit-learn              0.23.1           py37h8a51577_0    conda-forge\\r\\n     scipy                     1.5.3            py37h8911b10_0    conda-forge\\r\\n     seaborn                   0.11.1               hd8ed1ab_1    conda-forge\\r\\n     seaborn-base              0.11.1             pyhd8ed1ab_1    conda-forge\\r\\n     send2trash                1.5.0                      py_0    conda-forge\\r\\n     setuptools                49.6.0           py37h89c1867_3    conda-forge\\r\\n     shapely                   1.7.1            py37hba0730f_1    conda-forge\\r\\n     simpervisor               0.4                pyhd8ed1ab_0    conda-forge\\r\\n     six                       1.15.0             pyh9f0ad1d_0    conda-forge\\r\\n     snappy                    1.1.8                he1b5a44_3    conda-forge\\r\\n     sortedcontainers          2.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     spdlog                    1.7.0                hc9558a2_2    conda-forge\\r\\n     sqlalchemy                1.4.3            py37h5e8e339_0    conda-forge\\r\\n     sqlite                    3.34.0               h74cdb3f_0    conda-forge\\r\\n     statsmodels               0.12.2           py37h902c9e0_0    conda-forge\\r\\n     streamz                   0.6.2              pyh44b312d_0    conda-forge\\r\\n     tbb                       2020.2               h4bd325d_3    conda-forge\\r\\n     tblib                     1.6.0                      py_0    conda-forge\\r\\n     terminado                 0.9.2            py37h89c1867_0    conda-forge\\r\\n     testpath                  0.4.4                      py_0    conda-forge\\r\\n     threadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge\\r\\n     thrift                    0.13.0           py37hcd2ae1e_2    conda-forge\\r\\n     thrift_sasl               0.4.2            py37h8f50634_0    conda-forge\\r\\n     tiledb                    2.1.6                h1022b9d_0    conda-forge\\r\\n     tk                        8.6.10               h21135ba_1    conda-forge\\r\\n     toml                      0.10.2             pyhd8ed1ab_0    conda-forge\\r\\n     toolz                     0.11.1                     py_0    conda-forge\\r\\n     tornado                   6.1              py37h5e8e339_1    conda-forge\\r\\n     tqdm                      4.58.0             pyhd8ed1ab_0    conda-forge\\r\\n     traitlets                 5.0.5                      py_0    conda-forge\\r\\n     treelite                  1.0.0            py37hc731546_0    conda-forge\\r\\n     treelite-runtime          1.0.0                    pypi_0    pypi\\r\\n     typing-extensions         3.7.4.3                       0    conda-forge\\r\\n     typing_extensions         3.7.4.3                    py_0    conda-forge\\r\\n     tzcode                    2021a                h7f98852_1    conda-forge\\r\\n     ucx                       1.9.0+gcd9efd3       cuda10.1_0    rapidsai-nightly\\r\\n     ucx-proc                  1.0.0                       gpu    rapidsai-nightly\\r\\n     ucx-py                    0.18.0a210323   py37_gcd9efd3_19    rapidsai-nightly\\r\\n     umap-learn                0.5.1            py37h89c1867_0    conda-forge\\r\\n     urllib3                   1.26.3             pyhd8ed1ab_0    conda-forge\\r\\n     virtualenv                20.4.7                   pypi_0    pypi\\r\\n     virtualenv-clone          0.5.4                    pypi_0    pypi\\r\\n     wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\\r\\n     webencodings              0.5.1                      py_1    conda-forge\\r\\n     websockets                8.1              py37h5e8e339_3    conda-forge\\r\\n     werkzeug                  2.0.1                    pypi_0    pypi\\r\\n     wheel                     0.36.2             pyhd3deb0d_0    conda-forge\\r\\n     widgetsnbextension        3.5.1            py37h89c1867_4    conda-forge\\r\\n     wrapt                     1.12.1           py37h5e8e339_3    conda-forge\\r\\n     wtforms                   2.3.3                    pypi_0    pypi\\r\\n     xarray                    0.17.0             pyhd8ed1ab_0    conda-forge\\r\\n     xerces-c                  3.2.3                h9d8b166_2    conda-forge\\r\\n     xgboost                   1.3.3dev.rapidsai0.18  cuda10.1py37_0    rapidsai-nightly\\r\\n     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge\\r\\n     xorg-libice               1.0.10               h7f98852_0    conda-forge\\r\\n     xorg-libsm                1.2.3             hd9c2040_1000    conda-forge\\r\\n     xorg-libx11               1.7.0                h7f98852_0    conda-forge\\r\\n     xorg-libxau               1.0.9                h7f98852_0    conda-forge\\r\\n     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\\r\\n     xorg-libxext              1.3.4                h7f98852_1    conda-forge\\r\\n     xorg-libxrender           0.9.10            h7f98852_1003    conda-forge\\r\\n     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge\\r\\n     xorg-xextproto            7.3.0             h7f98852_1002    conda-forge\\r\\n     xorg-xproto               7.0.31            h7f98852_1007    conda-forge\\r\\n     xz                        5.2.5                h516909a_1    conda-forge\\r\\n     yaml                      0.2.5                h516909a_0    conda-forge\\r\\n     yarl                      1.6.3            py37h5e8e339_1    conda-forge\\r\\n     zeromq                    4.3.4                h9c3ff4c_0    conda-forge\\r\\n     zict                      2.0.0                      py_0    conda-forge\\r\\n     zipp                      3.4.0                      py_0    conda-forge\\r\\n     zlib                      1.2.11            h516909a_1010    conda-forge\\r\\n     zstd                      1.4.8                hdf46e1d_0    conda-forge\\r\\n     \\r\\n</pre></details>\\ncreatedAt: 2021-06-22T15:07:25Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Pierrick Bruneau\\ncompany: Luxembourg Institute of Science and Technology', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 57}),\n",
       " Document(page_content=\": 156\\ntitle: [FEA] Scalar factory functions do not let you provide a validity bool.\\nbody: Scalars can be null and contain a validity bool.  The constructors for the various scalars take an `is_valid` parameter for this purpose.  But the factory functions themselves don't let you specify one in the call. Seems like an oversight. This applies to all scalar types.\\r\\n```\\r\\nstruct_scalar(table&& data,\\r\\n                bool is_valid                       = true,\\r\\n                rmm::cuda_stream_view stream        = rmm::cuda_stream_default,\\r\\n                rmm::mr::device_memory_resource* mr = rmm::mr::get_current_device_resource());\\r\\n```\\r\\n\\r\\n```\\r\\nstd::unique_ptr<scalar> make_struct_scalar(\\r\\n  table_view const& data,\\r\\n  rmm::cuda_stream_view stream        = rmm::cuda_stream_default,\\r\\n  rmm::mr::device_memory_resource* mr = rmm::mr::get_current_device_resource());\\r\\n```\\ncreatedAt: 2021-06-30T18:32:32Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 58}),\n",
       " Document(page_content=': 160\\ntitle: [BUG] Missing \"inplace\" argument in \"dask_cudf.DataFrame.drop\" although it exists in documentation\\nbody: Hi guys,\\r\\n\\r\\nI tried `gdf.drop(columns=[\\'Churn_Value\\'], inplace=True)` where `gdf` is a `dask_cudf.DataFrame` and I got this error `TypeError: drop() got an unexpected keyword argument \\'inplace\\'` even though it is listed among the list of parameters in the doc for `dask_cudf.DataFrame.drop` :\\r\\n\\r\\n```\\r\\ndask_cudf.DataFrame.drop(\\r\\n    self,\\r\\n    labels=None,\\r\\n    axis=0,\\r\\n    columns=None,\\r\\n    errors=\\'raise\\',\\r\\n)\\r\\nDocstring:\\r\\nDrop specified labels from rows or columns.\\r\\n\\r\\nThis docstring was copied from pandas.core.frame.DataFrame.drop.\\r\\n\\r\\nSome inconsistencies with the Dask version may exist.\\r\\n\\r\\nRemove rows or columns by specifying label names and corresponding\\r\\naxis, or by specifying directly index or column names. When using a\\r\\nmulti-index, labels on different levels can be removed by specifying\\r\\nthe level.\\r\\n\\r\\nParameters\\r\\n----------\\r\\nlabels : single label or list-like\\r\\n    Index or column labels to drop.\\r\\naxis : {0 or \\'index\\', 1 or \\'columns\\'}, default 0\\r\\n    Whether to drop labels from the index (0 or \\'index\\') or\\r\\n    columns (1 or \\'columns\\').\\r\\nindex : single label or list-like  (Not supported in Dask)\\r\\n    Alternative to specifying axis (``labels, axis=0``\\r\\n    is equivalent to ``index=labels``).\\r\\ncolumns : single label or list-like\\r\\n    Alternative to specifying axis (``labels, axis=1``\\r\\n    is equivalent to ``columns=labels``).\\r\\nlevel : int or level name, optional  (Not supported in Dask)\\r\\n    For MultiIndex, level from which the labels will be removed.\\r\\ninplace : bool, default False  (Not supported in Dask)\\r\\n    If False, return a copy. Otherwise, do operation\\r\\n    inplace and return None.\\r\\nerrors : {\\'ignore\\', \\'raise\\'}, default \\'raise\\'\\r\\n    If \\'ignore\\', suppress error and only existing labels are\\r\\n    dropped.\\r\\n\\r\\nReturns\\r\\n-------\\r\\nDataFrame or None\\r\\n    DataFrame without the removed index or column labels or\\r\\n    None if ``inplace=True``.\\r\\n```\\r\\nCan you guys check this out ?\\r\\nThanks :)\\ncreatedAt: 2021-07-09T07:32:08Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Bassem Karoui\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 59}),\n",
       " Document(page_content=': 163\\ntitle: [BUG] DataFrame constructor incorrectly loads nested dictionary input\\nbody: **What is your question?**\\r\\nGot different results when trying to convert dictionary to dataframe using pandas and cudf\\r\\n![image](https://user-images.githubusercontent.com/87376384/125461623-98da6483-d5eb-4278-bdeb-944276949a5e.png)\\ncreatedAt: 2021-07-13T13:38:28Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 60}),\n",
       " Document(page_content=': 168\\ntitle: [BUG] dataframe reindex NaN\\nbody: **Describe the bug**\\r\\ncuDF DataFrame is not reindexed as intented. Using a multiindex, it ends up in NaNs.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\ndata_df = cudf.read_parquet(\\'../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0/c439ef22282f412ba39e9137a3fdabac.parquet\\')\\r\\noffsets = data_df.groupby([\\'time_id\\'], as_index=False).agg({\\'seconds_in_bucket\\':\\'min\\'}).reset_index(drop=True)\\r\\noffsets.columns = [\\'time_id\\', \\'offset\\']\\r\\ndata_df = cudf.merge(data_df, offsets, on = [\\'time_id\\'], how = \\'left\\')\\r\\ndata_df.seconds_in_bucket = data_df.seconds_in_bucket - data_df.offset\\r\\n# MultiIndex.from_product uses pandas in the background\\r\\n# That\\'s why we need to transform the data into pd dataframe\\r\\ndata_df = data_df.set_index([\\'time_id\\', \\'seconds_in_bucket\\'])\\r\\ncolumns = [col for col in data_df.columns.values]\\r\\ndata_df = data_df.reindex(cudf.MultiIndex.from_product([data_df.to_pandas().index.levels[0], np.arange(0,600)], names = [\\'time_id\\', \\'seconds_in_bucket\\']), columns=columns).fillna(method=\\'ffill\\')\\r\\ndata_df = cudf.DataFrame(data_df.reset_index())\\r\\n```\\r\\nhttps://www.kaggle.com/medali1992/optiver-train-dataset?scriptVersionId=68637709\\r\\n\\r\\nThis workaround works:\\r\\n```\\r\\nindices = cudf.MultiIndex.from_product([data_df.to_pandas().index.levels[0], np.arange(0,600)], names = [\\'time_id\\', \\'seconds_in_bucket\\'])\\r\\ndata_df = cudf.DataFrame().set_index(indices).join(data_df, how=\"left\").fillna(method=\\'ffill\\').reset_index(drop=True)\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nI expect reindex function to get the correct values instead of NaNs as in pandas.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\nKaggle GPU Docker, RAPIDS 21.06\\ncreatedAt: 2021-07-20T18:56:35Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ahmet Erdem\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 61}),\n",
       " Document(page_content=\": 172\\ntitle: [BUG] Drop function for Multicolumn index doesn't work\\nbody: **Describe the bug**\\r\\nDrop function for Multicolumn index doesn't work as expected\\r\\nThe error I get is: 'One or more values not found in axis'\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```python\\r\\nimport cudf\\r\\ndf=cudf.DataFrame()\\r\\ndf['src_lat']=[-46.0,-46.0,-46.0, -34.0,-34.0,-34.0, 11.5, 11.5, 11.5]; df['src_long']=df['src_lat']+1\\r\\ndf['dst_lat']=[-46.0, -34.0,11.5,-46.0, -34.0,11.5,-46.0, -34.0,11.5];df['dst_long']=df['dst_lat']+1\\r\\ndf['val']=[0.1,0.2,0.1,0.3,0.2,0.1,0.3,0.3,0.1]\\r\\ndf = df.pivot(index=['src_lat', 'src_long'], columns=['dst_lat', 'dst_long'], values=['val'])\\r\\ndf.columns = df.index\\r\\ndf.drop([(11.5, 12.5), (-46.0, -45.0)])\\r\\n```\\ncreatedAt: 2021-08-06T15:48:46Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 62}),\n",
       " Document(page_content=\": 173\\ntitle: [FEA] Support the `min_count` argument in groupby aggregations\\nbody: Updated 5/13/2024: `numeric_only` is now supported (as of #10629). `min_count` is not yet supported.\\r\\n\\r\\nIn Pandas,  groupby aggregations (e.g., [`max`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.max.html)) accept the following arguments:\\r\\n\\r\\n- `min_count`: the minimum number of non-null values required per group in order for the result to be non-null\\r\\n- `numeric_only`: only aggregate numeric columns\\r\\n\\r\\nIt would be nice for cuDF to support these as well:\\r\\n\\r\\n```python\\r\\nIn [6]: df = cudf.DataFrame({'a': [1, 1, 1, 2, 2], 'b': ['a', 'b', 'c', 'd', 'e'], 'c': [1, 2, 3, 4, 5]})\\r\\n\\r\\nIn [7]: df\\r\\nOut[7]:\\r\\n   a  b  c\\r\\n0  1  a  1\\r\\n1  1  b  2\\r\\n2  1  c  3\\r\\n3  2  d  4\\r\\n4  2  e  5\\r\\n\\r\\nIn [8]: df.groupby('a').max(numeric_only=True)\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\n<ipython-input-8-612714d07c42> in <module>\\r\\n----> 1 df.groupby('a').max(numeric_only=True)\\r\\n\\r\\nTypeError: max() got an unexpected keyword argument 'numeric_only'\\r\\n\\r\\nIn [9]: df.to_pandas().groupby('a').max(numeric_only=True)\\r\\nOut[9]:\\r\\n   c\\r\\na\\r\\n1  3\\r\\n2  5\\r\\n```\\ncreatedAt: 2021-08-10T18:17:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 63}),\n",
       " Document(page_content=': 187\\ntitle: [BUG] pyorc does not read string column statistics of cuDF generated files\\nbody: When reading the statistics for an ORC file written by cuDF, the result for sum is wrong when read using cuDF and absent when using pyorc.\\r\\n\\r\\n```python\\r\\nIn [1]: import cudf\\r\\n\\r\\nIn [2]: import pyorc\\r\\n\\r\\nIn [3]: gdf = cudf.DataFrame({\\'b\\':[1,7], \\'a\\':[\\'Badam khao\\', \\'roz\\']})\\r\\n\\r\\nIn [4]: gdf.to_orc(\"temp.orc\")\\r\\n\\r\\nIn [5]: cudf.io.orc.read_orc_statistics([\"temp.orc\"])\\r\\nOut[5]: \\r\\n([{\\'col0\\': {\\'number_of_values\\': 2},\\r\\n   \\'b\\': {\\'number_of_values\\': 2, \\'minimum\\': 1, \\'maximum\\': 7, \\'sum\\': 8},\\r\\n   \\'a\\': {\\'number_of_values\\': 2,\\r\\n    \\'minimum\\': \\'Badam khao\\',\\r\\n    \\'maximum\\': \\'roz\\',\\r\\n    \\'sum\\': -7}}],\\r\\n [{\\'col0\\': {\\'number_of_values\\': 2},\\r\\n   \\'b\\': {\\'number_of_values\\': 2, \\'minimum\\': 1, \\'maximum\\': 7, \\'sum\\': 8},\\r\\n   \\'a\\': {\\'number_of_values\\': 2,\\r\\n    \\'minimum\\': \\'Badam khao\\',\\r\\n    \\'maximum\\': \\'roz\\',\\r\\n    \\'sum\\': -7}}])\\r\\n\\r\\nIn [6]: f = open(\"temp.orc\", \\'rb\\')\\r\\n\\r\\nIn [7]: r = pyorc.Reader(f)\\r\\n\\r\\nIn [8]: r[1].statistics\\r\\nOut[8]: \\r\\n{\\'has_null\\': False,\\r\\n \\'number_of_values\\': 2,\\r\\n \\'minimum\\': 1,\\r\\n \\'maximum\\': 7,\\r\\n \\'sum\\': 8,\\r\\n \\'kind\\': <TypeKind.LONG: 4>}\\r\\n\\r\\nIn [9]: r[2].statistics\\r\\nOut[9]: {\\'has_null\\': False, \\'number_of_values\\': 2, \\'kind\\': <TypeKind.STRING: 7>}\\r\\n```\\r\\n\\r\\n#### Expected result\\r\\nSum statistics contains the sum of lengths of all the strings in the column. We do correctly compute this in libcudf, so it should be present when reading with pyorc and correct when reading with cudf.\\r\\n\\r\\nThere\\'s two issues here:\\r\\n\\r\\n- [x] String sum statistics are encoded incorrectly (will be fixed by https://github.com/rapidsai/cudf/pull/11740)\\r\\n- [ ] pyroc does not read cuDF-written ORC string statistics\\ncreatedAt: 2021-09-27T11:01:54Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Devavret Makkar\\ncompany: @VoltronData', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 64}),\n",
       " Document(page_content=': 194\\ntitle: [FEA] Support \"on\" parameter in cudf.DataFrame.join\\nbody: Version used: cuml==21.8.2\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nleft = cudf.DataFrame([100, 101], columns=[\"item_id\"])\\r\\nright = cudf.DataFrame([\"a\",\"b\"], index=[100,101], columns=[\"item_name\"])\\r\\n\\r\\n# This will result in having only <NA> in item_name\\r\\nleft.join(right, on=\"item_id\")\\r\\n\\r\\n# This works as expected\\r\\nleft.to_pandas().join(right.to_pandas(), on=\"item_id\")\\r\\n\\r\\n# Workarround\\r\\nleft.merge(right, left_on=\"item_id\", right_index=True)\\r\\n```\\ncreatedAt: 2021-10-25T10:19:46Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Nico Kreiling\\ncompany: scieneers', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 65}),\n",
       " Document(page_content=\": 198\\ntitle: [FEA] Supporting `timedelta64` dtypes for ceil/floor operations\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThis issue is created as a follow-up to #9571  and #9554 where we add support for ceil/floor operations for `datetime64[ns]` data type. In this case, we would like additional support for `timedelta64[ns]` types as well.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n```python\\r\\nimport cudf\\r\\ntdIndex = cudf.TimedeltaIndex(data =['4 day 8h 20min 35us 45ns', '+17:42:19.999999',\\r\\n'9 day 3h 08:16:02.000055', '+22:35:25.000075'])\\r\\ntdIndex.ceil(freq='T'))\\r\\n```\\r\\nOutput:\\r\\n```bash\\r\\nTimedeltaIndex(['4 days 08:21:00', '0 days 17:43:00', '9 days 11:17:00',\\r\\n'0 days 22:36:00'],\\r\\ndtype='timedelta64[ns]', freq=None)\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nSimilar [to how pandas supports it](https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html?pandas.TimedeltaIndex.ceil#pandas-timedeltaindex-ceil)\\ncreatedAt: 2021-10-29T16:12:50Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Mayank Anand\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 66}),\n",
       " Document(page_content=\": 199\\ntitle: [BUG] Aggregation with NaN not matching Pandas behavior\\nbody: Aggregation(mean/sum) on cols NaN result in NaN value. even with dropna as `True`\\r\\n\\r\\n```\\r\\n>>> df  = cudf.DataFrame()\\r\\n>>> df['a'] = [1,2,3,0,4]\\r\\n>>> df['b'] = [1,1,1,0,1]\\r\\n>>> df['c'] = df.a/df.b\\r\\n>>> df['s'] = 0\\r\\n>>> df\\r\\n   a  b    c  s\\r\\n0  1  1  1.0  0\\r\\n1  2  1  2.0  0\\r\\n2  3  1  3.0  0\\r\\n3  0  0  NaN  0\\r\\n4  4  1  4.0  0\\r\\n>>> df[['c', 's']].groupby(['s']).mean()\\r\\n    c\\r\\ns    \\r\\n0 NaN\\r\\n```\\r\\n\\r\\n**Expected/Pandas behavior**\\r\\n```\\r\\n>>> import pandas as pd\\r\\n>>> df = pd.DataFrame()\\r\\n>>> df['a'] = [1,2,3,0,4]\\r\\n>>> df['b'] = [1,1,1,0,1]\\r\\n>>> df['c'] = df.a/df.b\\r\\n>>> df['s'] = 0\\r\\n>>> df\\r\\n   a  b    c  s\\r\\n0  1  1  1.0  0\\r\\n1  2  1  2.0  0\\r\\n2  3  1  3.0  0\\r\\n3  0  0  NaN  0\\r\\n4  4  1  4.0  0\\r\\n>>> df[['c', 's']].groupby(['s']).mean()\\r\\n     c\\r\\ns     \\r\\n0  2.5\\r\\n```\\ncreatedAt: 2021-11-01T17:48:00Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lahir Marni\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 67}),\n",
       " Document(page_content=': 210\\ntitle: [FEA] Improve cudf.read_csv empty file error message\\nbody: It\\'s embarrassingly common to accidentally produce empty \"CSV\" files, then for a downstream system to fail on attempting to read them.\\r\\n\\r\\nIf I\\'m trying to read an empty file with Pandas, I get a helpful error message indicating the problem.\\r\\n\\r\\n```\\r\\nimport pandas as pd\\r\\n\\r\\nwith open(\\'test.csv\\', \\'w\\') as fp:\\r\\n    fp.write(\\'\\')\\r\\n\\r\\npd.read_csv(\\'test.csv\\')\\r\\n```\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nEmptyDataError                            Traceback (most recent call last)\\r\\n/tmp/ipykernel_3734411/2382990058.py in <module>\\r\\n      4     fp.write(\\'\\')\\r\\n      5 \\r\\n----> 6 pd.read_csv(\\'test.csv\\')\\r\\n\\r\\n~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs)\\r\\n    309                     stacklevel=stacklevel,\\r\\n    310                 )\\r\\n--> 311             return func(*args, **kwargs)\\r\\n    312 \\r\\n    313         return wrapper\\r\\n\\r\\n~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/readers.py in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\\r\\n    584     kwds.update(kwds_defaults)\\r\\n    585 \\r\\n--> 586     return _read(filepath_or_buffer, kwds)\\r\\n    587 \\r\\n    588 \\r\\n\\r\\n~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/readers.py in _read(filepath_or_buffer, kwds)\\r\\n    480 \\r\\n    481     # Create the parser.\\r\\n--> 482     parser = TextFileReader(filepath_or_buffer, **kwds)\\r\\n    483 \\r\\n    484     if chunksize or iterator:\\r\\n\\r\\n~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/readers.py in __init__(self, f, engine, **kwds)\\r\\n    809             self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\\r\\n    810 \\r\\n--> 811         self._engine = self._make_engine(self.engine)\\r\\n    812 \\r\\n    813     def close(self):\\r\\n\\r\\n~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/readers.py in _make_engine(self, engine)\\r\\n   1038             )\\r\\n   1039         # error: Too many arguments for \"ParserBase\"\\r\\n-> 1040         return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\\r\\n   1041 \\r\\n   1042     def _failover_to_python(self):\\r\\n\\r\\n~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py in __init__(self, src, **kwds)\\r\\n     67         kwds[\"dtype\"] = ensure_dtype_objs(kwds.get(\"dtype\", None))\\r\\n     68         try:\\r\\n---> 69             self._reader = parsers.TextReader(self.handles.handle, **kwds)\\r\\n     70         except Exception:\\r\\n     71             self.handles.close()\\r\\n\\r\\n~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader.__cinit__()\\r\\n\\r\\nEmptyDataError: No columns to parse from file\\r\\n```\\r\\n\\r\\nWhen I try to read an empty CSV file from Dask-cudf (or cudf directly), it\\'s not clear if I perhaps OOMed or some other non-input-file-related problem:\\r\\n```\\r\\n~/conda/envs/dsql-dask-main/lib/python3.8/site-packages/cudf-21.12.0a0+254.g84e5a03032-py3.8-linux-x86_64.egg/cudf/io/csv.py in read_csv(filepath_or_buffer, lineterminator, quotechar, quoting, doublequote, header, mangle_dupe_cols, usecols, sep, delimiter, delim_whitespace, skipinitialspace, names, dtype, skipfooter, skiprows, dayfirst, compression, thousands, decimal, true_values, false_values, nrows, byte_range, skip_blank_lines, parse_dates, comment, na_values, keep_default_na, na_filter, prefix, index_col, use_python_file_object, **kwargs)\\r\\n     78         na_values = [na_values]\\r\\n     79 \\r\\n---> 80     return libcudf.csv.read_csv(\\r\\n     81         filepath_or_buffer,\\r\\n     82         lineterminator=lineterminator,\\r\\n\\r\\ncudf/_lib/csv.pyx in cudf._lib.csv.read_csv()\\r\\n\\r\\ncudf/_lib/csv.pyx in cudf._lib.csv.make_csv_reader_options()\\r\\n\\r\\ncudf/_lib/io/utils.pyx in cudf._lib.io.utils.make_source_info()\\r\\n\\r\\nIndexError: Out of bounds on buffer access (axis 0)\\r\\n```\\ncreatedAt: 2021-11-12T22:16:00Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Randy Gelhausen\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 68}),\n",
       " Document(page_content=\": 212\\ntitle: [FEA] `pack`/`unpack` functions to merge/split (multiple) `device_buffer`(s)\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nIt would be useful to have a `pack` function to merge multiple `device_buffer`s into a single `device_buffer`. This is helpful in situations where having one large `device_buffer` to read from is more performant. However it ultimately consists of many smaller data segments that would need to be merged together. Example use cases include sending data with UCX and spilling data from device to host.\\r\\n\\r\\nSimilarly it would be useful to have an `unpack` function to split a `device_buffer` into multiple `device_buffer`s. This is helpful in situations where having one large `device_buffer` to write into is more performant. However it ultimately consists of many smaller data segments that may need to be freed at different times. Example use cases include receiving data with UCX and unspilling data from host to device.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nFor `pack` it would be nice if it simply takes several `device_buffer`s in `vector` form and return a single one. Additionally it would be nice if `pack` could recognize when `device_buffer`s are contiguous in memory and avoid a copy. Though admittedly this last part is tricky (maybe less so if `unpack` is used regularly?). If we allow `pack` to change the order (to benefit from contiguous memory for example), we may want additional information about where the data segments live in the larger `device_buffer`.\\r\\n\\r\\nFor `unpack` it would be nice if it takes a single `device_buffer` and `size_t`s in `vector` form to split and return a `vector` of multiple `device_buffer`s. Additionally it would be nice if `unpack` did not perform any copies. Hopefully that is straightforward, but there may be things I'm not understanding.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\nOne might consider using variadics in C++ for the arguments. While nice at the C++ level, this seems tricky to use from the Cython and Python levels. Hence the suggestion to just use `vector`.\\r\\n\\r\\n`pack` itself could be implemented by a user simply allocating a larger buffer and copying over. Would be nice to avoid the extra allocation when possible though (which may require knowledge that RMM has about the allocations).\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nHaving `unpack` in particular would be helpful for aggregated receives. A natural extension of this would be to have `pack` for aggregated sends. All-in-all this should allow transmitting a larger amount of data at once with UCX and thus benefiting from this use case it is more honed for. PR  ( https://github.com/dask/distributed/pull/3453 ) provides a WIP implementation of aggregated receives for context.\\r\\n\\r\\nAlso having `pack` would be useful when spilling several `device_buffer`s from device to host as it would allow us to pack them into one `device_buffer` before transferring ( https://github.com/rapidsai/dask-cuda/issues/250 ). Having `unpack` would help us break up the allocation whenever the object is unspilled.\\r\\n\\r\\nThis need has also come up in downstream contexts ( https://github.com/rapidsai/cudf/issues/3793 ). Maybe they would benefit from an upstream solution as well?\\ncreatedAt: 2020-03-01T22:37:33Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 69}),\n",
       " Document(page_content=': 214\\ntitle: [FEA] Improve the performance of sample\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThe sample without replacement is slower than the CPU.\\r\\n\\r\\n**Additional context**\\r\\nWith replacement is really fast. \\r\\nThis indicates that thrust::shuffle_copy is the reason for the slowness.\\r\\n```\\r\\n// replacement is true\\r\\nspark.time(spark.range(Int.MaxValue * 12L).sample(true, 0.01, 0).selectExpr(\"SUM(id)\", \"COUNT(id)\").show())\\r\\n+-------------------+---------+\\r\\n|            sum(id)|count(id)|\\r\\n+-------------------+---------+\\r\\n|3320410258800588221|257697960|\\r\\n+-------------------+---------+\\r\\nTime taken: 670 ms\\r\\n\\r\\n// without replacement\\r\\nscala> spark.time(spark.range(Int.MaxValue).sample(0.01, 0).agg(functions.sum(\"id\")).show())\\r\\n+-----------------+                                                             \\r\\n|          sum(id)|\\r\\n+-----------------+\\r\\n|23058247476802342|\\r\\n+-----------------+\\r\\n\\r\\nTime taken: 1608 ms\\r\\n```\\r\\n\\r\\n[Sample code link](https://github.com/rapidsai/cudf/blob/branch-22.02/cpp/include/cudf/copying.hpp#L935)\\ncreatedAt: 2021-12-03T09:29:34Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Chong Gao\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 70}),\n",
       " Document(page_content=\": 216\\ntitle: [FEA] Add version of extract_re that takes an index\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nFrom Spark, when we call `extract_re` we often are only interested in extracting a single group rather than all the groups in the pattern. We currently call `extract_re` which returns a `Table` and we then get the column we are interested in and discard the others. It would be more efficient if we could pass the column index to cuDF so that only one column needs instantiating.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nI would like a signature something like `extract_re(pattern, index)`.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nNone\\r\\n\\r\\n**Additional context**\\r\\nNone\\ncreatedAt: 2021-12-07T17:56:51Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Andy Grove\\ncompany: @Apple\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 71}),\n",
       " Document(page_content=': 222\\ntitle: [BUG] dask_cudf from_delayed throws exception when meta is included in the from_delayed\\nbody: Exception:\\r\\n\\r\\n```\\r\\nColumns: [_col10, _col5, _col0, _col12, visit_date]\\r\\nIndex: [], \\'from_delayed\\')\\r\\nkwargs:    {}\\r\\nException: \"ValueError(\\'Metadata mismatch found in `from_delayed`.\\\\\\\\n\\\\\\\\nExpected partition of type `pandas.core.frame.DataFrame` but got `cudf.core.dataframe.DataFrame`\\')\"\\r\\n```\\r\\n\\r\\nReproducer:\\r\\n```\\r\\nimport cudf\\r\\nimport numpy as np\\r\\nfrom dask.dataframe import from_delayed\\r\\nfrom dask.delayed import delayed\\r\\nimport numpy as np\\r\\nimport cudf\\r\\nfrom dask.distributed import Client\\r\\nfrom dask_cuda import LocalCUDACluster\\r\\nimport dask_cudf\\r\\n\\r\\ndf = cudf.DataFrame()\\r\\nfor i in range(100):\\r\\n    df[f\\'_col{i}\\'] = np.random.randint(20, size=100)\\r\\n    \\r\\ndf.to_orc(\\'test1.orc\\')\\r\\ndf.to_orc(\\'test0.orc\\')\\r\\n\\r\\nfiles = [((\\'a\\',), \\'test0.orc\\'), ((\\'a\\',), \\'test1.orc\\')]\\r\\nprint(files)\\r\\n\\r\\n\\r\\ndef rd(f, cols, meta=None):\\r\\n    if partitions:\\r\\n        cols = list(set(cols) - set([x[0] for x in partitions]))\\r\\n    if type(f).__name__ == \\'str\\':\\r\\n        f = ((), f)\\r\\n    df = cudf.read_orc(f[1], columns=cols,  use_index=False)\\r\\n    if partitions:\\r\\n        for i, col in enumerate(partitions):\\r\\n            df[col[0]] = f[0][i]\\r\\n            df[col[0]] = df[col[0]].astype(col[1])\\r\\n    if meta:\\r\\n        return df[list(meta.keys())]\\r\\n    else:\\r\\n        return df\\r\\n\\r\\n\\r\\npartitions =[(\\'visit_date\\', \\'str\\')]\\r\\ncols = [\\'_col0\\', \\'_col12\\', \\'_col10\\', \\'_col5\\']\\r\\nmeta = dict(rd(files[0], cols, meta=None).dtypes)\\r\\nfor i in partitions:\\r\\n    meta[i[0]] = i[1]\\r\\n    \\r\\nprint(meta)\\r\\n\\r\\ndef main():\\r\\n    c=Client(LocalCUDACluster())\\r\\n    dfs=[delayed(rd)(f, cols=cols, meta=meta) for f in files[:2]]\\r\\n    xx = dask_cudf.from_delayed(dfs, meta=meta)\\r\\n    print(xx.compute())\\r\\n\\r\\n\\r\\nif __name__ == \"__main__\":\\r\\n    main()\\r\\n```\\r\\n\\r\\nthis issue is very similar to issue here: https://github.com/dask/dask/issues/8528\\r\\n\\r\\nthe difference is from_delayed with meta, throws another exception \"The columns in the computed data do not match the columns in the provided metadata\" even though both dfs have same columns and dtypes.\\r\\nsince we provide the meta here, we run into different issue.\\ncreatedAt: 2022-01-05T19:52:25Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lahir Marni\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 72}),\n",
       " Document(page_content=': 223\\ntitle: [BUG] `DataFrame.merge` does not assign `dtype` as expected in result as pandas does\\nbody: The `dtype` in the result of a merge is inconsistent with the equivalent pandas merge for the same inputs:\\r\\ncuDF:\\r\\n```\\r\\n>>> df1=cudf.DataFrame({\"a\":[1,2,3,4]})\\r\\n>>> df2=cudf.DataFrame(columns=[\"a\"])\\r\\n>>> r=df2.merge(df1,how=\"outer\")\\r\\n>>> df1[\"a\"].dtype\\r\\ndtype(\\'int64\\')\\r\\n>>> r[\"a\"].dtype\\r\\ndtype(\\'float64\\')\\r\\n```\\r\\npandas:\\r\\n```\\r\\n>>> pdf1=pd.DataFrame({\"a\":[1,2,3,4]})\\r\\n>>> pdf2=pd.DataFrame(columns=[\"a\"])\\r\\n>>> pr=pdf2.merge(pdf1,how=\"outer\")\\r\\n>>> pdf1[\"a\"].dtype\\r\\ndtype(\\'int64\\')\\r\\n>>> pr[\"a\"].dtype\\r\\ndtype(\\'int64\\')\\r\\n```\\ncreatedAt: 2022-01-06T16:01:41Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Rick Ratzel\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 73}),\n",
       " Document(page_content=\": 224\\ntitle: [FEA] Supporting separators with more than 1 character in cudf.read_csv method\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nWhen calling the method _cudf.read_csv_, the _sep_ argument only accepts a 1 character string - which was an old issue in pandas. However, they have already included support for multi-character separators and it would be a useful thing to have on cudf.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nCalling the _cudf.read_csv_ method as \\r\\n\\r\\n```python\\r\\ncudf.read_csv(filepath, sep='::')\\r\\n```\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nPerhaps allowing users to use a regex as a separator definer would provide a more robust solution.\\r\\n\\r\\n**Additional context**\\r\\nPython code example\\r\\n\\r\\n```python\\r\\nimport pandas as pd\\r\\nimport cudf\\r\\n\\r\\nfilepath = './example.csv'\\r\\nwith open(filepath, 'w') as f:\\r\\n    f.write('column0::column1\\\\n')\\r\\n    f.write('value00::value01\\\\n')\\r\\n    f.write('value10::value11\\\\n')\\r\\n\\r\\ndf_pandas = pd.read_csv(filepath, sep='::')\\r\\nprint ('Loaded csv file from pandas')\\r\\ndf_cudf = cudf.read_csv(filepath, sep='::')\\r\\nprint ('Loaded csv file from cudf')\\r\\n```\\r\\n\\r\\nCurrent output: `ValueError: only single character unicode strings can be converted to Py_UCS4, got length 2`\\ncreatedAt: 2022-01-06T20:26:21Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Joao Felipe Guedes\\ncompany: Globo.com\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 74}),\n",
       " Document(page_content=': 229\\ntitle: [FEA] Add Localization support to cudf\\'s Datetime capabilities\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\ncuDF does not support UTC offsets, `utc=True` in `cudf.to_datetime()`, `.tz_localize()`, nor external packages localization parameters (like `dateutils.parse` and `pytz`) in its datetime accessor.  We had an issue where a user tried to do that, and got errors\\r\\n\\r\\nhttps://stackoverflow.com/questions/70511547/compatibility-of-datetime-with-cudf-and-pandas-for-filter-datetime-in-python/70704931#70704931 (issue code and proposed work around solution is below)\\r\\n\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nwhere `testdata.csv` is \\r\\n```\\r\\nDatetime,Open,High,Low,Close,Adj Close,Volume \\r\\n2021-10-22 13:30:00+00:00,149.69,149.75,149.01,149.04,149.04,4032096.0 \\r\\n2021-10-22 13:40:00+00:00,149.69,150.175,148.845,149.92,149.92,19671400.0\\r\\n2021-11-22 13:50:00+00:00,149.975,150.18,149.5601,149.75,149.75,11911828.0 \\r\\n```\\r\\npandas works, but cudf doesn\\'t, declaring that the output doesn\\'t looke like it\\'s in datetime format\\r\\n```\\r\\nimport pandas as pd\\r\\n#import cudf as pd # uncomment to see cudf error out\\r\\nimport time \\r\\nimport datetime \\r\\nimport dateutil\\r\\n\\r\\nif __name__ == \"__main__\":\\r\\n    Zeit_start = datetime.datetime.now()\\r\\n    AGdata_search = pd.read_csv(\"testdata.csv\",parse_dates=[\\'Datetime\\'],infer_datetime_format=True,cache_dates=False)\\r\\n    AGdata_TEST = AGdata_search.loc[(AGdata_search[\\'Datetime\\'] >= dateutil.parser.parse(\"2021-11-02 13:44:00+00:00\"))] \\r\\n    AGdata_TEST.to_csv(\"output.csv\", encoding=\\'utf-8\\',index=False)\\r\\n```\\r\\nThese are the Pandas dtypes\\r\\n```\\r\\nDatetime     datetime64[ns, UTC]\\r\\nOpen                     float64\\r\\nHigh                     float64\\r\\nLow                      float64\\r\\nClose                    float64\\r\\nAdj Close                float64\\r\\nVolume                   float64\\r\\ndtype: object\\r\\n```\\r\\n\\r\\ncuDF dtype would only recognize:\\r\\n```\\r\\nDatetime     datetime64[ns]\\r\\n```\\r\\n\\r\\nAlso tried these with obvious, but various errors that would work in Pandas\\r\\n```\\r\\nAGdata_search[\\'Datetime\\'].dt.tz_localize(None)\\r\\n# AttributeError: Can only use .dt accessor with datetimelike values\\r\\n\\r\\nAGdata_search[\\'Datetime\\'].astype(\\'datetime64[ns]\\')\\r\\n# not a recognized datetime format\\r\\n\\r\\nAGdata_search[\\'Datetime\\'].astype(\\'datetime64[ns, UTC]\\')\\r\\n# unrecognized dtype error\\r\\n\\r\\nAGdata_search[\\'Datetime\\'] = cudf.to_datetime(AGdata_search[\\'Datetime\\'], utc=True)\\r\\n# no affect\\r\\n\\r\\nimport pytz\\r\\nAGdata_search[\\'Datetime\\'].tz_localize(pytz.utc)\\r\\n# AttributeError: \\'Series\\' object has no attribute \\'tz_localize\\'\\r\\n```\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nThe workaround proposed was to explicitly declare the format code \\r\\n```\\r\\nAGdata_search[\\'Datetime\\'] = cudf.to_datetime(AGdata_search[\\'Datetime\\'], format=\\'%Y-%m-D %H:%M:%S+%z\\')\\r\\n```\\r\\nand the full solution presented was:\\r\\n```\\r\\nimport cudf as cudf \\r\\nimport time \\r\\nimport datetime \\r\\nimport dateutil\\r\\n\\r\\nif __name__ == \"__main__\":\\r\\n    Zeit_start = datetime.datetime.now()\\r\\n    AGdata_search = cudf.read_csv(\"testdata.csv\")\\r\\n    AGdata_search[\\'Datetime\\'] = cudf.to_datetime(AGdata_search[\\'Datetime\\'], format=\\'%Y-%m-%d %H:%M:%S+%z\\') # this makes it work)\\r\\n    AGdata_TEST = AGdata_search.loc[(AGdata_search[\\'Datetime\\'] >= dateutil.parser.parse(\"2021-11-02 13:44:00+00:00\"))]\\r\\n    AGdata_TEST.to_csv(\"output.csv\", encoding=\\'utf-8\\',index=False)\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nThis format seems to be used often in the financial market analysis.\\r\\n\\r\\nhere is some other pandas code that works only in pandas i stumbled on while trying to find a workaround\\r\\n```\\r\\nimport pandas as pd\\r\\nimport pytz\\r\\n\\r\\nindex = pd.date_range(\\'20140101 21:55\\', freq=\\'15S\\', periods=5)\\r\\ndf = pd.DataFrame(1, index=index, columns=[\\'X\\'])\\r\\nprint(df)\\r\\n#                      X\\r\\n# 2014-01-01 21:55:00  1\\r\\n# 2014-01-01 21:55:15  1\\r\\n# 2014-01-01 21:55:30  1\\r\\n# 2014-01-01 21:55:45  1\\r\\n# 2014-01-01 21:56:00  1\\r\\n\\r\\n# [5 rows x 1 columns]\\r\\nprint(df.index)\\r\\n# <class \\'pandas.tseries.index.DatetimeIndex\\'>\\r\\n# [2014-01-01 21:55:00, ..., 2014-01-01 21:56:00]\\r\\n# Length: 5, Freq: 15S, Timezone: None\\r\\n\\r\\neastern = pytz.timezone(\\'US/Eastern\\')\\r\\ndf.index = df.index.tz_localize(pytz.utc).tz_convert(eastern)\\r\\nprint(df)\\r\\n#                            X\\r\\n# 2014-01-01 16:55:00-05:00  1\\r\\n# 2014-01-01 16:55:15-05:00  1\\r\\n# 2014-01-01 16:55:30-05:00  1\\r\\n# 2014-01-01 16:55:45-05:00  1\\r\\n# 2014-01-01 16:56:00-05:00  1\\r\\n\\r\\n# [5 rows x 1 columns]\\r\\n\\r\\nprint(df.index)\\r\\n# <class \\'pandas.tseries.index.DatetimeIndex\\'>\\r\\n# [2014-01-01 16:55:00-05:00, ..., 2014-01-01 16:56:00-05:00]\\r\\n# Length: 5, Freq: 15S, Timezone: US/Eastern\\r\\n```\\ncreatedAt: 2022-01-14T02:13:28Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Taurean Dyer\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 75}),\n",
       " Document(page_content=\": 235\\ntitle: [BUG] ValueError: 'category' column dtypes are currently not supported by the gpu accelerated parquet writer\\nbody: The following exception is thrown when a column of type 'int' is written using to_parquet, and read with read_parquet and re-written with to-parquet again.\\r\\n\\r\\nSo, the first to_parquet is changing the `int` col type to catg, but when reading again, and the same file is re-written it fails.\\r\\n\\r\\nException: ValueError: 'category' column dtypes are currently not supported by the gpu accelerated parquet writer\\r\\n\\r\\nReproducer Code:\\r\\n```\\r\\nimport cudf\\r\\ndf = cudf.DataFrame()\\r\\n\\r\\ndf['a'] = [0 , 0 , 0, 1]\\r\\ndf['b'] = [0 , 0 , 0, 1]\\r\\n\\r\\ndf['a']  = df.a.astype('int')\\r\\ndf.to_parquet('test', partition_cols=['a'], partition_file_name=f'0.parquet')\\r\\ndf = cudf.read_parquet('test/a=0/0.parquet')\\r\\ndf.to_parquet('test.pq')\\r\\n```\\ncreatedAt: 2022-01-24T22:45:20Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lahir Marni\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 76}),\n",
       " Document(page_content=': 236\\ntitle: [FEA] Support \"mode\" argument to to_csv\\nbody: I\\'m trying to iteratively write (append) to an existing CSV file:\\r\\n```\\r\\nimport cudf\\r\\n\\r\\ndf = cudf.DataFrame({\\'id\\': [0, 1, 2]})\\r\\ndf.to_csv(\\'test.csv\\', header=False, index=False, mode=\\'a\\')\\r\\n```\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\nInput In [3], in <module>\\r\\n      1 import cudf\\r\\n      3 df = cudf.DataFrame({\\'id\\': [0, 1, 2]})\\r\\n----> 4 df.to_csv(\\'test.csv\\', header=False, index=False, mode=\"a\")\\r\\n\\r\\nFile ~/conda/envs/dsql-1-25/lib/python3.8/site-packages/cudf/core/dataframe.py:5749, in DataFrame.to_csv(self, path_or_buf, sep, na_rep, columns, header, index, line_terminator, chunksize, encoding, compression, **kwargs)\\r\\n   5746 \"\"\"{docstring}\"\"\"\\r\\n   5747 from cudf.io import csv as csv\\r\\n-> 5749 return csv.to_csv(\\r\\n   5750     self,\\r\\n   5751     path_or_buf=path_or_buf,\\r\\n   5752     sep=sep,\\r\\n   5753     na_rep=na_rep,\\r\\n   5754     columns=columns,\\r\\n   5755     header=header,\\r\\n   5756     index=index,\\r\\n   5757     line_terminator=line_terminator,\\r\\n   5758     chunksize=chunksize,\\r\\n   5759     encoding=encoding,\\r\\n   5760     compression=compression,\\r\\n   5761     **kwargs,\\r\\n   5762 )\\r\\n\\r\\nFile ~/conda/envs/dsql-1-25/lib/python3.8/contextlib.py:75, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     72 @wraps(func)\\r\\n     73 def inner(*args, **kwds):\\r\\n     74     with self._recreate_cm():\\r\\n---> 75         return func(*args, **kwds)\\r\\n\\r\\nFile ~/conda/envs/dsql-1-25/lib/python3.8/site-packages/cudf/io/csv.py:148, in to_csv(df, path_or_buf, sep, na_rep, columns, header, index, line_terminator, chunksize, encoding, compression, **kwargs)\\r\\n    145     path_or_buf = StringIO()\\r\\n    146     return_as_string = True\\r\\n--> 148 path_or_buf = ioutils.get_writer_filepath_or_buffer(\\r\\n    149     path_or_data=path_or_buf, mode=\"w\", **kwargs\\r\\n    150 )\\r\\n    152 if columns is not None:\\r\\n    153     try:\\r\\n\\r\\nTypeError: get_writer_filepath_or_buffer() got multiple values for keyword argument \\'mode\\'\\r\\n```\\r\\n\\r\\nAs a workaround, I could always write to a new, separate CSV file and concat them together afterwards.\\ncreatedAt: 2022-01-25T18:43:02Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Randy Gelhausen\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 77}),\n",
       " Document(page_content=\": 245\\ntitle: [FEA] Support for callable functions in groupby transform\\nbody: **What is your question?**\\r\\nWe would to run this code on a dataframe loaded using cudf, but encounter the following error.\\r\\nif anyone have an answer for this problem, thank you\\r\\n\\r\\n`df['rmean'] = df.groupby(['outlet', 'product'])['sales'].transform(lambda x: x.rolling(window=win).mean()).astype(np.float32)`\\r\\n\\r\\n`AttributeError: type object 'cudf._lib.aggregation.GroupbyAggregation' has no attribute 'rolling'`\\ncreatedAt: 2022-02-08T04:02:19Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Muhammad Rizky Ferlanda\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 78}),\n",
       " Document(page_content=': 247\\ntitle: [FEA] JSON reader: ignores Java/C++ style comment\\nbody: This is part of FEA of https://github.com/NVIDIA/spark-rapids/issues/9\\r\\nWe have a JSON file\\r\\n\\r\\n``` json\\r\\n{\"name\": // name\\r\\n \"Reynold Xin\"}\\r\\n```\\r\\n\\r\\nSpark can parse it when enabling `allowComments` and `multiLine`\\r\\n\\r\\nor \\r\\n\\r\\n``` json\\r\\n{\\'name\\': /* hello */ \\'Reynold Xin\\'}\\r\\n```\\r\\n\\r\\nSpark can parse it when enabling `allowComments` \\r\\n\\r\\nWe expect there is a configure `allowComments` to control this behavior.\\ncreatedAt: 2022-02-10T08:58:50Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Bobby Wang\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 79}),\n",
       " Document(page_content=': 248\\ntitle: [FEA] JSON reader: support unquoted JSON field names.\\nbody: This is part of FEA of https://github.com/NVIDIA/spark-rapids/issues/9\\r\\nWe have a JSON file\\r\\n\\r\\n``` json\\r\\n{name: \"Reynold Xin\"}\\r\\n```\\r\\n\\r\\nSpark can parse it when enabling `allowUnquotedFieldNames`\\r\\n\\r\\nCUDF parsing will throw exception\\r\\n\\r\\nWe expect there is a configure `allowUnquotedFieldNames` to control this behavior.\\ncreatedAt: 2022-02-10T09:10:57Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Bobby Wang\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 80}),\n",
       " Document(page_content=': 249\\ntitle: [FEA] JSON reader: support multi-lines\\nbody: This is part of FEA of https://github.com/NVIDIA/spark-rapids/issues/9\\r\\nWe have a JSON file\\r\\n\\r\\n``` json\\r\\n{\"name\":\\r\\n   \"Reynold Xin\"}\\r\\n```\\r\\n\\r\\nSpark can parse it when enabling `multiLine`\\r\\n\\r\\nCUDF parsing will throw an exception\\r\\n\\r\\nWe expect there is a configure `multiLine` to control this behavior.\\ncreatedAt: 2022-02-10T09:18:20Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Bobby Wang\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 81}),\n",
       " Document(page_content=': 256\\ntitle: Use \"ranger\" to prevent grid stride loop overflow\\nbody: (updated Aug 2023)\\r\\n\\r\\n### Background\\r\\n\\r\\nWe found a kernel indexing overflow issue, first discovered in the `fused_concatenate` kernels (https://github.com/rapidsai/cudf/issues/10333) and this issue is present in a number of our CUDA kernels that take the following form:\\r\\n\\r\\n```\\r\\nsize_type output_index = threadIdx.x + blockIdx.x * blockDim.x;  \\r\\nwhile (output_index < output_size) {\\r\\n  output_index += blockDim.x * gridDim.x;\\r\\n}\\r\\n```\\r\\n\\r\\nIf we have an output_size of say 1.2 billion and a grid size that\\'s the same, the following happens:  Some late thread id, say 1.19 billion attempts to add 1.2 billion (blockDim.x * gridDim.x) and overflows the size_type (signed 32 bits). \\r\\n\\r\\nWe made a round of fixes in #10448, and then later found another instance of this error in #13838. Our first pass of investigation was not adequate to contain the issue, so we need to take another close look.\\r\\n\\r\\n\\r\\n### Part 1 - First pass fix kernels with this issue\\r\\n\\r\\n| Source file | Kernels | Status | \\r\\n|---|---|---|\\r\\n| `copying/concatenate.cu` | `fused_concatenate_kernel` |  #10448 |\\r\\n| `valid_if.cuh` | `valid_if_kernel` |  #10448 |\\r\\n| `scatter.cu` | `marking_bitmask_kernel` |  #10448 |\\r\\n| `replace/nulls.cu` | `replace_nulls_strings` | #10448 |\\r\\n| `replace/nulls.cu` | `replace_nulls` |  #10448 |\\r\\n| `rolling/rolling_detail.cuh` | `gpu_rolling` |  #10448 |\\r\\n| `rolling/jit/kernel.cu` | `gpu_rolling_new` | #10448 |\\r\\n| `transform/compute_column.cu` | `compute_column_kernel`  | #10448 |\\r\\n|`copying/concatenate.cu` | `fused_concatenate_string_offset_kernel` |  #13838 |\\r\\n| `replace/replace.cu` |   `replace_strings_first_pass` <br>   `replace_strings_second_pass` <br>  `replace_kernel` | #13905 |\\r\\n| `copying/concatenate.cu` |   `concatenate_masks_kernel` <br>   `fused_concatenate_string_offset_kernel` <br>   `fused_concatenate_string_chars_kernel` <br>  `fused_concatenate_kernel` (int64) | #13906 | | \\r\\n| `hash/helper_functions.cuh` |   `init_hashtbl` | #13895  |\\r\\n| `null_mask.cu` |  `set_null_mask_kernel` <br>   `copy_offset_bitmask` <br>   `count_set_bits_kernel` | #13895  | \\r\\n| `transform/row_bit_count.cu` |   `compute_row_sizes` | #13895  | \\r\\n| `multibyte_split.cu` |   `multibyte_split_init_kernel` <br>   `multibyte_split_seed_kernel` (auto??) <br>   `multibyte_split_kernel`  | #13910 | \\r\\n| IO modules: parquet, orc, json | | #13910 | \\r\\n| `io/utilities/parsing_utils.cu` |   `count_and_set_positions` (uint64_t)  | #13910 |  \\r\\n| `conditional_join_kernels.cuh` |   `compute_conditional_join_output_size` <br>   `conditional_join` | #13971 | \\r\\n| `merge.cu` |   `materialize_merged_bitmask_kernel`  | #13972 | \\r\\n| `partitioning.cu` |   `compute_row_partition_numbers`  <br>  `compute_row_output_locations` <br>   `copy_block_partitions`  | #13973  | \\r\\n| `json_path.cu` |  `get_json_object_kernel`  | #13962 | \\r\\n | `tdigest` |   `compute_percentiles_kernel` (int)  | #13962 | \\r\\n| `strings/attributes.cu` |   `count_characters_parallel_fn`  | #13968 |  \\r\\n| `strings/convert/convert_urls.cu` |   `url_decode_char_counter` (int) <br>   `url_decode_char_replacer` (int)  | #13968 |  \\r\\n| `text/subword/data_normalizer.cu` |   `kernel_data_normalizer` (uint32_t)  |  #13915  | \\r\\n| `text/subword/subword_tokenize.cu`  |  `kernel_compute_tensor_metadata` (uint32_t)  |  #13915 | \\r\\n| `text/subword/wordpiece_tokenizer.cu` |  `init_data_and_mark_word_start_and_ends` (uint32_t) <br>   `mark_string_start_and_ends` (uint32_t) <br>   `kernel_wordpiece_tokenizer` (uint32_t) | #13915  | \\r\\n\\r\\n### Part 2 - Take another pass over more challenging kernels\\r\\n\\r\\n\\r\\n| Source file | Kernels | Status | \\r\\n|---|---|---|\\r\\n| null_mash.cuh | [subtract_set_bits_range_boundaries_kernel](https://github.com/rapidsai/cudf/blob/b4da39cfbe569e290ae42ca9cf8ff868d5788757/cpp/include/cudf/detail/null_mask.cuh#L215) | |\\r\\n| valid_if.cuh | [valid_if_n_kernel](https://github.com/rapidsai/cudf/blob/b4da39cfbe569e290ae42ca9cf8ff868d5788757/cpp/include/cudf/detail/valid_if.cuh#L154) | |\\r\\n|copy_if_else.cuh | [copy_if_else_kernel](https://github.com/rapidsai/cudf/blob/b4da39cfbe569e290ae42ca9cf8ff868d5788757/cpp/include/cudf/detail/copy_if_else.cuh#L41) | |\\r\\n| gather.cuh | [gather_chars_fn_string_parallel](https://github.com/rapidsai/cudf/blob/b4da39cfbe569e290ae42ca9cf8ff868d5788757/cpp/include/cudf/strings/detail/gather.cuh#L78) | |\\r\\n| more? | search `gridDim.x` or `blockDim.x` to find more examples | | \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n### Part 3 - Use [ranger](https://github.com/harrism/ranger) to prevent grid stride loop overflow\\r\\n* incorporate the ranger header as a libcudf utility\\r\\n* use ranger instead of manual indexing in libcudf kernels\\r\\n\\r\\n\\r\\n### Additional information\\r\\n\\r\\nThere are also a number of kernels that have this pattern but probably don\\'t ever overflow because they are indexing by bitmask words.  ([Example](https://github.com/rapidsai/cudf/blob/4c9ef5161268e2486938546deef00f7fc84c9a95/cpp/include/cudf/detail/copy_range.cuh#L41))\\r\\nAdditional, In this kernel, `source_idx` probably overflows, but harmlessly.\\r\\n\\r\\nA snippet of code to see this in action:\\r\\n```\\r\\nsize_type const size = 1200000000;\\r\\nauto big = cudf::make_fixed_width_column(data_type{type_id::INT32}, size, mask_state::UNALLOCATED);  \\r\\nauto x = cudf::rolling_window(*big, 1, 1, 1, cudf::detail::sum_aggregation{}); \\r\\n```\\r\\n\\r\\nNote:  rmm may mask out of bounds accesses in some cases, so it\\'s helpful to run with the plain cuda allocator.\\ncreatedAt: 2022-02-28T19:30:02Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 82}),\n",
       " Document(page_content=': 257\\ntitle: [FEA] Cleanup of unneeded functions in Python aggregation types.\\nbody: With this PR  https://github.com/rapidsai/cudf/pull/10357 all aggregations in cudf are now represented as algorithm-specific aggregation classes.   There is some followup cleanup work to be done in the python bindings. See:\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/pull/10357#issuecomment-1054204554\\ncreatedAt: 2022-03-07T16:28:51Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 83}),\n",
       " Document(page_content=': 263\\ntitle: [FEA] Iterator versions of make_device_uvector_sync() and make_device_uvector_async()\\nbody: Ran into some code in a PR that was staging results into a std::vector just so that it could be passed to a factory function.  Seems like it would be useful to have versions that take (device) iterators directly.\\ncreatedAt: 2022-03-18T15:49:01Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 84}),\n",
       " Document(page_content=': 267\\ntitle: [FEA] Provide a way to specify the maximum allowable precision for integers/floats\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nGPU memory is a valuable resource, and using int64/float64 columns where int32/float32 would suffice means using 2x as much memory unnecessarily. As opposed to scientific computing, 32-bit data types (or lower) are sufficient for many data science applications.\\r\\n\\r\\nEven only 32-bit data types as inputs, the resulting output can be a 64-bit type:\\r\\n\\r\\n```python\\r\\n>>> cudf.Series([1, 2, 3], dtype=\"int32\") + cudf.Scalar(1, dtype=\"float32\")\\r\\n0    2.0\\r\\n1    3.0\\r\\n2    4.0\\r\\ndtype: float64\\r\\n```\\r\\n\\r\\n(this is consistent with Pandas and NumPy)\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nIt would be nice to be able to specify a maximum bitwidth for integer/floating types. If an operation would result in a value greater than could be accommodated, simply overflowing would be acceptable.\\r\\n\\r\\nThis could be another use case for [cudf.config](https://github.com/rapidsai/cudf/issues/5311).\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\n\\r\\nThe user can carefully cast results back from 64bit to 32bit to reduce memory usage, but this is tedious and does not help with peak memory usage.\\ncreatedAt: 2022-03-31T18:28:33Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 85}),\n",
       " Document(page_content=': 268\\ntitle: [BUG] Parsing string to float is inconsistent between CSV reader and to_numeric\\nbody: **Describe the bug**\\r\\nThe parsing of strings to floats has different results in different contexts, as discussed in https://github.com/NVIDIA/spark-rapids/issues/5035.\\r\\n\\r\\n## Parsing floats from CSV\\r\\n\\r\\nGiven the following input file:\\r\\n\\r\\n```\\r\\n0.1\\r\\n0.2\\r\\n0.3\\r\\n```\\r\\n\\r\\nThe following code parses the floats as follows.\\r\\n\\r\\n``` python\\r\\n>>> df  = cudf.read_csv(\"floats.csv\", names=[\"a\"], dtype=[\"float64\"])\\r\\n>>> df[\\'a\\'][0]\\r\\n0.1\\r\\n>>> df[\\'a\\'][1]\\r\\n0.2\\r\\n>>> df[\\'a\\'][2]\\r\\n0.30000000000000004\\r\\n```\\r\\n\\r\\n## Parsing floats with to_numeric\\r\\n\\r\\nParsing the same values using `to_numeric` produces different results.\\r\\n\\r\\n``` python\\r\\n>>> s = cudf.Series([\\'0.1\\', \\'0.2\\', \\'0.3\\'])\\r\\n>>> x = cudf.to_numeric(s)\\r\\n>>> x[0]\\r\\n0.09999999999999999\\r\\n>>> x[1]\\r\\n0.19999999999999998\\r\\n>>> x[2]\\r\\n0.3\\r\\n```\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nSee above code examples.\\r\\n\\r\\n**Expected behavior**\\r\\nThese two paths should produce consistent results.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\nBare metal (desktop PC).\\r\\n\\r\\n**Environment details**\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n     \\r\\n     **git***\\r\\n     commit 9932a03894f12f9c3f83ae635792c7d79eb430a1 (HEAD, sperlingxx/enable_zero_backref)\\r\\n     Author: sperlingxx <lovedreamf@gmail.com>\\r\\n     Date:   Wed Mar 30 08:44:00 2022 +0800\\r\\n     \\r\\n     update\\r\\n     **git submodules***\\r\\n     \\r\\n     ***OS Information***\\r\\n     DISTRIB_ID=Ubuntu\\r\\n     DISTRIB_RELEASE=20.04\\r\\n     DISTRIB_CODENAME=focal\\r\\n     DISTRIB_DESCRIPTION=\"Ubuntu 20.04.3 LTS\"\\r\\n     NAME=\"Ubuntu\"\\r\\n     VERSION=\"20.04.3 LTS (Focal Fossa)\"\\r\\n     ID=ubuntu\\r\\n     ID_LIKE=debian\\r\\n     PRETTY_NAME=\"Ubuntu 20.04.3 LTS\"\\r\\n     VERSION_ID=\"20.04\"\\r\\n     HOME_URL=\"https://www.ubuntu.com/\"\\r\\n     SUPPORT_URL=\"https://help.ubuntu.com/\"\\r\\n     BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\\r\\n     PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\\r\\n     VERSION_CODENAME=focal\\r\\n     UBUNTU_CODENAME=focal\\r\\n     Linux ripper 5.13.0-39-generic #44~20.04.1-Ubuntu SMP Thu Mar 24 16:43:35 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux\\r\\n     \\r\\n     ***GPU Information***\\r\\n     Tue Apr  5 14:53:32 2022\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\\r\\n     |-------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                               |                      |               MIG M. |\\r\\n     |===============================+======================+======================|\\r\\n     |   0  NVIDIA GeForce ...  On   | 00000000:42:00.0  On |                  N/A |\\r\\n     |  0%   50C    P5    26W / 320W |   1086MiB / 10014MiB |      5%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     \\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | Processes:                                                                  |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n     |        ID   ID                                                   Usage      |\\r\\n     |=============================================================================|\\r\\n     |    0   N/A  N/A      1714      G   /usr/lib/xorg/Xorg                102MiB |\\r\\n     |    0   N/A  N/A      2459      G   /usr/lib/xorg/Xorg                605MiB |\\r\\n     |    0   N/A  N/A      2595      G   /usr/bin/gnome-shell              109MiB |\\r\\n     |    0   N/A  N/A      3028      G   ...AAAAAAAAA= --shared-files        8MiB |\\r\\n     |    0   N/A  N/A      3409      G   /usr/lib/firefox/firefox          168MiB |\\r\\n     |    0   N/A  N/A      9759      G   ...veSuggestionsOnlyOnDemand       51MiB |\\r\\n     |    0   N/A  N/A     39765      G   ..._20525.log --shared-files        4MiB |\\r\\n     |    0   N/A  N/A    126249      G   ./jetbrains-toolbox                12MiB |\\r\\n     |    0   N/A  N/A    147354      G   /usr/lib/firefox/firefox            3MiB |\\r\\n     |    0   N/A  N/A    190794      G   /usr/lib/firefox/firefox            3MiB |\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     \\r\\n     ***CPU***\\r\\n     Architecture:                    x86_64\\r\\n     CPU op-mode(s):                  32-bit, 64-bit\\r\\n     Byte Order:                      Little Endian\\r\\n     Address sizes:                   43 bits physical, 48 bits virtual\\r\\n     CPU(s):                          48\\r\\n     On-line CPU(s) list:             0-47\\r\\n     Thread(s) per core:              2\\r\\n     Core(s) per socket:              24\\r\\n     Socket(s):                       1\\r\\n     NUMA node(s):                    4\\r\\n     Vendor ID:                       AuthenticAMD\\r\\n     CPU family:                      23\\r\\n     Model:                           8\\r\\n     Model name:                      AMD Ryzen Threadripper 2970WX 24-Core Processor\\r\\n     Stepping:                        2\\r\\n     Frequency boost:                 enabled\\r\\n     CPU MHz:                         2166.041\\r\\n     CPU max MHz:                     3000.0000\\r\\n     CPU min MHz:                     2200.0000\\r\\n     BogoMIPS:                        5988.02\\r\\n     Virtualization:                  AMD-V\\r\\n     L1d cache:                       768 KiB\\r\\n     L1i cache:                       1.5 MiB\\r\\n     L2 cache:                        12 MiB\\r\\n     L3 cache:                        64 MiB\\r\\n     NUMA node0 CPU(s):               0-5,24-29\\r\\n     NUMA node1 CPU(s):               12-17,36-41\\r\\n     NUMA node2 CPU(s):               6-11,30-35\\r\\n     NUMA node3 CPU(s):               18-23,42-47\\r\\n     Vulnerability Itlb multihit:     Not affected\\r\\n     Vulnerability L1tf:              Not affected\\r\\n     Vulnerability Mds:               Not affected\\r\\n     Vulnerability Meltdown:          Not affected\\r\\n     Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp\\r\\n     Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\r\\n     Vulnerability Spectre v2:        Mitigation; LFENCE, IBPB conditional, STIBP disabled, RSB filling\\r\\n     Vulnerability Srbds:             Not affected\\r\\n     Vulnerability Tsx async abort:   Not affected\\r\\n     Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid amd_dcm aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb hw_pstate ssbd ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 rdseed adx smap clflushopt sha_ni xsaveopt xsavec xgetbv1 xsaves clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif overflow_recov succor smca sme sev sev_es\\r\\n     \\r\\n     ***CMake***\\r\\n     /usr/bin/cmake\\r\\n     cmake version 3.16.3\\r\\n     \\r\\n     CMake suite maintained and supported by Kitware (kitware.com/cmake).\\r\\n     \\r\\n     ***g++***\\r\\n     /usr/bin/g++\\r\\n     g++ (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\\r\\n     Copyright (C) 2019 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n     \\r\\n     \\r\\n     ***nvcc***\\r\\n     /usr/local/cuda/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2021 NVIDIA Corporation\\r\\n     Built on Thu_Nov_18_09:45:30_PST_2021\\r\\n     Cuda compilation tools, release 11.5, V11.5.119\\r\\n     Build cuda_11.5.r11.5/compiler.30672275_0\\r\\n     \\r\\n     ***Python***\\r\\n     /home/andy/miniconda3/envs/rapids-22.04/bin/python\\r\\n     Python 3.8.13\\r\\n     \\r\\n     ***Environment Variables***\\r\\n     PATH                            : /home/andy/miniconda3/envs/rapids-22.04/bin:/home/andy/miniconda3/condabin:/home/andy/.cargo/bin:/home/andy/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/apache-maven-3.8.4/bin:mvnd-0.5.2-linux-amd64/bin:/usr/local/cuda/bin\\r\\n     LD_LIBRARY_PATH                 : :/usr/local/cuda/targets/x86_64-linux/lib/:/usr/local/cuda/lib64\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /home/andy/miniconda3/envs/rapids-22.04\\r\\n     PYTHON_PATH                     :\\r\\n     \\r\\n     ***conda packages***\\r\\n     /home/andy/miniconda3/condabin/conda\\r\\n     # packages in environment at /home/andy/miniconda3/envs/rapids-22.04:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                       1_gnu    conda-forge\\r\\n     abseil-cpp                20210324.2           h9c3ff4c_0    conda-forge\\r\\n     aiohttp                   3.8.1            py38h0a891b7_1    conda-forge\\r\\n     aiosignal                 1.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     alsa-lib                  1.2.3                h516909a_0    conda-forge\\r\\n     anyio                     3.5.0            py38h578d9bd_0    conda-forge\\r\\n     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge\\r\\n     argon2-cffi               21.3.0             pyhd8ed1ab_0    conda-forge\\r\\n     argon2-cffi-bindings      21.2.0           py38h497a2fe_1    conda-forge\\r\\n     arrow-cpp                 6.0.1           py38h4dc56cc_5_cuda    conda-forge\\r\\n     arrow-cpp-proc            3.0.0                      cuda    conda-forge\\r\\n     asgiref                   3.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     asttokens                 2.0.5              pyhd8ed1ab_0    conda-forge\\r\\n     async-timeout             4.0.2              pyhd8ed1ab_0    conda-forge\\r\\n     attrs                     21.4.0             pyhd8ed1ab_0    conda-forge\\r\\n     aws-c-auth                0.6.8                hadad3cd_1    conda-forge\\r\\n     aws-c-cal                 0.5.12               h70efedd_7    conda-forge\\r\\n     aws-c-common              0.6.17               h7f98852_0    conda-forge\\r\\n     aws-c-compression         0.2.14               h7c7754b_7    conda-forge\\r\\n     aws-c-event-stream        0.2.7               hd2be095_32    conda-forge\\r\\n     aws-c-http                0.6.10               h416565a_3    conda-forge\\r\\n     aws-c-io                  0.10.14              he836878_0    conda-forge\\r\\n     aws-c-mqtt                0.7.10               h885097b_0    conda-forge\\r\\n     aws-c-s3                  0.1.29               h8d70ed6_0    conda-forge\\r\\n     aws-c-sdkutils            0.1.1                h7c7754b_4    conda-forge\\r\\n     aws-checksums             0.1.12               h7c7754b_6    conda-forge\\r\\n     aws-crt-cpp               0.17.10              h6ab17b9_5    conda-forge\\r\\n     aws-sdk-cpp               1.9.160              h36ff4c5_0    conda-forge\\r\\n     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\\r\\n     backports                 1.0                        py_2    conda-forge\\r\\n     backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\\r\\n     backports.zoneinfo        0.2.1            py38h497a2fe_4    conda-forge\\r\\n     beautifulsoup4            4.10.0             pyha770c72_0    conda-forge\\r\\n     bleach                    4.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     blosc                     1.21.0               h9c3ff4c_0    conda-forge\\r\\n     bokeh                     2.4.2            py38h578d9bd_0    conda-forge\\r\\n     boost                     1.74.0           py38h2b96118_5    conda-forge\\r\\n     boost-cpp                 1.74.0               h312852a_4    conda-forge\\r\\n     brotli                    1.0.9                h166bdaf_7    conda-forge\\r\\n     brotli-bin                1.0.9                h166bdaf_7    conda-forge\\r\\n     brotlipy                  0.7.0           py38h0a891b7_1004    conda-forge\\r\\n     brunsli                   0.1                  h9c3ff4c_0    conda-forge\\r\\n     bzip2                     1.0.8                h7f98852_4    conda-forge\\r\\n     c-ares                    1.18.1               h7f98852_0    conda-forge\\r\\n     c-blosc2                  2.0.4                h5f21a17_1    conda-forge\\r\\n     ca-certificates           2021.10.8            ha878542_0    conda-forge\\r\\n     cachetools                5.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     cairo                     1.16.0            h6cf1ce9_1008    conda-forge\\r\\n     certifi                   2021.10.8        py38h578d9bd_2    conda-forge\\r\\n     cffi                      1.15.0           py38h3931269_0    conda-forge\\r\\n     cfitsio                   3.470                hb418390_7    conda-forge\\r\\n     charls                    2.2.0                h9c3ff4c_0    conda-forge\\r\\n     charset-normalizer        2.0.12             pyhd8ed1ab_0    conda-forge\\r\\n     click                     8.0.4            py38h578d9bd_0    conda-forge\\r\\n     click-plugins             1.1.1                      py_0    conda-forge\\r\\n     cligj                     0.7.2              pyhd8ed1ab_1    conda-forge\\r\\n     cloudpickle               2.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     colorama                  0.4.4              pyh9f0ad1d_0    conda-forge\\r\\n     colorcet                  3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     cryptography              36.0.2           py38h2b5fc30_1    conda-forge\\r\\n     cucim                     22.04.00a220405 cuda_11_py38_g7602774_34    rapidsai-nightly\\r\\n     cuda-python               11.6.1           py38h3fd9d12_0    nvidia\\r\\n     cudatoolkit               11.5.1               hcf5317a_9    nvidia\\r\\n     cudf                      22.04.00a220405 cuda_11_py38_g4c84184a3f_304    rapidsai-nightly\\r\\n     cudf_kafka                22.04.00a220405 py38_g4c84184a3f_304    rapidsai-nightly\\r\\n     cugraph                   22.04.00a220405 cuda11_py38_g38be932f_101    rapidsai-nightly\\r\\n     cuml                      22.04.00a220405 cuda11_py38_g5feaf7b74_107    rapidsai-nightly\\r\\n     cupy                      9.6.0            py38h177b0fd_0    conda-forge\\r\\n     curl                      7.82.0               h7bff187_0    conda-forge\\r\\n     cusignal                  22.04.00a220405 py39_g8878bf7_15    rapidsai-nightly\\r\\n     cuspatial                 22.04.00a220405 py38_g7709a43_19    rapidsai-nightly\\r\\n     custreamz                 22.04.00a220405 py38_g4c84184a3f_304    rapidsai-nightly\\r\\n     cuxfilter                 22.04.00a220405 py38_gf9a106c_18    rapidsai-nightly\\r\\n     cycler                    0.11.0             pyhd8ed1ab_0    conda-forge\\r\\n     cyrus-sasl                2.1.27               h230043b_5    conda-forge\\r\\n     cytoolz                   0.11.2           py38h497a2fe_1    conda-forge\\r\\n     dask                      2022.3.0           pyhd8ed1ab_1    conda-forge\\r\\n     dask-core                 2022.3.0           pyhd8ed1ab_0    conda-forge\\r\\n     dask-cuda                 22.04.00a220405         py38_29    rapidsai-nightly\\r\\n     dask-cudf                 22.04.00a220405 cuda_11_py38_g4c84184a3f_304    rapidsai-nightly\\r\\n     dask-sql                  2022.1.1a220405  py_gab2aa5a_33    dask/label/dev\\r\\n     datashader                0.13.1a                    py_0    rapidsai-nightly\\r\\n     datashape                 0.5.4                      py_1    conda-forge\\r\\n     debugpy                   1.5.1            py38h709712a_0    conda-forge\\r\\n     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     distributed               2022.3.0           pyhd8ed1ab_0    conda-forge\\r\\n     dlpack                    0.5                  h9c3ff4c_0    conda-forge\\r\\n     entrypoints               0.4                pyhd8ed1ab_0    conda-forge\\r\\n     executing                 0.8.3              pyhd8ed1ab_0    conda-forge\\r\\n     expat                     2.4.8                h27087fc_0    conda-forge\\r\\n     faiss-proc                1.0.0                      cuda    conda-forge\\r\\n     fastapi                   0.75.1             pyhd8ed1ab_0    conda-forge\\r\\n     fastavro                  1.4.10           py38h0a891b7_0    conda-forge\\r\\n     fastrlock                 0.8              py38hfa26641_1    conda-forge\\r\\n     fiona                     1.8.20           py38hbb147eb_2    conda-forge\\r\\n     flit-core                 3.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge\\r\\n     font-ttf-inconsolata      3.000                h77eed37_0    conda-forge\\r\\n     font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge\\r\\n     font-ttf-ubuntu           0.83                 hab24e00_0    conda-forge\\r\\n     fontconfig                2.14.0               h8e229c2_0    conda-forge\\r\\n     fonts-conda-ecosystem     1                             0    conda-forge\\r\\n     fonts-conda-forge         1                             0    conda-forge\\r\\n     fonttools                 4.31.2           py38h0a891b7_0    conda-forge\\r\\n     freetype                  2.10.4               h0708190_1    conda-forge\\r\\n     freexl                    1.0.6                h7f98852_0    conda-forge\\r\\n     frozenlist                1.3.0            py38h0a891b7_1    conda-forge\\r\\n     fsspec                    2022.3.0           pyhd8ed1ab_0    conda-forge\\r\\n     gdal                      3.3.2            py38h81a01a0_3    conda-forge\\r\\n     geopandas                 0.9.0              pyhd8ed1ab_1    conda-forge\\r\\n     geopandas-base            0.9.0              pyhd8ed1ab_1    conda-forge\\r\\n     geos                      3.9.1                h9c3ff4c_2    conda-forge\\r\\n     geotiff                   1.7.0                h08e826d_2    conda-forge\\r\\n     gettext                   0.19.8.1          h73d1719_1008    conda-forge\\r\\n     gflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\n     giflib                    5.2.1                h36c2ea0_2    conda-forge\\r\\n     glog                      0.5.0                h48cff8f_0    conda-forge\\r\\n     graphite2                 1.3.13            h58526e2_1001    conda-forge\\r\\n     grpc-cpp                  1.42.0               ha1441d3_1    conda-forge\\r\\n     h11                       0.13.0             pyhd8ed1ab_0    conda-forge\\r\\n     harfbuzz                  2.9.1                h83ec7ef_1    conda-forge\\r\\n     hdf4                      4.2.15               h10796ff_3    conda-forge\\r\\n     hdf5                      1.12.1          nompi_h2386368_104    conda-forge\\r\\n     heapdict                  1.0.1                      py_0    conda-forge\\r\\n     holoviews                 1.14.6             pyhd8ed1ab_0    conda-forge\\r\\n     icu                       68.2                 h9c3ff4c_0    conda-forge\\r\\n     idna                      3.3                pyhd8ed1ab_0    conda-forge\\r\\n     imagecodecs               2021.8.26        py38hb5ce8f7_1    conda-forge\\r\\n     imageio                   2.16.1             pyhcf75d05_0    conda-forge\\r\\n     importlib-metadata        4.11.3           py38h578d9bd_1    conda-forge\\r\\n     importlib_metadata        4.11.3               hd8ed1ab_1    conda-forge\\r\\n     importlib_resources       5.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     ipykernel                 6.12.1           py38h7f3c49e_0    conda-forge\\r\\n     ipython                   8.2.0            py38h578d9bd_0    conda-forge\\r\\n     ipython_genutils          0.2.0                      py_1    conda-forge\\r\\n     ipywidgets                7.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     jbig                      2.1               h7f98852_2003    conda-forge\\r\\n     jedi                      0.18.1           py38h578d9bd_1    conda-forge\\r\\n     jinja2                    3.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     joblib                    1.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     jpeg                      9e                   h7f98852_0    conda-forge\\r\\n     jpype1                    1.3.0            py38h1fd1430_2    conda-forge\\r\\n     json-c                    0.15                 h98cffda_0    conda-forge\\r\\n     jsonschema                4.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter-server-proxy      3.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_client            7.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_core              4.9.2            py38h578d9bd_0    conda-forge\\r\\n     jupyter_server            1.16.0             pyhd8ed1ab_1    conda-forge\\r\\n     jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\\r\\n     jupyterlab_widgets        1.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     jxrlib                    1.1                  h7f98852_2    conda-forge\\r\\n     kealib                    1.4.14               h87e4c3c_3    conda-forge\\r\\n     keyutils                  1.6.1                h166bdaf_0    conda-forge\\r\\n     kiwisolver                1.4.2            py38h43d8883_1    conda-forge\\r\\n     krb5                      1.19.3               h3790be6_0    conda-forge\\r\\n     lcms2                     2.12                 hddcbb42_0    conda-forge\\r\\n     ld_impl_linux-64          2.36.1               hea4e1c9_2    conda-forge\\r\\n     lerc                      3.0                  h9c3ff4c_0    conda-forge\\r\\n     libaec                    1.0.6                h9c3ff4c_0    conda-forge\\r\\n     libblas                   3.9.0           13_linux64_openblas    conda-forge\\r\\n     libbrotlicommon           1.0.9                h166bdaf_7    conda-forge\\r\\n     libbrotlidec              1.0.9                h166bdaf_7    conda-forge\\r\\n     libbrotlienc              1.0.9                h166bdaf_7    conda-forge\\r\\n     libcblas                  3.9.0           13_linux64_openblas    conda-forge\\r\\n     libcucim                  22.04.00a220405 cuda11_g7602774_34    rapidsai-nightly\\r\\n     libcudf                   22.04.00a220405 cuda11_g4c84184a3f_304    rapidsai-nightly\\r\\n     libcudf_kafka             22.04.00a220405 g4c84184a3f_304    rapidsai-nightly\\r\\n     libcugraph                22.04.00a220405 cuda11_g38be932f_101    rapidsai-nightly\\r\\n     libcugraph_etl            22.04.00a220405 cuda11_g38be932f_101    rapidsai-nightly\\r\\n     libcugraphops             22.04.00a220405 cuda11_ga9f323f_32    rapidsai-nightly\\r\\n     libcuml                   22.04.00a220405 cuda11_g5feaf7b74_107    rapidsai-nightly\\r\\n     libcumlprims              22.04.00a220324 cuda11_g99e8d8f_15    rapidsai-nightly\\r\\n     libcurl                   7.82.0               h7bff187_0    conda-forge\\r\\n     libcusolver               11.3.4.124           h33c3c4e_0    nvidia\\r\\n     libcuspatial              22.04.00a220405 cuda11_g7709a43_19    rapidsai-nightly\\r\\n     libdap4                   3.20.6               hd7c4107_2    conda-forge\\r\\n     libdeflate                1.8                  h7f98852_0    conda-forge\\r\\n     libedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\n     libev                     4.33                 h516909a_1    conda-forge\\r\\n     libevent                  2.1.10               h9b69904_4    conda-forge\\r\\n     libfaiss                  1.7.0           cuda112h5bea7ad_8_cuda    conda-forge\\r\\n     libffi                    3.4.2                h7f98852_5    conda-forge\\r\\n     libgcc-ng                 11.2.0              h1d223b6_14    conda-forge\\r\\n     libgcrypt                 1.10.0               h7f98852_0    conda-forge\\r\\n     libgdal                   3.3.2                h6acdded_3    conda-forge\\r\\n     libgfortran-ng            11.2.0              h69a702a_14    conda-forge\\r\\n     libgfortran5              11.2.0              h5c6108e_14    conda-forge\\r\\n     libglib                   2.70.2               h174f98d_4    conda-forge\\r\\n     libgomp                   11.2.0              h1d223b6_14    conda-forge\\r\\n     libgpg-error              1.44                 h9eb791d_0    conda-forge\\r\\n     libgsasl                  1.10.0               h5b4c23d_0    conda-forge\\r\\n     libhwloc                  2.3.0                h5e5b7d1_1    conda-forge\\r\\n     libiconv                  1.16                 h516909a_0    conda-forge\\r\\n     libkml                    1.3.0             h238a007_1014    conda-forge\\r\\n     liblapack                 3.9.0           13_linux64_openblas    conda-forge\\r\\n     libllvm11                 11.1.0               hf817b99_3    conda-forge\\r\\n     libnetcdf                 4.8.1           nompi_hb3fd0d9_101    conda-forge\\r\\n     libnghttp2                1.47.0               h727a467_0    conda-forge\\r\\n     libnsl                    2.0.0                h7f98852_0    conda-forge\\r\\n     libntlm                   1.4               h7f98852_1002    conda-forge\\r\\n     libopenblas               0.3.18          pthreads_h8fe5266_0    conda-forge\\r\\n     libpng                    1.6.37               h21135ba_2    conda-forge\\r\\n     libpq                     13.5                 hd57d9b9_1    conda-forge\\r\\n     libprotobuf               3.19.4               h780b84a_0    conda-forge\\r\\n     libraft-distance          22.04.00a220405 cuda11_gc509483_112    rapidsai-nightly\\r\\n     libraft-headers           22.04.00a220405 cuda11_gc509483_112    rapidsai-nightly\\r\\n     libraft-nn                22.04.00a220405 cuda11_gc509483_112    rapidsai-nightly\\r\\n     librdkafka                1.7.0                hc49e61c_1    conda-forge\\r\\n     librmm                    22.04.00a220405 cuda11_g1420689_48    rapidsai-nightly\\r\\n     librttopo                 1.1.0                h1185371_6    conda-forge\\r\\n     libsodium                 1.0.18               h36c2ea0_1    conda-forge\\r\\n     libspatialindex           1.9.3                h9c3ff4c_4    conda-forge\\r\\n     libspatialite             5.0.1                h5cf074c_8    conda-forge\\r\\n     libssh2                   1.10.0               ha56f1ee_2    conda-forge\\r\\n     libstdcxx-ng              11.2.0              he4da1e4_14    conda-forge\\r\\n     libthrift                 0.15.0               he6d91bd_1    conda-forge\\r\\n     libtiff                   4.3.0                h6f004c6_2    conda-forge\\r\\n     libutf8proc               2.7.0                h7f98852_0    conda-forge\\r\\n     libuuid                   2.32.1            h7f98852_1000    conda-forge\\r\\n     libuv                     1.43.0               h7f98852_0    conda-forge\\r\\n     libwebp                   1.2.2                h3452ae3_0    conda-forge\\r\\n     libwebp-base              1.2.2                h7f98852_1    conda-forge\\r\\n     libxcb                    1.13              h7f98852_1004    conda-forge\\r\\n     libxgboost                1.5.2dev.rapidsai22.04       cuda_11_0    rapidsai-nightly\\r\\n     libxml2                   2.9.12               h72842e0_0    conda-forge\\r\\n     libzip                    1.8.0                h4de3113_1    conda-forge\\r\\n     libzlib                   1.2.11            h166bdaf_1014    conda-forge\\r\\n     libzopfli                 1.0.3                h9c3ff4c_0    conda-forge\\r\\n     llvmlite                  0.38.0           py38h38d86a4_1    conda-forge\\r\\n     locket                    0.2.0                      py_2    conda-forge\\r\\n     lz4                       4.0.0            py38h1bf946c_1    conda-forge\\r\\n     lz4-c                     1.9.3                h9c3ff4c_1    conda-forge\\r\\n     mapclassify               2.4.3              pyhd8ed1ab_0    conda-forge\\r\\n     markdown                  3.3.6              pyhd8ed1ab_0    conda-forge\\r\\n     markupsafe                2.1.1            py38h0a891b7_1    conda-forge\\r\\n     matplotlib-base           3.5.1            py38hf4fb855_0    conda-forge\\r\\n     matplotlib-inline         0.1.3              pyhd8ed1ab_0    conda-forge\\r\\n     mistune                   0.8.4           py38h497a2fe_1005    conda-forge\\r\\n     msgpack-python            1.0.3            py38h43d8883_1    conda-forge\\r\\n     multidict                 6.0.2            py38h0a891b7_1    conda-forge\\r\\n     multipledispatch          0.6.0                      py_0    conda-forge\\r\\n     munch                     2.5.0                      py_0    conda-forge\\r\\n     munkres                   1.1.4              pyh9f0ad1d_0    conda-forge\\r\\n     nbclient                  0.5.13             pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert                 6.4.5              pyhd8ed1ab_2    conda-forge\\r\\n     nbconvert-core            6.4.5              pyhd8ed1ab_2    conda-forge\\r\\n     nbconvert-pandoc          6.4.5              pyhd8ed1ab_2    conda-forge\\r\\n     nbformat                  5.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     nccl                      2.12.7.1             h0800d71_0    conda-forge\\r\\n     ncurses                   6.3                  h9c3ff4c_0    conda-forge\\r\\n     nest-asyncio              1.5.5              pyhd8ed1ab_0    conda-forge\\r\\n     networkx                  2.6.3              pyhd8ed1ab_1    conda-forge\\r\\n     nodejs                    14.18.3              h92b4a50_1    conda-forge\\r\\n     notebook                  6.4.10             pyha770c72_0    conda-forge\\r\\n     nspr                      4.32                 h9c3ff4c_1    conda-forge\\r\\n     nss                       3.77                 h2350873_0    conda-forge\\r\\n     numba                     0.55.1           py38h4bf6c61_0    conda-forge\\r\\n     numpy                     1.21.5           py38h87f13fb_0    conda-forge\\r\\n     nvtx                      0.2.3            py38h497a2fe_1    conda-forge\\r\\n     openjdk                   11.0.9.1             h5cc2fde_1    conda-forge\\r\\n     openjpeg                  2.4.0                hb52868f_1    conda-forge\\r\\n     openssl                   1.1.1n               h166bdaf_0    conda-forge\\r\\n     orc                       1.7.1                h1be678f_1    conda-forge\\r\\n     packaging                 21.3               pyhd8ed1ab_0    conda-forge\\r\\n     pandas                    1.3.5            py38h43a58ef_0    conda-forge\\r\\n     pandoc                    2.17.1.1             ha770c72_0    conda-forge\\r\\n     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     panel                     0.12.7             pyhd8ed1ab_0    conda-forge\\r\\n     param                     1.12.1             pyh6c4a22f_0    conda-forge\\r\\n     parquet-cpp               1.5.1                         2    conda-forge\\r\\n     parso                     0.8.3              pyhd8ed1ab_0    conda-forge\\r\\n     partd                     1.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     pcre                      8.45                 h9c3ff4c_0    conda-forge\\r\\n     pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\\r\\n     pickleshare               0.7.5                   py_1003    conda-forge\\r\\n     pillow                    9.1.0            py38h0ee0e06_0    conda-forge\\r\\n     pip                       22.0.4             pyhd8ed1ab_0    conda-forge\\r\\n     pixman                    0.40.0               h36c2ea0_0    conda-forge\\r\\n     poppler                   21.09.0              ha39eefc_3    conda-forge\\r\\n     poppler-data              0.4.11               hd8ed1ab_0    conda-forge\\r\\n     postgresql                13.5                 h2510834_1    conda-forge\\r\\n     proj                      8.1.0                h277dcde_1    conda-forge\\r\\n     prometheus_client         0.13.1             pyhd8ed1ab_0    conda-forge\\r\\n     prompt-toolkit            3.0.29             pyha770c72_0    conda-forge\\r\\n     protobuf                  3.19.4           py38h709712a_0    conda-forge\\r\\n     psutil                    5.9.0            py38h0a891b7_1    conda-forge\\r\\n     pthread-stubs             0.4               h36c2ea0_1001    conda-forge\\r\\n     ptxcompiler               0.2.0            py38h98f4b32_0    rapidsai-nightly\\r\\n     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\\r\\n     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     py-xgboost                1.5.2dev.rapidsai22.04  cuda_11_py38_0    rapidsai-nightly\\r\\n     pyarrow                   6.0.1           py38ha746e9d_5_cuda    conda-forge\\r\\n     pycparser                 2.21               pyhd8ed1ab_0    conda-forge\\r\\n     pyct                      0.4.6                      py_0    conda-forge\\r\\n     pyct-core                 0.4.6                      py_0    conda-forge\\r\\n     pydantic                  1.9.0            py38h0a891b7_1    conda-forge\\r\\n     pydeck                    0.5.0              pyh9f0ad1d_0    conda-forge\\r\\n     pyee                      8.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     pygments                  2.11.2             pyhd8ed1ab_0    conda-forge\\r\\n     pylibcugraph              22.04.00a220405 cuda11_py38_g38be932f_101    rapidsai-nightly\\r\\n     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyopenssl                 22.0.0             pyhd8ed1ab_0    conda-forge\\r\\n     pyparsing                 3.0.7              pyhd8ed1ab_0    conda-forge\\r\\n     pyppeteer                 1.0.2              pyhd8ed1ab_0    conda-forge\\r\\n     pyproj                    3.1.0            py38h3701b11_4    conda-forge\\r\\n     pyraft                    22.04.00a220405 cuda11_py38_gc509483_112    rapidsai-nightly\\r\\n     pyrsistent                0.18.1           py38h0a891b7_1    conda-forge\\r\\n     pysocks                   1.7.1            py38h578d9bd_5    conda-forge\\r\\n     python                    3.8.13          h582c2e5_0_cpython    conda-forge\\r\\n     python-confluent-kafka    1.7.0            py38h497a2fe_2    conda-forge\\r\\n     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\\r\\n     python-fastjsonschema     2.15.3             pyhd8ed1ab_0    conda-forge\\r\\n     python-tzdata             2022.1             pyhd8ed1ab_0    conda-forge\\r\\n     python_abi                3.8                      2_cp38    conda-forge\\r\\n     pytz                      2022.1             pyhd8ed1ab_0    conda-forge\\r\\n     pytz-deprecation-shim     0.1.0.post0      py38h578d9bd_1    conda-forge\\r\\n     pyviz_comms               2.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     pywavelets                1.3.0            py38h3ec907f_0    conda-forge\\r\\n     pyyaml                    6.0              py38h0a891b7_4    conda-forge\\r\\n     pyzmq                     22.3.0           py38hfc09fa9_2    conda-forge\\r\\n     rapids                    22.04.00a220405 cuda11_py38_g5d1fba5_121    rapidsai-nightly\\r\\n     rapids-xgboost            22.04.00a220405 cuda11_py38_g5d1fba5_121    rapidsai-nightly\\r\\n     re2                       2021.11.01           h9c3ff4c_0    conda-forge\\r\\n     readline                  8.1                  h46c0cb4_0    conda-forge\\r\\n     requests                  2.27.1             pyhd8ed1ab_0    conda-forge\\r\\n     rmm                       22.04.00a220405 cuda11_py38_g1420689_48    rapidsai-nightly\\r\\n     rtree                     0.9.7            py38h02d302b_3    conda-forge\\r\\n     s2n                       1.3.0                h9b69904_0    conda-forge\\r\\n     scikit-image              0.19.2           py38h43a58ef_0    conda-forge\\r\\n     scikit-learn              1.0.2            py38h1561384_0    conda-forge\\r\\n     scipy                     1.8.0            py38h56a6a73_1    conda-forge\\r\\n     send2trash                1.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     setuptools                59.8.0           py38h578d9bd_1    conda-forge\\r\\n     shapely                   1.8.0            py38hb7fe4a8_0    conda-forge\\r\\n     simpervisor               0.4                pyhd8ed1ab_0    conda-forge\\r\\n     six                       1.16.0             pyh6c4a22f_0    conda-forge\\r\\n     snappy                    1.1.8                he1b5a44_3    conda-forge\\r\\n     sniffio                   1.2.0            py38h578d9bd_3    conda-forge\\r\\n     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     soupsieve                 2.3.1              pyhd8ed1ab_0    conda-forge\\r\\n     spdlog                    1.8.5                h4bd325d_1    conda-forge\\r\\n     sqlite                    3.37.1               h4ff8645_0    conda-forge\\r\\n     stack_data                0.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     starlette                 0.17.1             pyhd8ed1ab_0    conda-forge\\r\\n     streamz                   0.6.3              pyh6c4a22f_0    conda-forge\\r\\n     tabulate                  0.8.9              pyhd8ed1ab_0    conda-forge\\r\\n     tblib                     1.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     terminado                 0.13.3           py38h578d9bd_1    conda-forge\\r\\n     testpath                  0.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     threadpoolctl             3.1.0              pyh8a188c0_0    conda-forge\\r\\n     tifffile                  2021.11.2          pyhd8ed1ab_0    conda-forge\\r\\n     tiledb                    2.3.4                he87e0bf_0    conda-forge\\r\\n     tk                        8.6.12               h27826a3_0    conda-forge\\r\\n     toolz                     0.11.2             pyhd8ed1ab_0    conda-forge\\r\\n     tornado                   6.1              py38h0a891b7_3    conda-forge\\r\\n     tqdm                      4.64.0             pyhd8ed1ab_0    conda-forge\\r\\n     traitlets                 5.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     treelite                  2.3.0            py38hdd725b4_0    conda-forge\\r\\n     treelite-runtime          2.3.0                    pypi_0    pypi\\r\\n     typing-extensions         4.1.1                hd8ed1ab_0    conda-forge\\r\\n     typing_extensions         4.1.1              pyha770c72_0    conda-forge\\r\\n     tzcode                    2022a                h166bdaf_0    conda-forge\\r\\n     tzdata                    2022a                h191b570_0    conda-forge\\r\\n     tzlocal                   4.2              py38h578d9bd_0    conda-forge\\r\\n     ucx                       1.12.0+gd367332      cuda11.2_0    rapidsai-nightly\\r\\n     ucx-proc                  1.0.0                       gpu    rapidsai-nightly\\r\\n     ucx-py                    0.25.00a220405  py38_gd367332_13    rapidsai-nightly\\r\\n     unicodedata2              14.0.0           py38h0a891b7_1    conda-forge\\r\\n     urllib3                   1.26.9             pyhd8ed1ab_0    conda-forge\\r\\n     uvicorn                   0.17.6           py38h578d9bd_0    conda-forge\\r\\n     wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\\r\\n     webencodings              0.5.1                      py_1    conda-forge\\r\\n     websocket-client          1.3.2              pyhd8ed1ab_0    conda-forge\\r\\n     websockets                10.2             py38h0a891b7_0    conda-forge\\r\\n     wheel                     0.37.1             pyhd8ed1ab_0    conda-forge\\r\\n     widgetsnbextension        3.6.0            py38h578d9bd_0    conda-forge\\r\\n     xarray                    2022.3.0           pyhd8ed1ab_0    conda-forge\\r\\n     xerces-c                  3.2.3                h9d8b166_3    conda-forge\\r\\n     xgboost                   1.5.2dev.rapidsai22.04  cuda_11_py38_0    rapidsai-nightly\\r\\n     xorg-fixesproto           5.0               h7f98852_1002    conda-forge\\r\\n     xorg-inputproto           2.3.2             h7f98852_1002    conda-forge\\r\\n     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge\\r\\n     xorg-libice               1.0.10               h7f98852_0    conda-forge\\r\\n     xorg-libsm                1.2.3             hd9c2040_1000    conda-forge\\r\\n     xorg-libx11               1.7.2                h7f98852_0    conda-forge\\r\\n     xorg-libxau               1.0.9                h7f98852_0    conda-forge\\r\\n     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\\r\\n     xorg-libxext              1.3.4                h7f98852_1    conda-forge\\r\\n     xorg-libxfixes            5.0.3             h7f98852_1004    conda-forge\\r\\n     xorg-libxi                1.7.10               h7f98852_0    conda-forge\\r\\n     xorg-libxrender           0.9.10            h7f98852_1003    conda-forge\\r\\n     xorg-libxtst              1.2.3             h7f98852_1002    conda-forge\\r\\n     xorg-recordproto          1.14.2            h7f98852_1002    conda-forge\\r\\n     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge\\r\\n     xorg-xextproto            7.3.0             h7f98852_1002    conda-forge\\r\\n     xorg-xproto               7.0.31            h7f98852_1007    conda-forge\\r\\n     xz                        5.2.5                h516909a_1    conda-forge\\r\\n     yaml                      0.2.5                h7f98852_2    conda-forge\\r\\n     yarl                      1.7.2            py38h0a891b7_2    conda-forge\\r\\n     zeromq                    4.3.4                h9c3ff4c_1    conda-forge\\r\\n     zfp                       0.5.5                h9c3ff4c_8    conda-forge\\r\\n     zict                      2.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     zipp                      3.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     zlib                      1.2.11            h166bdaf_1014    conda-forge\\r\\n     zstd                      1.5.2                ha95c52a_0    conda-forge\\r\\n     \\r\\n</pre></details>\\r\\n\\r\\n**Additional context**\\r\\nSee https://github.com/NVIDIA/spark-rapids/issues/5035\\ncreatedAt: 2022-04-05T20:54:06Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Andy Grove\\ncompany: @Apple', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 86}),\n",
       " Document(page_content=': 271\\ntitle: [FEA] Define unary operations like `__neg__`, `__pos__`, `__abs__` and `__invert__` for `Column`.\\nbody: Currently, invoking Python\\'s builtin unary operators on columns raises:\\r\\n\\r\\n```python\\r\\n>>> s = cudf.Series([1, 2, 3])\\r\\n>>> -s._column  # TypeError\\r\\n```\\r\\n\\r\\nThis came up in https://github.com/rapidsai/cudf/pull/10564.\\r\\n\\r\\nA workaround is to do for example, `s._column.unary_operator(\"abs\")` or `0 - s._column`, but it would be nice to do this in a more Pythonic way.\\ncreatedAt: 2022-04-06T20:23:25Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 87}),\n",
       " Document(page_content=\": 272\\ntitle: [FEA] Support for approx_count_distinct\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nI would like to be able to implement a GPU version of Spark's `approx_count_distinct` function, which uses the [HyperLogLog++](https://en.wikipedia.org/wiki/HyperLogLog) cardinality estimation algorithm. \\r\\n\\r\\ncuDF does not appear to provide any features today that would allow me to do this.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nI would like cuDF to implement this capability and expose an API that is likely similar to `approx_percentile` in that there would be methods both for computing and merging the underlying data structure, whether that is based on HyperLogLog++ or some other algorithm.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nNone\\r\\n\\r\\n**Additional context**\\r\\nNone\\ncreatedAt: 2022-04-13T18:16:08Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Andy Grove\\ncompany: @Apple\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 88}),\n",
       " Document(page_content=\": 277\\ntitle: [FEA] Support cudf.DataFrame.corrwith\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nDeveloper request to use 'corrwith' in cudf.DataFrame and it is the basic block for their business. \\r\\n\\r\\n**Describe the solution you'd like**\\r\\nSimilar in pandas.DataFrame.corrwith(https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html#pandas.DataFrame.corrwith), understand its realization in pandas and try to make it happen in cudf.\\ncreatedAt: 2022-04-28T13:53:32Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 89}),\n",
       " Document(page_content=': 280\\ntitle: [ENH]: serialization schema cleanup\\nbody: Followup from #10784. Hyphens and underscores are used inconsistently when separating names in metadata keys in `serialize`; go through and standardise on one choice (hyphens seem more popular).\\ncreatedAt: 2022-05-05T16:45:28Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 90}),\n",
       " Document(page_content=': 282\\ntitle: [BUG] can\\'t set groupby transform output to a new column\\nbody: **Describe the bug**\\r\\nI try to use groupby count transform for frequency encoding of a column. I get an error when I do it:\\r\\n\\r\\n> ValueError: Cannot align indices with non-unique values\\r\\n\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n`df[\"a_freq\"] = df.groupby([\"a\"])[\"b\"].transform(\"count\")\\r\\n`\\r\\nThis throws an error.\\r\\nSetting the column in advance with zero or using values work as workarounds.\\r\\n```\\r\\ndf[\"a_freq\"] = 0\\r\\ndf[\"a_freq\"] = df.groupby([\"a\"])[\"b\"].transform(\"count\")\\r\\n```\\r\\n`df[\"a_freq\"] = df.groupby([\"a\"])[\"b\"].transform(\"count\").values`\\r\\n\\r\\n**Expected behavior**\\r\\nI expect it to work as it works in pandas.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: local\\r\\n - Method of cuDF install: conda\\r\\n\\r\\n**Environment details**\\r\\nconda environment with RAPIDS 22.02\\ncreatedAt: 2022-05-11T10:01:53Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ahmet Erdem\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 91}),\n",
       " Document(page_content=': 285\\ntitle: [ENH] Support more input data layouts in `cudf.from_dlpack`\\nbody: Related to #10754, the current implementation of `from_dlpack` requires unit-stride fortran order, and produces appropriate error messages in the unsupported cases\\r\\n\\r\\nConsider\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\nimport cupy\\r\\na = cupy.arange(10)\\r\\nb = a[::2]\\r\\nc = cudf.from_dlpack(b.__dlpack__())\\r\\n=> RuntimeError: from_dlpack of 1D DLTensor only for unit-stride data\\r\\nb = cupy.broadcast_to(a[1], (10,)) # b is stride-0\\r\\n=> RuntimeError: from_dlpack of 1D DLTensor only for unit-stride data\\r\\n\\r\\na = cupy.arange(12).reshape(3, 4).copy(order=\"F\")\\r\\nb = a[::2, :]\\r\\nc = cudf.from_dlpack(b.__dlpack__())\\r\\n=> RuntimeError: from_dlpack of 2D DLTensor only for column-major unit-stride data\\r\\n```\\r\\n\\r\\nSince `from_dlpack` copies in all cases right now, I think that things can be handled like so:\\r\\n\\r\\n1. Non-fortran-order: useful error\\r\\n2. unit-stride: current `cudaMemcpyAsync` one column at a time\\r\\n3. fastest-dimension is stride-0 (broadcasted arrays): `std::fill` for the 1D case, just getting the strides right for the 2D case\\r\\n4. fastest-dimension is stride-N (sliced arrays): `cudaMemcpy2DAsync` with appropriate choices of pitch and stride for the source array\\r\\n\\r\\nHowever, I\\'m not really sure of the performance implications of these choices, and if the current approach of producing an error and requiring that the caller copy to contiguous fortran-order first before calling `from_dlpack` is not better. For example, for case 4 is it faster to copy to a contiguous buffer first rather than copying column by column?\\ncreatedAt: 2022-05-13T13:56:20Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 92}),\n",
       " Document(page_content=\": 289\\ntitle: [FEA] Don't copy data in to/from_dlpack when unnecessary\\nbody: To `.to_dlpack()` and `.from_dlpack()` methods in cuDF currently always perform a copy to/from the DLTensor. This is reasonable for DataFrames, as the columns of a dataframe in cuDF are not contiguous in memory, nor are they always of the same data type.\\r\\n\\r\\nFor a Series however, I believe we should be able to zero-copy to and from DLPack. That is not the case today:\\r\\n\\r\\n```python\\r\\n>>> import cudf\\r\\n>>> import cupy as cp\\r\\n>>> s = cudf.Series([1, 2, 3])\\r\\n>>> arr = cp.from_dlpack(s.to_dlpack())\\r\\n>>> s._column.data.ptr\\r\\n139742968545280\\r\\n>>> arr.data.ptr\\r\\n139742968545792\\r\\n```\\ncreatedAt: 2022-05-17T13:03:27Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 93}),\n",
       " Document(page_content=\": 294\\ntitle: [FEA]Support for list columns\\nbody: **PROBLEM DESCRIPTION**\\r\\n\\r\\ncudF doesn't support applymap or applying using defined functions to columns containing list as cell values. Also, cudf can not save to_csv when dataframe has list columns. Both of these are supported in Pandas. However, switching back and forth between pandas and cudf is time-consuming for huge amount of datas, and it will be great if we can bring more support for list column dataframe\\r\\n\\r\\n**SOLUTION**\\r\\nI want to apply user defined functions to cudF columns with lists. The functions are not simple function with one arguement but more complex operation. Moreover I want to save cudf dataframe to csv or hdf5 without switching to pandas for the same type of dataframe.\\r\\n\\r\\n**Alternatives**\\r\\nOne alternative is to switch to pandas which is not ideal as I want to do everything in GPU. Another alternate solution I tried is by loading the list columns into numpy array and then apply the user defined function and then write them back to the dataframe which is again time-consuming. It will be way easier if I can just apply the function to the column directly.\\ncreatedAt: 2022-05-31T12:20:12Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Arpan Das\\ncompany: The École polytechnique fédérale de Lausanne\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 94}),\n",
       " Document(page_content=': 301\\ntitle: [BUG] Using `.iloc[]` to set a single value in a Series does not do so in-place\\nbody: ```python\\r\\n>>> import  cudf\\r\\n>>> s = cudf.Series([1, 2, 3])\\r\\n>>> s2 = s.iloc[:]  # s2 is a view into s\\r\\n>>> s.iloc[0] = -1  # this line does not behave as expected\\r\\n>>> s\\r\\n0   -1\\r\\n1    2\\r\\n2    3\\r\\ndtype: int64\\r\\n>>> s2\\r\\n0    1\\r\\n1    2\\r\\n2    3\\r\\ndtype: int64\\r\\n```\\r\\n\\r\\nContrast with Pandas:\\r\\n\\r\\n```python\\r\\n>>> import pandas as pd\\r\\n>>> s = pd.Series([1, 2, 3])\\r\\n>>> s2 = s.iloc[:]  # s2 is a view into s\\r\\n>>> s.iloc[0] = -1\\r\\n>>> s\\r\\n0   -1\\r\\n1    2\\r\\n2    3\\r\\ndtype: int64\\r\\n>>> s2\\r\\n0   -1\\r\\n1    2\\r\\n2    3\\r\\ndtype: int64\\r\\n```\\r\\n\\r\\nNote that setting  by slice works as expected:\\r\\n\\r\\n```python\\r\\n>>> import cudf\\r\\n>>> s = cudf.Series([1, 2, 3])\\r\\n>>> s2 = s.iloc[:]\\r\\n>>> s.iloc[0:1] = -1\\r\\n>>> s\\r\\n0   -1\\r\\n1    2\\r\\n2    3\\r\\ndtype: int64\\r\\n>>> s2\\r\\n0   -1\\r\\n1    2\\r\\n2    3\\r\\ndtype: int64\\r\\n```\\ncreatedAt: 2022-06-08T20:02:53Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 95}),\n",
       " Document(page_content=\": 304\\ntitle: [BUG] libcudf tests warn when linking when building in a conda environment without conda compiler metapackages\\nbody: When building libcudf and tests in a conda environment without having the compiler metapackages installed (`c-compiler`, `cxx-compiler`, etc.), it produces warnings about not finding `libz.so.1` needed by `libcudf.so`:\\r\\n```\\r\\n[406/674] Linking CXX executable gtests/COLUMN_TEST\\r\\n/home/keith/miniconda3/envs/dev/bin/../lib/gcc/x86_64-conda-linux-gnu/10.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: warning: libz.so.1, needed by libcudf.so, not found (try using -rpath or -rpath-link)\\r\\n```\\r\\n\\r\\nI believe this is due to both the `conda_env` target (https://github.com/rapidsai/cudf/blob/branch-22.08/cpp/CMakeLists.txt#L628) and the zlib target (https://github.com/rapidsai/cudf/blob/branch-22.08/cpp/CMakeLists.txt#L622) both being private links for the libcudf target. zlib is just one example of this, but this could happen for any other private target of libcudf that comes from the conda environment.\\r\\n\\r\\nThis isn't a problem for the compiler metapackages because they set a slew of compiler CLI flags, notably an `rpath-link` flag into the conda environment. I do not use these metapackages because those CLI flags set will point into the conda environment before pointing into the local build directory, which makes having both an install and a working directory a pain.\\r\\n\\r\\nI believe the fix is either changing the `conda_env` link to be a `PUBLIC` link of the libcudf target, or adding a `conda_env` link to the tests.\\ncreatedAt: 2022-06-17T19:32:26Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Keith Kraus\\ncompany: @VoltronData\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 96}),\n",
       " Document(page_content=\": 308\\ntitle: [BUG] cudf.DataFrame.all error on pivot-generated data frame\\nbody: **Describe the bug**\\r\\nGetting an `UnboundLocalError: local variable 'index_class_type' referenced before assignment` when calling the cudf.DataFrame.all function. The data frame was created from comparing two data frames with the same columns and index attributes, one of which is generated from a call to cudf.DataFrame.pivot.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```Python\\r\\nimport cupy\\r\\nimport cudf\\r\\n\\r\\nx = cupy.array([[1,2,3],[4,2,5]])\\r\\ndf = cudf.DataFrame(x)\\r\\npivot_table = df.pivot(index=[0], columns=[1], values=[2])\\r\\ndf2 = cudf.DataFrame(cupy.broadcast_to(pivot_table.iloc[:,0].values[:,None], pivot_table.shape), index=pivot_table.index, columns=pivot_table.columns)\\r\\n\\r\\nprint((df2 == pivot_table).all())\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nExpected output:\\r\\n```\\r\\n2    True\\r\\ndtype: bool\\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Docker\\r\\n - Method of cuDF install: Docker\\r\\n   - `docker run -it --rm --gpus all --ipc=host --network=host -v .`\\r\\n\\r\\n**Environment details**\\r\\nVersion: 22.4.0a0+306.g0cb75a4913\\r\\n\\r\\n**Additional context**\\r\\nThis snippet works as expected in cuDF 22.2.0 but does not work on cuDF 22.4.0.\\ncreatedAt: 2022-06-24T20:37:57Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Alex Xu\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 97}),\n",
       " Document(page_content=': 309\\ntitle: [BUG] Timestamps displayed incorrectly due to Pandas not supporting >ns resolution\\nbody: The most minimal reproducer of the type of issues I\\'m seeing are:\\r\\n\\r\\n```python\\r\\nIn [13]: cudf.Series([\"2499-11-01 01:00:00\"], dtype=\"datetime64[s]\")\\r\\nOut[13]:\\r\\n0   1915-04-14 01:25:26.290448384\\r\\ndtype: datetime64[s]\\r\\n\\r\\n# indexing into a single element seems to work\\r\\nIn [14]: cudf.Series([\"2499-11-01 01:00:00\"], dtype=\"datetime64[s]\").iloc[0]\\r\\nOut[14]: numpy.datetime64(\\'2499-11-01T01:00:00\\')\\r\\n```\\r\\n\\r\\nThis is  most likely due to Pandas not being able to represent the timestamp accurately overflow occurring somewhere along the way.\\r\\n\\r\\nPerhaps we should not rely on conversion to Pandas for displaying timestamps?\\ncreatedAt: 2022-06-27T19:15:24Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 98}),\n",
       " Document(page_content=': 313\\ntitle: [BUG] Dask_cudf merge function returns too few rows\\nbody: **Describe the bug**\\r\\nThe dask_cudf merge functions returns too few rows when both the dtype of the column being merged on is mismatched (eg: `int64` on the left and `int32` on the right) _and_ when `npartitions>1`\\r\\n \\r\\n**Steps/Code to reproduce bug**\\r\\nHere\\'s a reproducer showing that when the dtype is mismatched the number of rows returned is dependent on the number of partitions in the dataframes being merged:\\r\\n```python\\r\\nimport cupy as cp\\r\\nimport cudf\\r\\nimport dask_cudf\\r\\n\\r\\ndfa = cudf.DataFrame({\"a\":cp.random.randint(0,100,100000), \"b\":cp.random.normal(size=100000)})\\r\\ndfb = cudf.DataFrame({\"a\":cp.random.randint(0,100,100000), \"c\":cp.random.normal(size=100000)})\\r\\n\\r\\ndfa[\"a\"] = dfa[\"a\"].astype(\"int32\")\\r\\ndfb[\"a\"] = dfb[\"a\"].astype(\"int64\")\\r\\n\\r\\nddfa = dask_cudf.from_cudf(dfa, npartitions=4)\\r\\nddfb = dask_cudf.from_cudf(dfb, npartitions=4)\\r\\nprint(\"npartitions:\")\\r\\nprint(\"left: {}\".format(ddfa.npartitions))\\r\\nprint(\"right: {}\".format(ddfb.npartitions))\\r\\n\\r\\nprint(\"Number of rows in merge result:\")\\r\\nprint(len(ddfa.merge(ddfb, how=\"inner\", on=\"a\")))\\r\\nprint(\"*\"*30)\\r\\n\\r\\nddfa = ddfa.repartition(npartitions=3)\\r\\nddfb = ddfb.repartition(npartitions=3)\\r\\nprint(\"npartitions:\")\\r\\nprint(\"left: {}\".format(ddfa.npartitions))\\r\\nprint(\"right: {}\".format(ddfb.npartitions))\\r\\n\\r\\nprint(\"Number of rows in merge result:\")\\r\\nprint(len(ddfa.merge(ddfb, how=\"inner\", on=\"a\")))\\r\\nprint(\"*\"*30)\\r\\n\\r\\nddfa = ddfa.repartition(npartitions=2)\\r\\nddfb = ddfb.repartition(npartitions=2)\\r\\nprint(\"npartitions:\")\\r\\nprint(\"left: {}\".format(ddfa.npartitions))\\r\\nprint(\"right: {}\".format(ddfb.npartitions))\\r\\n\\r\\nprint(\"Number of rows in merge result:\")\\r\\nprint(len(ddfa.merge(ddfb, how=\"inner\", on=\"a\")))\\r\\nprint(\"*\"*30)\\r\\n\\r\\nddfa = ddfa.repartition(npartitions=1)\\r\\nddfb = ddfb.repartition(npartitions=1)\\r\\nprint(\"npartitions:\")\\r\\nprint(\"left: {}\".format(ddfa.npartitions))\\r\\nprint(\"right: {}\".format(ddfb.npartitions))\\r\\n\\r\\nprint(\"Number of rows in merge result:\")\\r\\nprint(len(ddfa.merge(ddfb, how=\"inner\", on=\"a\")))\\r\\nprint(\"*\"*30)\\r\\n```\\r\\nThis returns:\\r\\n```\\r\\nnpartitions:\\r\\nleft: 4\\r\\nright: 4\\r\\nNumber of rows in merge result:\\r\\n16083716\\r\\n******************************\\r\\nnpartitions:\\r\\nleft: 3\\r\\nright: 3\\r\\nNumber of rows in merge result:\\r\\n35342145\\r\\n******************************\\r\\nnpartitions:\\r\\nleft: 2\\r\\nright: 2\\r\\nNumber of rows in merge result:\\r\\n46959990\\r\\n******************************\\r\\nnpartitions:\\r\\nleft: 1\\r\\nright: 1\\r\\nNumber of rows in merge result:\\r\\n100006687\\r\\n******************************\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nIf we perform the same operation with just cudf we can see the expected result:\\r\\n```python\\r\\nimport cupy as cp\\r\\nimport cudf\\r\\n\\r\\ndfa = cudf.DataFrame({\"a\":cp.random.randint(0,100,100000), \"b\":cp.random.normal(size=100000)})\\r\\ndfb = cudf.DataFrame({\"a\":cp.random.randint(0,100,100000), \"c\":cp.random.normal(size=100000)})\\r\\n\\r\\ndfa[\"a\"] = dfa[\"a\"].astype(\"int32\")\\r\\ndfb[\"a\"] = dfb[\"a\"].astype(\"int64\")\\r\\n\\r\\nprint(len(ddfa.merge(ddfb, how=\"inner\", on=\"a\")))\\r\\n```\\r\\nwhich returns:\\r\\n```\\r\\n100006687\\r\\n```\\r\\nwhich is the same as the dask_cudf version when `npartitions=1`\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Bare-metal\\r\\n - Method of cuDF install: conda\\r\\n\\r\\n\\r\\n**Environment details**\\r\\n```\\r\\ncudf                      22.08.00a220629 cuda_11_py38_gff63c0a745_173    rapidsai-nightly\\r\\ndask-cudf                 22.08.00a220629 cuda_11_py38_gff63c0a745_173    rapidsai-nightly\\r\\nlibcudf                   22.08.00a220629 cuda11_gff63c0a745_173    rapidsai-nightly\\r\\ndask                      2022.6.1           pyhd8ed1ab_0    conda-forge\\r\\ndask-core                 2022.6.1           pyhd8ed1ab_0    conda-forge\\r\\ndask-cuda                 22.08.00a220630         py38_21    rapidsai-nightly\\r\\ndistributed               2022.6.1           pyhd8ed1ab_0    conda-forge\\r\\n```\\r\\n\\r\\n**Note**\\r\\nThe same thing occurs when `how={\"left\", \"right\", \"outer\"}`\\ncreatedAt: 2022-07-01T17:22:10Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 99}),\n",
       " Document(page_content=': 318\\ntitle: [FEA] Potential missing performance in `partitioning.partition` (compared to `hash.hash_partition`)\\nbody: A common pattern in dask is to shuffle distributed data around by some hash-based index. For example, this comes up in merging dataframes. Since the determination of index buckets is typically carried out independently from the splitting of the dataframe, this turns into calls to `libcudf.partitioning.partition`. The other option for this particular case would be to call `libcudf.hash.hash_partition`. The latter appears  to be signficantly (~5x) faster for large dataframes (code attached below, which partitions a dataframe with row columns and 100_000_000 rows on the first column into a configurable number of partitions, for the results below I used 10). Typical numbers of partitions for this use case are likely O(10-1000). Although this performance difference is not the order one cost in a distributed shuffle, flipping the switch from partition by index to partition by hash in dask-cuda provides a 10% speedup in some benchmarks (see rapidsai/dask-cuda#952).\\r\\n\\r\\n```\\r\\n$ python scatter-test.py\\r\\npartition-by-indices: 52ms\\r\\npartition-by-hash: 9.5ms\\r\\n```\\r\\n\\r\\nTo help the timings for the `partition-by-indices` case, I only compute the indices to partition on once. Profiling with nsight shows this takes ~2.7ms. The `partition` call takes 52 ms (of which `scatter` takes 22ms), in contrast `hash-and-scatter` in one go via `hash_partition` takes 9.5ms. Since `partition` by indices needs to read an extra column (the indices), I might expect things to be a bit slower, but this large difference was a bit surprising.\\r\\n\\r\\nThere\\'s a note in the partitioning code that it might make sense to avoid atomics:\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/blob/ec0b32bf73fc725982f62b0932782718d3886125/cpp/src/partitioning/partitioning.cu#L631\\r\\n\\r\\nAside: the pathological case of `npartitions == 1` is a factor of 2x slower for the partition-by-indices case, and 10x slower for partition-by-hash (probably worthwhile dispatching into a fast-path copy for that).\\r\\n\\r\\n```python\\r\\nimport rmm\\r\\nimport cudf\\r\\nimport cudf._lib as libcudf\\r\\nimport cupy\\r\\nimport time\\r\\n\\r\\n\\r\\ndef build_dataframe(nrows):\\r\\n    return cudf.DataFrame({\"key\": cupy.arange(nrows),\\r\\n                           \"value\": cupy.arange(nrows)})\\r\\n\\r\\n\\r\\ndef partition_by_indices(df, indices, npartitions):\\r\\n    cols, offsets = libcudf.partitioning.partition(\\r\\n        list(df._columns),\\r\\n        indices,\\r\\n        npartitions\\r\\n    )\\r\\n    return cols, offsets\\r\\n\\r\\n\\r\\ndef partition_by_hash(df, key, npartitions):\\r\\n    cols, offsets = libcudf.hash.hash_partition(\\r\\n        list(df._columns),\\r\\n        [df._column_names.index(key)],\\r\\n        npartitions\\r\\n    )\\r\\n    return cols, offsets\\r\\n\\r\\n\\r\\ndef run(*, nrows=10**8, with_pool=True, npartitions=10):\\r\\n    rmm.reinitialize(pool_allocator=with_pool)\\r\\n    df = build_dataframe(nrows)\\r\\n    key = \"key\"\\r\\n    indices = (libcudf.hash.hash([df[key]._column], \"murmur3\") % npartitions)\\r\\n    start = time.time()\\r\\n    for _ in range(100):\\r\\n        _ = partition_by_indices(df, indices, npartitions)\\r\\n    end = time.time()\\r\\n    print(f\"partition-by-indices: {(end - start)*10:.3g}ms\")\\r\\n    start = time.time()\\r\\n    for _ in range(100):\\r\\n        _ = partition_by_hash(df, key, npartitions)\\r\\n    end = time.time()\\r\\n    print(f\"partition-by-hash: {(end - start)*10:.3g}ms\")\\r\\n\\r\\n\\r\\nif __name__ == \"__main__\":\\r\\n    run(nrows=10**8, with_pool=True, npartitions=10)\\r\\n```\\r\\n\\r\\ncc: @bdice, @shwina\\ncreatedAt: 2022-07-18T11:46:41Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 100}),\n",
       " Document(page_content=': 320\\ntitle: [BUG] Interchange `Column.get_buffers()` erroneously raises for empty string columns\\nbody: When using `get_buffers()` on an [interchange protocol](https://data-apis.org/dataframe-protocol/latest/API.html) string column of size 0, an error raises. <sup>Mind I might be constructing string columns incorrectly?</sup>\\r\\n\\r\\n```python\\r\\n>>> df = cudf.DataFrame({\"foo\": cudf.Series([], dtype=\"U8\")})\\r\\n>>> interchange_df = df.__dataframe__()\\r\\n>>> interchange_col = interchange_df.get_column_by_name(\"foo\")\\r\\n>>> interchange_col.get_buffers()\\r\\nTraceback (most recent call last)\\r\\n\\r\\n  File .../cudf/lib/python3.9/site-packages/cudf/core/df_protocol.py:390, in _CuDFColumn.get_buffers(self)\\r\\n      387     buffers[\"validity\"] = None\\r\\n      389 try:\\r\\n  --> 390     buffers[\"offsets\"] = self._get_offsets_buffer()\\r\\n      391 except RuntimeError:\\r\\n      392     buffers[\"offsets\"] = None\\r\\n\\r\\n  File .../cudf/lib/python3.9/site-packages/cudf/core/df_protocol.py:453, in _CuDFColumn._get_offsets_buffer(self)\\r\\n      444 \"\"\"\\r\\n      445 Return the buffer containing the offset values for\\r\\n      446 variable-size binary data (e.g., variable-length strings)\\r\\n    (...)\\r\\n      450 offsets buffer.\\r\\n      451 \"\"\"\\r\\n      452 if self.dtype[0] == _DtypeKind.STRING:\\r\\n  --> 453     offsets = self._col.children[0]\\r\\n      454     assert (offsets is not None) and (offsets.data is not None), \" \"\\r\\n      455     \"offsets(.data) should not be None for string column\"\\r\\n\\r\\nIndexError: tuple index out of range\\r\\n```\\r\\n\\r\\nColumns with 1+ elements seem to work just fine. I\\'m assuming the bug stems from an assumption of non-empty columns?\\r\\n\\r\\nEDIT: Thinking about it, maybe `get_buffers()` doesn\\'t make sense for 0-sided dataframes? Need to see if there\\'s been any previous discussion on the subject.\\r\\n\\r\\n**Environment overview**\\r\\n - Environment location: locally, Ubuntu 20.04.4\\r\\n - Method of cuDF install: conda via `rapidsai-nightly`\\r\\n - cudf version: `22.08.00a+213.g002cb1c45b`\\r\\n\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n     \\r\\n     **git***\\r\\n     commit 8b3ae33c2874025c29c3747de1c3254eac516f9f (HEAD -> main, origin/main)\\r\\n     Author: Matthew Barber <quitesimplymatt@gmail.com>\\r\\n     Date:   Tue Jul 12 09:58:38 2022 +0100\\r\\n     \\r\\n     `--max-examples` flag, skip specific flaky cases on CI\\r\\n     **git submodules***\\r\\n     \\r\\n     ***OS Information***\\r\\n     DISTRIB_ID=Ubuntu\\r\\n     DISTRIB_RELEASE=20.04\\r\\n     DISTRIB_CODENAME=focal\\r\\n     DISTRIB_DESCRIPTION=\"Ubuntu 20.04.4 LTS\"\\r\\n     NAME=\"Ubuntu\"\\r\\n     VERSION=\"20.04.4 LTS (Focal Fossa)\"\\r\\n     ID=ubuntu\\r\\n     ID_LIKE=debian\\r\\n     PRETTY_NAME=\"Ubuntu 20.04.4 LTS\"\\r\\n     VERSION_ID=\"20.04\"\\r\\n     HOME_URL=\"https://www.ubuntu.com/\"\\r\\n     SUPPORT_URL=\"https://help.ubuntu.com/\"\\r\\n     BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\\r\\n     PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\\r\\n     VERSION_CODENAME=focal\\r\\n     UBUNTU_CODENAME=focal\\r\\n     Linux honno-pc 5.13.0-52-generic #59~20.04.1-Ubuntu SMP Thu Jun 16 21:21:28 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux\\r\\n     \\r\\n     ***GPU Information***\\r\\n     Tue Jul 12 14:43:34 2022\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\\r\\n     |-------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                               |                      |               MIG M. |\\r\\n     |===============================+======================+======================|\\r\\n     |   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\\r\\n     | 40%   54C    P8    20W / 170W |   1312MiB / 12288MiB |      2%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     \\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | Processes:                                                                  |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n     |        ID   ID                                                   Usage      |\\r\\n     |=============================================================================|\\r\\n     |    0   N/A  N/A      1180      G   /usr/lib/xorg/Xorg                 35MiB |\\r\\n     |    0   N/A  N/A      1865      G   /usr/lib/xorg/Xorg                135MiB |\\r\\n     |    0   N/A  N/A      2019      G   /usr/bin/gnome-shell               66MiB |\\r\\n     |    0   N/A  N/A      2480      G   /usr/lib/firefox/firefox          130MiB |\\r\\n     |    0   N/A  N/A     10214      G   ...veSuggestionsOnlyOnDemand       68MiB |\\r\\n     |    0   N/A  N/A     62041      C   ...3/envs/cudf/bin/python3.9      431MiB |\\r\\n     |    0   N/A  N/A     65091      C   ..._playground/bin/python3.9      431MiB |\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     \\r\\n     ***CPU***\\r\\n     Architecture:                    x86_64\\r\\n     CPU op-mode(s):                  32-bit, 64-bit\\r\\n     Byte Order:                      Little Endian\\r\\n     Address sizes:                   39 bits physical, 48 bits virtual\\r\\n     CPU(s):                          12\\r\\n     On-line CPU(s) list:             0-11\\r\\n     Thread(s) per core:              2\\r\\n     Core(s) per socket:              6\\r\\n     Socket(s):                       1\\r\\n     NUMA node(s):                    1\\r\\n     Vendor ID:                       GenuineIntel\\r\\n     CPU family:                      6\\r\\n     Model:                           165\\r\\n     Model name:                      Intel(R) Core(TM) i5-10400F CPU @ 2.90GHz\\r\\n     Stepping:                        5\\r\\n     CPU MHz:                         2900.000\\r\\n     CPU max MHz:                     4300.0000\\r\\n     CPU min MHz:                     800.0000\\r\\n     BogoMIPS:                        5799.77\\r\\n     L1d cache:                       192 KiB\\r\\n     L1i cache:                       192 KiB\\r\\n     L2 cache:                        1.5 MiB\\r\\n     L3 cache:                        12 MiB\\r\\n     NUMA node0 CPU(s):               0-11\\r\\n     Vulnerability Itlb multihit:     KVM: Mitigation: VMX unsupported\\r\\n     Vulnerability L1tf:              Not affected\\r\\n     Vulnerability Mds:               Not affected\\r\\n     Vulnerability Meltdown:          Not affected\\r\\n     Vulnerability Mmio stale data:   Mitigation; Clear CPU buffers; SMT vulnerable\\r\\n     Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp\\r\\n     Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\r\\n     Vulnerability Spectre v2:        Mitigation; Enhanced IBRS, IBPB conditional, RSB filling\\r\\n     Vulnerability Srbds:             Mitigation; Microcode\\r\\n     Vulnerability Tsx async abort:   Not affected\\r\\n     Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp pku ospke md_clear flush_l1d arch_capabilities\\r\\n     \\r\\n     ***CMake***\\r\\n     /snap/bin/cmake\\r\\n     cmake version 3.23.2\\r\\n     \\r\\n     CMake suite maintained and supported by Kitware (kitware.com/cmake).\\r\\n     \\r\\n     ***g++***\\r\\n     /usr/bin/g++\\r\\n     g++ (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\\r\\n     Copyright (C) 2019 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n     \\r\\n     \\r\\n     ***nvcc***\\r\\n     /usr/local/cuda-11.7/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2022 NVIDIA Corporation\\r\\n     Built on Tue_May__3_18:49:52_PDT_2022\\r\\n     Cuda compilation tools, release 11.7, V11.7.64\\r\\n     Build cuda_11.7.r11.7/compiler.31294372_0\\r\\n     \\r\\n     ***Python***\\r\\n     /home/honno/anaconda3/envs/cudf_playground/bin/python\\r\\n     Python 3.9.13\\r\\n     \\r\\n     ***Environment Variables***\\r\\n     PATH                            : /home/honno/anaconda3/envs/cudf_playground/bin:/home/honno/anaconda3/condabin:/usr/local/cuda-11.7/bin:/home/honno/.pyenv/shims:/home/honno/.pyenv/bin:/home/honno/go/bin:/usr/local/go/bin:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/honno/.dotnet/tools\\r\\n     LD_LIBRARY_PATH                 :\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /home/honno/anaconda3/envs/cudf_playground\\r\\n     PYTHON_PATH                     :\\r\\n     \\r\\n     ***conda packages***\\r\\n     /home/honno/anaconda3/condabin/conda\\r\\n     # packages in environment at /home/honno/anaconda3/envs/cudf_playground:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                       2_gnu    conda-forge\\r\\n     abseil-cpp                20210324.2           h9c3ff4c_0    conda-forge\\r\\n     arrow-cpp                 8.0.0           py39h2f48f8a_4_cuda    conda-forge\\r\\n     arrow-cpp-proc            3.0.0                      cuda    conda-forge\\r\\n     asttokens                 2.0.5                    pypi_0    pypi\\r\\n     aws-c-cal                 0.5.11               h95a6274_0    conda-forge\\r\\n     aws-c-common              0.6.2                h7f98852_0    conda-forge\\r\\n     aws-c-event-stream        0.2.7               h3541f99_13    conda-forge\\r\\n     aws-c-io                  0.10.5               hfb6a706_0    conda-forge\\r\\n     aws-checksums             0.1.11               ha31a3da_7    conda-forge\\r\\n     aws-sdk-cpp               1.8.186              hb4091e7_3    conda-forge\\r\\n     backcall                  0.2.0                    pypi_0    pypi\\r\\n     bzip2                     1.0.8                h7f98852_4    conda-forge\\r\\n     c-ares                    1.18.1               h7f98852_0    conda-forge\\r\\n     ca-certificates           2022.6.15            ha878542_0    conda-forge\\r\\n     cachetools                5.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     cuda-python               11.7.0           py39h5a03fae_0    conda-forge\\r\\n     cudatoolkit               11.7.0              hd8887f6_10    conda-forge\\r\\n     cudf                      22.08.00a220712 cuda_11_py39_g002cb1c45b_213    rapidsai-nightly\\r\\n     cupy                      10.6.0           py39hc3c280e_0    conda-forge\\r\\n     decorator                 5.1.1                    pypi_0    pypi\\r\\n     dlpack                    0.5                  h9c3ff4c_0    conda-forge\\r\\n     executing                 0.8.3                    pypi_0    pypi\\r\\n     fastavro                  1.5.2            py39hb9d737c_0    conda-forge\\r\\n     fastrlock                 0.8              py39h5a03fae_2    conda-forge\\r\\n     fsspec                    2022.5.0           pyhd8ed1ab_0    conda-forge\\r\\n     gflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\n     glog                      0.6.0                h6f12383_0    conda-forge\\r\\n     grpc-cpp                  1.45.2               h3b8df00_4    conda-forge\\r\\n     ipython                   8.4.0                    pypi_0    pypi\\r\\n     jedi                      0.18.1                   pypi_0    pypi\\r\\n     keyutils                  1.6.1                h166bdaf_0    conda-forge\\r\\n     krb5                      1.19.3               h3790be6_0    conda-forge\\r\\n     ld_impl_linux-64          2.38                 h1181459_1\\r\\n     libblas                   3.9.0           15_linux64_openblas    conda-forge\\r\\n     libbrotlicommon           1.0.9                h166bdaf_7    conda-forge\\r\\n     libbrotlidec              1.0.9                h166bdaf_7    conda-forge\\r\\n     libbrotlienc              1.0.9                h166bdaf_7    conda-forge\\r\\n     libcblas                  3.9.0           15_linux64_openblas    conda-forge\\r\\n     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge\\r\\n     libcudf                   22.08.00a220712 cuda11_g002cb1c45b_213    rapidsai-nightly\\r\\n     libcurl                   7.83.1               h7bff187_0    conda-forge\\r\\n     libedit                   3.1.20210910         h7f8727e_0\\r\\n     libev                     4.33                 h516909a_1    conda-forge\\r\\n     libevent                  2.1.10               h9b69904_4    conda-forge\\r\\n     libffi                    3.4.2                h7f98852_5    conda-forge\\r\\n     libgcc-ng                 12.1.0              h8d9b700_16    conda-forge\\r\\n     libgfortran-ng            12.1.0              h69a702a_16    conda-forge\\r\\n     libgfortran5              12.1.0              hdcd56e2_16    conda-forge\\r\\n     libgomp                   12.1.0              h8d9b700_16    conda-forge\\r\\n     libgoogle-cloud           1.40.2               habd0e3a_0    conda-forge\\r\\n     liblapack                 3.9.0           15_linux64_openblas    conda-forge\\r\\n     libllvm11                 11.1.0               hf817b99_3    conda-forge\\r\\n     libnghttp2                1.47.0               h727a467_0    conda-forge\\r\\n     libnsl                    2.0.0                h7f98852_0    conda-forge\\r\\n     libopenblas               0.3.20          pthreads_h78a6416_0    conda-forge\\r\\n     libprotobuf               3.20.1               h6239696_0    conda-forge\\r\\n     librmm                    22.08.00a220712 cuda11_g5ac89d17_57    rapidsai-nightly\\r\\n     libssh2                   1.10.0               ha56f1ee_2    conda-forge\\r\\n     libstdcxx-ng              12.1.0              ha89aaad_16    conda-forge\\r\\n     libthrift                 0.16.0               h519c5ea_1    conda-forge\\r\\n     libutf8proc               2.7.0                h7f98852_0    conda-forge\\r\\n     libuuid                   2.32.1            h7f98852_1000    conda-forge\\r\\n     libzlib                   1.2.12               h166bdaf_1    conda-forge\\r\\n     llvmlite                  0.38.1           py39h7d9a04d_0    conda-forge\\r\\n     lz4-c                     1.9.3                h9c3ff4c_1    conda-forge\\r\\n     matplotlib-inline         0.1.3                    pypi_0    pypi\\r\\n     ncurses                   6.3                  h27087fc_1    conda-forge\\r\\n     numba                     0.55.2           py39h66db6d7_0    conda-forge\\r\\n     numpy                     1.22.4           py39hc58783e_0    conda-forge\\r\\n     nvtx                      0.2.3            py39h3811e60_1    conda-forge\\r\\n     openssl                   1.1.1q               h166bdaf_0    conda-forge\\r\\n     orc                       1.7.5                h6c59b99_0    conda-forge\\r\\n     packaging                 21.3               pyhd8ed1ab_0    conda-forge\\r\\n     pandas                    1.4.3            py39h1832856_0    conda-forge\\r\\n     parquet-cpp               1.5.1                         2    conda-forge\\r\\n     parso                     0.8.3                    pypi_0    pypi\\r\\n     pexpect                   4.8.0                    pypi_0    pypi\\r\\n     pickleshare               0.7.5                    pypi_0    pypi\\r\\n     pip                       22.1.2             pyhd8ed1ab_0    conda-forge\\r\\n     prompt-toolkit            3.0.30                   pypi_0    pypi\\r\\n     protobuf                  3.20.1           py39h5a03fae_0    conda-forge\\r\\n     ptxcompiler               0.4.0            py39h1eff087_0    conda-forge\\r\\n     ptyprocess                0.7.0                    pypi_0    pypi\\r\\n     pure-eval                 0.2.2                    pypi_0    pypi\\r\\n     pyarrow                   8.0.0           py39h1ed2e5d_4_cuda    conda-forge\\r\\n     pyflakes                  2.4.0                    pypi_0    pypi\\r\\n     pyflyby                   1.7.7                    pypi_0    pypi\\r\\n     pygments                  2.12.0                   pypi_0    pypi\\r\\n     pyparsing                 3.0.9              pyhd8ed1ab_0    conda-forge\\r\\n     python                    3.9.13          h9a8a25e_0_cpython    conda-forge\\r\\n     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\\r\\n     python_abi                3.9                      2_cp39    conda-forge\\r\\n     pytz                      2022.1             pyhd8ed1ab_0    conda-forge\\r\\n     re2                       2022.06.01           h27087fc_0    conda-forge\\r\\n     readline                  8.1.2                h0f457ee_0    conda-forge\\r\\n     rmm                       22.08.00a220712 cuda11_py39_g5ac89d17_57    rapidsai-nightly\\r\\n     s2n                       1.0.10               h9b69904_0    conda-forge\\r\\n     setuptools                63.1.0           py39hf3d152e_0    conda-forge\\r\\n     six                       1.16.0             pyh6c4a22f_0    conda-forge\\r\\n     snappy                    1.1.9                hbd366e4_1    conda-forge\\r\\n     spdlog                    1.8.5                h4bd325d_1    conda-forge\\r\\n     sqlite                    3.39.0               h4ff8645_0    conda-forge\\r\\n     stack-data                0.3.0                    pypi_0    pypi\\r\\n     tk                        8.6.12               h27826a3_0    conda-forge\\r\\n     traitlets                 5.3.0                    pypi_0    pypi\\r\\n     typing_extensions         4.3.0              pyha770c72_0    conda-forge\\r\\n     tzdata                    2022a                h191b570_0    conda-forge\\r\\n     wcwidth                   0.2.5                    pypi_0    pypi\\r\\n     wheel                     0.37.1             pyhd8ed1ab_0    conda-forge\\r\\n     xz                        5.2.5                h516909a_1    conda-forge\\r\\n     zlib                      1.2.12               h166bdaf_1    conda-forge\\r\\n     zstd                      1.5.2                h8a70e8d_2    conda-forge\\r\\n     \\r\\n</pre></details>\\ncreatedAt: 2022-07-20T12:49:41Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Barber\\ncompany: Hexegic', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 101}),\n",
       " Document(page_content=': 321\\ntitle: [BUG] Interchange `Column.describe_categorical` is a tuple, not a dict\\nbody: In the [interchange protocol](https://data-apis.org/dataframe-protocol/latest/API.html), `describe_categorical` should return a dict, but cuDF returns a tuple\\r\\n\\r\\n```python\\r\\n>>> df = cudf.DataFrame({\"foo\": cudf.Series([0, 1], dtype=\"category\")})\\r\\n>>> interchange_df = df.__dataframe__()\\r\\n>>> interchange_col = interchange_df.get_column_by_name(\"foo\")\\r\\n>>> interchange_col.describe_categorical\\r\\n(False, True, {0: 0, 1: 1})\\r\\n>>> type(interchange_col.describe_categorical)\\r\\ntuple  # should be dict\\r\\n```\\r\\n\\r\\nRelevant code returning a tuple as opposed to dict\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/blob/edc5062bdcc3e12755603b0ad07a4d271fe95261/python/cudf/cudf/core/df_protocol.py#L295\\r\\n\\r\\nThis prevents interchanging dataframes with categorical columns, e.g. with pandas\\r\\n```python\\r\\n>>> from pandas.api.exchange import from_dataframe\\r\\n>>> from_dataframe(df)\\r\\n.../pandas/core/exchange/from_dataframe.py:184, in categorical_column_to_series(col)\\r\\n    169 \"\"\"\\r\\n    170 Convert a column holding categorical data to a pandas Series.\\r\\n    171 \\r\\n   (...)\\r\\n    180     that keeps the memory alive.\\r\\n    181 \"\"\"\\r\\n    182 categorical = col.describe_categorical\\r\\n--> 184 if not categorical[\"is_dictionary\"]:\\r\\n    185     raise NotImplementedError(\"Non-dictionary categoricals not supported yet\")\\r\\n    187 mapping = categorical[\"mapping\"]\\r\\nTypeError: tuple indices must be integers or slices, not str\\r\\n```\\r\\n\\r\\n\\r\\npandas and modin are compliant here, but interestingly vaex currently returns a tuple too https://github.com/vaexio/vaex/issues/2113\\ncreatedAt: 2022-07-22T09:20:25Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Barber\\ncompany: Hexegic', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 102}),\n",
       " Document(page_content=\": 322\\ntitle: [FEA] Ability to write multiple files in `to_orc` in a similar file naming pattern to that of `to_csv`\\nbody: **What is your question?**\\r\\nHello guys,\\r\\n\\r\\nI wonder if we can rename the files when we use to_orc in dask_cudf,  such as  `ddf.to_orc('name-*.orc')`? I think we are able to do it in `ddf.to_csv()`. Thanks\\ncreatedAt: 2022-07-25T15:31:59Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Cg Lai\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 103}),\n",
       " Document(page_content=': 323\\ntitle: Constructing `Column` objects from `cudf::column` should always take ownership of the null mask\\nbody: This came out of discussions in #11354. The current approach that `Column.from_unique_ptr` drops a reference to the `cudf::column`s `null_mask` if `null_count == 0` can result in use-after-free if there are also `column_view`s referencing the `column`. See discussion in https://github.com/rapidsai/cudf/pull/11354#discussion_r930808913\\ncreatedAt: 2022-07-28T08:44:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 104}),\n",
       " Document(page_content=': 324\\ntitle: [BUG] Interchange `Column.dtype` returns format strings in NumPy-style, instead of Arrow-style\\nbody: In the [interchange protocol](https://data-apis.org/dataframe-protocol/latest/API.html), `Column.dtype` should return an [Arrow-style](https://arrow.apache.org/docs/format/CDataInterface.html#data-type-description-format-strings) format string, but instead a NumPy-styled one is returned\\r\\n\\r\\n```python\\r\\n>>> df = cudf.DataFrame({\"foo\": cudf.Series([0, 1], dtype=\"int8\")})\\r\\n>>> interchange_df = df.__dataframe__()\\r\\n>>> interchange_col = interchange_df.get_column_by_name(\"foo\")\\r\\n>>> interchange_col.dtype\\r\\n(<_DtypeKind.INT: 0>, 8, \\'|i1\\', \\'|\\')  # 3rd element (format string) should be \"c\"\\r\\n```\\r\\n\\r\\nIt looks like currently the `.str` attribute of the dtype objects (i.e. `np.dtype(...)`) is returned as-is\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/blob/edc5062bdcc3e12755603b0ad07a4d271fe95261/python/cudf/cudf/core/df_protocol.py#L260\\ncreatedAt: 2022-07-28T13:08:05Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Barber\\ncompany: Hexegic', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 105}),\n",
       " Document(page_content=\": 325\\ntitle: [FEA] Change cudf::io::detail::make_column() to have a more verbose name.\\nbody: ```\\r\\nstd::unique_ptr<column> make_column(column_buffer& buffer,\\r\\n                                    column_name_info* schema_info,\\r\\n                                    rmm::cuda_stream_view stream,\\r\\n                                    rmm::mr::device_memory_resource* mr)\\r\\n```\\r\\n\\r\\nThis is kind of a weakly named global function.   Because its name is so generic, it doesn't play nice with users who might want to create their own, more appropriately named `make_column` that does some other work along the way.  Changing this to `column_from_column_buffer()` or `make_column_from_buffer()`, or maybe making it a member of `column_buffer` would clean things up a bit\\r\\n\\r\\n Eg.\\r\\n\\r\\n```\\r\\n// user function (in parquet code for example)\\r\\nmake_column(column_buffer &b)\\r\\n{\\r\\n    // random preprocessing work\\r\\n    auto x = column_from_column_buffer(b);\\r\\n    // random postprocessing work\\r\\n}\\r\\n```\\ncreatedAt: 2022-07-28T16:10:13Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 106}),\n",
       " Document(page_content=': 326\\ntitle: Investigate need for output as binary configuration option\\nbody: It is possible that the output as binary options are not necessary as mentioned in this comment. Initial testing in the course of the PR showed list tests failing when using just physical type, so more investigation is needed.\\r\\n\\r\\n_Originally posted by @vuule in https://github.com/rapidsai/cudf/pull/11328#discussion_r932696159_\\ncreatedAt: 2022-07-28T21:58:26Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Mike Wilson\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 107}),\n",
       " Document(page_content=': 327\\ntitle: `schema_tree_node` needs a constructor.\\nbody: Nitpick: Looks like `schema_tree_node` needs a constructor. :]\\r\\n\\r\\nI would\\'ve recommended aggregate initialization, but I\\'m not sure how appropriate it would be, since it\\'s initializing parent members:\\r\\n```suggestion\\r\\n        schema_tree_node col_schema {\\r\\n          .type            = Type::BYTE_ARRAY,\\r\\n          .converted_type  = ConvertedType::UNKNOWN,\\r\\n          .stats_dtype     = statistics_dtype::dtype_byte_array,\\r\\n          .repetition_type = col_nullable ? OPTIONAL : REQUIRED,\\r\\n          .name = (schema[parent_idx].name == \"list\") ? \"element\" : col_meta.get_name(),\\r\\n          .parent_idx  = parent_idx,\\r\\n          .leaf_column = col\\r\\n        };\\r\\n```\\r\\n\\r\\nMy personal preference would be to avoid construct-then-initialize. But this is purely stylistic. Please feel free to ignore.\\r\\n\\r\\n_Originally posted by @mythrocks in https://github.com/rapidsai/cudf/pull/11328#discussion_r932746165_\\ncreatedAt: 2022-07-28T23:26:36Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Mike Wilson\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 108}),\n",
       " Document(page_content=\": 328\\ntitle: The example in the documentation for `get_dremel_data()` seems incorrect at line#1764\\nbody: I know this isn't part of the review, but the example in the documentation for `get_dremel_data()` seems incorrect at line#1738 (now [#1764](https://github.com/rapidsai/cudf/pull/11328/files#diff-e3891cd717ca174e53dd11bbf812ad3f13034d4c1a4626ea751f05bbed8470d5R1764)):\\r\\n```c++\\r\\n * Given a LIST column of type `List<List<int>>` like so:\\r\\n * ```\\r\\n * col = {\\r\\n *    [],\\r\\n *    [[], [1, 2, 3], [4, 5]],\\r\\n *    [[]]\\r\\n * }\\r\\n * ```\\r\\n * We can represent it in cudf format with two level of offsets like this:\\r\\n * ```\\r\\n * Level 0 offsets = {0, 0, 3, 5, 6}\\r\\n * Level 1 offsets = {0, 0, 3, 5, 5}\\r\\n * Values          = {1, 2, 3, 4, 5}\\r\\n * ```\\r\\n```\\r\\nThe `Level 0` offset values can't exceed `4`, since `Level 1` has only 4 ranges (i.e. 5 offsets).\\r\\nI'll try make sense of this at a later date, but I'm not sure I could follow along.\\r\\n\\r\\n_Originally posted by @mythrocks in https://github.com/rapidsai/cudf/pull/11328#discussion_r932727013_\\ncreatedAt: 2022-07-28T23:27:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Mike Wilson\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 109}),\n",
       " Document(page_content=': 330\\ntitle: [QST] Should byte_array_view in parquet reader/writer change\\nbody: **What is your question?**\\r\\nShould [`byte_array_view`](https://github.com/rapidsai/cudf/blob/branch-22.08/cpp/src/io/statistics/byte_array_view.cuh) change to a different implementation method or even go away completely.\\r\\n\\r\\n### Motivation\\r\\nWhen reviewing the `byte_array_view` PR it was brought up in [review comments](https://github.com/rapidsai/cudf/pull/11322#discussion_r928012252) that things could be done differently and possibly better. This issue is an attempt to bring this design out in the light and get some discourse going so we can build it the best way possible. Jake was, rightfully, concerned about the cognitive overload of having another object type that has to be understood, no matter how minimal the type turns out to be.\\r\\n\\r\\n### Backstory and origin\\r\\nThe original thought was that it would be nice to leverage the existing templates in the statistics code to get elements and compute max/min just like everything else. This meant that `.element` on a column would be able to return a type that represents a `list<uint8>`. This is almost identical to a string column, so the thought was to have something analogous to `string_view` that could be used. This was quickly dismissed due to the issue of not having all list columns comprised of this thing and it felt like we were forcing something. All string columns are lists of chars, but not all list columns are lists of bytes.\\r\\n\\r\\n### Requirements\\r\\nThe requirements in the statistics code are the ability to get an element from a table, compare elements, and compose an element from a pointer and a length. The statistics code goes to great length to type-erase the statistics blobs so they can be easily consumed at a large scale on the GPU and the reconstructs them later. It also uses `thrust::min` and `cub::reduceBlock` to process them, so comparison operators are needed.\\r\\n\\r\\n### Slippery issues to understand\\r\\nWe can\\'t use the same statistics types as strings because `string_view::max()` is actually not the same as a max byte or a max `byte_array_view`. The distinction is subtle, but important between all of them.\\r\\n\\r\\n- The max UTF8 string is actually just 5 bytes long and [defined inside the `string_view` header](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/include/cudf/strings/string_view.cuh#L75). No UTF8 string can have a higher value, so comparisons work even though it isn\\'t an infinitely-long character string as one would initially think.\\r\\n- Maximum value for an unsigned byte is obviously 255, but this isn\\'t the what is intended when one asks for the max byte array view. Instead, the goal is to know the \"biggest\" one. This includes the length and the internal bytes. `0xff, 0x05` is less than `0xff, 0x15` and `0xff` is less than `0x00, 0x00`.\\r\\n- Maximum `byte_array_view` is defined conceptually as an infinite array of 0xff. This isn\\'t possible to statically define for comparison like the `string_view` class, so some [magic values](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/statistics/byte_array_view.cuh#L173) were used of a nullptr and max length. These then have to be [explicitly compared](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/statistics/byte_array_view.cuh#L101) later in the comparison function to achieve the proper results.\\r\\n\\r\\nLots of places required special handling for `byte_array_view` and potentially get worse with the different possible solutions. The goal of course is to make these areas as clean as possible, so I thought it would be good to point some of them out here.\\r\\n\\r\\n - [Here](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/statistics/column_statistics.cuh#L115) is where the code grabs the data from the column. There is conversion in here for types, which is used for things like duration and timestamps. Originally it was thought this could be a good spot to convert from a `list_view`, which can be returned from `.element` calls on a list column. This didn\\'t end up being a great solution, but I can\\'t remember the details.\\r\\n - min/max calculations and block reduce happens down in [typed_statistics_chunk](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/statistics/typed_statistics_chunk.cuh#L207). This code is responsible for figuring out min, max, null counts, and aggregations like sum. It has to pick up this new type and operate on it.\\r\\n - Actual data writing in parquet looks [something like this](https://github.com/rapidsai/cudf/blob/03f1c1c5c5fcf90bd594aabd41b6e15f54690777/cpp/src/io/parquet/page_enc.cu#L1094) where an element is grabbed and written into place.\\r\\n\\r\\n### Possible solutions\\r\\n1. Use `device_span` directly. This requires passing comparison functions to cub and thrust for the calculations, but is completely doable. This was [attempted](https://github.com/hyperbolic2346/cudf/tree/mwilson/test_byte_array_view_removal), potentially poorly, with not great looking results.\\r\\n2. Composition vs inheritance. This came up multiple times as to why it was built with composition, holding a `device_span` inside, vs inheriting from `device_span` either publicly or privately. There isn\\'t a great answer here to argue against inheritance. I originally thought that this would be a very small subset of `device_span` and I didn\\'t want to muddy the waters with all the accessors and iterators, but after further inspection, I don\\'t see anything that I would want to remove from `device_span`, so this would be a viable path. It does still hold the issue of cognitive overload of yet another type someone encounters.\\r\\n3. Continues to live on as it is now.\\r\\n4. Your amazing idea that didn\\'t come up in development or review.\\ncreatedAt: 2022-07-29T21:19:39Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Mike Wilson\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 110}),\n",
       " Document(page_content=\": 331\\ntitle: [FEA] ClusterfuzzLite integration\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\ncuDF has an extensive fuzzing suite that could benefit the project by running in the CI.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nIn this issue I suggest [ClusterfuzzLite](https://google.github.io/clusterfuzzlite/) integration for cuDF. This would require:\\r\\n\\r\\n1. Adding a `.github/workflows/cflite.yml` file.\\r\\n2. Adding a .clusterfuzzlite directory with build files.\\r\\n3. Rewriting the fuzzers into coverage-guided fuzzers via [Atheris](https://github.com/google/atheris).\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\n\\r\\n**Additional context**\\r\\nClusterfuzzLite handles the management of running fuzzers in the CI when PRs are made. It has a number of features that are useful for projects with multiple fuzzers:\\r\\n\\r\\n1. CFL reuses corpus so that the fuzzers don't start from scratch every run.\\r\\n2. [Batch fuzzing](https://google.github.io/clusterfuzzlite/running-clusterfuzzlite/github-actions/#batch-fuzzing) will run the fuzzers periodically to look for harder-to-find bugs and build of the corpus.\\r\\n3. Only fuzzers that cover code that is changed in PRs run in the CI.\\r\\n\\r\\nI will be glad to take the lead on this one if it is of interest to cuDF.\\ncreatedAt: 2022-08-01T11:07:28Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: Adam@adalogics.com\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 111}),\n",
       " Document(page_content=': 332\\ntitle: [BUG] Multiple DataFrame.loc operations gives confusing error message upon compute on Dask-cuDF\\nbody: **Describe the bug**\\r\\nAfter creating a Dask-cuDF data frame, if I perform multiple .loc operations on it using boolean Dask-cuDF series, then when I compute the data frame, it produces a runtime error with the message `cuDF failure at: ../src/stream_compaction/apply_boolean_mask.cu:73: Column size mismatch`. A similar snippet works as expected on cuDF.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```python\\r\\nimport dask_cudf\\r\\nimport cudf\\r\\nddf1 = dask_cudf.from_cudf(cudf.DataFrame({\\'a\\':[1,2,3], \\'b\\':[4,5,6]}), npartitions=2)\\r\\nf1 = dask_cudf.from_cudf(cudf.Series([False, True, True]), npartitions=2)\\r\\nf2 = dask_cudf.from_cudf(cudf.Series([True, False]), npartitions=2)\\r\\nddf2 = ddf1.loc[f1]\\r\\nddf3 = ddf2.loc[f2]\\r\\nprint(ddf2.compute())\\r\\nprint(ddf3.compute())\\r\\n```\\r\\nThe above code produces the following output:\\r\\n```\\r\\n   a  b                        \\r\\n1  2  5\\r\\n2  3  6                                                       \\r\\nTraceback (most recent call last):     \\r\\n  File \"temp.py\", line 9, in <module>\\r\\n    print(ddf3.compute())\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/base.py\", line 292, in compute\\r\\n    (result,) = compute(self, traverse=False, **kwargs)\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/base.py\", line 575, in compute\\r\\n    results = schedule(dsk, keys, **kwargs)    \\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 554, in get_sync\\r\\n    return get_async(                                         \\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 497, in get_async                                       \\r\\n    for key, res_info, failed in queue_get(queue).result():\\r\\n  File \"/opt/conda/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\\r\\n    return self.__get_result()\\r\\n  File \"/opt/conda/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\\r\\n    raise self._exception\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 539, in submit\\r\\n    fut.set_result(fn(*args, **kwargs))\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 235, in batch_execute_tasks\\r\\n    return [execute_task(*a) for a in it]\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 235, in <listcomp>\\r\\n    return [execute_task(*a) for a in it]\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 226, in execute_task\\r\\n    result = pack_exception(e, dumps)\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 221, in execute_task\\r\\n    result = _execute_task(task, data)\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/core.py\", line 119, in _execute_task\\r\\n    return func(*(_execute_task(a, cache) for a in args))\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/optimization.py\", line 990, in __call__\\r\\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/core.py\", line 149, in get\\r\\n    result = _execute_task(task, cache)\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/core.py\", line 119, in _execute_task\\r\\n    return func(*(_execute_task(a, cache) for a in args))\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/utils.py\", line 39, in apply\\r\\n    return func(*args, **kwargs)\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/dataframe/core.py\", line 6330, in apply_and_enforce\\r\\n    df = func(*args, **kwargs)\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/dask/dataframe/methods.py\", line 37, in loc\\r\\n    return df.loc[iindexer]\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/cudf/core/dataframe.py\", line 127, in __getitem__\\r\\n    return self._getitem_tuple_arg(arg)\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/nvtx/nvtx.py\", line 101, in inner\\r\\n    result = func(*args, **kwargs)\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/cudf/core/dataframe.py\", line 267, in _getitem_tuple_arg\\r\\n    df = columns_df._apply_boolean_mask(tmp_arg[0])\\r\\n  File \"/opt/conda/lib/python3.8/site-packages/cudf/core/indexed_frame.py\", line 1696, in _apply_boolean_mask\\r\\n    libcudf.stream_compaction.apply_boolean_mask(\\r\\n  File \"cudf/_lib/stream_compaction.pyx\", line 101, in cudf._lib.stream_compaction.apply_boolean_mask\\r\\nRuntimeError: cuDF failure at: ../src/stream_compaction/apply_boolean_mask.cu:73: Column size mismatch\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nExpected output (verified with cudf instead of dask-cudf):\\r\\n```\\r\\n   a  b\\r\\n1  2  5\\r\\n2  3  6\\r\\n   a  b\\r\\n1  2  5\\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Docker\\r\\n - Method of cuDF install: Docker\\r\\n   - `docker run -it --rm --gpus all --ipc=host --network=host -v .`\\r\\n\\r\\n**Environment details**\\r\\ncuDF version 22.4.0a0+306.g0cb75a4913\\ncreatedAt: 2022-08-02T17:46:45Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Alex Xu\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 112}),\n",
       " Document(page_content=': 337\\ntitle: Need an address alignment utility function in cudf\\nbody: As found in review of code, there are alignment functions scattered around. We should have a single device-accessible alignment function that everything uses instead of doing the bit operations themselves or having a static local function for it.\\r\\n\\r\\n_Originally posted by @etseidl in https://github.com/rapidsai/cudf/pull/11403#discussion_r938132622_\\ncreatedAt: 2022-08-04T18:44:25Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Mike Wilson\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 113}),\n",
       " Document(page_content=': 339\\ntitle: [FEA] Support nested struct columns in ORC fuzz tests\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nFuzz testing support for nested struct columns in Orc is incomplete. Some patches were required as shown in #9395 discussion (https://github.com/rapidsai/cudf/issues/9395#issuecomment-1206776202.)\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nAdd support for nested struct columns in the Orc fuzz testing\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nAdhoc patches that bring side-effects to other fuzzers and unit tests in cuDF.\\r\\n\\r\\n**Additional context**\\r\\nWe would benefit from a way to limit the overall depth of the generated struct columns - I propose maximum nesting depth of 256. Setting `max_structs_nesting_depth` in the `IOFuzz` class does not seem sufficient to address this limit. Here is a traceback for the recursion error:\\r\\n```\\r\\n  File \"/home/gregorykimball/Repo/cudf/python/cudf/cudf/testing/dataset_generator.py\", line 387, in rand_dataframe\\r\\n    structDtype = create_nested_struct_type(\\r\\n...\\r\\n  File \"/home/gregorykimball/Repo/rapids-compose/etc/conda/cuda_11.5/envs/rapids/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 70, in _wrapreduction\\r\\n    passkwargs = {k: v for k, v in kwargs.items()\\r\\nRecursionError: maximum recursion depth exceeded while calling a Python object\\r\\n\\r\\n```\\ncreatedAt: 2022-08-05T19:11:48Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 114}),\n",
       " Document(page_content=': 341\\ntitle: [BUG] Some custom dask aggregations fail with dask_cudf dataframes\\nbody: **Describe the bug**\\r\\nSome dask custom aggregations (ex: a custom sum of squares aggregation) fail with dask_cudf.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nimport cudf\\r\\nimport dask_cudf\\r\\nimport dask.dataframe as dd\\r\\n\\r\\ndf = cudf.DataFrame({\"a\":[1,2,3], \"b\":[1,1,2]})\\r\\nddf = dask_cudf.from_cudf(df, npartitions=1)\\r\\n\\r\\nsum_of_squares = dd.Aggregation(\\r\\n    name=\\'sum_of_squares\\',\\r\\n    chunk=lambda s: s.agg(lambda x: (x**2).sum()),\\r\\n    agg=lambda s0: s0.sum()\\r\\n)\\r\\n\\r\\nddf.groupby(\"b\").agg(sum_of_squares).compute()\\r\\n```\\r\\nreturns:\\r\\n```\\r\\nTypeError: unsupported operand type(s) for ** or pow(): \\'type\\' and \\'int\\'\\r\\n```\\r\\nhowever when running with a pandas backed dask dataframe:\\r\\n```\\r\\nddf.to_dask_dataframe().groupby(\"b\").agg(sum_of_squares).compute()\\r\\n```\\r\\nthe expected result is returned:\\r\\n```\\r\\n   a\\r\\nb   \\r\\n1  5\\r\\n2  9\\r\\n\\u200b\\r\\n```\\r\\n\\r\\ncc: @randerzander\\ncreatedAt: 2022-08-11T16:04:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 115}),\n",
       " Document(page_content=': 344\\ntitle: [PERF] Improve \"isin\" performance by only sorting once\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nWhile benchmarking cuDF-python, I noticed that [bench_isin](https://github.com/rapidsai/cudf/blob/65a782112f4b76941483adf17f9a30a6824f6164/python/cudf/benchmarks/API/bench_dataframe.py#L50) has low end-to-end data throughput (<10GB/s). A closer look at the profiles showed that the data is being sorted twice, first with `.sort_values()` and then as part of `drop_duplicates()`. The following profile is for a test dataframe with 1 col and 100K rows, and is uses the `isin` argument `range(1000)` in the `bench_isin` benchmark.\\r\\n\\r\\n<img width=\"851\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12725111/185016040-8c8b70ab-a8fd-4cc5-8294-2fb9ea5acc5e.png\">\\r\\n\\r\\nWhen calling `isin` with a dataframe or dict argument, the profile shows two calls to `Frame.argsort`.\\r\\n\\r\\n<img width=\"841\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12725111/185018010-a4e5789e-cf0a-4a7f-8291-a9fdd52adbbe.png\">\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nFor a performance improvement, I\\'d like to refactor `isin` to only sort the data once. We should prefer the libcudf `unique` function to `drop_duplicates` for pre-sorted data.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nn/a\\r\\n\\r\\n**Additional context**\\r\\nAdd any other context, code examples, or references to existing implementations about the feature request here.\\ncreatedAt: 2022-08-17T01:48:17Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 116}),\n",
       " Document(page_content=': 345\\ntitle: [DOC] `.mode()` incorrectly states that axis=1 is supported as it throws \"NotImplementedError\" when you try\\nbody: ## Report incorrect documentation\\r\\n\\r\\n**Location of incorrect documentation**\\r\\nhttps://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.mode.html?highlight=mode#cudf.DataFrame.mode\\r\\n\\r\\n**Describe the problems or issues found in the documentation**\\r\\nDocumentation says that mode can be applied over columns (axis = 0) or rows (axis = 1), but when trying axis = 1, it says `Only axis=0 is currently supported`\\r\\n\\r\\n**Steps taken to verify documentation is incorrect**\\r\\n\\r\\n```\\r\\nimport cudf\\r\\ndf = cudf.DataFrame(np.random.randint(0,5,size=(15, 10)), columns=list(\\'ABCDEFGHIJ\\'))\\r\\ndf.mode(axis=1)\\r\\n```\\r\\nStack trace\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\n/tmp/ipykernel_2243/3323872345.py in <module>\\r\\n----> 1 df.mode(axis=1)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     73         def inner(*args, **kwds):\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n     77 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in mode(self, axis, numeric_only, dropna)\\r\\n   5678         \"\"\"\\r\\n   5679         if axis not in (0, \"index\"):\\r\\n-> 5680             raise NotImplementedError(\"Only axis=0 is currently supported\")\\r\\n   5681 \\r\\n   5682         if numeric_only:\\r\\n\\r\\nNotImplementedError: Only axis=0 is currently supported\\r\\n```\\r\\n**Suggested fix for documentation**\\r\\nEither \\r\\n1. state that axis = 1 is not supported\\r\\n2. remove references for axis = 1 in docs\\r\\n3. add the functionality\\ncreatedAt: 2022-08-19T15:42:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Taurean Dyer\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 117}),\n",
       " Document(page_content=': 350\\ntitle: [ENH] More type-stubs in the mypy pre-commit environment?\\nbody: Following on from #11640 (specifically https://github.com/rapidsai/cudf/pull/11640#discussion_r961551760) a question arises as to how complete we should make the mypy pre-commit environment in terms of supported typestubs.\\r\\n\\r\\nStatus quo:\\r\\n\\r\\nThe version of mypy installed via pre-commit only depends on the stdlib typeshed stubs (and after #11640 `types-cachetools`). We set `ignore_missing_imports = True` which means that mypy doesn\\'t complain if it sees an import for something (say numpy) that it can\\'t find. Consequently, any non-importable modules are typed as `Any` (as are all objects, methods, functions, etc... from that module); this is a type that always satisfies any type constraint.\\r\\n\\r\\nIn the development environment, all cudf modules _are_ importable, and so a type-checking run using that environment will deduce narrower types for many function calls in cudf. Many of these currently do not type-check, being of the following form: https://mypy-play.net/?mypy=latest&python=3.10&gist=8d3ba6046bb8ca39c6d6b71b442b432c\\r\\n```python\\r\\nfrom typing import Any\\r\\n\\r\\ndef foo(x: Any) -> Any:\\r\\n    if isinstance(x, bool):\\r\\n        y = x\\r\\n    elif isinstance(x, int):\\r\\n        y = (True, x)\\r\\n    else:\\r\\n        y = x\\r\\n\\r\\n    return y\\r\\n```\\r\\n\\r\\nmypy complains about the assignment `y = (True, x)` \"error: Incompatible types in assignment (expression has type \"Tuple[bool, int]\", variable has type \"bool\")\" because it deduces the type of `y` from the first assignment as `bool`.\\r\\n\\r\\nThere are various places in the codebase where we do this kind of untagged union dispatch, this could be fixed by explicitly typing all the variables as `Union[a, b, c, ...]` but I am not sure that in the end it would be worth it. If we install `numpy` and the `pandas-stubs` package (which provides type stubs for pandas) then we get about 120 errors of this nature.\\r\\n\\r\\nI think that fixing these things is rather difficult, the right approach is to use tagged unions, but there\\'s no support for that in python and any workaround would (I think) make the code unnecessarily non-idiomatic.\\r\\n\\r\\nIf we think it\\'s worthwhile pursuing this, I can prepare a draft patch for some of the uncovered typing issues so we can discuss more concretely.\\ncreatedAt: 2022-09-07T13:15:29Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 118}),\n",
       " Document(page_content=\": 354\\ntitle: [FEA] `read_csv` context-passing interface for distributed/segmented parsing\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nTo parse files from a regular language like CSV, we can only safely parse data inside a byte range if we know the parsing context from before this range. Without this information, we may accidentally interpret a record delimiter (newline) inside a quoted field as an actual delimiter.\\r\\n\\r\\nMore formally, when starting from a byte range, we don't know what state the DFA of the token language is in, so we need to store the transition vector starting from every possible state, and combine the vectors by function composition in the associative scan operation. This is pretty much identical to what is happening in [the finite state transducer](https://github.com/rapidsai/cudf/pull/11242).\\r\\n\\r\\nInstead of just running the scan on a full file, we can run it only on a byte range, and combine the resulting transition vectors in an exclusive scan over all byte ranges to establish local parsing context.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nI want to propose a slight extension to the `read_csv` interface to handle this case:\\r\\n\\r\\n1. add a `class csv_parse_context` that opaquely wraps `packed_rowctx_t`, only exposing the `merge_row_contexts` functionality to combine the parsing context from adjacent byte ranges, and a `finalize` operation that turns the transition vector into its value starting from the initial DFA state.\\r\\n2. add a `read_csv_context` function that only scans the local byte range to compute its `csv_parse_context` transition vector. It can probably take the same parameters as `read_csv`\\r\\n3. add a `csv_parse_context initial_parsing_state` parameter to `csv_reader_options` that defaults to the initial state. The `read_csv` function can then use this initial state to determine record offsets and do the actual parsing.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nAlternatively, we could implement backtracking by reading chunks before the byte range until we figured out an unambiguous parser state (that is not the error state). This could in the worst case lead to reading the entire prefix up to the byte range.\\r\\n\\r\\n**Additional context**\\r\\nThis is relevant if we want `dask.read_csv` to be able to handle quoted record delimiters (i.e. newlines) where the opening quote occurs before the byte range.\\r\\n\\r\\nThe interface has the advantage that it can be tested in isolation on a single node, without having to rely on dask.\\r\\n\\r\\nThe same kind of pattern could also apply to `read_json`, where on top of the regular parsing state, we also need to pass the stack transition operations from the beginning to the end of the byte range.\\ncreatedAt: 2022-09-21T10:22:51Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Tobias Ribizel\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 119}),\n",
       " Document(page_content=': 355\\ntitle: [FEA] Support New Median / Median-Approximate in Dask-cuDF\\nbody: In https://github.com/dask/dask/pull/9483 Dask now has an implementation of `median` and `median_approximate`.  These should available with dask_cudf.  cuDF currently raise a NotImplementedError with `mean(axis=1)`:\\r\\n\\r\\n\\r\\n```python\\r\\ncdf = cudf.datasets.timeseries()\\r\\ncdf = dd.from_pandas(cdf, npartitions=2)\\r\\ncdf.median(axis=1).compute()\\r\\n\\r\\nFile /datasets/bzaitlen/miniconda3/envs/tpcds-20220906/lib/python3.9/site-packages/cudf/core/dataframe.py:5225, in DataFrame.quantile(self, q, axis, numeric_only, interpolation, columns, exact)\\r\\n   5164 \"\"\"\\r\\n   5165 Return values at the given quantile.\\r\\n   5166\\r\\n   (...)\\r\\n   5222 0.5  2.5  55.0\\r\\n   5223 \"\"\"  # noqa: E501\\r\\n   5224 if axis not in (0, None):\\r\\n-> 5225     raise NotImplementedError(\"axis is not implemented yet\")\\r\\n   5227 data_df = self\\r\\n   5228 if numeric_only:\\r\\n```\\r\\n\\r\\nAs for `mean_approximate`, ValueError is thrown unexpectedly:\\r\\n\\r\\n\\r\\n```python\\r\\nIn [32]: cdf.compute()\\r\\nOut[32]:\\r\\n   x    y\\r\\n0  1  1.1\\r\\n1  2  2.2\\r\\n2  3  3.3\\r\\n3  4  4.4\\r\\n4  5  5.5\\r\\n\\r\\nIn [33]: cdf.median_approximate().compute()\\r\\n...\\r\\nFile /datasets/bzaitlen/miniconda3/envs/tpcds-20220906/lib/python3.9/site-packages/cudf/core/frame.py:898, in Frame.fillna(self, value, method, axis, inplace, limit)\\r\\n    892 should_fill = (\\r\\n    893     col_name in value\\r\\n    894     and col.contains_na_entries\\r\\n    895     and not libcudf.scalar._is_null_host_scalar(replace_val)\\r\\n    896 ) or method is not None\\r\\n    897 if should_fill:\\r\\n--> 898     filled_data[col_name] = col.fillna(replace_val, method)\\r\\n    899 else:\\r\\n    900     filled_data[col_name] = col.copy(deep=True)\\r\\n\\r\\nFile /datasets/bzaitlen/miniconda3/envs/tpcds-20220906/lib/python3.9/site-packages/cudf/core/column/numerical.py:503, in NumericalColumn.fillna(self, fill_value, method, dtype, fill_nan)\\r\\n    499     return super(NumericalColumn, col).fillna(fill_value, method)\\r\\n    501 if np.isscalar(fill_value):\\r\\n    502     # cast safely to the same dtype as self\\r\\n--> 503     fill_value_casted = col.dtype.type(fill_value)\\r\\n    504     if not np.isnan(fill_value) and (fill_value_casted != fill_value):\\r\\n    505         raise TypeError(\\r\\n    506             f\"Cannot safely cast non-equivalent \"\\r\\n    507             f\"{type(fill_value).__name__} to {col.dtype.name}\"\\r\\n    508         )\\r\\n\\r\\nValueError: cannot convert float NaN to integer\\r\\n```\\ncreatedAt: 2022-09-21T13:47:13Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Benjamin Zaitlen\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 120}),\n",
       " Document(page_content=': 356\\ntitle: [FEA] Support passing scalar string args to string_udfs\\nbody: Using the newly merged strings_udf support, I\\'m trying to pass scalar arguments to a string UDF:\\r\\n```\\r\\nimport cudf\\r\\n\\r\\ndf = cudf.DataFrame({\"str_col\": [\"a\", \"abb\", \"abc\"]})\\r\\n\\r\\ndef delim_count(row, delim):\\r\\n    return row[\"str_col\"].count(delim)\\r\\n\\r\\ndf.apply(delim_count, args=(\"b\",), axis=1)\\r\\n```\\r\\n\\r\\nBut I get udf compilation failed errors.\\r\\n\\r\\nTrace:\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nNumbaNotImplementedError                  Traceback (most recent call last)\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in cast(self, builder, val, fromty, toty)\\r\\n    711         try:\\r\\n--> 712             impl = self._casts.find((fromty, toty))\\r\\n    713             return impl(self, builder, fromty, toty, val)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in find(self, sig)\\r\\n     48         if out is None:\\r\\n---> 49             out = self._find(sig)\\r\\n     50             self._cache[sig] = out\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in _find(self, sig)\\r\\n     57         else:\\r\\n---> 58             raise errors.NumbaNotImplementedError(f\\'{self}, {sig}\\')\\r\\n     59 \\r\\n\\r\\nNumbaNotImplementedError: <numba.core.base.OverloadSelector object at 0x7f2498b3aca0>, (unicode_type, string_view)\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nNumbaNotImplementedError                  Traceback (most recent call last)\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in cast(self, builder, val, fromty, toty)\\r\\n    712             impl = self._casts.find((fromty, toty))\\r\\n--> 713             return impl(self, builder, fromty, toty, val)\\r\\n    714         except errors.NumbaNotImplementedError:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/udf/masked_lowering.py in cast_primitive_to_masked(context, builder, fromty, toty, val)\\r\\n    336 def cast_primitive_to_masked(context, builder, fromty, toty, val):\\r\\n--> 337     casted = context.cast(builder, val, fromty, toty.value_type)\\r\\n    338     ext = cgutils.create_struct_proxy(toty)(context, builder)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in cast(self, builder, val, fromty, toty)\\r\\n    714         except errors.NumbaNotImplementedError:\\r\\n--> 715             raise errors.NumbaNotImplementedError(\\r\\n    716                 \"Cannot cast %s to %s: %s\" % (fromty, toty, val))\\r\\n\\r\\nNumbaNotImplementedError: Cannot cast unicode_type to string_view: %\"inserted.parent\" = insertvalue {i8*, i64, i32, i32, i64, i8*, i8*} %\"inserted.meminfo\", i8* %\"arg.delim.6\", 6\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nNumbaNotImplementedError                  Traceback (most recent call last)\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/indexed_frame.py in _apply(self, func, kernel_getter, *args, **kwargs)\\r\\n   1817         try:\\r\\n-> 1818             kernel, retty = _compile_or_get(\\r\\n   1819                 self, func, args, kernel_getter=kernel_getter\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)\\r\\n     78             with self._recreate_cm():\\r\\n---> 79                 return func(*args, **kwds)\\r\\n     80         return inner\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/udf/utils.py in _compile_or_get(frame, func, args, kernel_getter)\\r\\n    214 \\r\\n--> 215     kernel, scalar_return_type = kernel_getter(frame, func, args)\\r\\n    216     np_return_type = numpy_support.as_dtype(scalar_return_type)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/udf/row_function.py in _get_row_kernel(frame, func, args)\\r\\n    132     )\\r\\n--> 133     scalar_return_type = _get_udf_return_type(row_type, func, args)\\r\\n    134     # this is the signature for the final full kernel compilation\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)\\r\\n     78             with self._recreate_cm():\\r\\n---> 79                 return func(*args, **kwds)\\r\\n     80         return inner\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/udf/utils.py in _get_udf_return_type(argty, func, args)\\r\\n     55     # needed here.\\r\\n---> 56     ptx, output_type = cudautils.compile_udf(func, compile_sig)\\r\\n     57     if not isinstance(output_type, MaskedType):\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/utils/cudautils.py in compile_udf(udf, type_signature)\\r\\n    249     # compilation with Numba\\r\\n--> 250     ptx_code, return_type = cuda.compile_ptx_for_current_device(\\r\\n    251         udf, type_signature, device=True\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/cuda/compiler.py in compile_ptx_for_current_device(pyfunc, args, debug, lineinfo, device, fastmath, opt)\\r\\n    289     cc = get_current_device().compute_capability\\r\\n--> 290     return compile_ptx(pyfunc, args, debug=debug, lineinfo=lineinfo,\\r\\n    291                        device=device, fastmath=fastmath, cc=cc, opt=True)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)\\r\\n     34             with self:\\r\\n---> 35                 return func(*args, **kwargs)\\r\\n     36         return _acquire_compile_lock\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/cuda/compiler.py in compile_ptx(pyfunc, args, debug, lineinfo, device, fastmath, cc, opt)\\r\\n    266 \\r\\n--> 267     cres = compile_cuda(pyfunc, None, args, debug=debug, lineinfo=lineinfo,\\r\\n    268                         nvvm_options=nvvm_options)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)\\r\\n     34             with self:\\r\\n---> 35                 return func(*args, **kwargs)\\r\\n     36         return _acquire_compile_lock\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/cuda/compiler.py in compile_cuda(pyfunc, return_type, args, debug, lineinfo, inline, fastmath, nvvm_options)\\r\\n    201     # Run compilation pipeline\\r\\n--> 202     cres = compiler.compile_extra(typingctx=typingctx,\\r\\n    203                                   targetctx=targetctx,\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\\r\\n    692                               args, return_type, flags, locals)\\r\\n--> 693     return pipeline.compile_extra(func)\\r\\n    694 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func)\\r\\n    428         self.state.lifted_from = None\\r\\n--> 429         return self._compile_bytecode()\\r\\n    430 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self)\\r\\n    496         assert self.state.func_ir is None\\r\\n--> 497         return self._compile_core()\\r\\n    498 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self)\\r\\n    475                     if is_final_pipeline:\\r\\n--> 476                         raise e\\r\\n    477             else:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self)\\r\\n    462                 try:\\r\\n--> 463                     pm.run(self.state)\\r\\n    464                     if self.state.cr is not None:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state)\\r\\n    352                 patched_exception = self._patch_error(msg, e)\\r\\n--> 353                 raise patched_exception\\r\\n    354 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state)\\r\\n    340                 if isinstance(pass_inst, CompilerPass):\\r\\n--> 341                     self._runPass(idx, pass_inst, state)\\r\\n    342                 else:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs)\\r\\n     34             with self:\\r\\n---> 35                 return func(*args, **kwargs)\\r\\n     36         return _acquire_compile_lock\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state)\\r\\n    295         with SimpleTimer() as pass_time:\\r\\n--> 296             mutated |= check(pss.run_pass, internal_state)\\r\\n    297         with SimpleTimer() as finalize_time:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state)\\r\\n    268         def check(func, compiler_state):\\r\\n--> 269             mangled = func(compiler_state)\\r\\n    270             if mangled not in (True, False):\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state)\\r\\n    393                                        metadata=metadata)\\r\\n--> 394                 lower.lower()\\r\\n    395                 if not flags.no_cpython_wrapper:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower(self)\\r\\n    195             self.genlower = None\\r\\n--> 196             self.lower_normal_function(self.fndesc)\\r\\n    197         else:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc)\\r\\n    249         self.extract_function_arguments()\\r\\n--> 250         entry_block_tail = self.lower_function_body()\\r\\n    251 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_function_body(self)\\r\\n    278             self.builder.position_at_end(bb)\\r\\n--> 279             self.lower_block(block)\\r\\n    280         self.post_lower()\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_block(self, block)\\r\\n    292                                    loc=self.loc, errcls_=defaulterrcls):\\r\\n--> 293                 self.lower_inst(inst)\\r\\n    294         self.post_block(block)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_inst(self, inst)\\r\\n    437             ty = self.typeof(inst.target.name)\\r\\n--> 438             val = self.lower_assign(ty, inst)\\r\\n    439             argidx = None\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_assign(self, ty, inst)\\r\\n    623         elif isinstance(value, ir.Expr):\\r\\n--> 624             return self.lower_expr(ty, value)\\r\\n    625 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_expr(self, resty, expr)\\r\\n   1158         elif expr.op == \\'call\\':\\r\\n-> 1159             res = self.lower_call(resty, expr)\\r\\n   1160             return res\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in lower_call(self, resty, expr)\\r\\n    888         else:\\r\\n--> 889             res = self._lower_call_normal(fnty, expr, signature)\\r\\n    890 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in _lower_call_normal(self, fnty, expr, signature)\\r\\n   1111         else:\\r\\n-> 1112             argvals = self.fold_call_args(\\r\\n   1113                 fnty, signature, expr.args, expr.vararg, expr.kws,\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in fold_call_args(self, fnty, signature, pos_args, vararg, kw_args)\\r\\n    810                                           \"when calling %s\" % (fnty,))\\r\\n--> 811             argvals = [self._cast_var(var, sigty)\\r\\n    812                        for var, sigty in zip(pos_args, signature.args)]\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in <listcomp>(.0)\\r\\n    810                                           \"when calling %s\" % (fnty,))\\r\\n--> 811             argvals = [self._cast_var(var, sigty)\\r\\n    812                        for var, sigty in zip(pos_args, signature.args)]\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/lowering.py in _cast_var(self, var, ty)\\r\\n    793             val = self.loadvar(var.name)\\r\\n--> 794         return self.context.cast(self.builder, val, varty, ty)\\r\\n    795 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/numba/core/base.py in cast(self, builder, val, fromty, toty)\\r\\n    714         except errors.NumbaNotImplementedError:\\r\\n--> 715             raise errors.NumbaNotImplementedError(\\r\\n    716                 \"Cannot cast %s to %s: %s\" % (fromty, toty, val))\\r\\n\\r\\nNumbaNotImplementedError: Failed in cuda mode pipeline (step: native lowering)\\r\\nCannot cast unicode_type to Masked(string_view): %\"inserted.parent\" = insertvalue {i8*, i64, i32, i32, i64, i8*, i8*} %\"inserted.meminfo\", i8* %\"arg.delim.6\", 6\\r\\nDuring: lowering \"$12call_method.5 = call $8load_method.3(delim, func=$8load_method.3, args=[Var(delim, 3005899295.py:6)], kws=(), vararg=None, target=None)\" at /tmp/ipykernel_2334/3005899295.py (6)\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nValueError                                Traceback (most recent call last)\\r\\n/tmp/ipykernel_2334/3005899295.py in <module>\\r\\n      6     return row[\"str_col\"].count(delim)\\r\\n      7 \\r\\n----> 8 df.apply(delim_count, args=(\"b\",), axis=1)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)\\r\\n     77         def inner(*args, **kwds):\\r\\n     78             with self._recreate_cm():\\r\\n---> 79                 return func(*args, **kwds)\\r\\n     80         return inner\\r\\n     81 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py in apply(self, func, axis, raw, result_type, args, **kwargs)\\r\\n   4089             raise ValueError(\"The `result_type` kwarg is not yet supported.\")\\r\\n   4090 \\r\\n-> 4091         return self._apply(func, _get_row_kernel, *args, **kwargs)\\r\\n   4092 \\r\\n   4093     def applymap(\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)\\r\\n     77         def inner(*args, **kwds):\\r\\n     78             with self._recreate_cm():\\r\\n---> 79                 return func(*args, **kwds)\\r\\n     80         return inner\\r\\n     81 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/indexed_frame.py in _apply(self, func, kernel_getter, *args, **kwargs)\\r\\n   1820             )\\r\\n   1821         except Exception as e:\\r\\n-> 1822             raise ValueError(\\r\\n   1823                 \"user defined function compilation failed.\"\\r\\n   1824             ) from e\\r\\n\\r\\nValueError: user defined function compilation failed.\\r\\n```\\r\\n\\r\\nnumba version: \\'0.55.2\\'\\r\\ncudf version: \\'22.10.00a+242.g387c5ff96d\\' (built from source)\\r\\n\\r\\ncc @brandon-b-miller\\ncreatedAt: 2022-09-21T16:17:00Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Randy Gelhausen\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 121}),\n",
       " Document(page_content=\": 357\\ntitle: [BUG] Grouping by a nonexistent key gives `ValueError` rather than `KeyError`\\nbody: I would expect the code below to raise a `KeyError`, but it raises a `ValueError` instead:\\r\\n\\r\\n```python\\r\\n>>> import cudf\\r\\n>>> df = cudf.DataFrame({'a': [1, 1, 2], 'b': [1, 2, 3]})\\r\\n>>> df.groupby('cd').sum() \\r\\n...\\r\\nValueError: Grouper and object must have same length\\r\\n```\\ncreatedAt: 2022-09-27T18:15:34Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 122}),\n",
       " Document(page_content=': 358\\ntitle: [FEA] Parquet reader code cleanup, re:  nested columns vs columns with lists.\\nbody: In the parquet reader there are two similar-sounding but distinct pieces of terminology:\\r\\n\\r\\n- Nested columns.  This is the same as in the cudf sense.  Anything involving structs or lists at any level.\\r\\n- Nested hierarchies.  This only involves columns (or _parts_ of columns) that contain lists (represented via repetition levels).\\r\\n\\r\\nThis causes confusion and bugs for a couple of reasons. A given (cudf) output column can contain both nested and non-nested hierarchies.  For example:\\r\\n```\\r\\n         A (struct)\\r\\n       /   \\\\\\r\\n      B     C (list)\\r\\n            |\\r\\n            D (int)\\r\\n```\\r\\nThis single output column contains two separate input column hierarchies.  A->B and A->C->D.  A->B does not contain repetition data and therefore is not a nested hierarchy.  A->C->D does contain repetition data and does constitute a nested hierarchy.  However they are _both_ nested in the cudf sense (more than 1 level deep).\\r\\n\\r\\nWe handle these two fundamental situations differently during the decoding process.  So if the two concepts get confused it can easily cause bugs.   \\r\\n\\r\\nIt would be great to do a pass that cleans this up in a comprehensive way.\\ncreatedAt: 2022-09-27T19:07:05Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 123}),\n",
       " Document(page_content=': 359\\ntitle: [BUG] sort_values on categorical column fails in dask_cudf\\nbody: **Describe the bug**\\r\\n`ddf.sort_values(col)` does not work with a `dask_cudf` DataFrame when `col` is categorical.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```python\\r\\nimport cudf\\r\\nimport dask_cudf\\r\\ndf = cudf.DataFrame({\"a\": list(\"caba\"), \"b\": list(range(4))})\\r\\ndf[\"a\"] = df[\"a\"].astype(\"category\")\\r\\nddf = dask_cudf.from_cudf(df, npartitions=2)\\r\\ndf.sort_values(\"a\")  # <-- works as expected\\r\\nddf.sort_values(\"a\")  # raises\\r\\n```\\r\\n<details>\\r\\n<summary>Traceback</summary>\\r\\n\\r\\n```python-traceback\\r\\n---------------------------------------------------------------------------\\r\\nValueError                                Traceback (most recent call last)\\r\\nCell In [7], line 1\\r\\n----> 1 ddf.sort_values(\"a\")\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/dask_cudf/core.py:256, in DataFrame.sort_values(self, by, ignore_index, max_branch, divisions, set_divisions, ascending, na_position, sort_function, sort_function_kwargs, **kwargs)\\r\\n    251 if kwargs:\\r\\n    252     raise ValueError(\\r\\n    253         f\"Unsupported input arguments passed : {list(kwargs.keys())}\"\\r\\n    254     )\\r\\n--> 256 df = sorting.sort_values(\\r\\n    257     self,\\r\\n    258     by,\\r\\n    259     max_branch=max_branch,\\r\\n    260     divisions=divisions,\\r\\n    261     set_divisions=set_divisions,\\r\\n    262     ignore_index=ignore_index,\\r\\n    263     ascending=ascending,\\r\\n    264     na_position=na_position,\\r\\n    265     sort_function=sort_function,\\r\\n    266     sort_function_kwargs=sort_function_kwargs,\\r\\n    267 )\\r\\n    269 if ignore_index:\\r\\n    270     return df.reset_index(drop=True)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/dask_cudf/sorting.py:266, in sort_values(df, by, max_branch, divisions, set_divisions, ignore_index, ascending, na_position, sort_function, sort_function_kwargs)\\r\\n    264 # Step 1 - Calculate new divisions (if necessary)\\r\\n    265 if divisions is None:\\r\\n--> 266     divisions = quantile_divisions(df, by, npartitions)\\r\\n    268 # Step 2 - Perform repartitioning shuffle\\r\\n    269 meta = df._meta._constructor_sliced([0])\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/dask_cudf/sorting.py:213, in quantile_divisions(df, by, npartitions)\\r\\n    211 dtype = df[col].dtype\\r\\n    212 if dtype != \"object\":\\r\\n--> 213     divisions[col] = divisions[col].astype(\"int64\")\\r\\n    214     divisions[col].iloc[-1] += 1\\r\\n    215     divisions[col] = divisions[col].astype(dtype)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/series.py:1857, in Series.astype(self, dtype, copy, errors, **kwargs)\\r\\n   1855 else:\\r\\n   1856     dtype = {self.name: dtype}\\r\\n-> 1857 return super().astype(dtype, copy, errors, **kwargs)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/indexed_frame.py:3264, in IndexedFrame.astype(self, dtype, copy, errors, **kwargs)\\r\\n   3262 except Exception as e:\\r\\n   3263     if errors == \"raise\":\\r\\n-> 3264         raise e\\r\\n   3265     return self\\r\\n   3267 return self._from_data(data, index=self._index)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/indexed_frame.py:3261, in IndexedFrame.astype(self, dtype, copy, errors, **kwargs)\\r\\n   3258     raise ValueError(\"invalid error value specified\")\\r\\n   3260 try:\\r\\n-> 3261     data = super().astype(dtype, copy, **kwargs)\\r\\n   3262 except Exception as e:\\r\\n   3263     if errors == \"raise\":\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/frame.py:328, in Frame.astype(self, dtype, copy, **kwargs)\\r\\n    326 dt = dtype.get(col_name, col.dtype)\\r\\n    327 if not is_dtype_equal(dt, col.dtype):\\r\\n--> 328     result[col_name] = col.astype(dt, copy=copy, **kwargs)\\r\\n    329 else:\\r\\n    330     result[col_name] = col.copy() if copy else col\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/column/column.py:857, in ColumnBase.astype(self, dtype, **kwargs)\\r\\n    851 dtype = (\\r\\n    852     pandas_dtypes_alias_to_cudf_alias.get(dtype, dtype)\\r\\n    853     if isinstance(dtype, str)\\r\\n    854     else pandas_dtypes_to_np_dtypes.get(dtype, dtype)\\r\\n    855 )\\r\\n    856 if _is_non_decimal_numeric_dtype(dtype):\\r\\n--> 857     return self.as_numerical_column(dtype, **kwargs)\\r\\n    858 elif is_categorical_dtype(dtype):\\r\\n    859     return self.as_categorical_column(dtype, **kwargs)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/column/categorical.py:1236, in CategoricalColumn.as_numerical_column(self, dtype, **kwargs)\\r\\n   1235 def as_numerical_column(self, dtype: Dtype, **kwargs) -> NumericalColumn:\\r\\n-> 1236     return self._get_decategorized_column().as_numerical_column(dtype)\\r\\n\\r\\nFile ~/miniconda3/envs/cugraph_dev15/lib/python3.9/site-packages/cudf/core/column/string.py:5312, in StringColumn.as_numerical_column(self, dtype, **kwargs)\\r\\n   5310 if out_dtype.kind in {\"i\", \"u\"}:\\r\\n   5311     if not libstrings.is_integer(string_col).all():\\r\\n-> 5312         raise ValueError(\\r\\n   5313             \"Could not convert strings to integer \"\\r\\n   5314             \"type due to presence of non-integer values.\"\\r\\n   5315         )\\r\\n   5316 elif out_dtype.kind == \"f\":\\r\\n   5317     if not libstrings.is_float(string_col).all():\\r\\n\\r\\nValueError: Could not convert strings to integer type due to presence of non-integer values.\\r\\n```\\r\\n\\r\\n</details>\\r\\n\\r\\n**Expected behavior**\\r\\nI expect it to work--that is, match the result of cudf and dask.dataframe.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Bare-metal\\r\\n - Method of cuDF install: conda\\r\\n\\r\\n**Environment details**\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n\\r\\n     **git***\\r\\n     commit 82b9922cc1635f6f0923f633a17a7c12f93ebdbe (HEAD -> pg_set_index_and_categorical, eriknw/pg_set_index_and_categorical)\\r\\n     Author: Erik Welch <erik.n.welch@gmail.com>\\r\\n     Date:   Tue Sep 27 11:28:04 2022 -0700\\r\\n\\r\\n     workaround dask_cudf issue with `sort_values` on categorical column\\r\\n     **git submodules***\\r\\n\\r\\n     ***OS Information***\\r\\n     DGX_NAME=\"DGX Server\"\\r\\n     DGX_PRETTY_NAME=\"NVIDIA DGX Server\"\\r\\n     DGX_SWBUILD_DATE=\"2020-03-04\"\\r\\n     DGX_SWBUILD_VERSION=\"4.4.0\"\\r\\n     DGX_COMMIT_ID=\"ee09ebc\"\\r\\n     DGX_PLATFORM=\"DGX Server for DGX-1\"\\r\\n     DGX_SERIAL_NUMBER=\"QTFCOU8220028\"\\r\\n\\r\\n     DGX_R418_REPO_ENABLED=20220727-142458\\r\\n\\r\\n     DGX_OTA_VERSION=\"4.13.0\"\\r\\n     DGX_OTA_DATE=\"Wed Jul 27 14:38:05 PDT 2022\"\\r\\n     DISTRIB_ID=Ubuntu\\r\\n     DISTRIB_RELEASE=18.04\\r\\n     DISTRIB_CODENAME=bionic\\r\\n     DISTRIB_DESCRIPTION=\"Ubuntu 18.04.6 LTS\"\\r\\n     NAME=\"Ubuntu\"\\r\\n     VERSION=\"18.04.6 LTS (Bionic Beaver)\"\\r\\n     ID=ubuntu\\r\\n     ID_LIKE=debian\\r\\n     PRETTY_NAME=\"Ubuntu 18.04.6 LTS\"\\r\\n     VERSION_ID=\"18.04\"\\r\\n     HOME_URL=\"https://www.ubuntu.com/\"\\r\\n     SUPPORT_URL=\"https://help.ubuntu.com/\"\\r\\n     BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\\r\\n     PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\\r\\n     VERSION_CODENAME=bionic\\r\\n     UBUNTU_CODENAME=bionic\\r\\n     Linux dgx12 4.15.0-189-generic #200-Ubuntu SMP Wed Jun 22 19:53:37 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux\\r\\n\\r\\n     ***GPU Information***\\r\\n     Tue Sep 27 12:26:17 2022\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\\r\\n     |-------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                               |                      |               MIG M. |\\r\\n     |===============================+======================+======================|\\r\\n     |   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\\r\\n     | N/A   32C    P0    42W / 300W |      3MiB / 32768MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\\r\\n     | N/A   30C    P0    42W / 300W |      3MiB / 32768MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\\r\\n     | N/A   28C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\\r\\n     | N/A   28C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\\r\\n     | N/A   30C    P0    42W / 300W |      3MiB / 32768MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\\r\\n     | N/A   30C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\\r\\n     | N/A   33C    P0    43W / 300W |      3MiB / 32768MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\\r\\n     | N/A   29C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | Processes:                                                                  |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n     |        ID   ID                                                   Usage      |\\r\\n     |=============================================================================|\\r\\n     |  No running processes found                                                 |\\r\\n     +-----------------------------------------------------------------------------+\\r\\n\\r\\n     ***CPU***\\r\\n     Architecture:        x86_64\\r\\n     CPU op-mode(s):      32-bit, 64-bit\\r\\n     Byte Order:          Little Endian\\r\\n     CPU(s):              80\\r\\n     On-line CPU(s) list: 0-79\\r\\n     Thread(s) per core:  2\\r\\n     Core(s) per socket:  20\\r\\n     Socket(s):           2\\r\\n     NUMA node(s):        2\\r\\n     Vendor ID:           GenuineIntel\\r\\n     CPU family:          6\\r\\n     Model:               79\\r\\n     Model name:          Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz\\r\\n     Stepping:            1\\r\\n     CPU MHz:             3343.606\\r\\n     CPU max MHz:         3600.0000\\r\\n     CPU min MHz:         1200.0000\\r\\n     BogoMIPS:            4389.85\\r\\n     Virtualization:      VT-x\\r\\n     L1d cache:           32K\\r\\n     L1i cache:           32K\\r\\n     L2 cache:            256K\\r\\n     L3 cache:            51200K\\r\\n     NUMA node0 CPU(s):   0-19,40-59\\r\\n     NUMA node1 CPU(s):   20-39,60-79\\r\\n     Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap intel_pt xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts md_clear flush_l1d\\r\\n\\r\\n     ***CMake***\\r\\n     /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin/cmake\\r\\n     cmake version 3.24.2\\r\\n\\r\\n     CMake suite maintained and supported by Kitware (kitware.com/cmake).\\r\\n\\r\\n     ***g++***\\r\\n     /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin/g++\\r\\n     g++ (conda-forge gcc 10.4.0-16) 10.4.0\\r\\n     Copyright (C) 2020 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n\\r\\n\\r\\n     ***nvcc***\\r\\n     /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2021 NVIDIA Corporation\\r\\n     Built on Thu_Nov_18_09:45:30_PST_2021\\r\\n     Cuda compilation tools, release 11.5, V11.5.119\\r\\n     Build cuda_11.5.r11.5/compiler.30672275_0\\r\\n\\r\\n     ***Python***\\r\\n     /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin/python\\r\\n     Python 3.9.13\\r\\n\\r\\n     ***Environment Variables***\\r\\n     PATH                            : /home/nfs/erwelch/miniconda3/envs/cugraph_dev15/bin:/home/nfs/erwelch/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\\r\\n     LD_LIBRARY_PATH                 :\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /home/nfs/erwelch/miniconda3/envs/cugraph_dev15\\r\\n     PYTHON_PATH                     :\\r\\n\\r\\n     ***conda packages***\\r\\n     /home/nfs/erwelch/miniconda3/condabin/conda\\r\\n     # packages in environment at /home/nfs/erwelch/miniconda3/envs/cugraph_dev15:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                       2_gnu    conda-forge\\r\\n     alabaster                 0.7.12                     py_0    conda-forge\\r\\n     argon2-cffi               21.3.0             pyhd8ed1ab_0    conda-forge\\r\\n     argon2-cffi-bindings      21.2.0           py39hb9d737c_2    conda-forge\\r\\n     arrow-cpp                 9.0.0           py39hd3ccb9b_2_cpu    conda-forge\\r\\n     asttokens                 2.0.8              pyhd8ed1ab_0    conda-forge\\r\\n     asvdb                     0.4.2               g90e8f2c_40    rapidsai\\r\\n     attrs                     22.1.0             pyh71513ae_1    conda-forge\\r\\n     aws-c-cal                 0.5.11               h95a6274_0    conda-forge\\r\\n     aws-c-common              0.6.2                h7f98852_0    conda-forge\\r\\n     aws-c-event-stream        0.2.7               h3541f99_13    conda-forge\\r\\n     aws-c-io                  0.10.5               hfb6a706_0    conda-forge\\r\\n     aws-checksums             0.1.11               ha31a3da_7    conda-forge\\r\\n     aws-sdk-cpp               1.8.186              hb4091e7_3    conda-forge\\r\\n     babel                     2.10.3             pyhd8ed1ab_0    conda-forge\\r\\n     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\\r\\n     backports                 1.0                        py_2    conda-forge\\r\\n     backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\\r\\n     beautifulsoup4            4.11.1             pyha770c72_0    conda-forge\\r\\n     binutils                  2.36.1               hdd6e379_2    conda-forge\\r\\n     binutils_impl_linux-64    2.36.1               h193b22a_2    conda-forge\\r\\n     binutils_linux-64         2.36                hf3e587d_10    conda-forge\\r\\n     bleach                    5.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     bokeh                     2.4.3              pyhd8ed1ab_3    conda-forge\\r\\n     boost                     1.80.0           py39hac2352c_1    conda-forge\\r\\n     boost-cpp                 1.80.0               h75c5d50_0    conda-forge\\r\\n     boto3                     1.24.81            pyhd8ed1ab_0    conda-forge\\r\\n     botocore                  1.27.81            pyhd8ed1ab_0    conda-forge\\r\\n     brotlipy                  0.7.0           py39hb9d737c_1004    conda-forge\\r\\n     bzip2                     1.0.8                h7f98852_4    conda-forge\\r\\n     c-ares                    1.18.1               h7f98852_0    conda-forge\\r\\n     c-compiler                1.5.0                h166bdaf_0    conda-forge\\r\\n     ca-certificates           2022.9.24            ha878542_0    conda-forge\\r\\n     cachetools                5.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     certifi                   2022.9.24          pyhd8ed1ab_0    conda-forge\\r\\n     cffi                      1.15.1           py39he91dace_0    conda-forge\\r\\n     charset-normalizer        2.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     clang                     11.1.0               ha770c72_1    conda-forge\\r\\n     clang-11                  11.1.0          default_ha53f305_1    conda-forge\\r\\n     clang-tools               11.1.0          default_ha53f305_1    conda-forge\\r\\n     clangxx                   11.1.0          default_ha53f305_1    conda-forge\\r\\n     click                     8.1.3            py39hf3d152e_0    conda-forge\\r\\n     cloudpickle               2.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     cmake                     3.24.2               h5432695_0    conda-forge\\r\\n     colorama                  0.4.5              pyhd8ed1ab_0    conda-forge\\r\\n     commonmark                0.9.1                      py_0    conda-forge\\r\\n     coverage                  6.4.4            py39hb9d737c_0    conda-forge\\r\\n     cryptography              37.0.4           py39hd97740a_0    conda-forge\\r\\n     cuda-python               11.7.0           py39h3fd9d12_0    nvidia\\r\\n     cudatoolkit               11.5.1               hcf5317a_9    nvidia\\r\\n     cudf                      22.10.00a220920 cuda_11_py39_g0528b38f2b_241    rapidsai-nightly\\r\\n     cugraph                   22.10.0a0+84.gc2f983f0          pypi_0    pypi\\r\\n     cupy                      11.1.0           py39hc3c280e_0    conda-forge\\r\\n     cxx-compiler              1.5.0                h924138e_0    conda-forge\\r\\n     cython                    0.29.32          py39h5a03fae_0    conda-forge\\r\\n     cytoolz                   0.12.0           py39hb9d737c_0    conda-forge\\r\\n     dask                      2022.9.1           pyhd8ed1ab_0    conda-forge\\r\\n     dask-core                 2022.9.1           pyhd8ed1ab_0    conda-forge\\r\\n     dask-cuda                 22.10.00a220927 py39_g8de9ce3_19    rapidsai-nightly\\r\\n     dask-cudf                 22.10.00a220920 cuda_11_py39_g0528b38f2b_241    rapidsai-nightly\\r\\n     debugpy                   1.6.3            py39h5a03fae_0    conda-forge\\r\\n     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     distributed               2022.9.1           pyhd8ed1ab_0    conda-forge\\r\\n     distro                    1.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     dlpack                    0.5                  h9c3ff4c_0    conda-forge\\r\\n     docutils                  0.19             py39hf3d152e_0    conda-forge\\r\\n     doxygen                   1.9.5                h583eb01_0    conda-forge\\r\\n     entrypoints               0.4                pyhd8ed1ab_0    conda-forge\\r\\n     executing                 1.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     expat                     2.4.9                h27087fc_0    conda-forge\\r\\n     fastavro                  1.6.1            py39hb9d737c_0    conda-forge\\r\\n     fastrlock                 0.8              py39h5a03fae_2    conda-forge\\r\\n     flake8                    5.0.4              pyhd8ed1ab_0    conda-forge\\r\\n     flit-core                 3.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     freetype                  2.12.1               hca18f0e_0    conda-forge\\r\\n     fsspec                    2022.8.2           pyhd8ed1ab_0    conda-forge\\r\\n     future                    0.18.2           py39hf3d152e_5    conda-forge\\r\\n     gcc                       10.4.0              hb92f740_10    conda-forge\\r\\n     gcc_impl_linux-64         10.4.0              h7ee1905_16    conda-forge\\r\\n     gcc_linux-64              10.4.0              h9215b83_10    conda-forge\\r\\n     gflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\n     gh                        2.16.1               ha8f183a_0    conda-forge\\r\\n     glog                      0.6.0                h6f12383_0    conda-forge\\r\\n     gmock                     1.10.0               h4bd325d_7    conda-forge\\r\\n     grpc-cpp                  1.47.1               hbad87ad_6    conda-forge\\r\\n     gtest                     1.10.0               h4bd325d_7    conda-forge\\r\\n     gxx                       10.4.0              hb92f740_10    conda-forge\\r\\n     gxx_impl_linux-64         10.4.0              h7ee1905_16    conda-forge\\r\\n     gxx_linux-64              10.4.0              h6e491c6_10    conda-forge\\r\\n     heapdict                  1.0.1                      py_0    conda-forge\\r\\n     icecream                  2.1.3              pyhd8ed1ab_0    conda-forge\\r\\n     icu                       70.1                 h27087fc_0    conda-forge\\r\\n     idna                      3.4                pyhd8ed1ab_0    conda-forge\\r\\n     imagesize                 1.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     importlib-metadata        4.11.4           py39hf3d152e_0    conda-forge\\r\\n     importlib_resources       5.9.0              pyhd8ed1ab_0    conda-forge\\r\\n     iniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge\\r\\n     ipykernel                 6.16.0             pyh210e3f2_0    conda-forge\\r\\n     ipython                   8.5.0              pyh41d4057_1    conda-forge\\r\\n     ipython_genutils          0.2.0                      py_1    conda-forge\\r\\n     jedi                      0.18.1             pyhd8ed1ab_2    conda-forge\\r\\n     jinja2                    3.1.2              pyhd8ed1ab_1    conda-forge\\r\\n     jmespath                  1.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     joblib                    1.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     jpeg                      9e                   h166bdaf_2    conda-forge\\r\\n     jsonschema                4.16.0             pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_client            7.3.4              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_core              4.11.1           py39hf3d152e_0    conda-forge\\r\\n     jupyterlab_pygments       0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     kernel-headers_linux-64   2.6.32              he073ed8_15    conda-forge\\r\\n     keyutils                  1.6.1                h166bdaf_0    conda-forge\\r\\n     krb5                      1.19.3               h3790be6_0    conda-forge\\r\\n     lcms2                     2.12                 hddcbb42_0    conda-forge\\r\\n     ld_impl_linux-64          2.36.1               hea4e1c9_2    conda-forge\\r\\n     lerc                      4.0.0                h27087fc_0    conda-forge\\r\\n     libabseil                 20220623.0      cxx17_h48a1fff_4    conda-forge\\r\\n     libblas                   3.9.0           16_linux64_openblas    conda-forge\\r\\n     libbrotlicommon           1.0.9                h166bdaf_7    conda-forge\\r\\n     libbrotlidec              1.0.9                h166bdaf_7    conda-forge\\r\\n     libbrotlienc              1.0.9                h166bdaf_7    conda-forge\\r\\n     libcblas                  3.9.0           16_linux64_openblas    conda-forge\\r\\n     libclang-cpp11.1          11.1.0          default_ha53f305_1    conda-forge\\r\\n     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge\\r\\n     libcudf                   22.10.00a220920 cuda11_g0528b38f2b_241    rapidsai-nightly\\r\\n     libcugraphops             22.10.00a220927 cuda11_g553bacf_29    rapidsai-nightly\\r\\n     libcurl                   7.83.1               h7bff187_0    conda-forge\\r\\n     libcusolver               11.4.0.1                      0    nvidia\\r\\n     libcusparse               11.7.4.91                     0    nvidia\\r\\n     libdeflate                1.14                 h166bdaf_0    conda-forge\\r\\n     libedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\n     libev                     4.33                 h516909a_1    conda-forge\\r\\n     libevent                  2.1.10               h9b69904_4    conda-forge\\r\\n     libffi                    3.4.2                h7f98852_5    conda-forge\\r\\n     libgcc-devel_linux-64     10.4.0              h74af60c_16    conda-forge\\r\\n     libgcc-ng                 12.1.0              h8d9b700_16    conda-forge\\r\\n     libgfortran-ng            12.1.0              h69a702a_16    conda-forge\\r\\n     libgfortran5              12.1.0              hdcd56e2_16    conda-forge\\r\\n     libgomp                   12.1.0              h8d9b700_16    conda-forge\\r\\n     libgoogle-cloud           2.1.0                h9ebe8e8_2    conda-forge\\r\\n     libiconv                  1.17                 h166bdaf_0    conda-forge\\r\\n     liblapack                 3.9.0           16_linux64_openblas    conda-forge\\r\\n     libllvm11                 11.1.0               hf817b99_3    conda-forge\\r\\n     libnghttp2                1.47.0               hdcd2b5c_1    conda-forge\\r\\n     libnsl                    2.0.0                h7f98852_0    conda-forge\\r\\n     libopenblas               0.3.21          pthreads_h78a6416_3    conda-forge\\r\\n     libpng                    1.6.38               h753d276_0    conda-forge\\r\\n     libprotobuf               3.20.1               h6239696_4    conda-forge\\r\\n     libraft-distance          22.10.00a220927 cuda11_g1dd2feb1_54    rapidsai-nightly\\r\\n     libraft-headers           22.10.00a220927 cuda11_g1dd2feb1_54    rapidsai-nightly\\r\\n     librmm                    22.10.00a220927 cuda11_g6e0d65a9_20    rapidsai-nightly\\r\\n     libsanitizer              10.4.0              hde28e3b_16    conda-forge\\r\\n     libsodium                 1.0.18               h36c2ea0_1    conda-forge\\r\\n     libsqlite                 3.39.3               h753d276_0    conda-forge\\r\\n     libssh2                   1.10.0               haa6b8db_3    conda-forge\\r\\n     libstdcxx-devel_linux-64  10.4.0              h74af60c_16    conda-forge\\r\\n     libstdcxx-ng              12.1.0              ha89aaad_16    conda-forge\\r\\n     libthrift                 0.16.0               h491838f_2    conda-forge\\r\\n     libtiff                   4.4.0                h55922b4_4    conda-forge\\r\\n     libutf8proc               2.7.0                h7f98852_0    conda-forge\\r\\n     libuuid                   2.32.1            h7f98852_1000    conda-forge\\r\\n     libuv                     1.44.2               h166bdaf_0    conda-forge\\r\\n     libwebp-base              1.2.4                h166bdaf_0    conda-forge\\r\\n     libxcb                    1.13              h7f98852_1004    conda-forge\\r\\n     libxml2                   2.10.2               h4c7fe37_1    conda-forge\\r\\n     libxslt                   1.1.35               h8affb1d_0    conda-forge\\r\\n     libzlib                   1.2.12               h166bdaf_3    conda-forge\\r\\n     llvmlite                  0.38.1           py39h7d9a04d_0    conda-forge\\r\\n     locket                    1.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     lxml                      4.9.1            py39hb9d737c_0    conda-forge\\r\\n     lz4                       4.0.0            py39h029007f_2    conda-forge\\r\\n     lz4-c                     1.9.3                h9c3ff4c_1    conda-forge\\r\\n     make                      4.3                  hd18ef5c_1    conda-forge\\r\\n     markdown                  3.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     markupsafe                2.1.1            py39hb9d737c_1    conda-forge\\r\\n     matplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge\\r\\n     mccabe                    0.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     mistune                   2.0.4              pyhd8ed1ab_0    conda-forge\\r\\n     msgpack-python            1.0.4            py39hf939315_0    conda-forge\\r\\n     nbclient                  0.6.8              pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert                 7.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert-core            7.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert-pandoc          7.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     nbformat                  5.6.1              pyhd8ed1ab_0    conda-forge\\r\\n     nbsphinx                  0.8.9              pyhd8ed1ab_0    conda-forge\\r\\n     nccl                      2.14.3.1             h0800d71_0    conda-forge\\r\\n     ncurses                   6.3                  h27087fc_1    conda-forge\\r\\n     nest-asyncio              1.5.5              pyhd8ed1ab_0    conda-forge\\r\\n     networkx                  2.8.6              pyhd8ed1ab_0    conda-forge\\r\\n     notebook                  6.4.12             pyha770c72_0    conda-forge\\r\\n     numba                     0.55.2           py39h66db6d7_0    conda-forge\\r\\n     numpy                     1.22.4           py39hc58783e_0    conda-forge\\r\\n     numpydoc                  1.4.0              pyhd8ed1ab_1    conda-forge\\r\\n     nvcc_linux-64             10.1                hcaf9a05_10\\r\\n     nvtx                      0.2.3            py39h3811e60_1    conda-forge\\r\\n     openjpeg                  2.5.0                h7d73246_1    conda-forge\\r\\n     openssl                   1.1.1q               h166bdaf_0    conda-forge\\r\\n     orc                       1.7.6                h6c59b99_0    conda-forge\\r\\n     packaging                 21.3               pyhd8ed1ab_0    conda-forge\\r\\n     pandas                    1.4.4            py39h1832856_0    conda-forge\\r\\n     pandoc                    2.19.2               ha770c72_0    conda-forge\\r\\n     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     parquet-cpp               1.5.1                         2    conda-forge\\r\\n     parso                     0.8.3              pyhd8ed1ab_0    conda-forge\\r\\n     partd                     1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\\r\\n     pickleshare               0.7.5                   py_1003    conda-forge\\r\\n     pillow                    9.2.0            py39hd5dbb17_2    conda-forge\\r\\n     pip                       22.2.2             pyhd8ed1ab_0    conda-forge\\r\\n     pkgutil-resolve-name      1.3.10             pyhd8ed1ab_0    conda-forge\\r\\n     pluggy                    1.0.0            py39hf3d152e_3    conda-forge\\r\\n     prometheus_client         0.14.1             pyhd8ed1ab_0    conda-forge\\r\\n     prompt-toolkit            3.0.31             pyha770c72_0    conda-forge\\r\\n     protobuf                  3.20.1           py39h5a03fae_0    conda-forge\\r\\n     psutil                    5.9.2            py39hb9d737c_0    conda-forge\\r\\n     pthread-stubs             0.4               h36c2ea0_1001    conda-forge\\r\\n     ptxcompiler               0.2.0            py39h107f55c_0    rapidsai\\r\\n     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\\r\\n     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     py                        1.11.0             pyh6c4a22f_0    conda-forge\\r\\n     py-cpuinfo                8.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     pyarrow                   9.0.0           py39hc0775d8_2_cpu    conda-forge\\r\\n     pycodestyle               2.9.1              pyhd8ed1ab_0    conda-forge\\r\\n     pycparser                 2.21               pyhd8ed1ab_0    conda-forge\\r\\n     pydata-sphinx-theme       0.10.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyflakes                  2.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     pygal                     2.4.0                      py_0    conda-forge\\r\\n     pygments                  2.13.0             pyhd8ed1ab_0    conda-forge\\r\\n     pylibcugraph              22.10.0a0+84.gc2f983f0           dev_0    <develop>\\r\\n     pylibraft                 22.10.00a220927 cuda11_py39_g1dd2feb1_54    rapidsai-nightly\\r\\n     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyopenssl                 22.0.0             pyhd8ed1ab_1    conda-forge\\r\\n     pyparsing                 3.0.9              pyhd8ed1ab_0    conda-forge\\r\\n     pyrsistent                0.18.1           py39hb9d737c_1    conda-forge\\r\\n     pysocks                   1.7.1              pyha2e5f31_6    conda-forge\\r\\n     pytest                    7.1.3            py39hf3d152e_0    conda-forge\\r\\n     pytest-benchmark          3.2.3              pyh9f0ad1d_0    conda-forge\\r\\n     pytest-cov                3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     python                    3.9.13          h9a8a25e_0_cpython    conda-forge\\r\\n     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\\r\\n     python-fastjsonschema     2.16.2             pyhd8ed1ab_0    conda-forge\\r\\n     python_abi                3.9                      2_cp39    conda-forge\\r\\n     pytz                      2022.2.1           pyhd8ed1ab_0    conda-forge\\r\\n     pyyaml                    6.0              py39hb9d737c_4    conda-forge\\r\\n     pyzmq                     24.0.1           py39headdf64_0    conda-forge\\r\\n     raft-dask                 22.10.00a220927 cuda11_py39_g1dd2feb1_54    rapidsai-nightly\\r\\n     rapids-pytest-benchmark   0.0.14                     py_0    rapidsai\\r\\n     re2                       2022.06.01           h27087fc_0    conda-forge\\r\\n     readline                  8.1.2                h0f457ee_0    conda-forge\\r\\n     recommonmark              0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     requests                  2.28.1             pyhd8ed1ab_1    conda-forge\\r\\n     rhash                     1.4.3                h166bdaf_0    conda-forge\\r\\n     rmm                       22.10.00a220927 cuda11_py39_g6e0d65a9_20    rapidsai-nightly\\r\\n     s2n                       1.0.10               h9b69904_0    conda-forge\\r\\n     s3transfer                0.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     scikit-build              0.15.0             pyhb871ab6_0    conda-forge\\r\\n     scikit-learn              1.1.2            py39he5e8d7e_0    conda-forge\\r\\n     scipy                     1.9.1            py39h8ba3f38_0    conda-forge\\r\\n     send2trash                1.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     setuptools                65.4.0                   pypi_0    pypi\\r\\n     six                       1.16.0             pyh6c4a22f_0    conda-forge\\r\\n     snappy                    1.1.9                hbd366e4_1    conda-forge\\r\\n     snowballstemmer           2.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     soupsieve                 2.3.2.post1        pyhd8ed1ab_0    conda-forge\\r\\n     spdlog                    1.8.5                h4bd325d_1    conda-forge\\r\\n     sphinx                    5.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     sphinx-copybutton         0.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     sphinx-markdown-tables    0.0.17             pyh6c4a22f_0    conda-forge\\r\\n     sphinxcontrib-applehelp   1.0.2                      py_0    conda-forge\\r\\n     sphinxcontrib-devhelp     1.0.2                      py_0    conda-forge\\r\\n     sphinxcontrib-htmlhelp    2.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     sphinxcontrib-jsmath      1.0.1                      py_0    conda-forge\\r\\n     sphinxcontrib-qthelp      1.0.3                      py_0    conda-forge\\r\\n     sphinxcontrib-serializinghtml 1.1.5              pyhd8ed1ab_2    conda-forge\\r\\n     sphinxcontrib-websupport  1.2.4              pyhd8ed1ab_1    conda-forge\\r\\n     sqlite                    3.39.3               h4ff8645_0    conda-forge\\r\\n     stack_data                0.5.1              pyhd8ed1ab_0    conda-forge\\r\\n     sysroot_linux-64          2.12                he073ed8_15    conda-forge\\r\\n     tblib                     1.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     terminado                 0.15.0           py39hf3d152e_0    conda-forge\\r\\n     threadpoolctl             3.1.0              pyh8a188c0_0    conda-forge\\r\\n     tinycss2                  1.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     tk                        8.6.12               h27826a3_0    conda-forge\\r\\n     toml                      0.10.2             pyhd8ed1ab_0    conda-forge\\r\\n     tomli                     2.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     toolz                     0.12.0             pyhd8ed1ab_0    conda-forge\\r\\n     tornado                   6.1              py39hb9d737c_3    conda-forge\\r\\n     traitlets                 5.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     typing_extensions         4.3.0              pyha770c72_0    conda-forge\\r\\n     tzdata                    2022d                h191b570_0    conda-forge\\r\\n     ucx                       1.13.1               h538f049_0    conda-forge\\r\\n     ucx-proc                  1.0.0                       gpu    rapidsai\\r\\n     ucx-py                    0.28.00a220926  py39_g8e07f67_25    rapidsai-nightly\\r\\n     urllib3                   1.26.11            pyhd8ed1ab_0    conda-forge\\r\\n     wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\\r\\n     webencodings              0.5.1                      py_1    conda-forge\\r\\n     wheel                     0.37.1             pyhd8ed1ab_0    conda-forge\\r\\n     xorg-libxau               1.0.9                h7f98852_0    conda-forge\\r\\n     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\\r\\n     xz                        5.2.6                h166bdaf_0    conda-forge\\r\\n     yaml                      0.2.5                h7f98852_2    conda-forge\\r\\n     zeromq                    4.3.4                h9c3ff4c_1    conda-forge\\r\\n     zict                      2.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     zipp                      3.8.1              pyhd8ed1ab_0    conda-forge\\r\\n     zlib                      1.2.12               h166bdaf_3    conda-forge\\r\\n     zstd                      1.5.2                h6239696_4    conda-forge\\r\\n\\r\\n</pre></details>\\r\\n**Additional context**\\r\\nEncountered in ProperterGraph in cugraph.\\ncreatedAt: 2022-09-27T19:29:34Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Erik Welch\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 124}),\n",
       " Document(page_content=': 360\\ntitle: [QST] OOM issue while loading the 26GB twitter dataset into 128GB GPU memory\\nbody: Hey I try to load the twitter graph in a AWS `p3.16xlarge` instance, which has 8 16GB memory GPUs, in total 128GB. However, it is OOM. Could you please take a look if I missed anything? Thanks so much!\\r\\n\\r\\n```python\\r\\nimport dask\\r\\nfrom dask_cuda import LocalCUDACluster\\r\\nfrom dask.distributed import Client\\r\\nimport dask_cudf\\r\\nimport cugraph\\r\\nimport cugraph.dask as dask_cugraph\\r\\nfrom cugraph.dask.common.mg_utils import get_visible_devices\\r\\nfrom cugraph.dask.comms import comms as Comms\\r\\nimport time\\r\\n\\r\\ncsv_file_name = \"twitter-2010.csv\"\\r\\n\\r\\nwith dask.config.set(jit_unspill=True):\\r\\n    with LocalCUDACluster(n_workers=8, device_memory_limit=\"16GB\") as cluster:\\r\\n        with Client(cluster) as client:\\r\\n            client.wait_for_workers(len(get_visible_devices()))\\r\\n            Comms.initialize(p2p=True)\\r\\n            chunksize = dask_cugraph.get_chunksize(csv_file_name)\\r\\n            ddf = dask_cudf.read_csv(csv_file_name, chunksize=chunksize, delimiter=\\' \\', names=[\\'src\\', \\'dst\\'], dtype=[\\'int32\\', \\'int32\\'])\\r\\n            ddf.compute()\\r\\n            # G = cugraph.Graph(directed=True)\\r\\n            # G.from_dask_cudf_edgelist(ddf, source=\\'src\\', destination=\\'dst\\')\\r\\n```\\r\\n\\r\\nI can\\'t find similar issues,  this [one](https://github.com/rapidsai/cudf/issues/6087) got similar errors but it is because LocalCUDACluster is not used.\\r\\n\\r\\nI used the docker approach to install the rapid frameworks:\\r\\n\\r\\n```cmd\\r\\ndocker pull rapidsai/rapidsai-dev:22.08-cuda11.5-devel-ubuntu20.04-py3.9\\r\\ndocker run --gpus all --rm -it \\\\\\r\\n    --shm-size=10g --ulimit memlock=-1 \\\\\\r\\n    -p 8888:8888 -p 8787:8787 -p 8786:8786 \\\\\\r\\n    rapidsai/rapidsai-dev:22.08-cuda11.5-devel-ubuntu20.04-py3.9\\r\\n```\\r\\n\\r\\nThe error log:\\r\\n\\r\\n```\\r\\n2022-09-27 13:03:21,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,524 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,597 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\\r\\n2022-09-27 13:03:21,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\\r\\n---------------------------------------------------------------------------\\r\\nMemoryError                               Traceback (most recent call last)\\r\\n/tmp/ipykernel_5947/1798640855.py in <module>\\r\\n      9             chunksize = dask_cugraph.get_chunksize(csv_file_name)\\r\\n     10             ddf = dask_cudf.read_csv(csv_file_name, chunksize=chunksize, delimiter=\\' \\', names=[\\'src\\', \\'dst\\'], dtype=[\\'int32\\', \\'int32\\'])\\r\\n---> 11             ddf.compute()\\r\\n     12             # G = cugraph.Graph(directed=True)\\r\\n     13             # G.from_dask_cudf_edgelist(ddf, source=\\'src\\', destination=\\'dst\\')\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/base.py in compute(self, **kwargs)\\r\\n    313         dask.base.compute\\r\\n    314         \"\"\"\\r\\n--> 315         (result,) = compute(self, traverse=False, **kwargs)\\r\\n    316         return result\\r\\n    317 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/base.py in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\\r\\n    597 \\r\\n    598     results = schedule(dsk, keys, **kwargs)\\r\\n--> 599     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\\r\\n    600 \\r\\n    601 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/base.py in <listcomp>(.0)\\r\\n    597 \\r\\n    598     results = schedule(dsk, keys, **kwargs)\\r\\n--> 599     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\\r\\n    600 \\r\\n    601 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/core.py in finalize(results)\\r\\n    136 \\r\\n    137 def finalize(results):\\r\\n--> 138     return _concat(results)\\r\\n    139 \\r\\n    140 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask_cuda-22.8.0-py3.9.egg/dask_cuda/proxify_device_objects.py in wrapper(*args, **kwargs)\\r\\n    167     @functools.wraps(func)\\r\\n    168     def wrapper(*args, **kwargs):\\r\\n--> 169         ret = func(*args, **kwargs)\\r\\n    170         if dask.config.get(\"jit-unspill-compatibility-mode\", default=False):\\r\\n    171             ret = unproxify_device_objects(ret, skip_explicit_proxies=False)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/core.py in _concat(args, ignore_index)\\r\\n    131         args[0]\\r\\n    132         if not args2\\r\\n--> 133         else methods.concat(args2, uniform=True, ignore_index=ignore_index)\\r\\n    134     )\\r\\n    135 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/dispatch.py in concat(dfs, axis, join, uniform, filter_warning, ignore_index, **kwargs)\\r\\n     60     else:\\r\\n     61         func = concat_dispatch.dispatch(type(dfs[0]))\\r\\n---> 62         return func(\\r\\n     63             dfs,\\r\\n     64             axis=axis,\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask_cuda-22.8.0-py3.9.egg/dask_cuda/proxy_object.py in wrapper(*args, **kwargs)\\r\\n    900         args = [unproxy(d) for d in args]\\r\\n    901         kwargs = {k: unproxy(v) for k, v in kwargs.items()}\\r\\n--> 902         return func(*args, **kwargs)\\r\\n    903 \\r\\n    904     return wrapper\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/dispatch.py in concat(dfs, axis, join, uniform, filter_warning, ignore_index, **kwargs)\\r\\n     60     else:\\r\\n     61         func = concat_dispatch.dispatch(type(dfs[0]))\\r\\n---> 62         return func(\\r\\n     63             dfs,\\r\\n     64             axis=axis,\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)\\r\\n     77         def inner(*args, **kwds):\\r\\n     78             with self._recreate_cm():\\r\\n---> 79                 return func(*args, **kwds)\\r\\n     80         return inner\\r\\n     81 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/dask_cudf/backends.py in concat_cudf(dfs, axis, join, uniform, filter_warning, sort, ignore_index, **kwargs)\\r\\n    273         )\\r\\n    274 \\r\\n--> 275     return cudf.concat(dfs, axis=axis, ignore_index=ignore_index)\\r\\n    276 \\r\\n    277 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/reshape.py in concat(objs, axis, join, ignore_index, sort)\\r\\n    397                 # don\\'t filter out empty df\\'s\\r\\n    398                 objs = old_objs\\r\\n--> 399             result = cudf.DataFrame._concat(\\r\\n    400                 objs,\\r\\n    401                 axis=axis,\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/contextlib.py in inner(*args, **kwds)\\r\\n     77         def inner(*args, **kwds):\\r\\n     78             with self._recreate_cm():\\r\\n---> 79                 return func(*args, **kwds)\\r\\n     80         return inner\\r\\n     81 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py in _concat(cls, objs, axis, join, ignore_index, sort)\\r\\n   1674         # Concatenate the Tables\\r\\n   1675         out = cls._from_data(\\r\\n-> 1676             *libcudf.concat.concat_tables(\\r\\n   1677                 tables, ignore_index=ignore_index or are_all_range_index\\r\\n   1678             )\\r\\n\\r\\nconcat.pyx in cudf._lib.concat.concat_tables()\\r\\n\\r\\nconcat.pyx in cudf._lib.concat.concat_tables()\\r\\n```\\ncreatedAt: 2022-09-27T20:05:54Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: zhao feng\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 125}),\n",
       " Document(page_content=': 365\\ntitle: [FEA] dataframe.corr() missing \"kendall\" method\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nPandas has 4 options for the methods parameter in the corr() function: \"pearson\", \"spearman\", \"kendall\", and \"callable\" which accepts a callable object instead of a predetermined algorithm: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\\r\\n\\r\\n CuDF currently only supports \"pearson\" and \"spearman\": https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.corr.html\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nCan we evaluate cudf and dask+cudf to implement the \"kendall\" correlation method?\\r\\n\\r\\n**Context**\\r\\nNVIDIA Solutions Architect, filing on behalf of customer\\r\\n\\r\\nRelated request for \"callable\" method: https://github.com/rapidsai/cudf/issues/11926\\ncreatedAt: 2022-10-14T18:00:17Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 126}),\n",
       " Document(page_content=': 366\\ntitle: [FEA] dataframe.mode() axis parameter not supported\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThe cudf documentation lists the mode function\\'s {axis=0,1} parameter, but then has an additional note that \"axis parameter is currently not supported.\":  https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.mode.html \\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nIs this feature possible to be implemented? Or is there an underlying challenge with replicating this pandas functionality in cudf?\\r\\n\\r\\n**Additional context**\\r\\nNVIDIA Solutions Architect, filing on behalf of customer\\ncreatedAt: 2022-10-14T18:08:52Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 127}),\n",
       " Document(page_content=': 367\\ntitle: [FEA] dataframe.corr() missing \"callable\" method\\nbody: Is your feature request related to a problem? Please describe.\\r\\nPandas has 4 options for the methods parameter in the corr() function: \"pearson\", \"spearman\", \"kendall\", and \"callable\" which accepts a callable object instead of a predetermined algorithm: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\\r\\n\\r\\nCuDF currently only supports \"pearson\" and \"spearman\": https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.corr.html\\r\\n\\r\\nDescribe the solution you\\'d like\\r\\nIs it feasible to implement \"callable\" methods in cudf and dask+cudf?\\r\\n\\r\\nContext\\r\\nNVIDIA Solutions Architect, filing on behalf of customer\\r\\n\\r\\nrelated request for \"kendall\" method: https://github.com/rapidsai/cudf/issues/11924\\ncreatedAt: 2022-10-14T18:52:08Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 128}),\n",
       " Document(page_content=\": 368\\ntitle: [BUG] Assignment of string list to column doesn't work\\nbody: **Describe the bug**\\r\\n\\r\\nThis does not work:\\r\\n\\r\\ndf.loc[df['column'] =='value', 'column2'] = ['0','1']\\r\\n\\r\\nTypeError: Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()\\r\\nTo explicitly construct a host matrix, consider using .to_numpy().\\r\\n\\r\\nIntegers do work:\\r\\ndf.loc[df['column']=='value', 'column2'] = [0,1]\\r\\n\\r\\nBoth work in pandas.\\r\\n\\r\\nRapids 22.08\\r\\nUbuntu 20\\ncreatedAt: 2022-10-19T06:53:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Üllar Kask\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 129}),\n",
       " Document(page_content=\": 370\\ntitle: [FEA] cudf.DataFrame.filter\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code from pandas into cudf, trying to use `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n`cudf.DataFrame.filter` matching https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html\\ncreatedAt: 2022-10-21T13:55:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 130}),\n",
       " Document(page_content=': 371\\ntitle: [BUG] semantic mismatch for Int64 and int64\\nbody: **Describe the bug**\\r\\nrewriting code from pandas to cudf, using `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\n```\\r\\n$ python\\r\\nPython 3.9.13 (main, May 18 2022, 00:00:00) \\r\\n[GCC 11.3.1 20220421 (Red Hat 11.3.1-2)] on linux\\r\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\r\\n>>> import pandas, cudf\\r\\n\\r\\n>>> pandas.__version__\\r\\n\\'1.5.1\\'\\r\\n\\r\\n>>> cudf.__version__\\r\\n\\'22.10.00a+392.g1558403753\\'\\r\\n\\r\\n>>> pandas.Series([1, None], dtype=\"Int64\")\\r\\n0       1\\r\\n1    <NA>\\r\\ndtype: Int64\\r\\n\\r\\n>>> pandas.Series([1, None], dtype=\"int64\")\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \".../python3.9/site-packages/pandas/core/series.py\", line 470, in __init__\\r\\n    data = sanitize_array(data, index, dtype, copy)\\r\\n  File \".../python3.9/site-packages/pandas/core/construction.py\", line 622, in sanitize_array\\r\\n    subarr = _try_cast(data, dtype, copy, raise_cast_failure)\\r\\n  File \".../python3.9/site-packages/pandas/core/construction.py\", line 835, in _try_cast\\r\\n    subarr = maybe_cast_to_integer_array(arr, dtype)\\r\\n  File \".../python3.9/site-packages/pandas/core/dtypes/cast.py\", line 1834, in maybe_cast_to_integer_array\\r\\n    casted = np.array(arr, dtype=dtype, copy=copy)\\r\\nTypeError: int() argument must be a string, a bytes-like object or a number, not \\'NoneType\\'\\r\\n\\r\\n>>> cudf.Series([1, None], dtype=\"Int64\")\\r\\nTraceback (most recent call last):\\r\\n  File \".../python3.9/site-packages/cudf/core/column/column.py\", line 2038, in as_column\\r\\n    memoryview(arbitrary), dtype=dtype, nan_as_null=nan_as_null\\r\\nTypeError: memoryview: a bytes-like object is required, not \\'list\\'\\r\\nDuring handling of the above exception, another exception occurred:\\r\\nTraceback (most recent call last):\\r\\n  File \".../python3.9/site-packages/cudf/core/column/column.py\", line 2127, in as_column\\r\\n    np_type = np.dtype(dtype).type\\r\\nTypeError: data type \\'Int64\\' not understood\\r\\nDuring handling of the above exception, another exception occurred:\\r\\nTraceback (most recent call last):\\r\\n  File \".../python3.9/site-packages/cudf/core/column/column.py\", line 2199, in _construct_array\\r\\n    arbitrary = cupy.asarray(arbitrary, dtype=dtype)\\r\\n  File \".../python3.9/site-packages/cupy/_creation/from_data.py\", line 76, in asarray\\r\\n    return _core.array(a, dtype, False, order)\\r\\n  File \"cupy/_core/core.pyx\", line 2266, in cupy._core.core.array\\r\\n  File \"cupy/_core/core.pyx\", line 2290, in cupy._core.core.array\\r\\n  File \"cupy/_core/core.pyx\", line 2415, in cupy._core.core._array_default\\r\\nTypeError: int() argument must be a string, a bytes-like object or a number, not \\'NoneType\\'\\r\\nDuring handling of the above exception, another exception occurred:\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \".../python3.9/site-packages/nvtx/nvtx.py\", line 101, in inner\\r\\n    result = func(*args, **kwargs)\\r\\n  File \".../python3.9/site-packages/cudf/core/series.py\", line 536, in __init__\\r\\n    data = column.as_column(data, nan_as_null=nan_as_null, dtype=dtype)\\r\\n  File \".../python3.9/site-packages/cudf/core/column/column.py\", line 2184, in as_column\\r\\n    _construct_array(arbitrary, dtype),\\r\\n  File \".../python3.9/site-packages/cudf/core/column/column.py\", line 2212, in _construct_array\\r\\n    arbitrary = np.asarray(\\r\\nTypeError: int() argument must be a string, a bytes-like object or a number, not \\'NoneType\\'\\r\\n\\r\\n>>> cudf.Series([1, None], dtype=\"int64\")\\r\\n0       1\\r\\n1    <NA>\\r\\ndtype: int64\\r\\n\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n**Expected behavior**\\r\\nmatching behavior for `Int64` and `int64`\\r\\n\\r\\nref https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html and https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes\\ncreatedAt: 2022-10-24T11:25:25Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 131}),\n",
       " Document(page_content=\": 373\\ntitle: [FEA] Support imaginary numbers in cuDF dataframes\\nbody: Hello, I am trying to store some imaginary numbers as a cudf dataframe column. Each column cell is a list of imaginary numbers. I am wondering what would be the most efficient way to do it as cudf dataframe doesn't support imaginary numbers? Seperating the real and imaginary part is what I am doing now but this is a huge dataset and it is taking a lot of time.\\ncreatedAt: 2022-10-25T09:33:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Arpan Das\\ncompany: The École polytechnique fédérale de Lausanne\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 132}),\n",
       " Document(page_content=': 375\\ntitle: [ENH/QST] actually inplace updates in `__setitem__` and friends\\nbody: ## Context\\r\\n\\r\\nAs noted in #11085, in many cases (though inconsistently right now), obtaining a view on `Series` (probably a `DataFrame` as well) using `iloc[:]` _inadvertently_ behaves with pseudo-copy-on-write semantics\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\nimport numpy as np\\r\\ns = cudf.Series([1, 2, 3])\\r\\nsview = s.iloc[:]\\r\\ns.iloc[[1, 2]] = [4, 5]\\r\\nassert np.allclose(s.values, sview.values) # => False\\r\\n\\r\\nsview = s.iloc[:]\\r\\ns.iloc[0:2] = 3\\r\\nassert np.allclose(s.values, sview.values) # => True\\r\\n```\\r\\n\\r\\nNote: pandas is moving towards _all_ indexing [behaving with copy semantics](https://docs.google.com/document/d/1ZCQ9mx3LBMy-nhwRl33_jgcvWo9IWdEfxDNQ2thyTb0), so for some of these cases we\\'ve already skated to the right answer :)\\r\\n\\r\\n## Why does this happen?\\r\\n\\r\\nMost (but not all) of the `__setitem__`-like calls into (e.g. `copy_range`, `scatter`) `libcudf` do not operate in place, but instead return a new `cudf::column` that must be wrapped up. As a consequence, to pretend like the operation was in place, we call `_mimic_inplace(...)` to switch out the backing data of the `Column` object we\\'re doing `__setitem__` on:\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\ns = cudf.Series([1, 2, 3])\\r\\nold_data = s._column.data\\r\\ns.iloc[1:3] = [4, 5]\\r\\nnew_data = s._column.data\\r\\nassert old_data is new_data # => False\\r\\n```\\r\\n\\r\\nThis is kind of fine as long as there\\'s only one object holding on to the column data, but this breaks down as soon as we have views.\\r\\n\\r\\n## Why is the status quo problematic?\\r\\n\\r\\n1. The current inconsistencies make implementing copy-on-write rather delicate (and in many cases provoke more copies than needed).\\r\\n2. Operations that to the user do not provoke a copy can overflow GPU memory:\\r\\n     ```python\\r\\n      # on a system with 32 GB gpu memory\\r\\n      import cudf\\r\\n      import cupy as cp\\r\\n      import numpy as np\\r\\n      df = cudf.DataFrame({f\"{i}\": cp.ones(10**9, dtype=np.uint8) for i in range(20)}) # about 20GB\\r\\n      # expectation: this behaves in place, so the operation should fit in memory.\\r\\n      df.iloc[[0, 2]] = list(range(20)) # => MemoryError: std::bad_alloc: out_of_memory: CUDA error at: rmm/mr/device/cuda_memory_resource.hpp\\r\\n    ````\\r\\n3. If the scatter/copy_foo operations in libcudf had an in place then we would have lower memory pressure (as point 2) and in the (common) case where we have a target table view, could avoid a memcopy of the whole table.\\r\\n\\r\\n## Possible solutions\\r\\n\\r\\nI don\\'t know the history as to why the libcudf generally tends to offer \"return a copy\" rather than \"modify in place\", but one could make an effort to offer in place versions of most functions. If these operations were available, then the Cython layer could switch to calling into them. In those cases where we really want a copy, we would allocate and copy into an empty table before calling into libcudf.\\r\\n\\r\\nEdit: modification in place only works at the libcudf level for fixed-width column types (so no strings, lists), and having in- and out-of-place modification for every operation is too much work without some significant motivating use case.\\r\\n\\r\\nSince we need a work-around that works for string/list columns that cannot by modified in-place _anyway_, I don\\'t think this issue is a sufficiently motivating use case.\\r\\n\\r\\nThe above solution is a no-go, so what else could we do?\\r\\n\\r\\n- Given that we\\'re trying to move to copy-on-write, we could go the other way and audit all places where `__setitem__` really is in place, and break that connection. ~Note that this is not actually copy-on-write, but copy-on-read so it\\'s not a great option.~ Something close to this probably is copy-on-write, so looks perhaps reasonable.\\r\\n- ~Change the way `_mimic_inplace(self, other, inplace=True)` works: rather than rewriting where `self.data` points to, we could instead `memcopy` from `other.data` back into `self.data` and then drop `other`. This maintains the same memory footprint right now, at the cost of (another) full `memcopy`, and makes `__setitem__` really behave in place (even for views).~ As pointed out below, this doesn\\'t work for non-fixed-width column dtypes.\\ncreatedAt: 2022-10-25T17:17:48Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 133}),\n",
       " Document(page_content=': 379\\ntitle: Refactor groupby to rely less on storing keys as `Index` objects\\nbody: https://github.com/rapidsai/cudf/pull/11792 introduces the ability to group on list columns. In the future, we can expect grouping by, e.g., structs and other types that are not supported by Pandas.\\r\\n\\r\\nIn https://github.com/rapidsai/cudf/issues/6932, we made the decision not to support creating an `Index` with elements of type `list`. \\r\\n\\r\\nUnfortunately, our groupby internals rely heavily on being able to store the key columns of a groupby as an `Index`. In particular, the internal [`_Grouping.keys`](https://github.com/rapidsai/cudf/blob/991c86b13acdbc28ab60609bee6eba2f9eac1ecc/python/cudf/cudf/core/groupby/groupby.py#L1836) method is heavily used.\\r\\n\\r\\nWe should rely less on storing keys as `Index` objects, which will make it much easier to support grouping by lists and structs.\\ncreatedAt: 2022-11-01T14:51:06Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 134}),\n",
       " Document(page_content=': 380\\ntitle: [ENH/QST]: Behaviour of type promotion in `__setitem__`\\nbody: # Summary\\r\\n\\r\\nCUDF is not consistent with Pandas (under a bunch of circumstances) in\\r\\nits behaviour when upcasting during `__setitem__`. In some cases, we\\r\\nmight want to mimic pandas behaviour (though they are very keen to use\\r\\nvalue-based type promotion). In others, where we have more structured\\r\\ndtypes than pandas, we need to decide what to do (current behaviour is\\r\\ninternally inconsistent and buggy in a bunch of cases).\\r\\n\\r\\nI summarise what I think the current state is (by way of experiment),\\r\\nand then discuss some options. Opinions welcome!\\r\\n\\r\\ncc: @vyasr, @mroeschke, @shwina\\r\\n# Pandas behaviour\\r\\n\\r\\nPandas version 1.5.1, MacOS (Apple Silicon)\\r\\n\\r\\nEdit: updated code for generating more tables.\\r\\n\\r\\nI should note that these tables are for single index `__setitem__` (`s.iloc[i] = value`). I should check if the same behaviour also occurs for:\\r\\n- [x] slice-based `__setitem__` with single value `s.iloc[:1] = [value]`\\r\\n- [x] slice-based `__setitem__` with list of values `s.iloc[:2] = [value for _ in range(2)]`\\r\\n- [x] mask-based `__setitem__` with singleton value `s.iloc[[True, False]] = [value]`\\r\\n- [x] mask-based `__setitem__` with multiple values `s.iloc[[True, False, True]] = [value, value]`\\r\\n- [x] index-based `__setitem__` with single value `s.iloc[[1]] = value`\\r\\n- [x] index-based `__setitem__` with multiple values `s.iloc[[1, 2]] = [value, value]`\\r\\n\\r\\n<details>\\r\\n<summary>Code to generate tables</summary>\\r\\n\\r\\n```python\\r\\nfrom __future__ import annotations\\r\\n\\r\\nimport os\\r\\nfrom enum import Enum, IntEnum, auto\\r\\nfrom itertools import filterfalse, repeat\\r\\nfrom operator import not_\\r\\nfrom pathlib import Path\\r\\n\\r\\nimport numpy as np\\r\\nimport pandas as pd\\r\\nimport typer\\r\\n\\r\\ntry:\\r\\n    import cudf\\r\\n    import cupy\\r\\n\\r\\n    class Backend(str, Enum):\\r\\n        PANDAS = \"pandas\"\\r\\n        CUDF = \"cudf\"\\r\\n\\r\\nexcept ImportError:\\r\\n\\r\\n    class Backend(str, Enum):\\r\\n        PANDAS = \"pandas\"\\r\\n\\r\\n\\r\\ndef numeric_series(values, dtype, *, pandas):\\r\\n    if pandas:\\r\\n        return pd.Series(values, dtype=dtype)\\r\\n    else:\\r\\n        return cudf.Series(values, dtype=dtype)\\r\\n\\r\\n\\r\\ndef format_val(v):\\r\\n    try:\\r\\n        dt = v.dtype\\r\\n        return f\"np.{dt.type.__name__}({v})\"\\r\\n    except AttributeError:\\r\\n        return f\"{v}\"\\r\\n\\r\\n\\r\\nclass IndexType(IntEnum):\\r\\n    SINGLE_INT = auto()\\r\\n    SINGLETON_SLICE = auto()\\r\\n    CONTIG_SLICE = auto()\\r\\n    STRIDED_SLICE = auto()\\r\\n    SINGLETON_MASK = auto()\\r\\n    GENERAL_MASK = auto()\\r\\n    SINGLETON_SCATTER = auto()\\r\\n    GENERAL_SCATTER = auto()\\r\\n\\r\\n\\r\\ndef indexing(index_type: IndexType, n: int) -> tuple[int | slice | list, slice | list]:\\r\\n    assert n >= 3\\r\\n    if index_type == IndexType.SINGLE_INT:\\r\\n        return n - 1, slice(0, n - 1, None)\\r\\n    elif index_type == IndexType.SINGLETON_SLICE:\\r\\n        return slice(1, 2, 1), [0, *range(2, n)]\\r\\n    elif index_type == IndexType.CONTIG_SLICE:\\r\\n        return slice(1, n - 2, 1), [0, *range(n - 2, n)]\\r\\n    elif index_type == IndexType.STRIDED_SLICE:\\r\\n        return slice(0, n, 2), slice(1, n, 2)\\r\\n    elif index_type == IndexType.SINGLETON_MASK:\\r\\n        yes = [False, True, *repeat(False, n - 2)]\\r\\n        no = list(map(not_, yes))\\r\\n        return yes, no\\r\\n    elif index_type == IndexType.GENERAL_MASK:\\r\\n        yes = [True, False, True, *repeat(False, n - 3)]\\r\\n        no = list(map(not_, yes))\\r\\n        return yes, no\\r\\n    elif index_type == IndexType.SINGLETON_SCATTER:\\r\\n        yes = [1]\\r\\n        # Oh for Haskell-esque sections\\r\\n        no = list(filterfalse(yes.__contains__, range(n)))\\r\\n        return yes, no\\r\\n    elif index_type == IndexType.GENERAL_SCATTER:\\r\\n        yes = [0, 2]\\r\\n        no = list(filterfalse(yes.__contains__, range(n)))\\r\\n        return yes, no\\r\\n    else:\\r\\n        raise ValueError(\"Unhandled case\")\\r\\n\\r\\n\\r\\ndef generate_table(f, initial_values, values_to_try, dtype, *, index_type, pandas):\\r\\n    initial_values = np.asarray(initial_values, dtype=object)\\r\\n    f.write(\"| Initial dtype | New value | Final dtype | Lossy? |\\\\n\")\\r\\n    f.write(\"|---------------|-----------|-------------|--------|\\\\n\")\\r\\n\\r\\n    yes, no = indexing(index_type, len(initial_values))\\r\\n    for value in values_to_try:\\r\\n        s = numeric_series(initial_values, dtype=dtype, pandas=pandas)\\r\\n        otype = f\"np.{type(s.dtype).__name__}\"\\r\\n        try:\\r\\n            if index_type == IndexType.SINGLETON_SLICE:\\r\\n                value = cupy.asarray([value])\\r\\n            s.iloc[yes] = value\\r\\n        except BaseException as e:\\r\\n            f.write(f\"| `{otype}` | `{format_val(value)}` | N/A | {e} |\\\\n\")\\r\\n            continue\\r\\n        ntype = f\"np.{type(s.dtype).__name__}\"\\r\\n        expect = (np.asarray if pandas else cupy.asarray)(\\r\\n            initial_values[no], dtype=dtype\\r\\n        )\\r\\n        original_lost_info = (s.iloc[no].astype(dtype) != expect).any()\\r\\n        try:\\r\\n            new_vals = s.iloc[yes].astype(value.dtype)\\r\\n        except AttributeError:\\r\\n            if pandas:\\r\\n                new_vals = np.asarray(s.iloc[yes])\\r\\n            else:\\r\\n                new_vals = cupy.asarray(s.iloc[yes])\\r\\n        new_lost_info = (new_vals != value).any()\\r\\n        lossy = \"Yes\" if original_lost_info or new_lost_info else \"No\"\\r\\n        f.write(f\"| `{otype}` | `{format_val(value)}` | `{ntype}` | {lossy} |\\\\n\")\\r\\n\\r\\n\\r\\ndef generate_tables(output_directory: Path, backend: Backend, index_type: IndexType):\\r\\n    integer_column_values_to_try = [\\r\\n        10,\\r\\n        np.int64(10),\\r\\n        2**40,\\r\\n        np.int64(2**40),\\r\\n        2**80,\\r\\n        10.5,\\r\\n        np.float64(10),\\r\\n        np.float64(10.5),\\r\\n        np.float32(10),\\r\\n        np.float32(10.5),\\r\\n    ]\\r\\n    float_column_values_to_try = [\\r\\n        10,\\r\\n        np.int64(10),\\r\\n        2**40,\\r\\n        np.int64(2**40),\\r\\n        np.int32(2**31 - 100),\\r\\n        np.int64(2**63 - 100),\\r\\n        2**80 - 100,\\r\\n        10.5,\\r\\n        np.float64(10),\\r\\n        np.float64(10.5),\\r\\n        np.float64(np.finfo(np.float32).max.astype(np.float64) * 10),\\r\\n        np.float32(10),\\r\\n        np.float32(10.5),\\r\\n    ]\\r\\n\\r\\n    pandas = backend == Backend.PANDAS\\r\\n    filename = f\"{backend}-setitem-{index_type.name}.md\"\\r\\n    with open(output_directory / filename, \"w\") as f:\\r\\n        if pandas:\\r\\n            f.write(f\"Pandas {pd.__version__} behaviour for {index_type!r}\\\\n\\\\n\")\\r\\n        else:\\r\\n            f.write(f\"CUDF {cudf.__version__} behaviour for {index_type!r}\\\\n\\\\n\")\\r\\n\\r\\n        generate_table(\\r\\n            f,\\r\\n            [2**31 - 10, 2**31 - 100, 3, 4, 5],\\r\\n            integer_column_values_to_try,\\r\\n            np.int32,\\r\\n            index_type=index_type,\\r\\n            pandas=pandas,\\r\\n        )\\r\\n        f.write(\"\\\\n\")\\r\\n        generate_table(\\r\\n            f,\\r\\n            [2**63 - 10, 2**63 - 100, 3, 4, 5],\\r\\n            integer_column_values_to_try,\\r\\n            np.int64,\\r\\n            index_type=index_type,\\r\\n            pandas=pandas,\\r\\n        )\\r\\n        f.write(\"\\\\n\")\\r\\n        generate_table(\\r\\n            f,\\r\\n            [np.finfo(np.float32).max, np.float32(np.inf), 3, 4, 5],\\r\\n            float_column_values_to_try,\\r\\n            np.float32,\\r\\n            index_type=index_type,\\r\\n            pandas=pandas,\\r\\n        )\\r\\n        f.write(\"\\\\n\")\\r\\n        generate_table(\\r\\n            f,\\r\\n            [np.finfo(np.float64).max, np.float64(np.inf), 3, 4, 5],\\r\\n            float_column_values_to_try,\\r\\n            np.float64,\\r\\n            index_type=index_type,\\r\\n            pandas=pandas,\\r\\n        )\\r\\n\\r\\n\\r\\ndef main(\\r\\n    output_directory: Path = typer.Argument(Path(\".\"), help=\"Output directory for results\"),\\r\\n    backend: Backend = typer.Option(\"pandas\", help=\"Dataframe backend to test\"),\\r\\n):\\r\\n    os.makedirs(output_directory, exist_ok=True)\\r\\n    for index_type in IndexType.__members__.values():\\r\\n        generate_tables(output_directory, backend, index_type)\\r\\n\\r\\n\\r\\nif __name__ == \"__main__\":\\r\\n    typer.run(main)\\r\\n```\\r\\n\\r\\n</details>\\r\\n\\r\\n## Numeric columns\\r\\n\\r\\n### Integer column dtypes\\r\\n\\r\\n#### dtype width < max integer width\\r\\n\\r\\nInitial values `[2**31 - 10, 2**31 - 100, 3]`. `np.int32` is\\r\\nrepresentative of any integer type that is smaller than the max width.\\r\\n\\r\\n| Initial dtype     | New value                   | Final dtype          | Lossy? |\\r\\n|-------------------|-----------------------------|----------------------|--------|\\r\\n| `np.dtype[int32]` | `10`                        | `np.dtype[int32]`    | No[^1] |\\r\\n| `np.dtype[int32]` | `np.int64(10)`              | `np.dtype[int32]`    | No[^1] |\\r\\n| `np.dtype[int32]` | `1099511627776`             | `np.dtype[longlong]` | No[^2] |\\r\\n| `np.dtype[int32]` | `np.int64(1099511627776)`   | `np.dtype[longlong]` | No[^2] |\\r\\n| `np.dtype[int32]` | `1208925819614629174706176` | `np.dtype[object_]`  | No[^3] |\\r\\n| `np.dtype[int32]` | `10.5`                      | `np.dtype[float64]`  | No[^4] |\\r\\n| `np.dtype[int32]` | `np.float64(10.0)`          | `np.dtype[int32]`    | No[^1] |\\r\\n| `np.dtype[int32]` | `np.float64(10.5)`          | `np.dtype[float64]`  | No[^2] |\\r\\n| `np.dtype[int32]` | `np.float32(10.0)`          | `np.dtype[int32]`    | No[^1] |\\r\\n| `np.dtype[int32]` | `np.float32(10.5)`          | `np.dtype[float64]`  | No[^5] |\\r\\n\\r\\n[^1]: value is exact in the initial dtype\\r\\n[^2]: next largest numpy type that contains the value\\r\\n[^3]: not representable in a numpy type, so coercion to object column\\r\\n[^4]: default float type is float64\\r\\n[^5]: `np.int32` is losslessly convertible to `np.float64`\\r\\n\\r\\n#### dtype width == max integer width\\r\\n\\r\\nInitial values `[2 ** 63 - 10, 2 ** 63 - 100, 3]`. These provoke edge\\r\\ncases in upcasting because:\\r\\n```python\\r\\nimport numpy as np\\r\\nnp.find_common_type([], [np.int64, np.float64])\\r\\n# => np.float64 Noooooo! Hates it\\r\\n# Yes, I know this is the same as the integer to float promotion in\\r\\n# C/C++, I\\'m allowed to hate that too.\\r\\n```\\r\\n\\r\\n| Initial dtype     | New value                   | Final dtype         | Lossy?  |\\r\\n|-------------------|-----------------------------|---------------------|---------|\\r\\n| `np.dtype[int64]` | `10`                        | `np.dtype[int64]`   | No[^1]  |\\r\\n| `np.dtype[int64]` | `np.int64(10)`              | `np.dtype[int64]`   | No[^1]  |\\r\\n| `np.dtype[int64]` | `1099511627776`             | `np.dtype[int64]`   | No[^1]  |\\r\\n| `np.dtype[int64]` | `np.int64(1099511627776)`   | `np.dtype[int64]`   | No[^1]  |\\r\\n| `np.dtype[int64]` | `1208925819614629174706176` | `np.dtype[object_]` | No[^3]  |\\r\\n| `np.dtype[int64]` | `10.5`                      | `np.dtype[float64]` | Yes[^6] |\\r\\n| `np.dtype[int64]` | `np.float64(10.0)`          | `np.dtype[int64]`   | No[^1]  |\\r\\n| `np.dtype[int64]` | `np.float64(10.5)`          | `np.dtype[float64]` | Yes[^6] |\\r\\n| `np.dtype[int64]` | `np.float32(10.0)`          | `np.dtype[int64]`   | No[^1]  |\\r\\n| `np.dtype[int64]` | `np.float32(10.5)`          | `np.dtype[float64]` | Yes[^6] |\\r\\n\\r\\n[^6]: `np.int64` is _not_ losslessly convertible `np.float64`\\r\\n\\r\\n### Float column dtypes\\r\\n\\r\\n#### dtype width < max float width\\r\\n\\r\\nInitial values `[np.finfo(np.float32).max, np.float32(np.inf), 3]`\\r\\n\\r\\n| Initial dtype       | New value                            | Final dtype         | Lossy?   |\\r\\n|---------------------|--------------------------------------|---------------------|----------|\\r\\n| `np.dtype[float32]` | `10`                                 | `np.dtype[float32]` | No[^1]   |\\r\\n| `np.dtype[float32]` | `np.int64(10)`                       | `np.dtype[float32]` | No[^1]   |\\r\\n| `np.dtype[float32]` | `1099511627776`                      | `np.dtype[float32]` | No[^1]   |\\r\\n| `np.dtype[float32]` | `np.int64(1099511627776)`            | `np.dtype[float32]` | No[^1]   |\\r\\n| `np.dtype[float32]` | `np.int32(2147483548)`               | `np.dtype[float64]` | No[^1]   |\\r\\n| `np.dtype[float32]` | `np.int64(9223372036854775708)`      | `np.dtype[float32]` | Yes[^7] |\\r\\n| `np.dtype[float32]` | `1208925819614629174706076`          | `np.dtype[object_]` | No[^3]  |\\r\\n| `np.dtype[float32]` | `10.5`                               | `np.dtype[float32]` | No[^1]   |\\r\\n| `np.dtype[float32]` | `np.float64(10.0)`                   | `np.dtype[float32]` | No[^1]   |\\r\\n| `np.dtype[float32]` | `np.float64(10.5)`                   | `np.dtype[float32]` | No[^1]   |\\r\\n| `np.dtype[float32]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float64]` | No[^2]  |\\r\\n| `np.dtype[float32]` | `np.float32(10.0)`                   | `np.dtype[float32]` | No[^1]   |\\r\\n| `np.dtype[float32]` | `np.float32(10.5)`                   | `np.dtype[float32]` | No[^1]   |\\r\\n\\r\\n[^7]: value is not losslessly representable, but also, expecting\\r\\n    `np.float64`!\\r\\n\\r\\n#### dtype width == max float width\\r\\n\\r\\nInitial values `[np.finfo(np.float64).max, np.float64(np.inf), 3]`\\r\\n\\r\\n| Initial dtype       | New value                            | Final dtype         | Lossy?   |\\r\\n|---------------------|--------------------------------------|---------------------|----------|\\r\\n| `np.dtype[float64]` | `10`                                 | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `np.int64(10)`                       | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `1099511627776`                      | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `np.int64(1099511627776)`            | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `np.int32(2147483548)`               | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `np.int64(9223372036854775708)`      | `np.dtype[float64]` | Yes[^6] |\\r\\n| `np.dtype[float64]` | `1208925819614629174706076`          | `np.dtype[object_]` | No[^3]  |\\r\\n| `np.dtype[float64]` | `10.5`                               | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `np.float64(10.0)`                   | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `np.float64(10.5)`                   | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `np.float32(10.0)`                   | `np.dtype[float64]` | No[^1]  |\\r\\n| `np.dtype[float64]` | `np.float32(10.5)`                   | `np.dtype[float64]` | No[^1]  |\\r\\n\\r\\n## Everything else\\r\\n\\r\\nBasically, you can put anything in a column and you get an object out,\\r\\nbut numpy types are converted to `object` first.\\r\\n\\r\\n# CUDF behaviour\\r\\n\\r\\nCUDF trunk, and state in #11904.\\r\\n\\r\\n## Numeric columns\\r\\n\\r\\n### Integer column dtypes\\r\\n\\r\\n#### dtype width < max integer width\\r\\n\\r\\nInitial values `[2**31 - 10, 2**31 - 100, 3]`. `np.int32` is\\r\\nrepresentative of any integer type that is smaller than the max width.\\r\\n\\r\\n| Initial dtype     | New value                   | Final dtype (trunk)   | Final dtype (#11904)    | Lossy? (trunk) | Lossy? (#11904) |\\r\\n|-------------------|-----------------------------|-----------------------|-------------------------|----------------|-----------------|\\r\\n| `np.dtype[int32]` | `10`                        | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\\r\\n| `np.dtype[int32]` | `np.int64(10)`              | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\\r\\n| `np.dtype[int32]` | `1099511627776`             | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | Yes            | No              |\\r\\n| `np.dtype[int32]` | `np.int64(1099511627776)`   | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | Yes            | No              |\\r\\n| `np.dtype[int32]` | `1208925819614629174706176` | OverflowError         | OverflowError           | N/A            | N/A             |\\r\\n| `np.dtype[int32]` | `10.5`                      | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | Yes            | No              |\\r\\n| `np.dtype[int32]` | `np.float64(10.0)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\\r\\n| `np.dtype[int32]` | `np.float64(10.5)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | Yes            | No              |\\r\\n| `np.dtype[int32]` | `np.float32(10.0)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\\r\\n| `np.dtype[int32]` | `np.float32(10.5)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | Yes            | No              |\\r\\n\\r\\n[^8]: Bug fixed by #11904\\r\\n[^9]: CUDF doesn\\'t inspect values, so type-based promotion (difference\\r\\n    from pandas)\\r\\n\\r\\n#### dtype width == max integer width\\r\\n\\r\\nInitial values `[2 ** 63 - 10, 2 ** 63 - 100, 3]`.\\r\\n\\r\\n| Initial dtype     | New value                   | Final dtype (trunk)   | Final dtype (#11904)    | Lossy? (trunk) | Lossy? (#11904) |\\r\\n|-------------------|-----------------------------|-----------------------|-------------------------|----------------|-----------------|\\r\\n| `np.dtype[int64]` | `10`                        | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\\r\\n| `np.dtype[int64]` | `np.int64(10)`              | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\\r\\n| `np.dtype[int64]` | `1099511627776`             | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\\r\\n| `np.dtype[int64]` | `np.int64(1099511627776)`   | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\\r\\n| `np.dtype[int64]` | `1208925819614629174706176` | OverflowError         | OverflowError           | N/A            | N/A             |\\r\\n| `np.dtype[int64]` | `10.5`                      | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | Yes            | Yes[^6]         |\\r\\n| `np.dtype[int64]` | `np.float64(10.0)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | No             | Yes[^6]         |\\r\\n| `np.dtype[int64]` | `np.float64(10.5)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | Yes            | Yes[^6]         |\\r\\n| `np.dtype[int64]` | `np.float32(10.0)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | No             | Yes[^6]         |\\r\\n| `np.dtype[int64]` | `np.float32(10.5)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | Yes            | Yes[^6]         |\\r\\n\\r\\n### Float column dtypes\\r\\n\\r\\n#### dtype width < max float width\\r\\n\\r\\nInitial values `[np.finfo(np.float32).max, np.float32(np.inf), 3]`\\r\\n\\r\\n| Initial dtype       | New value                            | Final dtype (trunk)     | Final dtype (#11904)    | Lossy? (trunk) | Lossy? (#11904) |\\r\\n|---------------------|--------------------------------------|-------------------------|-------------------------|----------------|-----------------|\\r\\n| `np.dtype[float32]` | `10`                                 | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\\r\\n| `np.dtype[float32]` | `np.int64(10)`                       | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\\r\\n| `np.dtype[float32]` | `1099511627776`                      | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\\r\\n| `np.dtype[float32]` | `np.int64(1099511627776)`            | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\\r\\n| `np.dtype[float32]` | `np.int32(2147483548)`               | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | Yes[^10]       | No              |\\r\\n| `np.dtype[float32]` | `np.int64(9223372036854775708)`      | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | Yes[^10]       | Yes[^6]         |\\r\\n| `np.dtype[float32]` | `1208925819614629174706076`          | OverflowError           | OverflowError           | N/A            | N/A             |\\r\\n| `np.dtype[float32]` | `10.5`                               | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\\r\\n| `np.dtype[float32]` | `np.float64(10.0)`                   | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\\r\\n| `np.dtype[float32]` | `np.float64(10.5)`                   | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\\r\\n| `np.dtype[float32]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | Yes[^8]        | No              |\\r\\n| `np.dtype[float32]` | `np.float32(10.0)`                   | `np.dtype[float32]`[^8] | `np.dtype[float32]`[^9] | No             | No              |\\r\\n| `np.dtype[float32]` | `np.float32(10.5)`                   | `np.dtype[float32]`[^8] | `np.dtype[float32]`[^9] | No             | No              |\\r\\n\\r\\n[^10]: As for [^6], but promotion from `np.int32` to `np.float32` is\\r\\n    also not lossless.\\r\\n\\r\\n#### dtype width == max float width\\r\\n\\r\\nInitial values `[np.finfo(np.float64).max, np.float64(np.inf), 3]`\\r\\n\\r\\n| Initial dtype       | New value                            | Final dtype (trunk) | Final dtype (#11904) | Lossy? (trunk) | Lossy? (#11904) |\\r\\n|---------------------|--------------------------------------|---------------------|----------------------|----------------|-----------------|\\r\\n| `np.dtype[float64]` | `10`                                 | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `np.int64(10)`                       | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `1099511627776`                      | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `np.int64(1099511627776)`            | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `np.int32(2147483548)`               | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `np.int64(9223372036854775708)`      | `np.dtype[float64]` | `np.dtype[float64]`  | Yes[^6]        | Yes[^6]         |\\r\\n| `np.dtype[float64]` | `1208925819614629174706076`          | OverflowError       | OverflowError        | N/A            | N/A             |\\r\\n| `np.dtype[float64]` | `10.5`                               | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `np.float64(10.0)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `np.float64(10.5)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `np.float32(10.0)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n| `np.dtype[float64]` | `np.float32(10.5)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\\r\\n\\r\\n## Everything else\\r\\n\\r\\nThis is where it starts to get _really_ messy. This section is a work\\r\\nin progress. We should decide what we _want_ the semantics to be,\\r\\nbecause in most cases pandas doesn\\'t have the same dtypes that CUDF does.\\r\\n\\r\\n### Inserting strings into numerical columns\\r\\n\\r\\nThis \"works\", for some value of \"works\" on #11904 if the string value\\r\\nis parseable as the target dtype.\\r\\n\\r\\nSo\\r\\n\\r\\n```python\\r\\ns = cudf.Series([1, 2, 3], dtype=int)\\r\\ns.iloc[2] = \"4\" # works\\r\\ns.iloc[2] = \"0xf\" # => ValueError: invalid literal for int() with base 10: \\'0xf\\'\\r\\n```\\r\\n\\r\\nAnd similarly for float strings and float dtypes.\\r\\n\\r\\nThis is probably a nice feature.\\r\\n\\r\\n### Inserting things into string columns\\r\\n\\r\\nWorks if the the \"thing\" is convertible to a string (so numbers work),\\r\\nbut Scalars with list or struct dtypes don\\'t work.\\r\\n\\r\\nI would argue that explicit casting from the user here is probably\\r\\nbetter.\\r\\n\\r\\n### List columns\\r\\n\\r\\nThe new value must have an identical dtype to that of the target column.\\r\\n\\r\\n### Struct columns\\r\\n\\r\\nThe new value must have leaf dtypes that are considered compatible in\\r\\nsome sense, but then the leaves are downcast to the leaf dtypes of the\\r\\ntarget column. So this is lossy and likely a bug:\\r\\n\\r\\n```python\\r\\n sr = cudf.Series([{\"a\": 1, \"b\": 2}])\\r\\n sr.iloc[0] = {\"a\": 10.5, \"b\": 2}\\r\\n sr[0] # => {\"a\": 10, \"b\": 2} (lost data in \"a\")\\r\\n```\\r\\n## What I think we want (for composite columns)\\r\\n\\r\\nFor composite columns, if the dtype shapes match, I think the casting\\r\\nrule should be to traverse to the leaf dtypes and promote using the\\r\\nrules for non-composite columns. If shapes don\\'t match, `__setitem__`\\r\\nshould not be allowed.\\r\\n\\r\\nThis, to me, exhibits principle of least surprise.\\ncreatedAt: 2022-11-01T18:01:16Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 135}),\n",
       " Document(page_content=': 383\\ntitle: [BUG] cudf astype(\\'int32\\') behavior does not match pandas\\nbody: **Steps/Code to reproduce bug**\\r\\n```\\r\\n$ python3.9 -m IPython\\r\\nPython 3.9.14 (main, Sep  7 2022, 23:43:48) \\r\\nType \\'copyright\\', \\'credits\\' or \\'license\\' for more information\\r\\nIPython 8.5.0 -- An enhanced Interactive Python. Type \\'?\\' for help.\\r\\n\\r\\nIn [1]: import pandas as pd, cudf\\r\\n\\r\\nIn [2]: pd.__version__, cudf.__version__\\r\\nOut[2]: (\\'1.4.4\\', \\'22.10.00a+392.g1558403753\\')\\r\\n\\r\\nIn [3]: pdf = pd.DataFrame({\\'a\\': [\\'123_1\\']})\\r\\n\\r\\nIn [4]: pdf.a.astype(\\'int32\\')\\r\\nOut[4]: \\r\\n0    1231\\r\\nName: a, dtype: int32\\r\\n\\r\\nIn [5]: cdf = cudf.DataFrame({\\'a\\': [\\'123_1\\']})\\r\\n\\r\\nIn [6]: cdf.a.astype(\\'int32\\')\\r\\n---------------------------------------------------------------------------\\r\\nValueError                                Traceback (most recent call last)\\r\\nCell In [6], line 1\\r\\n----> 1 cdf.a.astype(\\'int32\\')\\r\\n\\r\\n...\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/column/string.py:5314, in StringColumn.as_numerical_column(self, dtype, **kwargs)\\r\\n   5312 if out_dtype.kind in {\"i\", \"u\"}:\\r\\n   5313     if not libstrings.is_integer(string_col).all():\\r\\n-> 5314         raise ValueError(\\r\\n   5315             \"Could not convert strings to integer \"\\r\\n   5316             \"type due to presence of non-integer values.\"\\r\\n   5317         )\\r\\n   5318 elif out_dtype.kind == \"f\":\\r\\n   5319     if not libstrings.is_float(string_col).all():\\r\\n\\r\\nValueError: Could not convert strings to integer type due to presence of non-integer values.\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n`cudf` to produce the same result as `pandas`\\r\\n\\r\\n\\r\\n**Environment overview**\\r\\n```\\r\\n$ nvidia-smi \\r\\nWed Nov  2 16:48:53 2022       \\r\\n+-----------------------------------------------------------------------------+\\r\\n| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |\\r\\n|-------------------------------+----------------------+----------------------+\\r\\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n|                               |                      |               MIG M. |\\r\\n|===============================+======================+======================|\\r\\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\\r\\n| N/A   56C    P8    15W /  70W |      0MiB / 15360MiB |      0%      Default |\\r\\n|                               |                      |                  N/A |\\r\\n+-------------------------------+----------------------+----------------------+\\r\\n                                                                               \\r\\n+-----------------------------------------------------------------------------+\\r\\n| Processes:                                                                  |\\r\\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n|        ID   ID                                                   Usage      |\\r\\n|=============================================================================|\\r\\n|  No running processes found                                                 |\\r\\n+-----------------------------------------------------------------------------+\\r\\n```\\ncreatedAt: 2022-11-02T16:53:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 136}),\n",
       " Document(page_content=\": 384\\ntitle: [FEA] cudf.Timestamp\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code from pandas into cudf, using `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n`cudf.Timestamp` matching https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html\\ncreatedAt: 2022-11-03T12:49:31Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 137}),\n",
       " Document(page_content=': 386\\ntitle: [FEA] cudf::column needs a set_stream() function.\\nbody: `cudf::column` uses `rmm::device_buffer` for internal storage. `rmm::device_buffer` internally stores the stream it was created on.  This can create issues when creating columns on temporary worker-style streams and then returning them to a primary stream.  When the column gets destroyed, rmm throws exceptions about invalid device contexts.\\r\\n\\r\\nA `set_stream(rmm::cuda_stream_view)` function that recurses through all children would make it easier to hand off columns between streams. \\r\\n\\r\\nWe initially encountered this issue with `cudf::io::column_buffer` which has a similar problem but it will also be an issue for columns themselves.\\ncreatedAt: 2022-11-08T17:39:15Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 138}),\n",
       " Document(page_content=': 387\\ntitle: dataframe.drop not working for multindex[QST]\\nbody: I have a cudf dataframe which looks like this  \\r\\n![Screen Shot 2022-11-09 at 3 24 26 PM](https://user-images.githubusercontent.com/23120837/200855560-cdf38efd-c095-42c2-9c8d-269dcac2515d.png)\\r\\n\\r\\nI want to drop all the rows corresponding to some multiindex. For example I want to drop \\r\\n\\r\\n`index_to_drop= cudf.MultiIndex.from_tuples(zip([0,0], [1,2]), names=(\"B_0\", \"B_1\"))`\\r\\n\\r\\n`df.drop(index=index_to_drop)` \\r\\n\\r\\nI am getting a NotImplementedError, however same thing is working in Pandas\\ncreatedAt: 2022-11-09T14:38:27Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Arpan Das\\ncompany: The École polytechnique fédérale de Lausanne', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 139}),\n",
       " Document(page_content=': 389\\ntitle: [BUG] off-by-one errors in `cudf.date_range`\\nbody: **Describe the bug**\\r\\n\\r\\n[As part of attempting to get to XPASS-zero in the test suite]\\r\\n\\r\\nIf the date range is long enough, and for some frequencies, `cudf.date_range` has a fencepost error in the number of dates it produces.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```python\\r\\nimport cudf\\r\\nimport pandas as pd\\r\\nstart = \"1831-05-08 15:23:21\"\\r\\nend = \"1996-11-21 04:05:30\"\\r\\nfreq = \"110546789L\"\\r\\n\\r\\ncr = cudf.date_range(start=start, end=end, freq=freq)\\r\\npr = pd.date_range(start=start, end=end, freq=freq)\\r\\n\\r\\nassert len(cr) == len(pr) # => False, len(cr) == len(pr) + 1\\r\\nprint(cr[-1])\\r\\n# => 1996-11-21T14:14:21.984000000\\r\\n# Which is _after_ the specified end\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nNo fencepost error.\\ncreatedAt: 2022-11-11T18:47:11Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 140}),\n",
       " Document(page_content=': 390\\ntitle: Behaviour of inplace for `copy_range` when range is empty.\\nbody: In `copying.copy_range` we have an `inplace=False/True` argument.\\r\\n\\r\\nIf `inplace` is `True`, then the column is modified in place, if `inplace` is False, a new (copied) column is created and then modified. If the case that the range we are copying is empty, at present `inplace=False` _still_ returns a new copy (even though `copy_range` is a no-op in this situation).\\r\\n\\r\\nShould it be allowed that\\r\\n\\r\\n```\\r\\ncopy_range(source, target, empty_range, inplace=False)\\r\\n```\\r\\n\\r\\nCan return `target` (rather than a copy of `target`)?\\r\\n\\r\\nSee discussion where this came p: https://github.com/rapidsai/cudf/pull/12075#discussion_r1015307155\\ncreatedAt: 2022-11-14T11:17:05Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 141}),\n",
       " Document(page_content=': 392\\ntitle: [FEA] Follow up on refactoring possibility from parquet chunked reader PR\\nbody: There is a small refactoring that can be done to de-duplicate some code in the parquet decoder which needs to be done as a followup.\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/pull/11867#discussion_r1022137500\\r\\n\\r\\n<img width=\"770\" alt=\"image\" src=\"https://github.com/rapidsai/cudf/assets/12725111/e10d9380-c7bf-4c37-9dfc-c1c6d301b211\">\\ncreatedAt: 2022-11-15T02:44:37Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 142}),\n",
       " Document(page_content=': 397\\ntitle: [BUG/pandas-compat]: Handling of type promotion and division/mod by zero for boolean columns\\nbody: After #12074, most type promotions between columns of mixed types (and non-mixed types) match pandas. The exception is columns with boolean dtypes.\\r\\n\\r\\nPandas have taken the decision to disallow division and exponentiation on boolean types when both operands are booleans (https://github.com/pandas-dev/pandas/blob/d13c9e034ce8a1d738766c4b1cec80c76f5523be/pandas/core/ops/array_ops.py#L503).\\r\\n\\r\\nAside: I kind of disagree with this since this is all perfectly well defined (excepting the usual caveat of division by zero).\\r\\n\\r\\nWhen only one of the operands is `bool`, the status quo depends on the dtype of the other operand:\\r\\n\\r\\n## Pandas behaviour:\\r\\n\\r\\nFor `a % b`, with `a == 1`, `b == 0` for various dtypes\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | int8(0) (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |\\r\\n| int | int64(0) (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |\\r\\n| float | float64(NaN) (or ZeroDivisionError[^1])| float64(NaN) | float64(NaN) |\\r\\n\\r\\nFor `a / b` (or `a // b`) with `a == 1`, `b = 0`\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | NotImplemented (or ZeroDivisionError[^1]) | float64(inf) | float64(inf) |\\r\\n| int | float64(inf)(or ZeroDivisionError[^1]) | float64(inf) | float64(inf) |\\r\\n| float | float64(inf) (or ZeroDivisionError[^1])| float64(inf) | float64(inf) |\\r\\n\\r\\nFor `a % b`, with `a == 0`, `b == 0` for various dtypes\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | int8(0)(or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |\\r\\n| int | int64(0) (or ZeroDivisionError[^1])| float64(NaN) | float64(NaN) |\\r\\n| float | float64(NaN) (or ZeroDivisionError[^1])| float64(NaN) | float64(NaN) |\\r\\n\\r\\nFor `a / b` (or `a // b`) with `a == 0`, `b = 0`\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | NotImplemented (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |\\r\\n| int | float64(NaN) (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |\\r\\n| float | float64(NaN) (or ZeroDivisionError[^1]) | float64(NaN) | float64(NaN) |\\r\\n\\r\\n[^1]: If the operands are different lengths, we get a ZeroDivisionError (see https://github.com/pandas-dev/pandas/issues/49699)\\r\\n\\r\\n## cuDF behaviour:\\r\\n\\r\\nFor `a % b`, with `a == 1`, `b == 0` for various dtypes\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | bool(0) | float64(NaN) | float64(NaN) |\\r\\n| int | int64(2**32 - 1) | float64(NaN) | float64(NaN) |\\r\\n| float | float64(NaN) | float64(NaN) | float64(NaN) |\\r\\n\\r\\nFor `a // b` with `a == 1`, `b = 0`\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | bool(1) | float64(inf) | float64(inf) |\\r\\n| int | int64(2**32 - 1) | float64(inf) | float64(inf) |\\r\\n| float | float64(inf) | float64(inf) | float64(inf) |\\r\\n\\r\\nFor `a / b` with `a == 1`, `b = 0`\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | float32(inf) | float64(inf) | float64(inf) |\\r\\n| int | float64(inf) | float64(inf) | float64(inf) |\\r\\n| float | float64(inf) | float64(inf) | float64(inf) |\\r\\n\\r\\nFor `a % b`, with `a == 0`, `b == 0` for various dtypes\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | bool(0) | float64(NaN) | float64(NaN) |\\r\\n| int | int64(2**32 - 1) | float64(NaN) | float64(NaN) |\\r\\n| float | float64(NaN) | float64(NaN) | float64(NaN) |\\r\\n\\r\\nFor `a // b` with `a == 0`, `b = 0`\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | bool(False) | float64(NaN) | float64(NaN) |\\r\\n| int | int64(2**32 - 1) | float64(NaN) | float64(NaN) |\\r\\n| float | float64(NaN) | float64(NaN) | float64(NaN) |\\r\\n\\r\\nFor `a / b` with `a == 0`, `b = 0`\\r\\n\\r\\n|  dtype-a \\\\ dtype-b  | bool | int | float |\\r\\n|----------|------|------|-|\\r\\n| bool | float32(NaN) | float64(NaN) | float64(NaN) |\\r\\n| int | float64(NaN) | float64(NaN) | float64(NaN) |\\r\\n| float | float64(NaN) | float64(NaN) | float64(NaN) |\\ncreatedAt: 2022-11-16T11:31:10Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 143}),\n",
       " Document(page_content=\": 403\\ntitle: [FEA] Use RMM memory pool by default\\nbody: We should move to using an RMM managed memory pool by default.\\r\\n\\r\\nThis was brought up before in https://github.com/rapidsai/cudf/issues/2676. In response to that issue, we implemented `set_allocator`, https://github.com/rapidsai/cudf/pull/2682, but we chose not to enable the RMM pool by default (likely because we didn't want to monopolize GPU memory away from other libraries). \\r\\n\\r\\nSince then, CuPy, Numba (and soon [PyTorch](https://github.com/pytorch/pytorch/pull/86786)) all can be configured to use RMM, and therefore share the same memory pool as cuDF.\\r\\n\\r\\n## Proposal\\r\\n\\r\\nConcretely, the proposal is that `import cudf` will:\\r\\n\\r\\n* Set RMM's default memory resource to a [pool memory resource](https://docs.rapids.ai/api/rmm/stable/api.html#rmm.mr.PoolMemoryResource)\\r\\n* Configure CuPy, Numba, (and PyTorch?) to all use RMM's default memory resource\\r\\n\\r\\n## What should the initial and maximum pool size be? \\r\\n\\r\\nAn RMM pool can be configured with an initial and maximum pool size. The pool grows according to an implementation-defined strategy (see [here](https://github.com/rapidsai/rmm/blob/d132e5236b444d2dcdae25e846c4fe4d5651ee79/include/rmm/mr/device/pool_memory_resource.hpp#L246-L249) for the current strategy).\\r\\n\\r\\n- As we cannot assume that all (or any) GPU memory is available when cuDF is imported, the initial pool size should be 0 bytes.\\r\\n- The only reasonable maximum pool size I can think of is the maximum available GPU memory. If the pool cannot expand to this size because of allocations made outside of RMM, so be it: we will OOM. \\r\\n\\r\\n## What happens if `import cudf` appears in the middle of the program?\\r\\n\\r\\nAll this works well if `import cudf` appears at the beginning of the program, i.e., before any device memory is actually allocated by any library). However, if it appears _after_ some device objects have already been allocated, it can lead to early out-of-memory errors. As an example, consider some code that uses both PyTorch and cuDF in the following way:\\r\\n\\r\\n```python\\r\\nimport torch\\r\\n \\r\\n# this part of the code uses PyTorch\\r\\n\\r\\nimport cudf\\r\\n\\r\\n# this part of the code uses cudf\\r\\n```\\r\\n\\r\\nBecause PyTorch [uses a caching allocator](https://pytorch.org/docs/stable/notes/cuda.html#memory-management), a memory pool already exists by the time we import cuDF. Importing cuDF initializes a second pool that all libraries (including PyTorch) will use going forward. The first pool essentially becomes a kind of dead space: no new device objects are ever allocated within the pool, and no device memory is ever freed from it. \\r\\n\\r\\nThere's no perfect solution I can think of to this particular problem, but it's probably a good idea to call [`empty_cache()`](https://pytorch.org/docs/stable/generated/torch.cuda.empty_cache.html#torch.cuda.empty_cache) before resetting the PyTorch allocator to minimize the amount of wasted memory.\\r\\n\\r\\n---\\r\\n\\r\\nThat's just one example of the kind of issues that can arise if `import cudf` appears later. I think it's fine to assume this will be less common than importing it at the beginning.\\ncreatedAt: 2022-11-23T16:49:48Z\\nn_body_reactions_thumbs_up: 2\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 144}),\n",
       " Document(page_content=': 405\\ntitle: [BUG] libcudf tests of binary operations (in `binop-compiled-test.cpp`) mostly do not test against a ground truth\\nbody: **Describe the bug**\\r\\n\\r\\nBinary operations between columns are implemented by runtime typed dispatch to device functors in [`cpp/src/binaryop/compiled/operation.cuh`](https://github.com/rapidsai/cudf/blob/7426a06a4510280650df4cf54b76504d690c80b2/cpp/src/binaryop/compiled/operation.cuh).\\r\\n\\r\\nTests of this functionality compare to host-based compute, with an implementation of the functors in [`cpp/tests/binaryop/util/operation.h`](https://github.com/rapidsai/cudf/blob/7426a06a4510280650df4cf54b76504d690c80b2/cpp/tests/binaryop/util/operation.h)\\r\\n\\r\\nThis is a very weak test of correctness that really is testing:\\r\\n\\r\\n1. Can the author of the test copy the device functor implementation into the host implementation?\\r\\n2. Can the device and host compilers emit correct code for these cases?\\r\\n\\r\\nThese tests should more properly test against a ground truth (either manually constructed, or automatically).\\ncreatedAt: 2022-11-24T18:40:03Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 145}),\n",
       " Document(page_content=\": 406\\ntitle: [FEA] Support device-side de/compression of CSV files\\nbody: I have a lot of gzip compressed CSV files. When I use cudf to read them, the host handles decompression before copying decompressed data to device.\\r\\n\\r\\nFor cudf, that's not a problem, since it'll at worst be no slower than CPU.\\r\\n\\r\\nBut when I read w/ dask_cudf, compared to CPU dask.dataframe, I will usually have <=8 workers in a LocalCUDACluster. If I'm reading a large number of compressed files, those 8 workers will be highly bottlenecked by decompression.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nIdeally, we could have fast device side decompression for gzip compressed CSVs.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nAnother solution for dask_cudf could be some logic to make more parallel use of host CPUs for decompression, which should increase throughput t device.\\r\\n\\r\\n**Additional context**\\r\\nPer file compression level can be high, such that doing device side decompression, even if faster than CPU, could easily lead to OOM scenarios.\\r\\n\\r\\nAn illustrative dataset for use in exploring this problem is NOAA's daily weather observations:\\r\\n```\\r\\nimport urllib, os\\r\\n\\r\\ndata_dir = '/raid/weather/csv/'\\r\\n\\r\\n# download weather observations\\r\\nbase_url = 'ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/'\\r\\nyears = list(range(1763, 2020))\\r\\nfor year in years:\\r\\n    fn = str(year) + '.csv.gz'\\r\\n    if not os.path.isfile(data_dir+fn):\\r\\n        print(f'Downloading {base_url+fn} to {data_dir+fn}')\\r\\n        urllib.request.urlretrieve(base_url+fn, data_dir+fn) \\r\\n```\\r\\n\\r\\ncc @GregoryKimball\\ncreatedAt: 2022-11-29T17:34:28Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Randy Gelhausen\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 146}),\n",
       " Document(page_content=': 407\\ntitle: [FEA] automatic construction of MultiIndex DataFrame\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code from pandas into cudf, using `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\n>>> import pandas as pd\\r\\n>>> import cudf\\r\\n>>> cudf.__version__\\r\\n\\'22.12.00a+281.gcc4b4dd27c\\'\\r\\n>>> df = pd.DataFrame([[1],[2]], index=[[\\'a\\', \\'a\\'],[\\'b\\',\\'c\\']])\\r\\n>>> df\\r\\n     0\\r\\na b  1\\r\\n  c  2\\r\\n>>> cudf.DataFrame([[1],[2]], index=[[\\'a\\', \\'a\\'],[\\'b\\',\\'c\\']])\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/contextlib.py\", line 79, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py\", line 710, in __init__\\r\\n    self._init_from_list_like(\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/contextlib.py\", line 79, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py\", line 838, in _init_from_list_like\\r\\n    index = as_index(index)\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/contextlib.py\", line 79, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/index.py\", line 3019, in as_index\\r\\n    return as_index(\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/contextlib.py\", line 79, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/index.py\", line 3005, in as_index\\r\\n    return _index_from_data({kwargs.get(\"name\", None): arbitrary})\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/index.py\", line 122, in _index_from_data\\r\\n    raise NotImplementedError(\\r\\nNotImplementedError: Unsupported column type passed to create an Index: <class \\'cudf.core.column.lists.ListColumn\\'>\\r\\n```\\r\\ni would like the same functionality in `cudf` as is present in `pandas` (see https://pandas.pydata.org/docs/user_guide/advanced.html#hierarchical-indexing-multiindex)\\ncreatedAt: 2022-11-29T23:08:04Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 147}),\n",
       " Document(page_content=\": 408\\ntitle: [FEA] cudf.DataFrame.xs\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code from pandas to cudf, using `import cudf as pd`\\r\\n\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n`cudf.DataFrame.xs` matching https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.xs.html\\ncreatedAt: 2022-11-29T23:18:59Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 148}),\n",
       " Document(page_content=\": 410\\ntitle: [BUG] DataFrame.groupby.describe differs between cudf and pandas\\nbody: **Describe the bug**\\r\\n```\\r\\n>>> import pandas as pd\\r\\n>>> import cudf\\r\\n>>> cudf.__version__\\r\\n'22.12.00a+281.gcc4b4dd27c'\\r\\n>>> data = {'a': ['b'], 'p': ['q'], 'n': [0]}\\r\\n>>> pd.DataFrame(data).groupby('a').describe()\\r\\n      n                                  \\r\\n  count mean std  min  25%  50%  75%  max\\r\\na                                        \\r\\nb   1.0  0.0 NaN  0.0  0.0  0.0  0.0  0.0\\r\\n>>> cudf.DataFrame(data).groupby('a').describe()\\r\\n      p             n                                  \\r\\n  count min max count mean   std min  25%  50%  75% max\\r\\na                                                      \\r\\nb     1   q   q     1  0.0  <NA>   0  0.0  0.0  0.0   0\\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\nrapidsai/rapidsai-nightly:22.12-cuda11.5-runtime-rockylinux8-py3.9 on 29 nov 2022\\ncreatedAt: 2022-11-30T00:51:25Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 149}),\n",
       " Document(page_content=': 414\\ntitle: [FEA] For cuDF `bench_merge`, make output size scale with input size\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThe benchmark [bench_merge](https://github.com/rapidsai/cudf/blob/ff3b64325d3ac48fc0e8e0e9e1cf6246dd4aa075/python/cudf/benchmarks/API/bench_dataframe.py#L32) in [bench_dataframe.py](https://github.com/rapidsai/cudf/blob/branch-23.02/python/cudf/benchmarks/API/bench_dataframe.py) yields geometrically-increasing output size when `num_key_cols=2` . As a result, this particular benchmark runs into out-of-memory failures long before any other in the benchmarking suite. \\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nI would like to add a data generator with characteristics that make the output row count a roughly constant multiple of the input row count. \\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nOne alternative is to disable this benchmark for row counts >1M. However, cuDF join performance is one of its strongest features and we don\\'t want to restrict our benchmarking to smaller tables.\\r\\n\\r\\n**Additional context**\\r\\nHere is a code snippet that demonstrates the problem as well as a potential solution.\\r\\n```\\r\\nimport string\\r\\nimport cupy\\r\\nimport cudf\\r\\n\\r\\nrandom_state = cupy.random.RandomState(42)\\r\\ncolumn_generators = {\\r\\n    \"int\": (lambda nr: random_state.randint(low=0, high=100, size=nr)),\\r\\n    \"inthc\": (lambda nr: random_state.randint(low=0, high=nr ** 0.5, size=nr)),\\r\\n}\\r\\n\\r\\nfor gen in [\\'int\\', \\'inthc\\']:       \\r\\n    print(f\\'using column generator key {gen}\\')\\r\\n    for nr in [100, 10_000, 100_000, 1_000_000]:               \\r\\n        df = cudf.DataFrame({f\"{string.ascii_lowercase[i]}\": column_generators[gen](nr)  for i in range(6)})\\r\\n        m = df.merge(df, on=[\\'a\\', \\'b\\'])\\r\\n        print(\\'for input size {}, output size is {} (the ratio is {:.2f})\\'.format(nr, len(m), len(m)/nr))\\r\\n```\\r\\n\\r\\n```\\r\\nusing column generator key int\\r\\nfor input size 100, output size is 100 (the ratio is 1.00)\\r\\nfor input size 10000, output size is 20234 (the ratio is 2.02)\\r\\nfor input size 100000, output size is 1100538 (the ratio is 11.01)\\r\\nfor input size 1000000, output size is 101002012 (the ratio is 101.00)\\r\\nusing column generator key inthc\\r\\nfor input size 100, output size is 214 (the ratio is 2.14)\\r\\nfor input size 10000, output size is 19868 (the ratio is 1.99)\\r\\nfor input size 100000, output size is 199970 (the ratio is 2.00)\\r\\nfor input size 1000000, output size is 2000782 (the ratio is 2.00)\\r\\n```\\ncreatedAt: 2022-12-01T05:43:36Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 150}),\n",
       " Document(page_content=': 415\\ntitle: Poor scaling for larger query/loc with cudf Dataframe[QST]\\nbody: I am trying to extract the some columns of a cudf dataframe \\r\\n\\r\\n```\\r\\n%%time\\r\\ncudf_file = \"/work/ska/cudfoutput/lofar30MHz1_t201806301100_SBL153.parquet\"\\r\\ndf = cudf.read_parquet(cudf_file, columns =[\\'TIME\\',\\'ANTENNA1\\',\\'ANTENNA2\\',\\'FLAG\\',\\'DATA\\'])\\r\\ndf3 = df.loc[df[\\'TIME\\'].isin(unique_time)]\\r\\nfor t in unique_time:   \\r\\n    df2 = df3[df3.TIME == t]\\r\\n    beam_id_0_cp = cp.asarray(df2[\\'ANTENNA1\\'])\\r\\n    beam_id_1_cp = cp.asarray(df2[\\'ANTENNA2\\'])\\r\\n    dfflag = df2[\\'FLAG\\']\\r\\n    data_flag_cp = cp.asarray(dfflag.list.leaves).reshape(len(dfflag),len(dfflag.iloc[0]),len(dfflag.iloc[0][0]))\\r\\n    dfdata = df2[\\'DATA\\']\\r\\n    data_cp = cp.asarray(dfdata.list.leaves, dtype=np.float64).reshape(len(dfdata),len(dfdata.iloc[0]),len(dfdata.iloc[0][0])).view(np.complex128)\\r\\n   ```\\r\\n\\r\\nThe scaling becomes worse if we have a bigger loop (>1000 steps), for smaller timesteps it is the faster but as we go higher the scaling is becoming an issue. However, I am wondering why as I am not reading the dataframe inside the loop. Is there a better way to do this? I have tried groupby as well and the results are similar\\ncreatedAt: 2022-12-02T11:13:41Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Arpan Das\\ncompany: The École polytechnique fédérale de Lausanne', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 151}),\n",
       " Document(page_content=\": 417\\ntitle: [FEA] Support segmented reductions (MIN/MAX/COUNT DISTINCT) in cuDF `list` accessor\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nCurrently, we use cuDF to implement distributed group aggregation operations. That is, GROUP BY + DISTINCT is performed on the local node, and GROUP BY + MIN/MAX/COUNT DISTINCT are performed on the merge node. The LIST is transferred as an intermediate format, but the aggregation operation cannot be implemented.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nGroup +  Aggregation supports the list format.\\r\\n\\r\\n![捕获2](https://user-images.githubusercontent.com/43532055/205540928-0359139e-03ea-4c71-bd8d-0daaf0d5f875.PNG)\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\nAggregation operators are supported in the list format. For example, the current list supports only `len`, and aggregation operators such as `count`, `min`, `max`, and `avg` are expected to be added.\\r\\n\\r\\n![捕获](https://user-images.githubusercontent.com/43532055/205540951-3d8b4f09-7227-4cb1-836e-49e79c428e31.PNG)\\ncreatedAt: 2022-12-05T03:11:31Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Liu\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 152}),\n",
       " Document(page_content=': 421\\ntitle: [FEA] AST expression was provided non-matching operand types\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting `pandas` code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\n>>> import pandas as pd\\r\\n>>> import cudf\\r\\n>>> cudf.__version__\\r\\n\\'22.10.01+2.gca9a422da9\\' <- rapidsai/rapidsai-nightly:cuda11.5-runtime-centos7-py3.9 (3b7d5d24867a) on 6 dec 2022\\r\\n>>> df = cudf.DataFrame({\\'a\\': [1,2,3], \\'b\\': [3.0,2.0,1.0]})\\r\\n>>> df.to_pandas().eval(\\'a + b\\')\\r\\n0    4.0\\r\\n1    4.0\\r\\n2    4.0\\r\\ndtype: float64\\r\\n>>> df.eval(\\'a + b\\')\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/contextlib.py\", line 79, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.9/site-packages/cudf/core/dataframe.py\", line 6766, in eval\\r\\n    None: libcudf.transform.compute_column(\\r\\n  File \"transform.pyx\", line 190, in cudf._lib.transform.compute_column\\r\\nRuntimeError: cuDF failure at: /workspace/.conda-bld/work/cpp/src/ast/expression_parser.cpp:149: An AST expression was provided non-matching operand types.\\r\\n```\\r\\n\\r\\nsame behavior as `pandas`\\ncreatedAt: 2022-12-06T18:09:14Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 153}),\n",
       " Document(page_content=': 422\\ntitle: [FEA] Support inferring column names when using the `byte_range=` parameter in `read_csv`\\nbody: I cannot use the `byte_range` parameter with `read_csv` if the column names need to be inferred.\\r\\n\\r\\n```python\\r\\n>>> cudf.read_csv(StringIO(\"1,2,3\\\\n4,5,6\"), dtype=int, byte_range=(3, 6))\\r\\nRuntimeError: cuDF failure at: cudf/cpp/src/io/csv/reader_impl.cu:438: byte_range offset with header not supported\\r\\n```\\r\\n\\r\\nBut this works:\\r\\n\\r\\n```python\\r\\n>>> cudf.read_csv(StringIO(\"1,2,3\\\\n4,5,6\"), dtype=int, byte_range=(3, 6), names=[\\'x\\', \\'y\\', \\'z\\'])\\r\\n   x  y  z\\r\\n0  4  5  6\\r\\n```\\r\\n\\r\\nAnd this works:\\r\\n\\r\\n```python\\r\\n>>> cudf.read_csv(StringIO(\"1,2,3\\\\n4,5,6\"), dtype=int, byte_range=(3, 6), header=None)\\r\\n   0  1  2\\r\\n0  4  5  6\\r\\n```\\ncreatedAt: 2022-12-07T12:53:06Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 154}),\n",
       " Document(page_content=': 425\\ntitle: [BUG] Random sampling with cupy does not support these inputs\\nbody: Weighted sampling with cudf series is documented as supported but throws the following error\\r\\n\\r\\nRepro:\\r\\n```\\r\\na = cudf.Series(range(100))\\r\\na.sample(n=10, weights=a.values_host, random_state=0)\\r\\n\\r\\nor\\r\\n\\r\\na = cudf.Series(range(100))\\r\\na.sample(n=10, weights=a.values_host, random_state=0)\\r\\n\\r\\n```\\r\\n\\r\\nException:\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\nFile /conda/envs/rapids-22.12/lib/python3.9/site-packages/cudf/core/indexed_frame.py:2952, in IndexedFrame._sample_axis_0(self, n, weights, replace, random_state, ignore_index)\\r\\n   2951 try:\\r\\n-> 2952     gather_map_array = random_state.choice(\\r\\n   2953         len(self), size=n, replace=replace, p=weights\\r\\n   2954     )\\r\\n   2955 except NotImplementedError as e:\\r\\n\\r\\nFile /conda/envs/rapids-22.12/lib/python3.9/site-packages/cupy/random/_generator.py:1066, in RandomState.choice(self, a, size, replace, p)\\r\\n   1065 if not replace:\\r\\n-> 1066     raise NotImplementedError\\r\\n   1068 if p is not None:\\r\\n\\r\\nNotImplementedError: \\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\nCell In [25], line 2\\r\\n      1 a = cudf.Series(range(100))\\r\\n----> 2 a.sample(n=10, weights=a, random_state=0)\\r\\n\\r\\nFile /conda/envs/rapids-22.12/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile /conda/envs/rapids-22.12/lib/python3.9/site-packages/cudf/core/indexed_frame.py:2930, in IndexedFrame.sample(self, n, frac, replace, weights, random_state, axis, ignore_index)\\r\\n   2927     weights = weights / weights.sum()\\r\\n   2929 if axis == 0:\\r\\n-> 2930     return self._sample_axis_0(\\r\\n   2931         n, weights, replace, random_state, ignore_index\\r\\n   2932     )\\r\\n   2933 else:\\r\\n   2934     if isinstance(random_state, cp.random.RandomState):\\r\\n\\r\\nFile /conda/envs/rapids-22.12/lib/python3.9/site-packages/cudf/core/indexed_frame.py:2956, in IndexedFrame._sample_axis_0(self, n, weights, replace, random_state, ignore_index)\\r\\n   2952     gather_map_array = random_state.choice(\\r\\n   2953         len(self), size=n, replace=replace, p=weights\\r\\n   2954     )\\r\\n   2955 except NotImplementedError as e:\\r\\n-> 2956     raise NotImplementedError(\\r\\n   2957         \"Random sampling with cupy does not support these inputs.\"\\r\\n   2958     ) from e\\r\\n   2960 return self._gather(\\r\\n   2961     cudf.core.column.as_column(gather_map_array),\\r\\n   2962     keep_index=not ignore_index,\\r\\n   2963     check_bounds=False,\\r\\n   2964 )\\r\\n\\r\\nNotImplementedError: Random sampling with cupy does not support these inputs.\\r\\n```\\ncreatedAt: 2022-12-08T17:08:17Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lahir Marni\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 155}),\n",
       " Document(page_content=\": 427\\ntitle: [FEA] support type float16\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code from pandas with `import cudf as pd` and managing memory usage\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n```\\r\\ndf['src'] = df['src'].astype('float16')\\r\\n\\r\\ncudf/core/dtypes.py:51, in dtype(arbitrary)\\r\\n...\\r\\nTypeError: Unsupported type float16\\r\\n```\\ncreatedAt: 2022-12-12T16:29:14Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 156}),\n",
       " Document(page_content=\": 429\\ntitle: Turn on `xfail_strict=true` in all subpackages\\nbody: Followup to #12244.\\r\\n\\r\\nCan we do the same for other packages in the repo? I would expect that dask-cudf / custreamz / cudf-kafka / strings_udf won't have as many problems as cudf.\\r\\n\\r\\n_Originally posted by @bdice in https://github.com/rapidsai/cudf/pull/12244#discussion_r1048803383_\\ncreatedAt: 2022-12-15T11:11:31Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 157}),\n",
       " Document(page_content=': 430\\ntitle: Split out exceptional cases in heavily parametrized array ufunc tests\\nbody: Followup to #12244; A number of the parametrized array ufunc tests need to xfail (or skip) a large subsection of their parameters since the behaviour varies.\\r\\n\\r\\nIn many cases, this is not really a bug that we\\'re intending to fix, and so the \"xfail\"s pollute test output and hide what is really problematic from what is not.\\r\\n\\r\\n_Originally posted by @vyasr in https://github.com/rapidsai/cudf/pull/12244#discussion_r1049220334_\\ncreatedAt: 2022-12-15T11:21:25Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 158}),\n",
       " Document(page_content=': 432\\ntitle: [FEA] DatetimeProperties day_name matching pandas\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nconverting code with `import cudf as pd`\\r\\n\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> pd.__version__\\r\\n\\'22.12.01\\'\\r\\n>>> df = pd.Series(pd.date_range(\"1984\", freq=\\'s\\', periods=6))\\r\\n>>> df.to_pandas().dt.day_name()\\r\\n0    Sunday\\r\\n1    Sunday\\r\\n2    Sunday\\r\\n3    Sunday\\r\\n4    Sunday\\r\\n5    Sunday\\r\\ndtype: object\\r\\n>>> df.dt.day_name()\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\nAttributeError: \\'DatetimeProperties\\' object has no attribute \\'day_name\\'\\r\\n>>> type(df.dt)\\r\\n<class \\'cudf.core.series.DatetimeProperties\\'>\\r\\n```\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nimplementation of `day_name()` matching https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_name.html\\ncreatedAt: 2022-12-17T15:01:49Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 159}),\n",
       " Document(page_content=': 433\\ntitle: [BUG] cannot pass numpy funcs to groupby().agg()\\nbody: **Describe the bug**\\r\\nconverting code with `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> pd.__version__\\r\\n\\'22.12.01\\'\\r\\n>>> df = pd.DataFrame({\\'a\\': [1,2,3]*10})\\r\\n\\r\\n>>> df.to_pandas().groupby(\\'a\\').agg({\\'a\\': np.sum})\\r\\n    a\\r\\na    \\r\\n1  10\\r\\n2  20\\r\\n3  30\\r\\n\\r\\n>>> df.groupby(\\'a\\').agg({\\'a\\': np.sum})\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \".../python3.8/contextlib.py\", line 75, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \".../python3.8/site-packages/cudf/core/groupby/groupby.py\", line 460, in agg\\r\\n    ) = self._groupby.aggregate(columns, normalized_aggs)\\r\\n  File \"groupby.pyx\", line 309, in cudf._lib.groupby.GroupBy.aggregate\\r\\n  File \"groupby.pyx\", line 184, in cudf._lib.groupby.GroupBy.aggregate_internal\\r\\n  File \"aggregation.pyx\", line 866, in cudf._lib.aggregation.make_groupby_aggregation\\r\\n  File \"<__array_function__ internals>\", line 180, in sum\\r\\n  File \".../python3.8/site-packages/numpy/core/fromnumeric.py\", line 2298, in sum\\r\\n    return _wrapreduction(a, np.add, \\'sum\\', axis, dtype, out, keepdims=keepdims,\\r\\n  File \".../python3.8/site-packages/numpy/core/fromnumeric.py\", line 84, in _wrapreduction\\r\\n    return reduction(axis=axis, out=out, **passkwargs)\\r\\nTypeError: sum() got an unexpected keyword argument \\'out\\'\\r\\n```\\ncreatedAt: 2022-12-17T15:10:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 160}),\n",
       " Document(page_content=': 434\\ntitle: [BUG] pivot_table does not accept single index / columns\\nbody: **Describe the bug**\\r\\ncannot use `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> pd.__version__\\r\\n\\'22.12.01\\'\\r\\n\\r\\n>>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\\r\\n...                          \"bar\", \"bar\", \"bar\", \"bar\"],\\r\\n...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\\r\\n...                          \"one\", \"one\", \"two\", \"two\"],\\r\\n...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\\r\\n...                          \"small\", \"large\", \"small\", \"small\",\\r\\n...                          \"large\"],\\r\\n...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\\r\\n...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\\r\\n>>> df\\r\\n     A    B      C  D  E\\r\\n0  foo  one  small  1  2\\r\\n1  foo  one  large  2  4\\r\\n2  foo  one  large  2  5\\r\\n3  foo  two  small  3  5\\r\\n4  foo  two  small  3  6\\r\\n5  bar  one  large  4  6\\r\\n6  bar  one  small  5  8\\r\\n7  bar  two  small  6  9\\r\\n8  bar  two  large  7  9\\r\\n\\r\\n\\r\\n>>> df.to_pandas().pivot_table(values=\\'D\\', index=\\'A\\', columns=\\'C\\', aggfunc=\\'sum\\')\\r\\nC    large  small\\r\\nA                \\r\\nbar     11     11\\r\\nfoo      4      7\\r\\n\\r\\n>>> df.pivot_table(values=\\'D\\', index=\\'A\\', columns=\\'C\\', aggfunc=\\'sum\\')\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \".../python3.8/contextlib.py\", line 75, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \".../python3.8/site-packages/cudf/core/dataframe.py\", line 6749, in pivot_table\\r\\n    return cudf.core.reshape.pivot_table(\\r\\n  File \".../python3.8/site-packages/cudf/core/reshape.py\", line 1382, in pivot_table\\r\\n    for x in keys + values:\\r\\nTypeError: can only concatenate str (not \"list\") to str\\r\\n```\\ncreatedAt: 2022-12-17T17:20:57Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 161}),\n",
       " Document(page_content=': 435\\ntitle: [BUG] pivot_table columns type differs from pandas\\nbody: **Describe the bug**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> pd.__version__\\r\\n\\'22.12.01\\'\\r\\n>>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\\r\\n...                          \"bar\", \"bar\", \"bar\", \"bar\"],\\r\\n...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\\r\\n...                          \"one\", \"one\", \"two\", \"two\"],\\r\\n...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\\r\\n...                          \"small\", \"large\", \"small\", \"small\",\\r\\n...                          \"large\"],\\r\\n...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\\r\\n...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\\r\\n>>> df.pivot_table(index=[\\'A\\'], columns=[\\'B\\'], values=\\'D\\')\\r\\nB         one  two\\r\\nA                 \\r\\nbar  4.500000  6.5\\r\\nfoo  1.666667  3.0\\r\\n>>> df.to_pandas().pivot_table(index=[\\'A\\'], columns=[\\'B\\'], values=\\'D\\')\\r\\nB         one  two\\r\\nA                 \\r\\nbar  4.500000  6.5\\r\\nfoo  1.666667  3.0\\r\\n>>> df.to_pandas().pivot_table(index=[\\'A\\'], columns=[\\'B\\'], values=\\'D\\').columns\\r\\nIndex([\\'one\\', \\'two\\'], dtype=\\'object\\', name=\\'B\\')\\r\\n>>> df.pivot_table(index=[\\'A\\'], columns=[\\'B\\'], values=\\'D\\').columns\\r\\nMultiIndex([(\\'one\\',),\\r\\n            (\\'two\\',)],\\r\\n           names=[\\'B\\'])\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nan `Index` when only aggregating across one column\\ncreatedAt: 2022-12-17T19:27:20Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 162}),\n",
       " Document(page_content=': 436\\ntitle: [FEA] groupby.agg() support for controlling output columns\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> pd.__version__\\r\\n\\'22.12.01\\'\\r\\n\\r\\n>>> df = pd.DataFrame({\\'kind\\': [\\'cat\\', \\'dog\\', \\'cat\\', \\'dog\\'], \\'height\\': [9.1, 6.0, 9.5, 34.0], \\'weight\\': [7.9, 7.5, 9.9, 198.0]})\\r\\n>>> df\\r\\n  kind  height  weight\\r\\n0  cat     9.1     7.9\\r\\n1  dog     6.0     7.5\\r\\n2  cat     9.5     9.9\\r\\n3  dog    34.0   198.0\\r\\n\\r\\n>>> df.to_pandas().groupby(\\'kind\\').agg(min_height=(\\'height\\', \\'min\\'), max_weight=(\\'weight\\', \\'max\\'))\\r\\n      min_height  max_weight\\r\\nkind                        \\r\\ncat          9.1         9.9\\r\\ndog          6.0       198.0\\r\\n\\r\\n>>> df.groupby(\\'kind\\').agg(min_height=(\\'height\\', \\'min\\'), max_weight=(\\'weight\\', \\'max\\'))\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \".../python3.8/contextlib.py\", line 75, in inner\\r\\n    return func(*args, **kwds)\\r\\nTypeError: agg() got an unexpected keyword argument \\'min_height\\'\\r\\n```\\r\\n\\r\\nreferences:\\r\\n- https://github.com/pandas-dev/pandas/pull/26399\\r\\n- https://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.20.0.html#deprecate-groupby-agg-with-a-dictionary-when-renaming\\ncreatedAt: 2022-12-17T22:38:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 163}),\n",
       " Document(page_content=\": 437\\ntitle: [BUG] read_csv() got an unexpected keyword argument 'encoding'\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code using `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nimplementation of `encoding` parameter that matches https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas-read-csv\\ncreatedAt: 2022-12-17T23:59:13Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 164}),\n",
       " Document(page_content=': 438\\ntitle: [BUG] support index functions in cudf.DataFrame.rename\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> pd.__version__\\r\\n\\'22.12.01\\'\\r\\n>>> df = pd.DataFrame({\\'a\\': range(10)})\\r\\n>>> df = df.rename(index=str, columns={\\'a\\': \\'b\\'})\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \".../python3.8/contextlib.py\", line 75, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \".../python3.8/site-packages/cudf/core/dataframe.py\", line 3365, in rename\\r\\n    any(type(item) == str for item in index.values())\\r\\nAttributeError: type object \\'str\\' has no attribute \\'values\\'\\r\\n```\\ncreatedAt: 2022-12-18T12:24:38Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 165}),\n",
       " Document(page_content=\": 439\\ntitle: [FEA] support tuple construction in apply with axis=1\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> df = pd.DataFrame({'a': range(10, 20), 'b': range(110, 120)})\\r\\n>>> pd.__version__\\r\\n'22.12.01'\\r\\n\\r\\n>>> df.apply(lambda row: (row[0], row[1]), axis=1)\\r\\n...\\r\\nnumba.core.errors.NumbaNotImplementedError: UniTuple(Masked(int64) x 2) cannot be represented as a NumPy dtype\\r\\n```\\ncreatedAt: 2022-12-18T12:39:53Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 166}),\n",
       " Document(page_content=': 440\\ntitle: [BUG] Series.clip does not work with numpy/cupy clip\\nbody: **Describe the bug**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> import cupy as np\\r\\n>>> pd.__version__\\r\\n\\'22.12.01\\'\\r\\n>>> np.__version__\\r\\n\\'11.4.0\\'\\r\\n\\r\\n>>> df = pd.DataFrame({\\'a\\': range(10, 30)})\\r\\n\\r\\n>>> np.clip(df.to_pandas().a, a_min=15, a_max=25)\\r\\n0     15\\r\\n1     15\\r\\n2     15\\r\\n3     15\\r\\n4     15\\r\\n5     15\\r\\n6     16\\r\\n7     17\\r\\n8     18\\r\\n9     19\\r\\n10    20\\r\\n11    21\\r\\n12    22\\r\\n13    23\\r\\n14    24\\r\\n15    25\\r\\n16    25\\r\\n17    25\\r\\n18    25\\r\\n19    25\\r\\nName: a, dtype: int64\\r\\n\\r\\n>>> np.clip(df.a, a_min=15, a_max=25)\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \".../python3.8/site-packages/cupy/_math/misc.py\", line 172, in clip\\r\\n    return a.clip(a_min, a_max, out=out)\\r\\n  File \".../python3.8/contextlib.py\", line 75, in inner\\r\\n    return func(*args, **kwds)\\r\\nTypeError: clip() got an unexpected keyword argument \\'out\\'\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.clip.html\\r\\n```\\r\\n*args, **kwargs\\r\\n    Additional keywords have no effect but might be accepted for compatibility with numpy.\\r\\n```\\ncreatedAt: 2022-12-18T13:19:47Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 167}),\n",
       " Document(page_content=': 441\\ntitle: [BUG] date_range support for computed parameters\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nimplementation of `cudf.date_range` that matches https://pandas.pydata.org/docs/reference/api/pandas.date_range.html\\r\\n\\r\\nspecifically the ability to compute missing parameters\\r\\n\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> pd.__version__\\r\\n\\'22.12.01\\'\\r\\n>>> pd.date_range(100, periods=42)\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \".../python3.8/site-packages/cudf/core/tools/datetimes.py\", line 820, in date_range\\r\\n    raise ValueError(\\r\\nValueError: Of the four parameters: start, end, periods, and freq, exactly three must be specified\\r\\n>>> import pandas\\r\\n>>> pandas.date_range(100, periods=42)\\r\\nDatetimeIndex([\\'1970-01-01 00:00:00.000000100\\',\\r\\n               \\'1970-01-02 00:00:00.000000100\\',\\r\\n               \\'1970-01-03 00:00:00.000000100\\',\\r\\n               \\'1970-01-04 00:00:00.000000100\\',\\r\\n               \\'1970-01-05 00:00:00.000000100\\',\\r\\n               \\'1970-01-06 00:00:00.000000100\\',\\r\\n               \\'1970-01-07 00:00:00.000000100\\',\\r\\n               \\'1970-01-08 00:00:00.000000100\\',\\r\\n               \\'1970-01-09 00:00:00.000000100\\',\\r\\n               \\'1970-01-10 00:00:00.000000100\\',\\r\\n               \\'1970-01-11 00:00:00.000000100\\',\\r\\n               \\'1970-01-12 00:00:00.000000100\\',\\r\\n               \\'1970-01-13 00:00:00.000000100\\',\\r\\n               \\'1970-01-14 00:00:00.000000100\\',\\r\\n               \\'1970-01-15 00:00:00.000000100\\',\\r\\n               \\'1970-01-16 00:00:00.000000100\\',\\r\\n               \\'1970-01-17 00:00:00.000000100\\',\\r\\n               \\'1970-01-18 00:00:00.000000100\\',\\r\\n               \\'1970-01-19 00:00:00.000000100\\',\\r\\n               \\'1970-01-20 00:00:00.000000100\\',\\r\\n               \\'1970-01-21 00:00:00.000000100\\',\\r\\n               \\'1970-01-22 00:00:00.000000100\\',\\r\\n               \\'1970-01-23 00:00:00.000000100\\',\\r\\n               \\'1970-01-24 00:00:00.000000100\\',\\r\\n               \\'1970-01-25 00:00:00.000000100\\',\\r\\n               \\'1970-01-26 00:00:00.000000100\\',\\r\\n               \\'1970-01-27 00:00:00.000000100\\',\\r\\n               \\'1970-01-28 00:00:00.000000100\\',\\r\\n               \\'1970-01-29 00:00:00.000000100\\',\\r\\n               \\'1970-01-30 00:00:00.000000100\\',\\r\\n               \\'1970-01-31 00:00:00.000000100\\',\\r\\n               \\'1970-02-01 00:00:00.000000100\\',\\r\\n               \\'1970-02-02 00:00:00.000000100\\',\\r\\n               \\'1970-02-03 00:00:00.000000100\\',\\r\\n               \\'1970-02-04 00:00:00.000000100\\',\\r\\n               \\'1970-02-05 00:00:00.000000100\\',\\r\\n               \\'1970-02-06 00:00:00.000000100\\',\\r\\n               \\'1970-02-07 00:00:00.000000100\\',\\r\\n               \\'1970-02-08 00:00:00.000000100\\',\\r\\n               \\'1970-02-09 00:00:00.000000100\\',\\r\\n               \\'1970-02-10 00:00:00.000000100\\',\\r\\n               \\'1970-02-11 00:00:00.000000100\\'],\\r\\n              dtype=\\'datetime64[ns]\\', freq=\\'D\\')\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\ngooooooaaaaaallllll!\\ncreatedAt: 2022-12-18T15:38:13Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 168}),\n",
       " Document(page_content=\": 442\\ntitle: [BUG] date_range support for anchored offsets\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nupdating code to use `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n`cudf.date_range` support matching `pandas.date_range`\\r\\n\\r\\nsee https://pandas.pydata.org/docs/reference/api/pandas.date_range.html\\r\\nsee https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases\\r\\n\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> pd.__version__\\r\\n'22.12.01'\\r\\n>>> import pandas\\r\\n>>> pandas.__version__\\r\\n'1.2.2'\\r\\n>>> pd.date_range('2011-12-31T00:00:00.000000000', periods=52, freq='W-FRI')\\r\\nDatetimeIndex(['2011-12-31', '2012-01-07', '2012-01-14', '2012-01-21',\\r\\n               '2012-01-28', '2012-02-04', '2012-02-11', '2012-02-18',\\r\\n               '2012-02-25', '2012-03-03', '2012-03-10', '2012-03-17',\\r\\n               '2012-03-24', '2012-03-31', '2012-04-07', '2012-04-14',\\r\\n               '2012-04-21', '2012-04-28', '2012-05-05', '2012-05-12',\\r\\n               '2012-05-19', '2012-05-26', '2012-06-02', '2012-06-09',\\r\\n               '2012-06-16', '2012-06-23', '2012-06-30', '2012-07-07',\\r\\n               '2012-07-14', '2012-07-21', '2012-07-28', '2012-08-04',\\r\\n               '2012-08-11', '2012-08-18', '2012-08-25', '2012-09-01',\\r\\n               '2012-09-08', '2012-09-15', '2012-09-22', '2012-09-29',\\r\\n               '2012-10-06', '2012-10-13', '2012-10-20', '2012-10-27',\\r\\n               '2012-11-03', '2012-11-10', '2012-11-17', '2012-11-24',\\r\\n               '2012-12-01', '2012-12-08', '2012-12-15', '2012-12-22'],\\r\\n              dtype='datetime64[ns]')\\r\\n>>> pandas.date_range('2011-12-31T00:00:00.000000000', periods=52, freq='W-FRI')\\r\\nDatetimeIndex(['2012-01-06', '2012-01-13', '2012-01-20', '2012-01-27',\\r\\n               '2012-02-03', '2012-02-10', '2012-02-17', '2012-02-24',\\r\\n               '2012-03-02', '2012-03-09', '2012-03-16', '2012-03-23',\\r\\n               '2012-03-30', '2012-04-06', '2012-04-13', '2012-04-20',\\r\\n               '2012-04-27', '2012-05-04', '2012-05-11', '2012-05-18',\\r\\n               '2012-05-25', '2012-06-01', '2012-06-08', '2012-06-15',\\r\\n               '2012-06-22', '2012-06-29', '2012-07-06', '2012-07-13',\\r\\n               '2012-07-20', '2012-07-27', '2012-08-03', '2012-08-10',\\r\\n               '2012-08-17', '2012-08-24', '2012-08-31', '2012-09-07',\\r\\n               '2012-09-14', '2012-09-21', '2012-09-28', '2012-10-05',\\r\\n               '2012-10-12', '2012-10-19', '2012-10-26', '2012-11-02',\\r\\n               '2012-11-09', '2012-11-16', '2012-11-23', '2012-11-30',\\r\\n               '2012-12-07', '2012-12-14', '2012-12-21', '2012-12-28'],\\r\\n              dtype='datetime64[ns]', freq='W-FRI')\\r\\n```\\ncreatedAt: 2022-12-18T16:14:11Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 169}),\n",
       " Document(page_content=\": 445\\ntitle: [FEA] Support for min_periods in DataFrame correlation\\nbody: Hi. Pip installation on Google Colab with `!pip install cudf-cu11 --extra-index-url=https://pypi.ngc.nvidia.com` seems to work but results in missing functionality. For example, trying to compute column correlations in a dataframe with a `min_periods` argument specified raises `NotImplementedError: Unsupported argument 'min_periods'`. Other general functionality seems to be missing as well with various errors raised. Interestingly, everything seemed to be working yesterday. Any thoughts on what could be going on? Having a working pip installation on colab would be a game changer!\\ncreatedAt: 2023-01-01T12:08:14Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 170}),\n",
       " Document(page_content=': 450\\ntitle: [FEA] category dtype support in parquet writer\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nsame behavior as `import pandas as pd`\\r\\n\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.01\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'a\\': [\\'one\\',\\'two\\',\\'three\\'] * 10})\\r\\n\\r\\nIn [4]: df.info()\\r\\n<class \\'cudf.core.dataframe.DataFrame\\'>\\r\\nRangeIndex: 30 entries, 0 to 29\\r\\nData columns (total 1 columns):\\r\\n #   Column  Non-Null Count  Dtype\\r\\n---  ------  --------------  -----\\r\\n 0   a       30 non-null     object\\r\\ndtypes: object(1)\\r\\nmemory usage: 234.0+ bytes\\r\\n\\r\\nIn [5]: df.a = df.astype(\\'category\\')\\r\\n\\r\\nIn [6]: df.info()\\r\\n<class \\'cudf.core.dataframe.DataFrame\\'>\\r\\nRangeIndex: 30 entries, 0 to 29\\r\\nData columns (total 1 columns):\\r\\n #   Column  Non-Null Count  Dtype\\r\\n---  ------  --------------  -----\\r\\n 0   a       30 non-null     category\\r\\ndtypes: category(1)\\r\\nmemory usage: 57.0 bytes\\r\\n\\r\\nIn [7]: df.to_parquet(\\'df.parquet\\')\\r\\n---------------------------------------------------------------------------\\r\\nValueError                                Traceback (most recent call last)\\r\\nCell In[7], line 1\\r\\n----> 1 df.to_parquet(\\'df.parquet\\')\\r\\n\\r\\nFile .../lib/python3.8/site-packages/cudf/core/dataframe.py:6287, in DataFrame.to_parquet(self, path, engine, compression, index, partition_cols, partition_file_name, partition_offsets, statistics, metadata_file_path, int96_timestamps, row_group_size_bytes, row_group_size_rows, max_page_size_bytes, max_page_size_rows, storage_options, return_metadata, *args, **kwargs)\\r\\n   6284 \"\"\"{docstring}\"\"\"\\r\\n   6285 from cudf.io import parquet\\r\\n-> 6287 return parquet.to_parquet(\\r\\n   6288     self,\\r\\n   6289     path=path,\\r\\n   6290     engine=engine,\\r\\n   6291     compression=compression,\\r\\n   6292     index=index,\\r\\n   6293     partition_cols=partition_cols,\\r\\n   6294     partition_file_name=partition_file_name,\\r\\n   6295     partition_offsets=partition_offsets,\\r\\n   6296     statistics=statistics,\\r\\n   6297     metadata_file_path=metadata_file_path,\\r\\n   6298     int96_timestamps=int96_timestamps,\\r\\n   6299     row_group_size_bytes=row_group_size_bytes,\\r\\n   6300     row_group_size_rows=row_group_size_rows,\\r\\n   6301     max_page_size_bytes=max_page_size_bytes,\\r\\n   6302     max_page_size_rows=max_page_size_rows,\\r\\n   6303     storage_options=storage_options,\\r\\n   6304     return_metadata=return_metadata,\\r\\n   6305     *args,\\r\\n   6306     **kwargs,\\r\\n   6307 )\\r\\n\\r\\nFile .../lib/python3.8/contextlib.py:75, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     72 @wraps(func)\\r\\n     73 def inner(*args, **kwds):\\r\\n     74     with self._recreate_cm():\\r\\n---> 75         return func(*args, **kwds)\\r\\n\\r\\nFile .../lib/python3.8/site-packages/cudf/io/parquet.py:700, in to_parquet(df, path, engine, compression, index, partition_cols, partition_file_name, partition_offsets, statistics, metadata_file_path, int96_timestamps, row_group_size_bytes, row_group_size_rows, max_page_size_bytes, max_page_size_rows, storage_options, return_metadata, *args, **kwargs)\\r\\n    698     if partition_cols is None or col not in partition_cols:\\r\\n    699         if df[col].dtype.name == \"category\":\\r\\n--> 700             raise ValueError(\\r\\n    701                 \"\\'category\\' column dtypes are currently not \"\\r\\n    702                 + \"supported by the gpu accelerated parquet writer\"\\r\\n    703             )\\r\\n    705 if partition_cols:\\r\\n    706     if metadata_file_path is not None:\\r\\n\\r\\nValueError: \\'category\\' column dtypes are currently not supported by the gpu accelerated parquet writer\\r\\n\\r\\nIn [8]: df.to_pandas().to_parquet(\\'df.parquet\\')\\r\\n\\r\\nIn [9]: %ls df.parquet\\r\\ndf.parquet\\r\\n```\\ncreatedAt: 2023-01-07T13:39:50Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 171}),\n",
       " Document(page_content=\": 451\\ntitle: [FEA] category dtype support in parquet reader\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nsame behavior as `import pandas as pd`\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: '22.12.01'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({'a': ['one','two','three'] * 10})\\r\\n\\r\\nIn [4]: df.info()\\r\\n<class 'cudf.core.dataframe.DataFrame'>\\r\\nRangeIndex: 30 entries, 0 to 29\\r\\nData columns (total 1 columns):\\r\\n #   Column  Non-Null Count  Dtype\\r\\n---  ------  --------------  -----\\r\\n 0   a       30 non-null     object\\r\\ndtypes: object(1)\\r\\nmemory usage: 234.0+ bytes\\r\\n\\r\\nIn [5]: df.a = df.astype('category')\\r\\n\\r\\nIn [6]: df.info()\\r\\n<class 'cudf.core.dataframe.DataFrame'>\\r\\nRangeIndex: 30 entries, 0 to 29\\r\\nData columns (total 1 columns):\\r\\n #   Column  Non-Null Count  Dtype\\r\\n---  ------  --------------  -----\\r\\n 0   a       30 non-null     category\\r\\ndtypes: category(1)\\r\\nmemory usage: 57.0 bytes\\r\\n\\r\\nIn [7]: %ls df.parquet\\r\\nls: cannot access 'df.parquet': No such file or directory\\r\\n\\r\\nIn [8]: df.to_pandas().to_parquet('df.parquet')\\r\\n\\r\\nIn [9]: %ls df.parquet\\r\\ndf.parquet\\r\\n\\r\\nIn [10]: pd.read_parquet('df.parquet').info()\\r\\n<class 'cudf.core.dataframe.DataFrame'>\\r\\nRangeIndex: 30 entries, 0 to 29\\r\\nData columns (total 1 columns):\\r\\n #   Column  Non-Null Count  Dtype\\r\\n---  ------  --------------  -----\\r\\n 0   a       30 non-null     object\\r\\ndtypes: object(1)\\r\\nmemory usage: 234.0+ bytes\\r\\n\\r\\nIn [11]: import pandas\\r\\n\\r\\nIn [12]: pandas.read_parquet('df.parquet').info()\\r\\n<class 'pandas.core.frame.DataFrame'>\\r\\nRangeIndex: 30 entries, 0 to 29\\r\\nData columns (total 1 columns):\\r\\n #   Column  Non-Null Count  Dtype   \\r\\n---  ------  --------------  -----   \\r\\n 0   a       30 non-null     category\\r\\ndtypes: category(1)\\r\\nmemory usage: 290.0 bytes\\r\\n\\r\\nIn [13]: pd.DataFrame(pandas.read_parquet('df.parquet')).info()\\r\\n<class 'cudf.core.dataframe.DataFrame'>\\r\\nRangeIndex: 30 entries, 0 to 29\\r\\nData columns (total 1 columns):\\r\\n #   Column  Non-Null Count  Dtype\\r\\n---  ------  --------------  -----\\r\\n 0   a       30 non-null     category\\r\\ndtypes: category(1)\\r\\nmemory usage: 57.0 bytes\\r\\n```\\r\\n\\r\\nthe parquet reader turns the column into dtype=object\\r\\n```\\r\\nIn [10]: pd.read_parquet('df.parquet').info()\\r\\n<class 'cudf.core.dataframe.DataFrame'>\\r\\nRangeIndex: 30 entries, 0 to 29\\r\\nData columns (total 1 columns):\\r\\n #   Column  Non-Null Count  Dtype\\r\\n---  ------  --------------  -----\\r\\n 0   a       30 non-null     object\\r\\ndtypes: object(1)\\r\\nmemory usage: 234.0+ bytes\\r\\n```\\ncreatedAt: 2023-01-07T13:45:35Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 172}),\n",
       " Document(page_content=': 452\\ntitle: [QST] CPU memory spike during cudf dataframe conversion\\nbody: Hi all, I have a dataframe that is ~19K Rows, ~11.4 MB (Profiled using ```df.info(memory_usage = \"deep\")```). We are currently running into CPU out of memory issues and so profiling our memory using this sample dataset. As you can see in the screenshot attached, there is a jump in mem usage, from 840MiB -> 4148MiB, during the type conversion of ```df```. Image below shows the dataframe memory usage after conversion. \\r\\n\\r\\nMy question is: Why is there a jump in the memory usage when converting a dataframe from pandas to cudf? Furthermore, this memory is not released after, and so increases from this point in following processing steps.\\r\\n\\r\\n<img width=\"508\" alt=\"Screenshot 2023-01-09 at 6 08 11 PM\" src=\"https://user-images.githubusercontent.com/58301316/211284128-f093d906-cdb5-42b9-9ea8-79d4ff237f95.png\">\\r\\n<img width=\"1179\" alt=\"Screenshot 2023-01-10 at 11 16 09 AM\" src=\"https://user-images.githubusercontent.com/58301316/211454005-c39e9bf0-393c-4bbc-83ad-9e9f23783991.png\">\\ncreatedAt: 2023-01-09T10:09:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Yi Kuang\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 173}),\n",
       " Document(page_content=\": 453\\ntitle: [QST]The group by collect performance is insufficient, and the performance deteriorates with the increase of the group by column length.\\nbody: **What is your question?**\\r\\nThe group by collect performance is insufficient, and the performance deteriorates with the increase of the group by column length.\\r\\n\\r\\n```\\r\\n>>> import cudf\\r\\n>>> import time\\r\\n>>>\\r\\n>>> import pandas\\r\\n>>> import pyarrow\\r\\n>>> import numpy as np\\r\\n>>>\\r\\n>>> def create_table(n_rows, n_cols, n_range):\\r\\n...     table = pyarrow.Table.from_pydict(\\r\\n...         {f'col_{c}': np.random.randint(0, n_range, size=[n_rows]) for c in range(n_cols)})\\r\\n...     return table\\r\\n...\\r\\n>>>\\r\\n>>> def create_table_with_str(n_rows, n_cols, n_strs, n_strs_cols, n_range):\\r\\n...     prefix = 'xxxx_' * ((n_strs - 10) // 5)\\r\\n...     cdf = create_table(n_rows, n_cols, n_range).to_pandas()\\r\\n...     for i in range(n_strs_cols):\\r\\n...         cdf[f'col_{i}'] = cdf[f'col_{i}'].apply(lambda x: f'{prefix}{x:010}')\\r\\n    return pyarrow.Table.from_pandas(cdf)...     return pyarrow.Table.from_pandas(cdf)\\r\\n...\\r\\n>>>\\r\\n>>> def stat_cost(str_len):\\r\\n...     tbl = create_table_with_str(2000 * 10000, 2, str_len, 1, 1500 * 10000)\\r\\n...     start = time.time()\\r\\n...     df = cudf.DataFrame.from_arrow(tbl)\\r\\n...     print(f'from arrow cost: {time.time() - start} s, '\\r\\n...           f'bandwidth: {df.shape[0] / 10000 / (time.time() - start)} WRows/s')\\r\\n...     print(df)\\r\\n...     start = time.time()\\r\\n...     result = df.groupby(['col_0']).collect()\\r\\n...     print(f'group by collect cost: {time.time() - start} s, '\\r\\n...           f'bandwidth: {df.shape[0] / 10000 / (time.time() - start)} WRows/s')\\r\\n...\\r\\n>>>\\r\\n>>> stat_cost(10)\\r\\nfrom arrow cost: 0.09801530838012695 s, bandwidth: 20401.15471699949 WRows/s\\r\\n               col_0     col_1\\r\\n0         0009882104   3942519\\r\\n1         0009170270   7183154\\r\\n2         0000346561  14059698\\r\\n3         0009672848   6882498\\r\\n4         0011532285  12876681\\r\\n...              ...       ...\\r\\n19999995  0000388357    579814\\r\\n19999996  0009951171  14008663\\r\\n19999997  0002681040    318695\\r\\n19999998  0003139531   5608877\\r\\n19999999  0007299816  12547343\\r\\n\\r\\n[20000000 rows x 2 columns]\\r\\ngroup by collect cost: 1.317047119140625 s, bandwidth: 1518.522440661447 WRows/s\\r\\n>>> stat_cost(20)\\r\\nfrom arrow cost: 0.14093589782714844 s, bandwidth: 14187.992497213516 WRows/s\\r\\n                         col_0     col_1\\r\\n0         xxxx_xxxx_0011097676   6734961\\r\\n1         xxxx_xxxx_0005386896  13758023\\r\\n2         xxxx_xxxx_0012936583  12093805\\r\\n3         xxxx_xxxx_0014685588    977351\\r\\n4         xxxx_xxxx_0002394173   4422859\\r\\n...                        ...       ...\\r\\n19999995  xxxx_xxxx_0008602092   1174373\\r\\n19999996  xxxx_xxxx_0006179928   9909283\\r\\n19999997  xxxx_xxxx_0004578043   4414022\\r\\n19999998  xxxx_xxxx_0004295524   9151066\\r\\n19999999  xxxx_xxxx_0009383727   5630830\\r\\n\\r\\n[20000000 rows x 2 columns]\\r\\ngroup by collect cost: 3.6019299030303955 s, bandwidth: 555.254619538489 WRows/s\\r\\n>>> stat_cost(30)\\r\\nfrom arrow cost: 0.1838366985321045 s, bandwidth: 10878.289477949978 WRows/s\\r\\n                                   col_0     col_1\\r\\n0         xxxx_xxxx_xxxx_xxxx_0012107927  11093137\\r\\n1         xxxx_xxxx_xxxx_xxxx_0008415030   6082935\\r\\n2         xxxx_xxxx_xxxx_xxxx_0001637082   5181973\\r\\n3         xxxx_xxxx_xxxx_xxxx_0014907884  13010547\\r\\n4         xxxx_xxxx_xxxx_xxxx_0011395415   8406699\\r\\n...                                  ...       ...\\r\\n19999995  xxxx_xxxx_xxxx_xxxx_0013393283   9371961\\r\\n19999996  xxxx_xxxx_xxxx_xxxx_0012288828   3685424\\r\\n19999997  xxxx_xxxx_xxxx_xxxx_0011403282  11832112\\r\\n19999998  xxxx_xxxx_xxxx_xxxx_0014808359  12467674\\r\\n19999999  xxxx_xxxx_xxxx_xxxx_0007966548   3177904\\r\\n\\r\\n[20000000 rows x 2 columns]\\r\\ngroup by collect cost: 6.546090126037598 s, bandwidth: 305.5246419013939 WRows/s\\r\\n\\r\\n```\\r\\n![捕获](https://user-images.githubusercontent.com/43532055/211317106-522eec4e-6bc4-439f-8eda-4dd889379a24.PNG)\\r\\n\\r\\nHow to improve performance?\\ncreatedAt: 2023-01-09T13:18:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Liu\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 174}),\n",
       " Document(page_content=': 454\\ntitle: [BUG] IndexError during assignment through loc[]\\nbody: **Describe the bug**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame(columns=[\\'a\\'])\\r\\n\\r\\nIn [4]: df.loc[0] = [1]\\r\\n---------------------------------------------------------------------------\\r\\nIndexError                                Traceback (most recent call last)\\r\\nCell In [4], line 1\\r\\n----> 1 df.loc[0] = [1]\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:149, in _DataFrameIndexer.__setitem__(self, key, value)\\r\\n    147 if not isinstance(key, tuple):\\r\\n    148     key = (key, slice(None))\\r\\n--> 149 return self._setitem_tuple_arg(key, value)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:393, in _DataFrameLocIndexer._setitem_tuple_arg(self, key, value)\\r\\n    386 # Otherwise, there are two situations. The key on row axis\\r\\n    387 # can be a scalar or 1d. In either of the situation, the\\r\\n    388 # ith element in value corresponds to the ith row in\\r\\n    389 # the indexed object.\\r\\n    390 # If the key is 1d, a broadcast will happen.\\r\\n    391 else:\\r\\n    392     for i, col in enumerate(columns_df._column_names):\\r\\n--> 393         self._frame[col].loc[key[0]] = value[i]\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/series.py:285, in _SeriesLocIndexer.__setitem__(self, key, value)\\r\\n    283     value = cudf.Series(value)\\r\\n    284     value = value._align_to_index(self._frame.index, how=\"right\")\\r\\n--> 285 self._frame.iloc[key] = value\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/series.py:236, in _SeriesIlocIndexer.__setitem__(self, key, value)\\r\\n    231     if to_dtype != self._frame._column.dtype:\\r\\n    232         self._frame._column._mimic_inplace(\\r\\n    233             self._frame._column.astype(to_dtype), inplace=True\\r\\n    234         )\\r\\n--> 236 self._frame._column[key] = value\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/column/column.py:496, in ColumnBase.__setitem__(self, key, value)\\r\\n    494     if not isinstance(key, cudf.core.column.NumericalColumn):\\r\\n    495         raise ValueError(f\"Invalid scatter map type {key.dtype}.\")\\r\\n--> 496     out = self._scatter_by_column(key, value_normalized)\\r\\n    498 if out:\\r\\n    499     self._mimic_inplace(out, inplace=True)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/column/column.py:580, in ColumnBase._scatter_by_column(self, key, value)\\r\\n    576     return libcudf.copying.boolean_mask_scatter([value], [self], key)[\\r\\n    577         0\\r\\n    578     ]._with_type_metadata(self.dtype)\\r\\n    579 else:\\r\\n--> 580     return libcudf.copying.scatter([value], key, [self])[\\r\\n    581         0\\r\\n    582     ]._with_type_metadata(self.dtype)\\r\\n\\r\\nFile /usr/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile copying.pyx:265, in cudf._lib.copying.scatter()\\r\\n\\r\\nIndexError: index out of bounds for column of size 0\\r\\n\\r\\nIn [5]: pdf = df.to_pandas()\\r\\n\\r\\nIn [6]: pdf\\r\\nOut[6]: \\r\\nEmpty DataFrame\\r\\nColumns: [a]\\r\\nIndex: []\\r\\n\\r\\nIn [7]: pdf.loc[0] = [1]\\r\\n\\r\\nIn [8]: pdf\\r\\nOut[8]: \\r\\n   a\\r\\n0  1\\r\\n```\\r\\n\\r\\n\\r\\n**Expected behavior**\\r\\nsame behavior as `import pandas as pd`\\ncreatedAt: 2023-01-09T21:16:15Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 175}),\n",
       " Document(page_content=': 455\\ntitle: [BUG] assignment through loc[] breaks DataFrame\\nbody: **Describe the bug**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'a\\':0})\\r\\n\\r\\nIn [4]: df\\r\\nOut[4]: \\r\\n   a\\r\\n0  0\\r\\n\\r\\nIn [5]: df.loc[1] = 2\\r\\n\\r\\nIn [6]: df\\r\\nOut[6]: ---------------------------------------------------------------------------\\r\\nValueError                                Traceback (most recent call last)\\r\\nFile ~/.local/lib/python3.9/site-packages/IPython/core/formatters.py:707, in PlainTextFormatter.__call__(self, obj)\\r\\n    700 stream = StringIO()\\r\\n    701 printer = pretty.RepresentationPrinter(stream, self.verbose,\\r\\n    702     self.max_width, self.newline,\\r\\n    703     max_seq_length=self.max_seq_length,\\r\\n    704     singleton_pprinters=self.singleton_printers,\\r\\n    705     type_pprinters=self.type_printers,\\r\\n    706     deferred_pprinters=self.deferred_printers)\\r\\n--> 707 printer.pretty(obj)\\r\\n    708 printer.flush()\\r\\n    709 return stream.getvalue()\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/IPython/lib/pretty.py:410, in RepresentationPrinter.pretty(self, obj)\\r\\n    407                         return meth(obj, self, cycle)\\r\\n    408                 if cls is not object \\\\\\r\\n    409                         and callable(cls.__dict__.get(\\'__repr__\\')):\\r\\n--> 410                     return _repr_pprint(obj, self, cycle)\\r\\n    412     return _default_pprint(obj, self, cycle)\\r\\n    413 finally:\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/IPython/lib/pretty.py:778, in _repr_pprint(obj, p, cycle)\\r\\n    776 \"\"\"A pprint that just redirects to the normal repr function.\"\"\"\\r\\n    777 # Find newlines and replace them with p.break_()\\r\\n--> 778 output = repr(obj)\\r\\n    779 lines = output.splitlines()\\r\\n    780 with p.group():\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:1863, in DataFrame.__repr__(self)\\r\\n   1860 @_cudf_nvtx_annotate\\r\\n   1861 def __repr__(self):\\r\\n   1862     output = self._get_renderable_dataframe()\\r\\n-> 1863     return self._clean_renderable_dataframe(output)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:1741, in DataFrame._clean_renderable_dataframe(self, output)\\r\\n   1738 else:\\r\\n   1739     width = None\\r\\n-> 1741 output = output.to_pandas().to_string(\\r\\n   1742     max_rows=max_rows,\\r\\n   1743     min_rows=min_rows,\\r\\n   1744     max_cols=max_cols,\\r\\n   1745     line_width=width,\\r\\n   1746     max_colwidth=max_colwidth,\\r\\n   1747     show_dimensions=show_dimensions,\\r\\n   1748 )\\r\\n   1750 lines = output.split(\"\\\\n\")\\r\\n   1752 if lines[-1].startswith(\"[\"):\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:5037, in DataFrame.to_pandas(self, nullable, **kwargs)\\r\\n   5034 out_index = self.index.to_pandas()\\r\\n   5036 for i, col_key in enumerate(self._data):\\r\\n-> 5037     out_data[i] = self._data[col_key].to_pandas(\\r\\n   5038         index=out_index, nullable=nullable\\r\\n   5039     )\\r\\n   5041 out_df = pd.DataFrame(out_data, index=out_index)\\r\\n   5042 out_df.columns = self._data.to_pandas_index()\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/column/numerical.py:732, in NumericalColumn.to_pandas(self, index, nullable, **kwargs)\\r\\n    729     pd_series = self.to_arrow().to_pandas(**kwargs)\\r\\n    731 if index is not None:\\r\\n--> 732     pd_series.index = index\\r\\n    733 return pd_series\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/pandas/core/generic.py:5588, in NDFrame.__setattr__(self, name, value)\\r\\n   5586 try:\\r\\n   5587     object.__getattribute__(self, name)\\r\\n-> 5588     return object.__setattr__(self, name, value)\\r\\n   5589 except AttributeError:\\r\\n   5590     pass\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/pandas/_libs/properties.pyx:70, in pandas._libs.properties.AxisProperty.__set__()\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/pandas/core/series.py:572, in Series._set_axis(self, axis, labels, fastpath)\\r\\n    568             pass\\r\\n    570 if not fastpath:\\r\\n    571     # The ensure_index call above ensures we have an Index object\\r\\n--> 572     self._mgr.set_axis(axis, labels)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py:214, in BaseBlockManager.set_axis(self, axis, new_labels)\\r\\n    212 def set_axis(self, axis: int, new_labels: Index) -> None:\\r\\n    213     # Caller is responsible for ensuring we have an Index object.\\r\\n--> 214     self._validate_set_axis(axis, new_labels)\\r\\n    215     self.axes[axis] = new_labels\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/pandas/core/internals/base.py:69, in DataManager._validate_set_axis(self, axis, new_labels)\\r\\n     66     pass\\r\\n     68 elif new_len != old_len:\\r\\n---> 69     raise ValueError(\\r\\n     70         f\"Length mismatch: Expected axis has {old_len} elements, new \"\\r\\n     71         f\"values have {new_len} elements\"\\r\\n     72     )\\r\\n\\r\\nValueError: Length mismatch: Expected axis has 2 elements, new values have 1 elements\\r\\n\\r\\nIn [7]: pdf = pd.DataFrame({\\'a\\':0}).to_pandas()\\r\\n\\r\\nIn [8]: pdf\\r\\nOut[8]: \\r\\n   a\\r\\n0  0\\r\\n\\r\\nIn [9]: pdf.loc[1] = 2\\r\\n\\r\\nIn [10]: pdf\\r\\nOut[10]: \\r\\n   a\\r\\n0  0\\r\\n1  2\\r\\n\\r\\nIn [11]: df.loc[0]\\r\\n---------------------------------------------------------------------------\\r\\nRuntimeError                              Traceback (most recent call last)\\r\\nCell In [13], line 1\\r\\n----> 1 df.loc[0]\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:144, in _DataFrameIndexer.__getitem__(self, arg)\\r\\n    142 if not isinstance(arg, tuple):\\r\\n    143     arg = (arg, slice(None))\\r\\n--> 144 return self._getitem_tuple_arg(arg)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:291, in _DataFrameLocIndexer._getitem_tuple_arg(self, arg)\\r\\n    286 tmp_col_name = str(uuid4())\\r\\n    287 other_df = DataFrame(\\r\\n    288     {tmp_col_name: column.arange(len(tmp_arg[0]))},\\r\\n    289     index=as_index(tmp_arg[0]),\\r\\n    290 )\\r\\n--> 291 df = other_df.join(columns_df, how=\"inner\")\\r\\n    292 # as join is not assigning any names to index,\\r\\n    293 # update it over here\\r\\n    294 df.index.name = columns_df.index.name\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:4038, in DataFrame.join(self, other, on, how, lsuffix, rsuffix, sort)\\r\\n   4035 if on is not None:\\r\\n   4036     raise NotImplementedError(\"The on parameter is not yet supported\")\\r\\n-> 4038 df = self.merge(\\r\\n   4039     other,\\r\\n   4040     left_index=True,\\r\\n   4041     right_index=True,\\r\\n   4042     how=how,\\r\\n   4043     suffixes=(lsuffix, rsuffix),\\r\\n   4044     sort=sort,\\r\\n   4045 )\\r\\n   4046 df.index.name = (\\r\\n   4047     None if self.index.name != other.index.name else self.index.name\\r\\n   4048 )\\r\\n   4049 return df\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:3987, in DataFrame.merge(self, right, on, left_on, right_on, left_index, right_index, how, sort, lsuffix, rsuffix, indicator, suffixes)\\r\\n   3984 elif how in {\"leftsemi\", \"leftanti\"}:\\r\\n   3985     merge_cls = MergeSemi\\r\\n-> 3987 return merge_cls(\\r\\n   3988     lhs,\\r\\n   3989     rhs,\\r\\n   3990     on=on,\\r\\n   3991     left_on=left_on,\\r\\n   3992     right_on=right_on,\\r\\n   3993     left_index=left_index,\\r\\n   3994     right_index=right_index,\\r\\n   3995     how=how,\\r\\n   3996     sort=sort,\\r\\n   3997     indicator=indicator,\\r\\n   3998     suffixes=suffixes,\\r\\n   3999 ).perform_merge()\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/join/join.py:200, in Merge.perform_merge(self)\\r\\n    189 gather_kwargs = {\\r\\n    190     \"nullify\": True,\\r\\n    191     \"check_bounds\": False,\\r\\n    192     \"keep_index\": self._using_left_index or self._using_right_index,\\r\\n    193 }\\r\\n    194 left_result = (\\r\\n    195     self.lhs._gather(gather_map=left_rows, **gather_kwargs)\\r\\n    196     if left_rows is not None\\r\\n    197     else cudf.DataFrame._from_data({})\\r\\n    198 )\\r\\n    199 right_result = (\\r\\n--> 200     self.rhs._gather(gather_map=right_rows, **gather_kwargs)\\r\\n    201     if right_rows is not None\\r\\n    202     else cudf.DataFrame._from_data({})\\r\\n    203 )\\r\\n    205 result = cudf.DataFrame._from_data(\\r\\n    206     *self._merge_results(left_result, right_result)\\r\\n    207 )\\r\\n    209 if self.sort:\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/indexed_frame.py:1722, in IndexedFrame._gather(self, gather_map, keep_index, nullify, check_bounds)\\r\\n   1716 if not libcudf.copying._gather_map_is_valid(\\r\\n   1717     gather_map, len(self), check_bounds, nullify\\r\\n   1718 ):\\r\\n   1719     raise IndexError(\"Gather map index is out of bounds.\")\\r\\n   1721 return self._from_columns_like_self(\\r\\n-> 1722     libcudf.copying.gather(\\r\\n   1723         list(self._index._columns + self._columns)\\r\\n   1724         if keep_index\\r\\n   1725         else list(self._columns),\\r\\n   1726         gather_map,\\r\\n   1727         nullify=nullify,\\r\\n   1728     ),\\r\\n   1729     self._column_names,\\r\\n   1730     self._index.names if keep_index else None,\\r\\n   1731 )\\r\\n\\r\\nFile /usr/lib/python3.9/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile copying.pyx:178, in cudf._lib.copying.gather()\\r\\n\\r\\nFile utils.pyx:46, in cudf._lib.utils.table_view_from_columns()\\r\\n\\r\\nRuntimeError: cuDF failure at: /project/cpp/src/table/table_view.cpp:35: Column size mismatch.\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nsame behavior as `import pandas as pd`\\ncreatedAt: 2023-01-09T21:22:09Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 176}),\n",
       " Document(page_content=': 456\\ntitle: [FEA] replace(): regex parameter is not implemented yet\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: df = pd.DataFrame({\\'a\\': [\\'abc\\',\\'bcd\\',\\'cde\\']})\\r\\n\\r\\nIn [3]: df.replace(\\'c\\', \\'C\\', regex=True)\\r\\n---------------------------------------------------------------------------\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\nCell In [3], line 1\\r\\n----> 1 df.replace(\\'c\\', \\'C\\', regex=True)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/indexed_frame.py:744, in IndexedFrame.replace(self, to_replace, value, inplace, limit, regex, method)\\r\\n    741     raise NotImplementedError(\"limit parameter is not implemented yet\")\\r\\n    743 if regex:\\r\\n--> 744     raise NotImplementedError(\"regex parameter is not implemented yet\")\\r\\n    746 if method not in (\"pad\", None):\\r\\n    747     raise NotImplementedError(\\r\\n    748         \"method parameter is not implemented yet\"\\r\\n    749     )\\r\\n\\r\\nNotImplementedError: regex parameter is not implemented yet\\r\\n\\r\\nIn [4]: df.to_pandas().replace(\\'c\\', \\'C\\', regex=True)\\r\\nOut[4]: \\r\\n     a\\r\\n0  abC\\r\\n1  bCd\\r\\n2  Cde\\r\\n\\r\\nIn [5]: pd.__version__\\r\\nOut[5]: \\'22.12.0\\'\\r\\n```\\ncreatedAt: 2023-01-09T21:30:39Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 177}),\n",
       " Document(page_content=': 457\\ntitle: [FEA] DataFrame.query support for strings\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with code using `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nfunctionality matching `import pandas as pd`\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: df = pd.DataFrame({\\'a\\': [\\'one\\', \\'two\\', \\'three\\']})\\r\\n\\r\\nIn [3]: df.query(\\'a == \"one\"\\')\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\nCell In [3], line 1\\r\\n----> 1 df.query(\\'a == \"one\"\\')\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:4174, in DataFrame.query(self, expr, local_dict)\\r\\n   4168 callenv = {\\r\\n   4169     \"locals\": callframe.f_locals,\\r\\n   4170     \"globals\": callframe.f_globals,\\r\\n   4171     \"local_dict\": local_dict,\\r\\n   4172 }\\r\\n   4173 # Run query\\r\\n-> 4174 boolmask = queryutils.query_execute(self, expr, callenv)\\r\\n   4175 return self._apply_boolean_mask(boolmask)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/utils/queryutils.py:218, in query_execute(df, expr, callenv)\\r\\n    216 # wait to check the types until we know which cols are used\\r\\n    217 if any(col.dtype not in SUPPORTED_QUERY_TYPES for col in colarrays):\\r\\n--> 218     raise TypeError(\\r\\n    219         \"query only supports numeric, datetime, timedelta, \"\\r\\n    220         \"or bool dtypes.\"\\r\\n    221     )\\r\\n    223 colarrays = [col.data_array_view for col in colarrays]\\r\\n    225 kernel = compiled[\"kernel\"]\\r\\n\\r\\nTypeError: query only supports numeric, datetime, timedelta, or bool dtypes.\\r\\n\\r\\nIn [4]: pd.__version__\\r\\nOut[4]: \\'22.12.0\\'\\r\\n\\r\\nIn [5]: df.to_pandas().query(\\'a == \"one\"\\')\\r\\nOut[5]: \\r\\n     a\\r\\n0  one\\r\\n```\\ncreatedAt: 2023-01-09T23:25:35Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 178}),\n",
       " Document(page_content=': 458\\ntitle: [FEA] DataFrame.query support for math ops\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nsupport for math ops matching `pandas`\\r\\n\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'a\\': [1**2, 2**2, 3**2]})\\r\\n\\r\\nIn [4]: df.query(\\'sqrt(a) >= 2\\')\\r\\n---------------------------------------------------------------------------\\r\\nKeyError                                  Traceback (most recent call last)\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:7559, in extract_col(df, col)\\r\\n   7558 try:\\r\\n-> 7559     return df._data[col]\\r\\n   7560 except KeyError:\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/column_accessor.py:155, in ColumnAccessor.__getitem__(self, key)\\r\\n    154 def __getitem__(self, key: Any) -> ColumnBase:\\r\\n--> 155     return self._data[key]\\r\\n\\r\\nKeyError: \\'sqrt\\'\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nKeyError                                  Traceback (most recent call last)\\r\\nCell In [4], line 1\\r\\n----> 1 df.query(\\'sqrt(a) >= 2\\')\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:4174, in DataFrame.query(self, expr, local_dict)\\r\\n   4168 callenv = {\\r\\n   4169     \"locals\": callframe.f_locals,\\r\\n   4170     \"globals\": callframe.f_globals,\\r\\n   4171     \"local_dict\": local_dict,\\r\\n   4172 }\\r\\n   4173 # Run query\\r\\n-> 4174 boolmask = queryutils.query_execute(self, expr, callenv)\\r\\n   4175 return self._apply_boolean_mask(boolmask)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/utils/queryutils.py:214, in query_execute(df, expr, callenv)\\r\\n    211 columns = compiled[\"colnames\"]\\r\\n    213 # prepare col args\\r\\n--> 214 colarrays = [cudf.core.dataframe.extract_col(df, col) for col in columns]\\r\\n    216 # wait to check the types until we know which cols are used\\r\\n    217 if any(col.dtype not in SUPPORTED_QUERY_TYPES for col in colarrays):\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/utils/queryutils.py:214, in <listcomp>(.0)\\r\\n    211 columns = compiled[\"colnames\"]\\r\\n    213 # prepare col args\\r\\n--> 214 colarrays = [cudf.core.dataframe.extract_col(df, col) for col in columns]\\r\\n    216 # wait to check the types until we know which cols are used\\r\\n    217 if any(col.dtype not in SUPPORTED_QUERY_TYPES for col in colarrays):\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:7567, in extract_col(df, col)\\r\\n   7561 if (\\r\\n   7562     col == \"index\"\\r\\n   7563     and col not in df.index._data\\r\\n   7564     and not isinstance(df.index, MultiIndex)\\r\\n   7565 ):\\r\\n   7566     return df.index._data.columns[0]\\r\\n-> 7567 return df.index._data[col]\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/column_accessor.py:155, in ColumnAccessor.__getitem__(self, key)\\r\\n    154 def __getitem__(self, key: Any) -> ColumnBase:\\r\\n--> 155     return self._data[key]\\r\\n\\r\\nKeyError: \\'sqrt\\'\\r\\n\\r\\nIn [5]: df.to_pandas().query(\\'sqrt(a) >= 2\\')\\r\\nOut[5]: \\r\\n   a\\r\\n1  4\\r\\n2  9\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nhttps://github.com/pandas-dev/pandas/blob/v1.5.2/pandas/core/computation/ops.py#L39-L60\\ncreatedAt: 2023-01-10T00:45:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 179}),\n",
       " Document(page_content=': 460\\ntitle: [FEA] Allow keep=\\'all\\' for nlargest/nsmallest\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'a\\': [1, 2, 3] * 2, \\'b\\': list(\\'abcdef\\')})\\r\\n\\r\\nIn [4]: df.nlargest(1, \\'a\\', keep=\\'all\\')\\r\\n---------------------------------------------------------------------------\\r\\nValueError                                Traceback (most recent call last)\\r\\nCell In [4], line 1\\r\\n----> 1 df.nlargest(1, \\'a\\', keep=\\'all\\')\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:3624, in DataFrame.nlargest(self, n, columns, keep)\\r\\n   3558 @_cudf_nvtx_annotate\\r\\n   3559 def nlargest(self, n, columns, keep=\"first\"):\\r\\n   3560     \"\"\"Return the first *n* rows ordered by *columns* in descending order.\\r\\n   3561 \\r\\n   3562     Return the first *n* rows with the largest values in *columns*, in\\r\\n   (...)\\r\\n   3622     Brunei      434000    12128      BN\\r\\n   3623     \"\"\"\\r\\n-> 3624     return self._n_largest_or_smallest(True, n, columns, keep)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/indexed_frame.py:2156, in IndexedFrame._n_largest_or_smallest(self, largest, n, columns, keep)\\r\\n   2154     return self._gather(indices, keep_index=True, check_bounds=False)\\r\\n   2155 else:\\r\\n-> 2156     raise ValueError(\\'keep must be either \"first\", \"last\"\\')\\r\\n\\r\\nValueError: keep must be either \"first\", \"last\"\\r\\n\\r\\nIn [5]: df.to_pandas().nlargest(1, \\'a\\', keep=\\'all\\')\\r\\nOut[5]: \\r\\n   a  b\\r\\n2  3  c\\r\\n5  3  f\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nhttps://github.com/pandas-dev/pandas/pull/21650\\ncreatedAt: 2023-01-10T13:33:01Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 180}),\n",
       " Document(page_content=': 461\\ntitle: [FEA] support for read_html\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nfunctionality matching https://pandas.pydata.org/docs/reference/api/pandas.read_html.html\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: pd.read_html(\"https://docs.rapids.ai/maintainers\")\\r\\n---------------------------------------------------------------------------\\r\\nAttributeError                            Traceback (most recent call last)\\r\\nCell In [3], line 1\\r\\n----> 1 pd.read_html(\"https://docs.rapids.ai/maintainers\")\\r\\n\\r\\nAttributeError: module \\'cudf\\' has no attribute \\'read_html\\'\\r\\n\\r\\nIn [4]: import pandas\\r\\n\\r\\nIn [5]: pandas.read_html(\"https://docs.rapids.ai/maintainers\")\\r\\nOut[5]: \\r\\n[                                         Phase        Start          End Duration\\r\\n 0          Development (cuDF/RMM/rapids-cmake)  Thu, Nov 10  Wed, Jan 18  42 days\\r\\n 1                         Development (others)  Thu, Nov 17  Wed, Jan 25  43 days\\r\\n 2             Burn Down(cuDF/RMM/rapids-cmake)  Thu, Jan 19  Wed, Jan 25   5 days\\r\\n 3                           Burn Down (others)  Thu, Jan 26   Wed, Feb 1   5 days\\r\\n 4  Code Freeze/Testing (cuDF/RMM/rapids-cmake)  Thu, Jan 26  Tue, Jan 31   4 days\\r\\n 5               Code Freeze/Testing (others) 1   Thu, Feb 2   Tue, Feb 7   4 days\\r\\n 6                                      Release   Wed, Feb 8   Thu, Feb 9   2 days,\\r\\n                                          Phase        Start          End Duration\\r\\n 0          Development (cuDF/RMM/rapids-cmake)  Thu, Jan 19  Wed, Mar 22  42 days\\r\\n 1                         Development (others)  Thu, Jan 26  Wed, Mar 29  42 days\\r\\n 2             Burn Down(cuDF/RMM/rapids-cmake)  Thu, Mar 23  Wed, Mar 29   5 days\\r\\n 3                           Burn Down (others)  Thu, Mar 30   Wed, Apr 5   5 days\\r\\n 4  Code Freeze/Testing (cuDF/RMM/rapids-cmake)  Thu, Mar 30   Tue, Apr 4   4 days\\r\\n 5               Code Freeze/Testing (others) 1   Thu, Apr 6  Tue, Apr 11   4 days\\r\\n 6                                      Release  Wed, Apr 12  Thu, Apr 13   2 days]\\r\\n```\\ncreatedAt: 2023-01-10T14:58:23Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 181}),\n",
       " Document(page_content=': 462\\ntitle: [FEA] Series.str.contains support for case\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nsame behavior as `import pandas as pd`\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'a\\': [\\'one\\', \\'One\\', \\'onE\\']})\\r\\n\\r\\nIn [4]: df.a.str.contains(\\'one\\', case=False)\\r\\n---------------------------------------------------------------------------\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\nCell In [4], line 1\\r\\n----> 1 df.a.str.contains(\\'one\\', case=False)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/column/string.py:759, in StringMethods.contains(self, pat, case, flags, na, regex)\\r\\n    650 r\"\"\"\\r\\n    651 Test if pattern or regex is contained within a string of a Series or\\r\\n    652 Index.\\r\\n   (...)\\r\\n    756 dtype: bool\\r\\n    757 \"\"\"  # noqa W605\\r\\n    758 if case is not True:\\r\\n--> 759     raise NotImplementedError(\"`case` parameter is not yet supported\")\\r\\n    760 if na is not np.nan:\\r\\n    761     raise NotImplementedError(\"`na` parameter is not yet supported\")\\r\\n\\r\\nNotImplementedError: `case` parameter is not yet supported\\r\\n\\r\\nIn [5]: df.to_pandas().a.str.contains(\\'one\\', case=False)\\r\\nOut[5]: \\r\\n0    True\\r\\n1    True\\r\\n2    True\\r\\nName: a, dtype: bool\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nhttps://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html\\ncreatedAt: 2023-01-10T15:05:46Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 182}),\n",
       " Document(page_content=\": 463\\ntitle: [FEA] DataFrame.to_markdown support\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nsupport for `to_markdown` matching https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html\\ncreatedAt: 2023-01-10T15:47:29Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 183}),\n",
       " Document(page_content=': 464\\ntitle: [BUG] groupby().agg() with list() expansion: TypeError: \\'type\\' object is not iterable\\nbody: **Describe the bug**\\r\\nrewriting code with `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\r\\n   ...:     \"col1\": [1, 2, 3, 4, 3],\\r\\n   ...:     \"col2\": [\"a\", \"a\", \"b\", \"b\", \"c\"],\\r\\n   ...:     \"col3\": [\"d\", \"e\", \"f\", \"g\", \"h\"]\\r\\n   ...: })\\r\\n\\r\\nIn [4]: df.groupby([\"col2\"]).agg({\"col1\": \"mean\", \"col3\": lambda x: list(x)})\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\nCell In [4], line 1\\r\\n----> 1 df.groupby([\"col2\"]).agg({\"col1\": \"mean\", \"col3\": lambda x: list(x)})\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:460, in GroupBy.agg(self, func)\\r\\n    451 column_names, columns, normalized_aggs = self._normalize_aggs(func)\\r\\n    453 # Note: When there are no key columns, the below produces\\r\\n    454 # a Float64Index, while Pandas returns an Int64Index\\r\\n    455 # (GH: 6945)\\r\\n    456 (\\r\\n    457     result_columns,\\r\\n    458     grouped_key_cols,\\r\\n    459     included_aggregations,\\r\\n--> 460 ) = self._groupby.aggregate(columns, normalized_aggs)\\r\\n    462 result_index = self.grouping.keys._from_columns_like_self(\\r\\n    463     grouped_key_cols,\\r\\n    464 )\\r\\n    466 multilevel = _is_multi_agg(func)\\r\\n\\r\\nFile groupby.pyx:309, in cudf._lib.groupby.GroupBy.aggregate()\\r\\n\\r\\nFile groupby.pyx:184, in cudf._lib.groupby.GroupBy.aggregate_internal()\\r\\n\\r\\nFile aggregation.pyx:866, in cudf._lib.aggregation.make_groupby_aggregation()\\r\\n\\r\\nCell In [4], line 1, in <lambda>(x)\\r\\n----> 1 df.groupby([\"col2\"]).agg({\"col1\": \"mean\", \"col3\": lambda x: list(x)})\\r\\n\\r\\nTypeError: \\'type\\' object is not iterable\\r\\n\\r\\nIn [5]: df.to_pandas().groupby([\"col2\"]).agg({\"col1\": \"mean\", \"col3\": lambda x: list(x)})\\r\\nOut[5]: \\r\\n      col1    col3\\r\\ncol2              \\r\\na      1.5  [d, e]\\r\\nb      3.5  [f, g]\\r\\nc      3.0     [h]\\r\\n```\\ncreatedAt: 2023-01-10T15:56:31Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 184}),\n",
       " Document(page_content=\": 465\\ntitle: [FEA] cudf.to_datetime support locale-specific formatting (%a, %A, %b, %B, %c, %x, %X, %p)\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n`cudf.to_datetime(..., format=...)` support matching https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html and https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\\r\\n\\r\\nrelated: https://github.com/rapidsai/cudf/issues/12419\\ncreatedAt: 2023-01-10T19:22:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 185}),\n",
       " Document(page_content=': 466\\ntitle: [FEA] support for groupby named aggregates\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n`groupby().agg()` matching `pandas`\\r\\n\\r\\nhttps://pandas.pydata.org/docs/user_guide/groupby.html#groupby-aggregate-named\\r\\n\\r\\ne.g.\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\"size\": [\"S\", \"S\", \"M\", \"L\"], \"price\": [44, 29.99, 10, 19]})\\r\\n\\r\\nIn [4]: df.groupby(\\'size\\').agg({\\'price\\': \\'mean\\'})\\r\\nOut[4]: \\r\\n       price\\r\\nsize        \\r\\nL     19.000\\r\\nM     10.000\\r\\nS     36.995\\r\\n\\r\\nIn [5]: df.groupby(\\'size\\').agg(mean_price=(\\'price\\', \\'mean\\'))\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\nCell In [5], line 1\\r\\n----> 1 df.groupby(\\'size\\').agg(mean_price=(\\'price\\', \\'mean\\'))\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nTypeError: agg() got an unexpected keyword argument \\'mean_price\\'\\r\\n\\r\\nIn [6]: df.to_pandas().groupby(\\'size\\').agg(mean_price=(\\'price\\', \\'mean\\'))\\r\\nOut[6]: \\r\\n      mean_price\\r\\nsize            \\r\\nL         19.000\\r\\nM         10.000\\r\\nS         36.995\\r\\n\\r\\n```\\ncreatedAt: 2023-01-10T19:57:06Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 186}),\n",
       " Document(page_content=\": 467\\ntitle: [FEA] support month (M) frequency for date_range and resample\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nhttps://pandas.pydata.org/docs/reference/api/pandas.date_range.html\\r\\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html\\r\\n\\r\\nfrequencies - https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases\\ncreatedAt: 2023-01-10T23:32:38Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 187}),\n",
       " Document(page_content=': 468\\ntitle: [BUG] cudf.pivot_table behavior does not match pandas.pivor_table - mismatched index structure\\nbody: **Describe the bug**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.00\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\\r\\n   ...:                          \"bar\", \"bar\", \"bar\", \"bar\"],\\r\\n   ...:                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\\r\\n   ...:                          \"one\", \"one\", \"two\", \"two\"],\\r\\n   ...:                    \"C\": [\"small\", \"large\", \"large\", \"small\",\\r\\n   ...:                          \"small\", \"large\", \"small\", \"small\",\\r\\n   ...:                          \"large\"],\\r\\n   ...:                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\\r\\n   ...:                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\\r\\n\\r\\nIn [4]: df\\r\\nOut[4]: \\r\\n     A    B      C  D  E\\r\\n0  foo  one  small  1  2\\r\\n1  foo  one  large  2  4\\r\\n2  foo  one  large  2  5\\r\\n3  foo  two  small  3  5\\r\\n4  foo  two  small  3  6\\r\\n5  bar  one  large  4  6\\r\\n6  bar  one  small  5  8\\r\\n7  bar  two  small  6  9\\r\\n8  bar  two  large  7  9\\r\\n\\r\\nIn [5]: pd.pivot_table(df, index=[\"A\"], columns=[\"B\"], aggfunc=\"size\", fill_value=0)\\r\\nOut[5]: \\r\\n      C       D       E    \\r\\nB   one two one two one two\\r\\nA                          \\r\\nbar   2   2   2   2   2   2\\r\\nfoo   3   2   3   2   3   2\\r\\n\\r\\nIn [6]: import pandas\\r\\n\\r\\nIn [7]: pandas.__version__\\r\\nOut[7]: \\'1.5.2\\'\\r\\n\\r\\nIn [8]: pandas.pivot_table(df.to_pandas(), index=[\"A\"], columns=[\"B\"], aggfunc=\"size\", fill_value=0)\\r\\nOut[8]: \\r\\nB    one  two\\r\\nA            \\r\\nbar    2    2\\r\\nfoo    3    2\\r\\n```\\ncreatedAt: 2023-01-18T14:45:09Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 188}),\n",
       " Document(page_content=': 469\\ntitle: [FEA] cudf.crosstab support for margins parameter\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nmatching behavior with [`pandas.crosstab`](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html)\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.00\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\\r\\n   ...:                          \"bar\", \"bar\", \"bar\", \"bar\"],\\r\\n   ...:                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\\r\\n   ...:                          \"one\", \"one\", \"two\", \"two\"],\\r\\n   ...:                    \"C\": [\"small\", \"large\", \"large\", \"small\",\\r\\n   ...:                          \"small\", \"large\", \"small\", \"small\",\\r\\n   ...:                          \"large\"],\\r\\n   ...:                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\\r\\n   ...:                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\\r\\n\\r\\nIn [4]: pd.crosstab(df.A, df.B, margins=True)\\r\\n---------------------------------------------------------------------------\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\nCell In[4], line 1\\r\\n----> 1 pd.crosstab(df.A, df.B, margins=True)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/cudf/core/reshape.py:1296, in crosstab(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)\\r\\n   1293     df[\"__dummy__\"] = values\\r\\n   1294     kwargs = {\"aggfunc\": aggfunc}\\r\\n-> 1296 table = pivot_table(\\r\\n   1297     data=df,\\r\\n   1298     index=rownames,\\r\\n   1299     columns=colnames,\\r\\n   1300     values=\"__dummy__\",\\r\\n   1301     margins=margins,\\r\\n   1302     margins_name=margins_name,\\r\\n   1303     dropna=dropna,\\r\\n   1304     **kwargs,\\r\\n   1305 )\\r\\n   1307 return table\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/cudf/core/reshape.py:1352, in pivot_table(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\\r\\n   1323 \"\"\"\\r\\n   1324 Create a spreadsheet-style pivot table as a DataFrame.\\r\\n   1325 \\r\\n   (...)\\r\\n   1349     An Excel style pivot table.\\r\\n   1350 \"\"\"\\r\\n   1351 if margins is not False:\\r\\n-> 1352     raise NotImplementedError(\"margins is not supported yet\")\\r\\n   1354 if margins_name != \"All\":\\r\\n   1355     raise NotImplementedError(\"margins_name is not supported yet\")\\r\\n\\r\\nNotImplementedError: margins is not supported yet\\r\\n```\\ncreatedAt: 2023-01-18T14:51:08Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 189}),\n",
       " Document(page_content=': 470\\ntitle: [FEA] support passing label to value_counts()\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nmatching behavior with `pandas`\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.00\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\"XYZ\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\"]})\\r\\n\\r\\nIn [4]: df.value_counts(\"XYZ\")\\r\\n---------------------------------------------------------------------------\\r\\nKeyError                                  Traceback (most recent call last)\\r\\nCell In[4], line 1\\r\\n----> 1 df.value_counts(\"XYZ\")\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:7188, in DataFrame.value_counts(self, subset, normalize, sort, ascending, dropna)\\r\\n   7186     diff = set(subset) - set(self._data)\\r\\n   7187     if len(diff) != 0:\\r\\n-> 7188         raise KeyError(f\"columns {diff} do not exist\")\\r\\n   7189 columns = list(self._data.names) if subset is None else subset\\r\\n   7190 result = (\\r\\n   7191     self.groupby(\\r\\n   7192         by=columns,\\r\\n   (...)\\r\\n   7196     .astype(\"int64\")\\r\\n   7197 )\\r\\n\\r\\nKeyError: \"columns {\\'Y\\', \\'X\\', \\'Z\\'} do not exist\"\\r\\n\\r\\nIn [5]: df.to_pandas().value_counts(\"XYZ\")\\r\\nOut[5]: \\r\\nXYZ\\r\\nfoo    5\\r\\ndtype: int64\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\n[`pandas.DataFrame.value_counts`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html) declares support for `list-like` input, but is [implemented](https://github.com/pandas-dev/pandas/blob/v1.5.2/pandas/core/frame.py#L7215) with [`pandas.DataFrame.groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html), which accepts `mapping, function, label, or list of labels`\\ncreatedAt: 2023-01-18T15:48:29Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 190}),\n",
       " Document(page_content=': 471\\ntitle: [FEA] DataFrame.query support for datetime\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.00\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'A\\': pd.date_range(start=\"2023-01-01\", periods=8, freq=\"D\")})\\r\\n\\r\\nIn [4]: df.info()\\r\\n<class \\'cudf.core.dataframe.DataFrame\\'>\\r\\nRangeIndex: 8 entries, 0 to 7\\r\\nData columns (total 1 columns):\\r\\n #   Column  Non-Null Count  Dtype\\r\\n---  ------  --------------  -----\\r\\n 0   A       8 non-null      datetime64[ns]\\r\\ndtypes: datetime64[ns](1)\\r\\nmemory usage: 64.0 bytes\\r\\n\\r\\nIn [5]: df.query(\\'A >= \"2023-01-02\"\\')\\r\\n---------------------------------------------------------------------------\\r\\nTypingError                               Traceback (most recent call last)\\r\\nCell In[5], line 1\\r\\n----> 1 df.query(\\'A >= \"2023-01-02\"\\')\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:4174, in DataFrame.query(self, expr, local_dict)\\r\\n   4168 callenv = {\\r\\n   4169     \"locals\": callframe.f_locals,\\r\\n   4170     \"globals\": callframe.f_globals,\\r\\n   4171     \"local_dict\": local_dict,\\r\\n   4172 }\\r\\n   4173 # Run query\\r\\n-> 4174 boolmask = queryutils.query_execute(self, expr, callenv)\\r\\n   4175 return self._apply_boolean_mask(boolmask)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/cudf/utils/queryutils.py:248, in query_execute(df, expr, callenv)\\r\\n    246 # run kernel\\r\\n    247 args = [out] + colarrays + envargs\\r\\n--> 248 kernel.forall(nrows)(*args)\\r\\n    249 out_mask = applyutils.make_aggregate_nullmask(df, columns=columns)\\r\\n    250 return out.set_mask(out_mask).fillna(False)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:438, in ForAll.__call__(self, *args)\\r\\n    436     specialized = self.dispatcher\\r\\n    437 else:\\r\\n--> 438     specialized = self.dispatcher.specialize(*args)\\r\\n    439 blockdim = self._compute_thread_per_block(specialized)\\r\\n    440 griddim = (self.ntasks + blockdim - 1) // blockdim\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:667, in CUDADispatcher.specialize(self, *args)\\r\\n    664 targetoptions = self.targetoptions\\r\\n    665 specialization = CUDADispatcher(self.py_func,\\r\\n    666                                 targetoptions=targetoptions)\\r\\n--> 667 specialization.compile(argtypes)\\r\\n    668 specialization.disable_compile()\\r\\n    669 specialization._specialized = True\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:794, in CUDADispatcher.compile(self, sig)\\r\\n    791 if not self._can_compile:\\r\\n    792     raise RuntimeError(\"Compilation disabled\")\\r\\n--> 794 kernel = _Kernel(self.py_func, argtypes, **self.targetoptions)\\r\\n    795 # We call bind to force codegen, so that there is a cubin to cache\\r\\n    796 kernel.bind()\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)\\r\\n     32 @functools.wraps(func)\\r\\n     33 def _acquire_compile_lock(*args, **kwargs):\\r\\n     34     with self:\\r\\n---> 35         return func(*args, **kwargs)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:75, in _Kernel.__init__(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)\\r\\n     66 self.extensions = extensions or []\\r\\n     68 nvvm_options = {\\r\\n     69     \\'debug\\': self.debug,\\r\\n     70     \\'lineinfo\\': self.lineinfo,\\r\\n     71     \\'fastmath\\': fastmath,\\r\\n     72     \\'opt\\': 3 if opt else 0\\r\\n     73 }\\r\\n---> 75 cres = compile_cuda(self.py_func, types.void, self.argtypes,\\r\\n     76                     debug=self.debug,\\r\\n     77                     lineinfo=self.lineinfo,\\r\\n     78                     inline=inline,\\r\\n     79                     fastmath=fastmath,\\r\\n     80                     nvvm_options=nvvm_options)\\r\\n     81 tgt_ctx = cres.target_context\\r\\n     82 code = self.py_func.__code__\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)\\r\\n     32 @functools.wraps(func)\\r\\n     33 def _acquire_compile_lock(*args, **kwargs):\\r\\n     34     with self:\\r\\n---> 35         return func(*args, **kwargs)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/compiler.py:212, in compile_cuda(pyfunc, return_type, args, debug, lineinfo, inline, fastmath, nvvm_options)\\r\\n    210 from numba.core.target_extension import target_override\\r\\n    211 with target_override(\\'cuda\\'):\\r\\n--> 212     cres = compiler.compile_extra(typingctx=typingctx,\\r\\n    213                                   targetctx=targetctx,\\r\\n    214                                   func=pyfunc,\\r\\n    215                                   args=args,\\r\\n    216                                   return_type=return_type,\\r\\n    217                                   flags=flags,\\r\\n    218                                   locals={},\\r\\n    219                                   pipeline_class=CUDACompiler)\\r\\n    221 library = cres.library\\r\\n    222 library.finalize()\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:716, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\\r\\n    692 \"\"\"Compiler entry point\\r\\n    693 \\r\\n    694 Parameter\\r\\n   (...)\\r\\n    712     compiler pipeline\\r\\n    713 \"\"\"\\r\\n    714 pipeline = pipeline_class(typingctx, targetctx, library,\\r\\n    715                           args, return_type, flags, locals)\\r\\n--> 716 return pipeline.compile_extra(func)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:452, in CompilerBase.compile_extra(self, func)\\r\\n    450 self.state.lifted = ()\\r\\n    451 self.state.lifted_from = None\\r\\n--> 452 return self._compile_bytecode()\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:520, in CompilerBase._compile_bytecode(self)\\r\\n    516 \"\"\"\\r\\n    517 Populate and run pipeline for bytecode input\\r\\n    518 \"\"\"\\r\\n    519 assert self.state.func_ir is None\\r\\n--> 520 return self._compile_core()\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:499, in CompilerBase._compile_core(self)\\r\\n    497         self.state.status.fail_reason = e\\r\\n    498         if is_final_pipeline:\\r\\n--> 499             raise e\\r\\n    500 else:\\r\\n    501     raise CompilerError(\"All available pipelines exhausted\")\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:486, in CompilerBase._compile_core(self)\\r\\n    484 res = None\\r\\n    485 try:\\r\\n--> 486     pm.run(self.state)\\r\\n    487     if self.state.cr is not None:\\r\\n    488         break\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:368, in PassManager.run(self, state)\\r\\n    365 msg = \"Failed in %s mode pipeline (step: %s)\" % \\\\\\r\\n    366     (self.pipeline_name, pass_desc)\\r\\n    367 patched_exception = self._patch_error(msg, e)\\r\\n--> 368 raise patched_exception\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:356, in PassManager.run(self, state)\\r\\n    354 pass_inst = _pass_registry.get(pss).pass_inst\\r\\n    355 if isinstance(pass_inst, CompilerPass):\\r\\n--> 356     self._runPass(idx, pass_inst, state)\\r\\n    357 else:\\r\\n    358     raise BaseException(\"Legacy pass in use\")\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)\\r\\n     32 @functools.wraps(func)\\r\\n     33 def _acquire_compile_lock(*args, **kwargs):\\r\\n     34     with self:\\r\\n---> 35         return func(*args, **kwargs)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:311, in PassManager._runPass(self, index, pss, internal_state)\\r\\n    309     mutated |= check(pss.run_initialization, internal_state)\\r\\n    310 with SimpleTimer() as pass_time:\\r\\n--> 311     mutated |= check(pss.run_pass, internal_state)\\r\\n    312 with SimpleTimer() as finalize_time:\\r\\n    313     mutated |= check(pss.run_finalizer, internal_state)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:273, in PassManager._runPass.<locals>.check(func, compiler_state)\\r\\n    272 def check(func, compiler_state):\\r\\n--> 273     mangled = func(compiler_state)\\r\\n    274     if mangled not in (True, False):\\r\\n    275         msg = (\"CompilerPass implementations should return True/False. \"\\r\\n    276                \"CompilerPass with name \\'%s\\' did not.\")\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/typed_passes.py:105, in BaseTypeInference.run_pass(self, state)\\r\\n     99 \"\"\"\\r\\n    100 Type inference and legalization\\r\\n    101 \"\"\"\\r\\n    102 with fallback_context(state, \\'Function \"%s\" failed type inference\\'\\r\\n    103                       % (state.func_id.func_name,)):\\r\\n    104     # Type inference\\r\\n--> 105     typemap, return_type, calltypes, errs = type_inference_stage(\\r\\n    106         state.typingctx,\\r\\n    107         state.targetctx,\\r\\n    108         state.func_ir,\\r\\n    109         state.args,\\r\\n    110         state.return_type,\\r\\n    111         state.locals,\\r\\n    112         raise_errors=self._raise_errors)\\r\\n    113     state.typemap = typemap\\r\\n    114     # save errors in case of partial typing\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/typed_passes.py:83, in type_inference_stage(typingctx, targetctx, interp, args, return_type, locals, raise_errors)\\r\\n     81     infer.build_constraint()\\r\\n     82     # return errors in case of partial typing\\r\\n---> 83     errs = infer.propagate(raise_errors=raise_errors)\\r\\n     84     typemap, restype, calltypes = infer.unify(raise_errors=raise_errors)\\r\\n     86 # Output all Numba warnings\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/typeinfer.py:1086, in TypeInferer.propagate(self, raise_errors)\\r\\n   1083 force_lit_args = [e for e in errors\\r\\n   1084                   if isinstance(e, ForceLiteralArg)]\\r\\n   1085 if not force_lit_args:\\r\\n-> 1086     raise errors[0]\\r\\n   1087 else:\\r\\n   1088     raise reduce(operator.or_, force_lit_args)\\r\\n\\r\\nTypingError: Failed in cuda mode pipeline (step: nopython frontend)\\r\\nFailed in cuda mode pipeline (step: nopython frontend)\\r\\nNo implementation of function Function(<built-in function ge>) found for signature:\\r\\n \\r\\n >>> ge(datetime64[ns], Literal[str](2023-01-02))\\r\\n \\r\\nThere are 26 candidate implementations:\\r\\n    - Of which 24 did not match due to:\\r\\n    Overload of function \\'ge\\': File: <numerous>: Line N/A.\\r\\n      With argument(s): \\'(datetime64[ns], unicode_type)\\':\\r\\n     No match.\\r\\n    - Of which 2 did not match due to:\\r\\n    Operator Overload in function \\'ge\\': File: unknown: Line unknown.\\r\\n      With argument(s): \\'(datetime64[ns], unicode_type)\\':\\r\\n     No match for registered cases:\\r\\n      * (bool, bool) -> bool\\r\\n      * (int8, int8) -> bool\\r\\n      * (int16, int16) -> bool\\r\\n      * (int32, int32) -> bool\\r\\n      * (int64, int64) -> bool\\r\\n      * (uint8, uint8) -> bool\\r\\n      * (uint16, uint16) -> bool\\r\\n      * (uint32, uint32) -> bool\\r\\n      * (uint64, uint64) -> bool\\r\\n      * (float32, float32) -> bool\\r\\n      * (float64, float64) -> bool\\r\\n\\r\\nDuring: typing of intrinsic-call at <string> (2)\\r\\n\\r\\nFile \"<string>\", line 2:\\r\\n<source missing, REPL/exec in use?>\\r\\n\\r\\nDuring: resolving callee type: type(CUDADispatcher(<function queryexpr_5817a7cbdce0865b at 0x7f0618ab7f70>))\\r\\nDuring: typing of call at <string> (6)\\r\\n\\r\\n\\r\\nFile \"<string>\", line 6:\\r\\n<source missing, REPL/exec in use?>\\r\\n\\r\\n\\r\\nIn [6]: df.to_pandas().query(\\'A >= \"2023-01-02\"\\')\\r\\nOut[6]: \\r\\n           A\\r\\n1 2023-01-02\\r\\n2 2023-01-03\\r\\n3 2023-01-04\\r\\n4 2023-01-05\\r\\n5 2023-01-06\\r\\n6 2023-01-07\\r\\n7 2023-01-08\\r\\n```\\ncreatedAt: 2023-01-18T17:39:46Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 191}),\n",
       " Document(page_content=': 473\\ntitle: [BUG] DataFrame.query binary-ops do not match pandas\\nbody: **Describe the bug**\\r\\nusing `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.00\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\\r\\n   ...:                          \"bar\", \"bar\", \"bar\", \"bar\"],\\r\\n   ...:                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\\r\\n   ...:                          \"one\", \"one\", \"two\", \"two\"],\\r\\n   ...:                    \"C\": [\"small\", \"large\", \"large\", \"small\",\\r\\n   ...:                          \"small\", \"large\", \"small\", \"small\",\\r\\n   ...:                          \"large\"],\\r\\n   ...:                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\\r\\n   ...:                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\\r\\n\\r\\nIn [4]: df.query(\"D > 5 & E > 5\")\\r\\nOut[4]: \\r\\nEmpty DataFrame\\r\\nColumns: [A, B, C, D, E]\\r\\nIndex: []\\r\\n\\r\\nIn [5]: df.to_pandas().query(\"D > 5 & E > 5\")\\r\\nOut[5]: \\r\\n     A    B      C  D  E\\r\\n7  bar  two  small  6  9\\r\\n8  bar  two  large  7  9\\r\\n\\r\\nIn [6]: df.query(\"D > 5 | E > 5\")\\r\\nOut[6]: \\r\\nEmpty DataFrame\\r\\nColumns: [A, B, C, D, E]\\r\\nIndex: []\\r\\n\\r\\nIn [7]: df.to_pandas().query(\"D > 5 | E > 5\")\\r\\nOut[7]: \\r\\n     A    B      C  D  E\\r\\n4  foo  two  small  3  6\\r\\n5  bar  one  large  4  6\\r\\n6  bar  one  small  5  8\\r\\n7  bar  two  small  6  9\\r\\n8  bar  two  large  7  9\\r\\n```\\ncreatedAt: 2023-01-18T17:50:38Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 192}),\n",
       " Document(page_content=': 474\\ntitle: [FEA] support datetime property in DataFrame.query\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwriting code with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.00\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'A\\': pd.date_range(start=\"2023-01-01\", periods=8, freq=\"D\")})\\r\\n\\r\\nIn [4]: df.query(\"A.dt.month == 1\")\\r\\n---------------------------------------------------------------------------\\r\\nTypingError                               Traceback (most recent call last)\\r\\nCell In[4], line 1\\r\\n----> 1 df.query(\"A.dt.month == 1\")\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:4174, in DataFrame.query(self, expr, local_dict)\\r\\n   4168 callenv = {\\r\\n   4169     \"locals\": callframe.f_locals,\\r\\n   4170     \"globals\": callframe.f_globals,\\r\\n   4171     \"local_dict\": local_dict,\\r\\n   4172 }\\r\\n   4173 # Run query\\r\\n-> 4174 boolmask = queryutils.query_execute(self, expr, callenv)\\r\\n   4175 return self._apply_boolean_mask(boolmask)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/cudf/utils/queryutils.py:248, in query_execute(df, expr, callenv)\\r\\n    246 # run kernel\\r\\n    247 args = [out] + colarrays + envargs\\r\\n--> 248 kernel.forall(nrows)(*args)\\r\\n    249 out_mask = applyutils.make_aggregate_nullmask(df, columns=columns)\\r\\n    250 return out.set_mask(out_mask).fillna(False)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:438, in ForAll.__call__(self, *args)\\r\\n    436     specialized = self.dispatcher\\r\\n    437 else:\\r\\n--> 438     specialized = self.dispatcher.specialize(*args)\\r\\n    439 blockdim = self._compute_thread_per_block(specialized)\\r\\n    440 griddim = (self.ntasks + blockdim - 1) // blockdim\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:667, in CUDADispatcher.specialize(self, *args)\\r\\n    664 targetoptions = self.targetoptions\\r\\n    665 specialization = CUDADispatcher(self.py_func,\\r\\n    666                                 targetoptions=targetoptions)\\r\\n--> 667 specialization.compile(argtypes)\\r\\n    668 specialization.disable_compile()\\r\\n    669 specialization._specialized = True\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:794, in CUDADispatcher.compile(self, sig)\\r\\n    791 if not self._can_compile:\\r\\n    792     raise RuntimeError(\"Compilation disabled\")\\r\\n--> 794 kernel = _Kernel(self.py_func, argtypes, **self.targetoptions)\\r\\n    795 # We call bind to force codegen, so that there is a cubin to cache\\r\\n    796 kernel.bind()\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)\\r\\n     32 @functools.wraps(func)\\r\\n     33 def _acquire_compile_lock(*args, **kwargs):\\r\\n     34     with self:\\r\\n---> 35         return func(*args, **kwargs)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:75, in _Kernel.__init__(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)\\r\\n     66 self.extensions = extensions or []\\r\\n     68 nvvm_options = {\\r\\n     69     \\'debug\\': self.debug,\\r\\n     70     \\'lineinfo\\': self.lineinfo,\\r\\n     71     \\'fastmath\\': fastmath,\\r\\n     72     \\'opt\\': 3 if opt else 0\\r\\n     73 }\\r\\n---> 75 cres = compile_cuda(self.py_func, types.void, self.argtypes,\\r\\n     76                     debug=self.debug,\\r\\n     77                     lineinfo=self.lineinfo,\\r\\n     78                     inline=inline,\\r\\n     79                     fastmath=fastmath,\\r\\n     80                     nvvm_options=nvvm_options)\\r\\n     81 tgt_ctx = cres.target_context\\r\\n     82 code = self.py_func.__code__\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)\\r\\n     32 @functools.wraps(func)\\r\\n     33 def _acquire_compile_lock(*args, **kwargs):\\r\\n     34     with self:\\r\\n---> 35         return func(*args, **kwargs)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/cuda/compiler.py:212, in compile_cuda(pyfunc, return_type, args, debug, lineinfo, inline, fastmath, nvvm_options)\\r\\n    210 from numba.core.target_extension import target_override\\r\\n    211 with target_override(\\'cuda\\'):\\r\\n--> 212     cres = compiler.compile_extra(typingctx=typingctx,\\r\\n    213                                   targetctx=targetctx,\\r\\n    214                                   func=pyfunc,\\r\\n    215                                   args=args,\\r\\n    216                                   return_type=return_type,\\r\\n    217                                   flags=flags,\\r\\n    218                                   locals={},\\r\\n    219                                   pipeline_class=CUDACompiler)\\r\\n    221 library = cres.library\\r\\n    222 library.finalize()\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:716, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\\r\\n    692 \"\"\"Compiler entry point\\r\\n    693 \\r\\n    694 Parameter\\r\\n   (...)\\r\\n    712     compiler pipeline\\r\\n    713 \"\"\"\\r\\n    714 pipeline = pipeline_class(typingctx, targetctx, library,\\r\\n    715                           args, return_type, flags, locals)\\r\\n--> 716 return pipeline.compile_extra(func)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:452, in CompilerBase.compile_extra(self, func)\\r\\n    450 self.state.lifted = ()\\r\\n    451 self.state.lifted_from = None\\r\\n--> 452 return self._compile_bytecode()\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:520, in CompilerBase._compile_bytecode(self)\\r\\n    516 \"\"\"\\r\\n    517 Populate and run pipeline for bytecode input\\r\\n    518 \"\"\"\\r\\n    519 assert self.state.func_ir is None\\r\\n--> 520 return self._compile_core()\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:499, in CompilerBase._compile_core(self)\\r\\n    497         self.state.status.fail_reason = e\\r\\n    498         if is_final_pipeline:\\r\\n--> 499             raise e\\r\\n    500 else:\\r\\n    501     raise CompilerError(\"All available pipelines exhausted\")\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler.py:486, in CompilerBase._compile_core(self)\\r\\n    484 res = None\\r\\n    485 try:\\r\\n--> 486     pm.run(self.state)\\r\\n    487     if self.state.cr is not None:\\r\\n    488         break\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:368, in PassManager.run(self, state)\\r\\n    365 msg = \"Failed in %s mode pipeline (step: %s)\" % \\\\\\r\\n    366     (self.pipeline_name, pass_desc)\\r\\n    367 patched_exception = self._patch_error(msg, e)\\r\\n--> 368 raise patched_exception\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:356, in PassManager.run(self, state)\\r\\n    354 pass_inst = _pass_registry.get(pss).pass_inst\\r\\n    355 if isinstance(pass_inst, CompilerPass):\\r\\n--> 356     self._runPass(idx, pass_inst, state)\\r\\n    357 else:\\r\\n    358     raise BaseException(\"Legacy pass in use\")\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs)\\r\\n     32 @functools.wraps(func)\\r\\n     33 def _acquire_compile_lock(*args, **kwargs):\\r\\n     34     with self:\\r\\n---> 35         return func(*args, **kwargs)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:311, in PassManager._runPass(self, index, pss, internal_state)\\r\\n    309     mutated |= check(pss.run_initialization, internal_state)\\r\\n    310 with SimpleTimer() as pass_time:\\r\\n--> 311     mutated |= check(pss.run_pass, internal_state)\\r\\n    312 with SimpleTimer() as finalize_time:\\r\\n    313     mutated |= check(pss.run_finalizer, internal_state)\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/compiler_machinery.py:273, in PassManager._runPass.<locals>.check(func, compiler_state)\\r\\n    272 def check(func, compiler_state):\\r\\n--> 273     mangled = func(compiler_state)\\r\\n    274     if mangled not in (True, False):\\r\\n    275         msg = (\"CompilerPass implementations should return True/False. \"\\r\\n    276                \"CompilerPass with name \\'%s\\' did not.\")\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/typed_passes.py:105, in BaseTypeInference.run_pass(self, state)\\r\\n     99 \"\"\"\\r\\n    100 Type inference and legalization\\r\\n    101 \"\"\"\\r\\n    102 with fallback_context(state, \\'Function \"%s\" failed type inference\\'\\r\\n    103                       % (state.func_id.func_name,)):\\r\\n    104     # Type inference\\r\\n--> 105     typemap, return_type, calltypes, errs = type_inference_stage(\\r\\n    106         state.typingctx,\\r\\n    107         state.targetctx,\\r\\n    108         state.func_ir,\\r\\n    109         state.args,\\r\\n    110         state.return_type,\\r\\n    111         state.locals,\\r\\n    112         raise_errors=self._raise_errors)\\r\\n    113     state.typemap = typemap\\r\\n    114     # save errors in case of partial typing\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/typed_passes.py:83, in type_inference_stage(typingctx, targetctx, interp, args, return_type, locals, raise_errors)\\r\\n     81     infer.build_constraint()\\r\\n     82     # return errors in case of partial typing\\r\\n---> 83     errs = infer.propagate(raise_errors=raise_errors)\\r\\n     84     typemap, restype, calltypes = infer.unify(raise_errors=raise_errors)\\r\\n     86 # Output all Numba warnings\\r\\n\\r\\nFile /usr/local/lib/python3.8/dist-packages/numba/core/typeinfer.py:1086, in TypeInferer.propagate(self, raise_errors)\\r\\n   1083 force_lit_args = [e for e in errors\\r\\n   1084                   if isinstance(e, ForceLiteralArg)]\\r\\n   1085 if not force_lit_args:\\r\\n-> 1086     raise errors[0]\\r\\n   1087 else:\\r\\n   1088     raise reduce(operator.or_, force_lit_args)\\r\\n\\r\\nTypingError: Failed in cuda mode pipeline (step: nopython frontend)\\r\\nFailed in cuda mode pipeline (step: nopython frontend)\\r\\nUnknown attribute \\'dt\\' of type datetime64[ns]\\r\\n\\r\\nFile \"<string>\", line 2:\\r\\n<source missing, REPL/exec in use?>\\r\\n\\r\\nDuring: typing of get attribute at <string> (2)\\r\\n\\r\\nFile \"<string>\", line 2:\\r\\n<source missing, REPL/exec in use?>\\r\\n\\r\\nDuring: resolving callee type: type(CUDADispatcher(<function queryexpr_a1b175044f595522 at 0x7f61a8bade50>))\\r\\nDuring: typing of call at <string> (6)\\r\\n\\r\\n\\r\\nFile \"<string>\", line 6:\\r\\n<source missing, REPL/exec in use?>\\r\\n\\r\\n\\r\\nIn [5]: df.to_pandas().query(\"A.dt.month == 1\")\\r\\nOut[5]: \\r\\n           A\\r\\n0 2023-01-01\\r\\n1 2023-01-02\\r\\n2 2023-01-03\\r\\n3 2023-01-04\\r\\n4 2023-01-05\\r\\n5 2023-01-06\\r\\n6 2023-01-07\\r\\n7 2023-01-08\\r\\n```\\ncreatedAt: 2023-01-18T17:54:09Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 193}),\n",
       " Document(page_content=': 475\\ntitle: [FEA] support inplace for DataFrame.query\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nusing `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.00\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\\r\\n   ...:                          \"bar\", \"bar\", \"bar\", \"bar\"],\\r\\n   ...:                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\\r\\n   ...:                          \"one\", \"one\", \"two\", \"two\"],\\r\\n   ...:                    \"C\": [\"small\", \"large\", \"large\", \"small\",\\r\\n   ...:                          \"small\", \"large\", \"small\", \"small\",\\r\\n   ...:                          \"large\"],\\r\\n   ...:                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\\r\\n   ...:                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\\r\\n\\r\\nIn [4]: df\\r\\nOut[4]: \\r\\n     A    B      C  D  E\\r\\n0  foo  one  small  1  2\\r\\n1  foo  one  large  2  4\\r\\n2  foo  one  large  2  5\\r\\n3  foo  two  small  3  5\\r\\n4  foo  two  small  3  6\\r\\n5  bar  one  large  4  6\\r\\n6  bar  one  small  5  8\\r\\n7  bar  two  small  6  9\\r\\n8  bar  two  large  7  9\\r\\n\\r\\nIn [5]: df.query(\"D ** 2 > 8\")\\r\\nOut[5]: \\r\\n     A    B      C  D  E\\r\\n3  foo  two  small  3  5\\r\\n4  foo  two  small  3  6\\r\\n5  bar  one  large  4  6\\r\\n6  bar  one  small  5  8\\r\\n7  bar  two  small  6  9\\r\\n8  bar  two  large  7  9\\r\\n\\r\\nIn [6]: df.query(\"D ** 2 > 8\", inplace=True)\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\nCell In[6], line 1\\r\\n----> 1 df.query(\"D ** 2 > 8\", inplace=True)\\r\\n\\r\\nTypeError: query() got an unexpected keyword argument \\'inplace\\'\\r\\n\\r\\nIn [7]: pdf = df.to_pandas()\\r\\n\\r\\nIn [8]: pdf\\r\\nOut[8]: \\r\\n     A    B      C  D  E\\r\\n0  foo  one  small  1  2\\r\\n1  foo  one  large  2  4\\r\\n2  foo  one  large  2  5\\r\\n3  foo  two  small  3  5\\r\\n4  foo  two  small  3  6\\r\\n5  bar  one  large  4  6\\r\\n6  bar  one  small  5  8\\r\\n7  bar  two  small  6  9\\r\\n8  bar  two  large  7  9\\r\\n\\r\\nIn [9]: pdf.query(\"D ** 2 > 8\", inplace=True)\\r\\n\\r\\nIn [10]: pdf\\r\\nOut[10]: \\r\\n     A    B      C  D  E\\r\\n3  foo  two  small  3  5\\r\\n4  foo  two  small  3  6\\r\\n5  bar  one  large  4  6\\r\\n6  bar  one  small  5  8\\r\\n7  bar  two  small  6  9\\r\\n8  bar  two  large  7  9\\r\\n```\\ncreatedAt: 2023-01-18T17:58:38Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 194}),\n",
       " Document(page_content=': 477\\ntitle: [BUG] read_csv always reads values in quotes as strings\\nbody: A CSV file containing quoted values:\\r\\n\\r\\n```python\\r\\nIn [15]: !cat test.csv\\r\\n\"1\",\"2\"\\r\\n\"3\",\"4\"\\r\\n```\\r\\n\\r\\nhas the data type of the quoted values inferred by Pandas:\\r\\n\\r\\n```python\\r\\nIn [20]: df = pd.read_csv(\"test.csv\", index_col=False, header=None)\\r\\n\\r\\nIn [21]: df\\r\\nOut[21]: \\r\\n   0  1\\r\\n0  1  2\\r\\n1  3  4\\r\\n\\r\\nIn [22]: df.dtypes\\r\\nOut[22]: \\r\\n0    int64\\r\\n1    int64\\r\\ndtype: object\\r\\n```\\r\\n\\r\\nbut cuDF reads them as strings (\"object\" data type):\\r\\n\\r\\n```python\\r\\nIn [23]: df = cudf.read_csv(\"test.csv\", index_col=False, header=None)\\r\\n\\r\\nIn [24]: df\\r\\nOut[24]: \\r\\n   0  1\\r\\n0  1  2\\r\\n1  3  4\\r\\n\\r\\nIn [25]: df.dtypes\\r\\nOut[25]: \\r\\n0    object\\r\\n1    object\\r\\ndtype: object\\r\\n```\\ncreatedAt: 2023-01-20T16:45:24Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 195}),\n",
       " Document(page_content=': 478\\ntitle: [FEA] Refactor `experimental/row_operators.cuh` and make it default\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nlibcudf contains two sets of row operators: [legacy row operators](https://github.com/rapidsai/cudf/blob/branch-23.02/cpp/include/cudf/table/row_operators.cuh) for simple types and [experimental row operators](https://github.com/rapidsai/cudf/blob/branch-23.02/cpp/include/cudf/table/experimental/row_operators.cuh) for complex types. When we have completed \"Part 1\" of #11844, then we can safely refactor the experimental row operators to be the default, and drop the `table::experimental` namespace\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nUltimately we will deprecate the legacy row operators and move the experimental row operators out of the experimental namespace. Please note that the new equality and lexicographic comparators will include \"fast paths\" for simple types (see #11330 and #11129), so the legacy row operators will continue to play a role.\\r\\n\\r\\nMerge plan for completing the deprecation\\r\\n- [x] Implement \"fast path\" for equality comparison (closed by #12676)\\r\\n- [ ] Breakup the row_comparator.cu (#11012)\\r\\n- [ ] Update all algorithms on new comparator, (complete Part 1 of #11844)\\r\\n- [ ] Drop the experimental namespace and remove legacy comparator\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nn/a\\r\\n\\r\\n**Additional context**\\r\\nSee #10186 and follow-on issue #11844 for more information about the nested type comparator project.\\ncreatedAt: 2023-01-23T17:56:35Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 196}),\n",
       " Document(page_content=': 481\\ntitle: [FEA] support DataFrameGroupBy.shift\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nhttps://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.shift.html\\r\\n\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'salary\\': [30000,40000,50000,85000,75000], \\'gender\\': list(\\'MFMFM\\')})\\r\\n\\r\\nIn [9]: df.groupby(\\'gender\\')[\\'salary\\'].transform(lambda x: x.shift(-1))\\r\\n---------------------------------------------------------------------------\\r\\nAttributeError                            Traceback (most recent call last)\\r\\nCell In [9], line 1\\r\\n----> 1 df.groupby(\\'gender\\')[\\'salary\\'].transform(lambda x: x.shift(-1))\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:1070, in GroupBy.transform(self, function)\\r\\n   1036 \"\"\"Apply an aggregation, then broadcast the result to the group size.\\r\\n   1037 \\r\\n   1038 Parameters\\r\\n   (...)\\r\\n   1067 agg\\r\\n   1068 \"\"\"\\r\\n   1069 try:\\r\\n-> 1070     result = self.agg(function)\\r\\n   1071 except TypeError as e:\\r\\n   1072     raise NotImplementedError(\\r\\n   1073         \"Currently, `transform()` supports only aggregations.\"\\r\\n   1074     ) from e\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:1749, in SeriesGroupBy.agg(self, func)\\r\\n   1748 def agg(self, func):\\r\\n-> 1749     result = super().agg(func)\\r\\n   1751     # downcast the result to a Series:\\r\\n   1752     if len(result._data):\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:460, in GroupBy.agg(self, func)\\r\\n    451 column_names, columns, normalized_aggs = self._normalize_aggs(func)\\r\\n    453 # Note: When there are no key columns, the below produces\\r\\n    454 # a Float64Index, while Pandas returns an Int64Index\\r\\n    455 # (GH: 6945)\\r\\n    456 (\\r\\n    457     result_columns,\\r\\n    458     grouped_key_cols,\\r\\n    459     included_aggregations,\\r\\n--> 460 ) = self._groupby.aggregate(columns, normalized_aggs)\\r\\n    462 result_index = self.grouping.keys._from_columns_like_self(\\r\\n    463     grouped_key_cols,\\r\\n    464 )\\r\\n    466 multilevel = _is_multi_agg(func)\\r\\n\\r\\nFile groupby.pyx:309, in cudf._lib.groupby.GroupBy.aggregate()\\r\\n\\r\\nFile groupby.pyx:184, in cudf._lib.groupby.GroupBy.aggregate_internal()\\r\\n\\r\\nFile aggregation.pyx:866, in cudf._lib.aggregation.make_groupby_aggregation()\\r\\n\\r\\nCell In [9], line 1, in <lambda>(x)\\r\\n----> 1 df.groupby(\\'gender\\')[\\'salary\\'].transform(lambda x: x.shift(-1))\\r\\n\\r\\nAttributeError: type object \\'cudf._lib.aggregation.GroupbyAggregation\\' has no attribute \\'shift\\'\\r\\n\\r\\nIn [10]: df.to_pandas().groupby(\\'gender\\')[\\'salary\\'].transform(lambda x: x.shift(-1))\\r\\nOut[10]: \\r\\n0    50000.0\\r\\n1    85000.0\\r\\n2    75000.0\\r\\n3        NaN\\r\\n4        NaN\\r\\nName: salary, dtype: float64\\r\\n```\\ncreatedAt: 2023-01-26T19:37:09Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 197}),\n",
       " Document(page_content=\": 482\\ntitle: [FEA] support PEP 249 – Python Database API Specification v2.0\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nconnecting a database to a DataFrame\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nhttps://peps.python.org/pep-0249/\\r\\n\\r\\n- [ ] https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html\\r\\n- [ ] https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html\\r\\n- [ ] https://pandas.pydata.org/docs/reference/api/pandas.read_sql_table.html\\r\\n- [ ] https://pandas.pydata.org/docs/reference/api/pandas.read_sql_query.html\\ncreatedAt: 2023-01-26T19:49:50Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 198}),\n",
       " Document(page_content=': 483\\ntitle: [FEA] support numeric_only parameter for groupby.mean()\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n`pandas`  has deprecated dropping invalid columns during aggregation, e.g. `mean(numeric_only=None)`\\r\\n\\r\\n`cudf` does not support automatic dropping and does not support `numeric_only`\\r\\n\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'a\\': [\\'apple\\', \\'orange\\'], \\'b\\': [[\\'one\\', \\'two\\', \\'three\\'], [\\'four\\', \\'five\\']]})\\r\\n\\r\\nIn [4]: df.to_pandas().explode(\\'b\\').groupby(\\'a\\').mean()\\r\\n<ipython-input-4-b1604cfc90a4>:1: FutureWarning: Dropping invalid columns in DataFrameGroupBy.mean is deprecated. In a future version, a TypeError will be raised. Before calling .mean, select only columns which should be valid for the function.\\r\\n  df.to_pandas().explode(\\'b\\').groupby(\\'a\\').mean()\\r\\nOut[4]: \\r\\nEmpty DataFrame\\r\\nColumns: []\\r\\nIndex: [apple, orange]\\r\\n\\r\\nIn [5]: df.explode(\\'b\\').groupby(\\'a\\').mean()\\r\\n---------------------------------------------------------------------------\\r\\nDataError                                 Traceback (most recent call last)\\r\\nCell In [5], line 1\\r\\n----> 1 df.explode(\\'b\\').groupby(\\'a\\').mean()\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/mixins/mixin_factory.py:11, in _partialmethod.<locals>.wrapper(self, *args2, **kwargs2)\\r\\n     10 def wrapper(self, *args2, **kwargs2):\\r\\n---> 11     return method(self, *args1, *args2, **kwargs1, **kwargs2)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:532, in GroupBy._reduce(self, op, numeric_only, min_count, *args, **kwargs)\\r\\n    528 if min_count != 0:\\r\\n    529     raise NotImplementedError(\\r\\n    530         \"min_count parameter is not implemented yet\"\\r\\n    531     )\\r\\n--> 532 return self.agg(op)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:460, in GroupBy.agg(self, func)\\r\\n    451 column_names, columns, normalized_aggs = self._normalize_aggs(func)\\r\\n    453 # Note: When there are no key columns, the below produces\\r\\n    454 # a Float64Index, while Pandas returns an Int64Index\\r\\n    455 # (GH: 6945)\\r\\n    456 (\\r\\n    457     result_columns,\\r\\n    458     grouped_key_cols,\\r\\n    459     included_aggregations,\\r\\n--> 460 ) = self._groupby.aggregate(columns, normalized_aggs)\\r\\n    462 result_index = self.grouping.keys._from_columns_like_self(\\r\\n    463     grouped_key_cols,\\r\\n    464 )\\r\\n    466 multilevel = _is_multi_agg(func)\\r\\n\\r\\nFile groupby.pyx:309, in cudf._lib.groupby.GroupBy.aggregate()\\r\\n\\r\\nFile groupby.pyx:199, in cudf._lib.groupby.GroupBy.aggregate_internal()\\r\\n\\r\\nDataError: All requested aggregations are unsupported.\\r\\n\\r\\nIn [6]: df.explode(\\'b\\').groupby(\\'a\\').mean(numeric_only=True)\\r\\n---------------------------------------------------------------------------\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\nCell In [6], line 1\\r\\n----> 1 df.explode(\\'b\\').groupby(\\'a\\').mean(numeric_only=True)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/mixins/mixin_factory.py:11, in _partialmethod.<locals>.wrapper(self, *args2, **kwargs2)\\r\\n     10 def wrapper(self, *args2, **kwargs2):\\r\\n---> 11     return method(self, *args1, *args2, **kwargs1, **kwargs2)\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/groupby/groupby.py:525, in GroupBy._reduce(self, op, numeric_only, min_count, *args, **kwargs)\\r\\n    502 \"\"\"Compute {op} of group values.\\r\\n    503 \\r\\n    504 Parameters\\r\\n   (...)\\r\\n    522     * Not supporting: numeric_only, min_count\\r\\n    523 \"\"\"\\r\\n    524 if numeric_only:\\r\\n--> 525     raise NotImplementedError(\\r\\n    526         \"numeric_only parameter is not implemented yet\"\\r\\n    527     )\\r\\n    528 if min_count != 0:\\r\\n    529     raise NotImplementedError(\\r\\n    530         \"min_count parameter is not implemented yet\"\\r\\n    531     )\\r\\n\\r\\nNotImplementedError: numeric_only parameter is not implemented yet\\r\\n```\\ncreatedAt: 2023-01-26T20:20:28Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 199}),\n",
       " Document(page_content=': 484\\ntitle: [FEA] support numeric_only for DataFrame.corr\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n`cudf.DataFrame.corr` matching `pandas.DataFrame.corr` behavior\\r\\n\\r\\n1. addition of `numeric_only` parameter \\r\\n2. default `numeric_only=None` with deprecation warning and lifecycle similar to `pandas`\\r\\n\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'22.12.0\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'a\\': range(10), \\'b\\': range(10,20), \\'c\\': list(\\'zyxwvutsrq\\')})\\r\\n\\r\\nIn [4]: df.corr()\\r\\n---------------------------------------------------------------------------\\r\\nKeyError                                  Traceback (most recent call last)\\r\\nCell In [4], line 1\\r\\n----> 1 df.corr()\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/dataframe.py:6490, in DataFrame.corr(self, method, min_periods)\\r\\n   6470 \"\"\"Compute the correlation matrix of a DataFrame.\\r\\n   6471 \\r\\n   6472 Parameters\\r\\n   (...)\\r\\n   6487     The requested correlation matrix.\\r\\n   6488 \"\"\"\\r\\n   6489 if method == \"pearson\":\\r\\n-> 6490     values = self.values\\r\\n   6491 elif method == \"spearman\":\\r\\n   6492     values = self.rank().values\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/frame.py:433, in Frame.values(self)\\r\\n    420 @property\\r\\n    421 def values(self):\\r\\n    422     \"\"\"\\r\\n    423     Return a CuPy representation of the DataFrame.\\r\\n    424 \\r\\n   (...)\\r\\n    431         The values of the DataFrame.\\r\\n    432     \"\"\"\\r\\n--> 433     return self.to_cupy()\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/nvtx/nvtx.py:101, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n     98 @wraps(func)\\r\\n     99 def inner(*args, **kwargs):\\r\\n    100     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 101     result = func(*args, **kwargs)\\r\\n    102     libnvtx_pop_range(self.domain.handle)\\r\\n    103     return result\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/frame.py:533, in Frame.to_cupy(self, dtype, copy, na_value)\\r\\n    507 @_cudf_nvtx_annotate\\r\\n    508 def to_cupy(\\r\\n    509     self,\\r\\n   (...)\\r\\n    512     na_value=None,\\r\\n    513 ) -> cupy.ndarray:\\r\\n    514     \"\"\"Convert the Frame to a CuPy array.\\r\\n    515 \\r\\n    516     Parameters\\r\\n   (...)\\r\\n    531     cupy.ndarray\\r\\n    532     \"\"\"\\r\\n--> 533     return self._to_array(\\r\\n    534         (lambda col: col.values.copy())\\r\\n    535         if copy\\r\\n    536         else (lambda col: col.values),\\r\\n    537         cupy.empty,\\r\\n    538         dtype,\\r\\n    539         na_value,\\r\\n    540     )\\r\\n\\r\\nFile ~/.local/lib/python3.9/site-packages/cudf/core/frame.py:498, in Frame._to_array(self, get_column_values, make_empty_matrix, dtype, na_value)\\r\\n    491 matrix = make_empty_matrix(\\r\\n    492     shape=(len(self), ncol), dtype=dtype, order=\"F\"\\r\\n    493 )\\r\\n    494 for i, col in enumerate(self._data.values()):\\r\\n    495     # TODO: col.values may fail if there is nullable data or an\\r\\n    496     # unsupported dtype. We may want to catch and provide a more\\r\\n    497     # suitable error.\\r\\n--> 498     matrix[:, i] = get_column_values_na(col)\\r\\n    499 return matrix\\r\\n\\r\\nFile cupy/_core/core.pyx:1508, in cupy._core.core.ndarray.__setitem__()\\r\\n\\r\\nFile cupy/_core/_routines_indexing.pyx:51, in cupy._core._routines_indexing._ndarray_setitem()\\r\\n\\r\\nFile cupy/_core/_routines_indexing.pyx:997, in cupy._core._routines_indexing._scatter_op()\\r\\n\\r\\nFile cupy/_core/_kernel.pyx:1292, in cupy._core._kernel.ufunc.__call__()\\r\\n\\r\\nFile cupy/_core/_kernel.pyx:1319, in cupy._core._kernel.ufunc._get_ufunc_kernel()\\r\\n\\r\\nFile cupy/_core/_kernel.pyx:1025, in cupy._core._kernel._get_ufunc_kernel()\\r\\n\\r\\nFile cupy/_core/_kernel.pyx:66, in cupy._core._kernel._get_simple_elementwise_kernel()\\r\\n\\r\\nFile cupy/_core/_kernel.pyx:322, in cupy._core._kernel._get_kernel_params()\\r\\n\\r\\nFile cupy/_core/_kernel.pyx:298, in cupy._core._kernel._ArgInfo.get_param_c_type()\\r\\n\\r\\nFile cupy/_core/_kernel.pyx:285, in cupy._core._kernel._ArgInfo.get_c_type()\\r\\n\\r\\nFile cupy/_core/_scalar.pyx:68, in cupy._core._scalar.get_typename()\\r\\n\\r\\nFile cupy/_core/_scalar.pyx:73, in cupy._core._scalar.get_typename()\\r\\n\\r\\nKeyError: <class \\'numpy.object_\\'>\\r\\n\\r\\nIn [5]: df.to_pandas().corr()\\r\\n<ipython-input-5-98783459b7d9>:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\\r\\n  df.to_pandas().corr()\\r\\nOut[5]: \\r\\n     a    b\\r\\na  1.0  1.0\\r\\nb  1.0  1.0\\r\\n```\\r\\n\\r\\n[`pandas` introduced a `numeric_only` parameter](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)\\r\\n\\r\\n```\\r\\nIn [6]: df.to_pandas().corr(numeric_only=True)\\r\\nOut[6]: \\r\\n     a    b\\r\\na  1.0  1.0\\r\\nb  1.0  1.0\\r\\n\\r\\nIn [7]: df.corr(numeric_only=True)\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\nCell In [7], line 1\\r\\n----> 1 df.corr(numeric_only=True)\\r\\n\\r\\nTypeError: corr() got an unexpected keyword argument \\'numeric_only\\'\\r\\n```\\r\\n```\\ncreatedAt: 2023-01-26T22:41:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 200}),\n",
       " Document(page_content=': 485\\ntitle: [DOC] Fix and/or remove cuda.h \"File Not Found\" warning in our 10 Minutes docs.\\nbody: ## Report incorrect documentation\\r\\n\\r\\n**Describe the problems or issues found in the documentation**\\r\\n`../../thread/thread_load.cuh(36): warning: cuda.h: [jitify] File not found` warning is in our stable and nightly docs on the site on 10mins.ipynb.  \\r\\n\\r\\n**Location of incorrect documentation**\\r\\nhttps://docs.rapids.ai/api/cudf/stable/user_guide/10min.html#object-creation\\r\\nhttps://docs.rapids.ai/api/cudf/nightly/user_guide/10min.html#object-creation\\r\\n\\r\\nCould we remove this from our docs and/or fix the underlying issue?\\ncreatedAt: 2023-01-27T12:30:41Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Taurean Dyer\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 201}),\n",
       " Document(page_content=\": 486\\ntitle: [BUG] DataFrame.dropna does not support axis='index' results in mismatch w/ pandas\\nbody: **Describe the bug**\\r\\nusing `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\n>>> import cudf as pd\\r\\n>>> import numpy as np\\r\\n\\r\\n>>> df = pd.DataFrame({'a': ['one', 'two', 'three', 'four', np.nan, None, 'NA'], 'b': ['this', 'that', 'the', 'other', np.nan, np.nan, 'Missing'], 'c': ['something', 'or', 'other', None, np.nan, 'hmm', 'NA'], 'd': ['00', '01', '02', '03', None, None, 'Missing']})\\r\\n>>> df\\r\\n       a        b          c        d\\r\\n0    one     this  something       00\\r\\n1    two     that         or       01\\r\\n2  three      the      other       02\\r\\n3   four    other       <NA>       03\\r\\n4   <NA>     <NA>       <NA>     <NA>\\r\\n5   <NA>     <NA>        hmm     <NA>\\r\\n6     NA  Missing         NA  Missing\\r\\n\\r\\n>>> df.dropna(axis='index')\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py:1165: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\\r\\n  mask = pd.Series(mask)\\r\\nEmpty DataFrame\\r\\nColumns: []\\r\\nIndex: [0, 1, 2, 3, 4, 5, 6]\\r\\n>>> df.to_pandas().dropna(axis='index')\\r\\n       a        b          c        d\\r\\n0    one     this  something       00\\r\\n1    two     that         or       01\\r\\n2  three      the      other       02\\r\\n6     NA  Missing         NA  Missing\\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - rapidsai/rapidsai-nightly:cuda11.5-runtime-ubuntu20.04-py3.8\\r\\n - sha256:4a69370ad40f47a71404805fe2b1dd0a5cf28d7f6a5d4dd1cad419f8a3c8ce5f\\r\\n - 30 jan 2023\\r\\n\\r\\n![Screenshot from 2023-01-30 14-12-11](https://user-images.githubusercontent.com/112653/215572351-96fdd5bc-b96a-47ed-a55b-f84e5cbd9603.png)\\r\\n![Screenshot from 2023-01-30 14-12-02](https://user-images.githubusercontent.com/112653/215572362-8705fc0a-9ae8-4e94-a62f-5f99a32ff235.png)\\ncreatedAt: 2023-01-30T19:13:24Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 202}),\n",
       " Document(page_content=': 487\\ntitle: [FEA] add DataFrame.interpolate methods supported by cupyx\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n[cudf.DataFrame.interpolate](https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.dataframe.interpolate) supports `method=\"linear\"`\\r\\n\\r\\n[pandas.DataFrame.interpolate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html) supports a number of methods, including\\r\\n- [ ] time\\r\\n- [ ] krogh\\r\\n- [ ] piecewise_polynomial\\r\\n- [ ] spline\\r\\n- [ ] pchip\\r\\n- [ ] akima\\r\\n- [ ] cubicspline\\r\\n\\r\\n[cupyx.scipy.interpolate](https://docs.cupy.dev/en/latest/reference/scipy_interpolate.html) provides implementations for most of these\\r\\n\\r\\nextend the supported methods by those available in `cupyx`\\ncreatedAt: 2023-01-31T00:23:42Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 203}),\n",
       " Document(page_content=\": 488\\ntitle: [FEA] support cudf.Series.at\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nfunctionality matching https://pandas.pydata.org/docs/reference/api/pandas.Series.at.html\\r\\n![image](https://user-images.githubusercontent.com/112653/215628566-44bab64b-d4b3-4250-a97a-ce28082f9c7f.png)\\ncreatedAt: 2023-01-31T00:37:27Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 204}),\n",
       " Document(page_content=': 490\\ntitle: [BUG] `cudf::strings::from_integers` does not appear to be `compute-sanitizer --tool initcheck` clean\\nbody: Conversion from (at least) integer to string columns (done a lot for printing on the cudf-python side of things) appears to have uninitialized device memory accesses. Related #8873.\\r\\n\\r\\nConsider the following:\\r\\n```c++\\r\\n#include <algorithm>\\r\\n#include <cstdint>\\r\\n#include <vector>\\r\\n\\r\\n#include <cudf/column/column.hpp>\\r\\n#include <cudf/column/column_view.hpp>\\r\\n#include <cudf/strings/convert/convert_integers.hpp>\\r\\n#include <cudf/types.hpp>\\r\\n\\r\\nint main(int argc, char **argv) {\\r\\n  using T = int64_t;\\r\\n  using size_type = cudf::size_type;\\r\\n  size_type size;\\r\\n  if (argc > 1) {\\r\\n    size = std::stoi(argv[1]);\\r\\n  } else {\\r\\n    size = 1;\\r\\n  }\\r\\n  std::vector<T> data{size};\\r\\n  std::generate(data.begin(), data.end(), []() { return 1; });\\r\\n  auto column = cudf::column{cudf::data_type{cudf::type_to_id<T>()}, size,\\r\\n                             rmm::device_buffer{data.data(), size * sizeof(T),\\r\\n                                                cudf::get_default_stream()}};\\r\\n  cudf::get_default_stream().synchronize();\\r\\n  auto string_col = cudf::strings::from_integers(\\r\\n      column.view(), rmm::mr::get_current_device_resource());\\r\\n  cudf::get_default_stream().synchronize();\\r\\n  return 0;\\r\\n}\\r\\n```\\r\\n\\r\\nWhen run as:\\r\\n```\\r\\n$ compute-sanitizer --tool initcheck ./test\\r\\n========= COMPUTE-SANITIZER\\r\\n========= Uninitialized __global__ memory read of size 4 bytes\\r\\n=========     at 0x1c0 in void cub::CUB_101702_860_NS::DeviceScanKernel<cub::CUB_101702_860_NS::DeviceScanPolicy<long>::Policy600, int *, cudf::detail::sizes_to_offsets_iterator<int *, long>, cub::CUB_101702_860_NS::ScanTileState<long, (bool)1>, thrust::plus<void>, cub::CUB_101702_860_NS::detail::InputValue<long, long *>, int>(T2, T3, T4, int, T5, T6, T7)\\r\\n=========     by thread (1,0,0) in block (0,0,0)\\r\\n=========     Address 0x7f26c3e00204\\r\\n=========     Saved host backtrace up to driver entry point at kernel launch time\\r\\n=========     Host Frame: [0x304e32]\\r\\n=========                in /usr/lib/x86_64-linux-gnu/libcuda.so.1\\r\\n=========     Host Frame: [0x1488c]\\r\\n=========                in /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/lib/libcudart.so.11.0\\r\\n=========     Host Frame:cudaLaunchKernel [0x6c318]\\r\\n=========                in /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/lib/libcudart.so.11.0\\r\\n=========     Host Frame:cudf::detail::sizes_to_offsets_iterator<int*, long> thrust::cuda_cub::detail::exclusive_scan_n_impl<thrust::detail::execute_with_allocator<rmm::mr::thrust_allocator<char>, thrust::cuda_cub::execute_on_stream_base>, int*, long, cudf::detail::sizes_to_offsets_iterator<int*, long>, long, thrust::plus<void> >(thrust::cuda_cub::execution_policy<thrust::detail::execute_with_allocator<rmm::mr::thrust_allocator<char>, thrust::cuda_cub::execute_on_stream_base> >&, int*, long, cudf::detail::sizes_to_offsets_iterator<int*, long>, long, thrust::plus<void>) [0x161bf95]\\r\\n=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so\\r\\n=========     Host Frame:auto cudf::detail::sizes_to_offsets<int*, int*>(int*, int*, int*, rmm::cuda_stream_view) [0x161c612]\\r\\n=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so\\r\\n=========     Host Frame:auto cudf::strings::detail::make_strings_children<cudf::strings::detail::(anonymous namespace)::from_integers_fn<long> >(cudf::strings::detail::(anonymous namespace)::from_integers_fn<long>, int, int, rmm::cuda_stream_view, rmm::mr::device_memory_resource*) [0x264fb1f]\\r\\n=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so\\r\\n=========     Host Frame:std::unique_ptr<cudf::column, std::default_delete<cudf::column> > cudf::strings::detail::(anonymous namespace)::dispatch_from_integers_fn::operator()<long, (void*)0>(cudf::column_view const&, rmm::cuda_stream_view, rmm::mr::device_memory_resource*) const [0x264feb1]\\r\\n=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so\\r\\n=========     Host Frame:cudf::strings::detail::from_integers(cudf::column_view const&, rmm::cuda_stream_view, rmm::mr::device_memory_resource*) [0x264a1e9]\\r\\n=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so\\r\\n=========     Host Frame:cudf::strings::from_integers(cudf::column_view const&, rmm::mr::device_memory_resource*) [0x264a2c7]\\r\\n=========                in /home/wence/Documents/src/rapids/cudf/cpp/build/libcudf.so\\r\\n=========     Host Frame:/home/wence/Documents/src/rapids/doodles/c++/test_from_integers.cpp:26:main [0x1ae5e]\\r\\n=========                in /home/wence/Documents/src/rapids/doodles/c++/./test\\r\\n=========     Host Frame:__libc_start_main [0x24083]\\r\\n=========                in /usr/lib/x86_64-linux-gnu/libc.so.6\\r\\n=========     Host Frame: [0x13079]\\r\\n=========                in /home/wence/Documents/src/rapids/doodles/c++/./test\\r\\n=========\\r\\n========= ERROR SUMMARY: 1 error\\r\\n```\\r\\n\\r\\nThis _looks_ like an off-by-one, but my tracking through the libcudf side of things didn\\'t spot anything, so perhaps it is a bug in thrust or CUB.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: [Bare-metal, Docker, Cloud(specify cloud provider)]\\r\\n - Method of cuDF install: [conda, Docker, or from source]\\r\\n   - If method of install is [Docker], provide `docker pull` & `docker run` commands used\\r\\n\\r\\n**Environment details**\\r\\n\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n\\r\\n     **git***\\r\\n     commit 55ef6018ed92bfd6d3cbb67d9736c72aadaa2668 (HEAD -> branch-23.02)\\r\\n     Author: Karthikeyan <6488848+karthikeyann@users.noreply.github.com>\\r\\n     Date:   Sat Jan 28 07:09:29 2023 +0530\\r\\n\\r\\n     Add JSON Writer (#12474)\\r\\n\\r\\n     Adds JSON writer with nested support.\\r\\n     It supports numeric, datetime, duration, strings,  nested types such as struct and list types.\\r\\n     `orient=\\'records\\'` is only supported now, with `lines=True/False`.\\r\\n     Usage: `df.to_json(engine=\\'cudf\\')`\\r\\n\\r\\n     closes https://github.com/rapidsai/cudf/issues/11165\\r\\n\\r\\n     Authors:\\r\\n     - Karthikeyan (https://github.com/karthikeyann)\\r\\n\\r\\n     Approvers:\\r\\n     - Vukasin Milovanovic (https://github.com/vuule)\\r\\n     - GALI PREM SAGAR (https://github.com/galipremsagar)\\r\\n     - David Wendt (https://github.com/davidwendt)\\r\\n     - Michael Wang (https://github.com/isVoid)\\r\\n     - Robert Maynard (https://github.com/robertmaynard)\\r\\n\\r\\n     URL: https://github.com/rapidsai/cudf/pull/12474\\r\\n     **git submodules***\\r\\n\\r\\n     ***OS Information***\\r\\n     DISTRIB_ID=Ubuntu\\r\\n     DISTRIB_RELEASE=20.04\\r\\n     DISTRIB_CODENAME=focal\\r\\n     DISTRIB_DESCRIPTION=\"Ubuntu 20.04.5 LTS\"\\r\\n     NAME=\"Ubuntu\"\\r\\n     VERSION=\"20.04.5 LTS (Focal Fossa)\"\\r\\n     ID=ubuntu\\r\\n     ID_LIKE=debian\\r\\n     PRETTY_NAME=\"Ubuntu 20.04.5 LTS\"\\r\\n     VERSION_ID=\"20.04\"\\r\\n     HOME_URL=\"https://www.ubuntu.com/\"\\r\\n     SUPPORT_URL=\"https://help.ubuntu.com/\"\\r\\n     BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\\r\\n     PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\\r\\n     VERSION_CODENAME=focal\\r\\n     UBUNTU_CODENAME=focal\\r\\n     Linux shallot 5.15.0-58-generic NVIDIA/cub#64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\\r\\n\\r\\n     ***GPU Information***\\r\\n     Wed Feb  1 16:01:12 2023\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\\r\\n     |-------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                               |                      |               MIG M. |\\r\\n     |===============================+======================+======================|\\r\\n     |   0  NVIDIA RTX A6000    On   | 00000000:17:00.0 Off |                  Off |\\r\\n     | 30%   31C    P8    21W / 300W |      6MiB / 49140MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     |   1  NVIDIA RTX A6000    On   | 00000000:B3:00.0  On |                  Off |\\r\\n     | 30%   43C    P3    49W / 300W |   1343MiB / 49140MiB |     13%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | Processes:                                                                  |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n     |        ID   ID                                                   Usage      |\\r\\n     |=============================================================================|\\r\\n     |    0   N/A  N/A      3089      G   /usr/lib/xorg/Xorg                  4MiB |\\r\\n     |    1   N/A  N/A      3089      G   /usr/lib/xorg/Xorg                738MiB |\\r\\n     |    1   N/A  N/A      3267      G   /usr/bin/gnome-shell              185MiB |\\r\\n     |    1   N/A  N/A     44652      G   ...veSuggestionsOnlyOnDemand      154MiB |\\r\\n     |    1   N/A  N/A     45338      G   /usr/bin/wezterm-gui               11MiB |\\r\\n     +-----------------------------------------------------------------------------+\\r\\n\\r\\n     ***CPU***\\r\\n     Architecture:                    x86_64\\r\\n     CPU op-mode(s):                  32-bit, 64-bit\\r\\n     Byte Order:                      Little Endian\\r\\n     Address sizes:                   46 bits physical, 48 bits virtual\\r\\n     CPU(s):                          32\\r\\n     On-line CPU(s) list:             0-31\\r\\n     Thread(s) per core:              2\\r\\n     Core(s) per socket:              16\\r\\n     Socket(s):                       1\\r\\n     NUMA node(s):                    1\\r\\n     Vendor ID:                       GenuineIntel\\r\\n     CPU family:                      6\\r\\n     Model:                           85\\r\\n     Model name:                      Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz\\r\\n     Stepping:                        7\\r\\n     CPU MHz:                         2900.000\\r\\n     CPU max MHz:                     3900.0000\\r\\n     CPU min MHz:                     1200.0000\\r\\n     BogoMIPS:                        5800.00\\r\\n     Virtualization:                  VT-x\\r\\n     L1d cache:                       512 KiB\\r\\n     L1i cache:                       512 KiB\\r\\n     L2 cache:                        16 MiB\\r\\n     L3 cache:                        22 MiB\\r\\n     NUMA node0 CPU(s):               0-31\\r\\n     Vulnerability Itlb multihit:     KVM: Mitigation: VMX disabled\\r\\n     Vulnerability L1tf:              Not affected\\r\\n     Vulnerability Mds:               Not affected\\r\\n     Vulnerability Meltdown:          Not affected\\r\\n     Vulnerability Mmio stale data:   Mitigation; Clear CPU buffers; SMT vulnerable\\r\\n     Vulnerability Retbleed:          Mitigation; Enhanced IBRS\\r\\n     Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp\\r\\n     Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\r\\n     Vulnerability Spectre v2:        Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence\\r\\n     Vulnerability Srbds:             Not affected\\r\\n     Vulnerability Tsx async abort:   Mitigation; TSX disabled\\r\\n     Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni md_clear flush_l1d arch_capabilities\\r\\n\\r\\n     ***CMake***\\r\\n     /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/bin/cmake\\r\\n     cmake version 3.25.2\\r\\n\\r\\n     CMake suite maintained and supported by Kitware (kitware.com/cmake).\\r\\n\\r\\n     ***g++***\\r\\n     /usr/local/sbin/g++\\r\\n     g++ (conda-forge gcc 9.5.0-19) 9.5.0\\r\\n     Copyright (C) 2019 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n\\r\\n\\r\\n     ***nvcc***\\r\\n     /usr/local/sbin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2022 NVIDIA Corporation\\r\\n     Built on Wed_Sep_21_10:33:58_PDT_2022\\r\\n     Cuda compilation tools, release 11.8, V11.8.89\\r\\n     Build cuda_11.8.r11.8/compiler.31833905_0\\r\\n\\r\\n     ***Python***\\r\\n     /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/bin/python\\r\\n     Python 3.8.15\\r\\n\\r\\n     ***Environment Variables***\\r\\n     PATH                            : /usr/local/sbin:/usr/local/bin:/home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/bin:/home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/cuda/bin\\r\\n     LD_LIBRARY_PATH                 : /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids/lib:/home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/lib:/home/wence/Documents/src/rapids/rmm/build/release:/home/wence/Documents/src/rapids/cudf/cpp/build/release:/home/wence/Documents/src/rapids/raft/cpp/build/release:/home/wence/Documents/src/rapids/cuml/cpp/build/release:/home/wence/Documents/src/rapids/cugraph/cpp/build/release:/home/wence/Documents/src/rapids/cuspatial/cpp/build/release\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids\\r\\n     PYTHON_PATH                     :\\r\\n\\r\\n     ***conda packages***\\r\\n     /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/bin/conda\\r\\n\\r\\n     # packages in environment at /home/wence/Documents/src/rapids/compose/etc/conda/cuda_11.8/envs/rapids:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                  2_kmp_llvm    conda-forge\\r\\n     _sysroot_linux-64_curr_repodata_hack 3                   h5bd9786_13    conda-forge\\r\\n     aiobotocore               2.4.2              pyhd8ed1ab_0    conda-forge\\r\\n     aiohttp                   3.8.3            py38h0a891b7_1    conda-forge\\r\\n     aioitertools              0.11.0             pyhd8ed1ab_0    conda-forge\\r\\n     aiosignal                 1.3.1              pyhd8ed1ab_0    conda-forge\\r\\n     alabaster                 0.7.13             pyhd8ed1ab_0    conda-forge\\r\\n     anyio                     3.6.2              pyhd8ed1ab_0    conda-forge\\r\\n     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge\\r\\n     argon2-cffi               21.3.0             pyhd8ed1ab_0    conda-forge\\r\\n     argon2-cffi-bindings      21.2.0           py38h0a891b7_3    conda-forge\\r\\n     arrow-cpp                 10.0.1           ha770c72_6_cpu    conda-forge\\r\\n     asttokens                 2.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     async-timeout             4.0.2              pyhd8ed1ab_0    conda-forge\\r\\n     attrs                     22.2.0             pyh71513ae_0    conda-forge\\r\\n     aws-c-auth                0.6.21               hd93a3ba_3    conda-forge\\r\\n     aws-c-cal                 0.5.20               hff2c3d7_3    conda-forge\\r\\n     aws-c-common              0.8.5                h166bdaf_0    conda-forge\\r\\n     aws-c-compression         0.2.16               hf5f93bc_0    conda-forge\\r\\n     aws-c-event-stream        0.2.18               h57874a7_0    conda-forge\\r\\n     aws-c-http                0.7.0                h96ef541_0    conda-forge\\r\\n     aws-c-io                  0.13.12              h57ca295_1    conda-forge\\r\\n     aws-c-mqtt                0.7.13              h0b5698f_12    conda-forge\\r\\n     aws-c-s3                  0.2.3                h82cbbf9_0    conda-forge\\r\\n     aws-c-sdkutils            0.1.7                hf5f93bc_0    conda-forge\\r\\n     aws-checksums             0.1.14               h6027aba_0    conda-forge\\r\\n     aws-crt-cpp               0.18.16             hf80f573_10    conda-forge\\r\\n     aws-sam-translator        1.58.1             pyhd8ed1ab_0    conda-forge\\r\\n     aws-sdk-cpp               1.10.57              ha834a50_1    conda-forge\\r\\n     aws-xray-sdk              2.11.0             pyhd8ed1ab_0    conda-forge\\r\\n     babel                     2.11.0             pyhd8ed1ab_0    conda-forge\\r\\n     backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\\r\\n     backports                 1.0                pyhd8ed1ab_3    conda-forge\\r\\n     backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\\r\\n     backports.zoneinfo        0.2.1            py38h0a891b7_7    conda-forge\\r\\n     bcrypt                    3.2.2            py38h0a891b7_1    conda-forge\\r\\n     beautifulsoup4            4.11.1             pyha770c72_0    conda-forge\\r\\n     binutils                  2.39                 hdd6e379_1    conda-forge\\r\\n     binutils_impl_linux-64    2.39                 he00db2b_1    conda-forge\\r\\n     binutils_linux-64         2.39                h5fc0e48_11    conda-forge\\r\\n     blas                      1.0                         mkl    conda-forge\\r\\n     bleach                    6.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     blosc                     1.21.3               hafa529b_0    conda-forge\\r\\n     bokeh                     2.4.3              pyhd8ed1ab_3    conda-forge\\r\\n     boost-cpp                 1.78.0               h75c5d50_1    conda-forge\\r\\n     boto3                     1.24.59            pyhd8ed1ab_0    conda-forge\\r\\n     botocore                  1.27.59            pyhd8ed1ab_0    conda-forge\\r\\n     branca                    0.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     breathe                   4.34.0             pyhd8ed1ab_0    conda-forge\\r\\n     brotli                    1.0.9                h166bdaf_8    conda-forge\\r\\n     brotli-bin                1.0.9                h166bdaf_8    conda-forge\\r\\n     brotlipy                  0.7.0           py38h0a891b7_1005    conda-forge\\r\\n     bzip2                     1.0.8                h7f98852_4    conda-forge\\r\\n     c-ares                    1.18.1               h7f98852_0    conda-forge\\r\\n     c-compiler                1.3.0                h7f98852_0    conda-forge\\r\\n     ca-certificates           2022.12.7            ha878542_0    conda-forge\\r\\n     cachetools                5.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     cairo                     1.16.0            ha61ee94_1014    conda-forge\\r\\n     certifi                   2022.12.7          pyhd8ed1ab_0    conda-forge\\r\\n     cffi                      1.15.1           py38h4a40e3a_3    conda-forge\\r\\n     cfgv                      3.3.1              pyhd8ed1ab_0    conda-forge\\r\\n     cfitsio                   4.2.0                hd9d235c_0    conda-forge\\r\\n     cfn-lint                  0.24.8                   py38_0    conda-forge\\r\\n     charset-normalizer        2.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     clang                     11.1.0               ha770c72_1    conda-forge\\r\\n     clang-11                  11.1.0          default_ha53f305_1    conda-forge\\r\\n     clang-tools               11.1.0          default_ha53f305_1    conda-forge\\r\\n     clangxx                   11.1.0          default_ha53f305_1    conda-forge\\r\\n     click                     8.1.3           unix_pyhd8ed1ab_2    conda-forge\\r\\n     click-plugins             1.1.1                      py_0    conda-forge\\r\\n     cligj                     0.7.2              pyhd8ed1ab_1    conda-forge\\r\\n     cloudpickle               2.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     cmake                     3.25.2               h077f3f9_0    conda-forge\\r\\n     cmake_setuptools          0.1.3                      py_0    rapidsai\\r\\n     colorama                  0.4.6              pyhd8ed1ab_0    conda-forge\\r\\n     comm                      0.1.2              pyhd8ed1ab_0    conda-forge\\r\\n     commonmark                0.9.1                      py_0    conda-forge\\r\\n     contourpy                 1.0.7            py38hfbd4bf9_0    conda-forge\\r\\n     coverage                  7.1.0            py38h1de0b5d_0    conda-forge\\r\\n     cryptography              39.0.0           py38h3d167d9_0    conda-forge\\r\\n     cubinlinker               0.2.2            py38h7144610_0    rapidsai\\r\\n     cuda-profiler-api         11.8.86                       0    nvidia\\r\\n     cuda-python               11.8.1           py38h241159d_2    conda-forge\\r\\n     cudatoolkit               11.8.0              h37601d7_11    conda-forge\\r\\n     cupy                      11.5.0           py38h405e1b6_0    conda-forge\\r\\n     curl                      7.87.0               hdc1c0ab_0    conda-forge\\r\\n     cxx-compiler              1.3.0                h4bd325d_0    conda-forge\\r\\n     cycler                    0.11.0             pyhd8ed1ab_0    conda-forge\\r\\n     cyrus-sasl                2.1.27               h9033bb2_6    conda-forge\\r\\n     cython                    0.29.33          py38h8dc9893_0    conda-forge\\r\\n     cytoolz                   0.12.0           py38h0a891b7_1    conda-forge\\r\\n     dask                      2023.1.0+17.g2a2b9d3c           dev_0    <develop>\\r\\n     dask-core                 2023.1.1a230127 py_g185eed2c9_23    dask/label/dev\\r\\n     dask-cuda                 23.2.0a0+41.g66a6a46.dirty          pypi_0    pypi\\r\\n     dask-glm                  0.2.1.dev52+g1daf4c5          pypi_0    pypi\\r\\n     dask-ml                   2022.5.27          pyhd8ed1ab_0    conda-forge\\r\\n     dataclasses               0.8                pyhc8e2a94_3    conda-forge\\r\\n     datasets                  1.18.3             pyhd8ed1ab_0    conda-forge\\r\\n     debugpy                   1.6.6            py38h8dc9893_0    conda-forge\\r\\n     decopatch                 1.4.10             pyhd8ed1ab_0    conda-forge\\r\\n     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     dill                      0.3.6              pyhd8ed1ab_1    conda-forge\\r\\n     distlib                   0.3.6              pyhd8ed1ab_0    conda-forge\\r\\n     distributed               2023.1.0+9.g0161991f.dirty           dev_0    <develop>\\r\\n     distro                    1.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     dlpack                    0.5                  h9c3ff4c_0    conda-forge\\r\\n     docker-py                 6.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     docutils                  0.19             py38h578d9bd_1    conda-forge\\r\\n     doxygen                   1.8.20               had0d8f1_0    conda-forge\\r\\n     ecdsa                     0.18.0             pyhd8ed1ab_1    conda-forge\\r\\n     entrypoints               0.4                pyhd8ed1ab_0    conda-forge\\r\\n     exceptiongroup            1.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     execnet                   1.9.0              pyhd8ed1ab_0    conda-forge\\r\\n     executing                 1.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     expat                     2.5.0                h27087fc_0    conda-forge\\r\\n     faiss-proc                1.0.0                      cuda    rapidsai\\r\\n     fastavro                  1.7.1            py38h1de0b5d_0    conda-forge\\r\\n     fastrlock                 0.8              py38hfa26641_3    conda-forge\\r\\n     filelock                  3.9.0              pyhd8ed1ab_0    conda-forge\\r\\n     fiona                     1.8.22           py38hc72d8cd_2    conda-forge\\r\\n     flask                     2.1.3              pyhd8ed1ab_0    conda-forge\\r\\n     flask_cors                3.0.10             pyhd3deb0d_0    conda-forge\\r\\n     flit-core                 3.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     folium                    0.14.0             pyhd8ed1ab_0    conda-forge\\r\\n     font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge\\r\\n     font-ttf-inconsolata      3.000                h77eed37_0    conda-forge\\r\\n     font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge\\r\\n     font-ttf-ubuntu           0.83                 hab24e00_0    conda-forge\\r\\n     fontconfig                2.14.2               h14ed4e7_0    conda-forge\\r\\n     fonts-conda-ecosystem     1                             0    conda-forge\\r\\n     fonts-conda-forge         1                             0    conda-forge\\r\\n     fonttools                 4.38.0           py38h0a891b7_1    conda-forge\\r\\n     freetype                  2.12.1               hca18f0e_1    conda-forge\\r\\n     freexl                    1.0.6                h166bdaf_1    conda-forge\\r\\n     frozenlist                1.3.3            py38h0a891b7_0    conda-forge\\r\\n     fsspec                    2023.1.0           pyhd8ed1ab_0    conda-forge\\r\\n     future                    0.18.3             pyhd8ed1ab_0    conda-forge\\r\\n     gcc                       9.5.0               h1fea6ba_11    conda-forge\\r\\n     gcc_impl_linux-64         9.5.0               h99780fb_19    conda-forge\\r\\n     gcc_linux-64              9.5.0               h4258300_11    conda-forge\\r\\n     gcovr                     5.1                pyhd8ed1ab_0    conda-forge\\r\\n     gdal                      3.5.3           py38h58634bd_15    conda-forge\\r\\n     geopandas                 0.12.2             pyhd8ed1ab_0    conda-forge\\r\\n     geopandas-base            0.12.2             pyha770c72_0    conda-forge\\r\\n     geos                      3.11.1               h27087fc_0    conda-forge\\r\\n     geotiff                   1.7.1                h7a142b4_6    conda-forge\\r\\n     gettext                   0.21.1               h27087fc_0    conda-forge\\r\\n     gflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\n     giflib                    5.2.1                h36c2ea0_2    conda-forge\\r\\n     glog                      0.6.0                h6f12383_0    conda-forge\\r\\n     gmock                     1.10.0               h4bd325d_7    conda-forge\\r\\n     gmp                       6.2.1                h58526e2_0    conda-forge\\r\\n     gmpy2                     2.1.2            py38h793c122_1    conda-forge\\r\\n     graphql-core              3.2.3              pyhd8ed1ab_0    conda-forge\\r\\n     greenlet                  2.0.2            py38h8dc9893_0    conda-forge\\r\\n     gtest                     1.10.0               h4bd325d_7    conda-forge\\r\\n     gxx                       9.5.0               h1fea6ba_11    conda-forge\\r\\n     gxx_impl_linux-64         9.5.0               h99780fb_19    conda-forge\\r\\n     gxx_linux-64              9.5.0               h43f449f_11    conda-forge\\r\\n     hdbscan                   0.8.29           py38h26c90d9_1    conda-forge\\r\\n     hdf4                      4.2.15               h9772cbc_5    conda-forge\\r\\n     hdf5                      1.12.2          nompi_h4df4325_101    conda-forge\\r\\n     heapdict                  1.0.1                      py_0    conda-forge\\r\\n     huggingface_hub           0.12.0             pyhd8ed1ab_0    conda-forge\\r\\n     hypothesis                6.65.2             pyha770c72_0    conda-forge\\r\\n     icu                       70.1                 h27087fc_0    conda-forge\\r\\n     identify                  2.5.17             pyhd8ed1ab_0    conda-forge\\r\\n     idna                      3.4                pyhd8ed1ab_0    conda-forge\\r\\n     imagesize                 1.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     importlib-metadata        6.0.0              pyha770c72_0    conda-forge\\r\\n     importlib_metadata        6.0.0                hd8ed1ab_0    conda-forge\\r\\n     iniconfig                 2.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     ipykernel                 6.21.0             pyh210e3f2_0    conda-forge\\r\\n     ipython                   8.9.0              pyh41d4057_0    conda-forge\\r\\n     ipython_genutils          0.2.0                      py_1    conda-forge\\r\\n     itsdangerous              2.1.2              pyhd8ed1ab_0    conda-forge\\r\\n     jedi                      0.18.2             pyhd8ed1ab_0    conda-forge\\r\\n     jinja2                    3.1.2              pyhd8ed1ab_1    conda-forge\\r\\n     jmespath                  1.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     joblib                    1.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     jpeg                      9e                   h166bdaf_2    conda-forge\\r\\n     json-c                    0.16                 hc379101_0    conda-forge\\r\\n     jsondiff                  2.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     jsonpatch                 1.32               pyhd8ed1ab_0    conda-forge\\r\\n     jsonpointer               2.0                        py_0    conda-forge\\r\\n     jsonschema                3.2.0              pyhd8ed1ab_3    conda-forge\\r\\n     jupyter-cache             0.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_client            8.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_core              5.2.0            py38h578d9bd_0    conda-forge\\r\\n     jupyter_events            0.6.3              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_server            2.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_server_terminals  0.4.4              pyhd8ed1ab_1    conda-forge\\r\\n     jupyterlab_pygments       0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     kealib                    1.5.0                ha7026e8_0    conda-forge\\r\\n     kernel-headers_linux-64   3.10.0              h4a8ded7_13    conda-forge\\r\\n     keyutils                  1.6.1                h166bdaf_0    conda-forge\\r\\n     kiwisolver                1.4.4            py38h43d8883_1    conda-forge\\r\\n     krb5                      1.20.1               h81ceb04_0    conda-forge\\r\\n     lcms2                     2.14                 hfd0df8a_1    conda-forge\\r\\n     ld_impl_linux-64          2.39                 hcc3a1bd_1    conda-forge\\r\\n     lerc                      4.0.0                h27087fc_0    conda-forge\\r\\n     libabseil                 20220623.0      cxx17_h05df665_6    conda-forge\\r\\n     libaec                    1.0.6                hcb278e6_1    conda-forge\\r\\n     libarrow                  10.0.1           hf9c26a6_6_cpu    conda-forge\\r\\n     libblas                   3.9.0            16_linux64_mkl    conda-forge\\r\\n     libbrotlicommon           1.0.9                h166bdaf_8    conda-forge\\r\\n     libbrotlidec              1.0.9                h166bdaf_8    conda-forge\\r\\n     libbrotlienc              1.0.9                h166bdaf_8    conda-forge\\r\\n     libcblas                  3.9.0            16_linux64_mkl    conda-forge\\r\\n     libclang-cpp11.1          11.1.0          default_ha53f305_1    conda-forge\\r\\n     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge\\r\\n     libcublas                 11.11.3.6                     0    nvidia\\r\\n     libcublas-dev             11.11.3.6                     0    nvidia\\r\\n     libcufft                  10.9.0.58                     0    nvidia\\r\\n     libcufft-dev              10.9.0.58                     0    nvidia\\r\\n     libcumlprims              23.02.00a230126 cuda11_ge28945f_11    rapidsai-nightly\\r\\n     libcurand                 10.3.0.86                     0    nvidia\\r\\n     libcurand-dev             10.3.0.86                     0    nvidia\\r\\n     libcurl                   7.87.0               hdc1c0ab_0    conda-forge\\r\\n     libcusolver               11.4.1.48                     0    nvidia\\r\\n     libcusolver-dev           11.4.1.48                     0    nvidia\\r\\n     libcusparse               11.7.5.86                     0    nvidia\\r\\n     libcusparse-dev           11.7.5.86                     0    nvidia\\r\\n     libdap4                   3.20.6               hd7c4107_2    conda-forge\\r\\n     libdeflate                1.17                 h0b41bf4_0    conda-forge\\r\\n     libedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\n     libev                     4.33                 h516909a_1    conda-forge\\r\\n     libevent                  2.1.10               h28343ad_4    conda-forge\\r\\n     libfaiss                  1.7.2           cuda118h2d43ea4_4_cuda    rapidsai\\r\\n     libffi                    3.4.2                h7f98852_5    conda-forge\\r\\n     libgcc-devel_linux-64     9.5.0               h0a57e50_19    conda-forge\\r\\n     libgcc-ng                 12.2.0              h65d4601_19    conda-forge\\r\\n     libgcrypt                 1.10.1               h166bdaf_0    conda-forge\\r\\n     libgdal                   3.5.3               h084b287_15    conda-forge\\r\\n     libgfortran-ng            12.2.0              h69a702a_19    conda-forge\\r\\n     libgfortran5              12.2.0              h337968e_19    conda-forge\\r\\n     libglib                   2.74.1               h606061b_1    conda-forge\\r\\n     libgomp                   12.2.0              h65d4601_19    conda-forge\\r\\n     libgoogle-cloud           2.5.0                h21dfe5b_1    conda-forge\\r\\n     libgpg-error              1.46                 h620e276_0    conda-forge\\r\\n     libgrpc                   1.51.1               h30feacc_0    conda-forge\\r\\n     libgsasl                  1.8.0                         2    conda-forge\\r\\n     libhwloc                  2.8.0                h32351e8_1    conda-forge\\r\\n     libiconv                  1.17                 h166bdaf_0    conda-forge\\r\\n     libjpeg-turbo             2.1.4                h166bdaf_0    conda-forge\\r\\n     libkml                    1.3.0             h37653c0_1015    conda-forge\\r\\n     liblapack                 3.9.0            16_linux64_mkl    conda-forge\\r\\n     libllvm11                 11.1.0               he0ac6c6_5    conda-forge\\r\\n     libnetcdf                 4.8.1           nompi_h261ec11_106    conda-forge\\r\\n     libnghttp2                1.51.0               hff17c54_0    conda-forge\\r\\n     libnsl                    2.0.0                h7f98852_0    conda-forge\\r\\n     libntlm                   1.4               h7f98852_1002    conda-forge\\r\\n     libpng                    1.6.39               h753d276_0    conda-forge\\r\\n     libpq                     15.1                 hb675445_3    conda-forge\\r\\n     libprotobuf               3.21.12              h3eb15da_0    conda-forge\\r\\n     librdkafka                1.7.0                hb1989a6_1    conda-forge\\r\\n     librttopo                 1.1.0               ha49c73b_12    conda-forge\\r\\n     libsanitizer              9.5.0               h2f262e1_19    conda-forge\\r\\n     libsodium                 1.0.18               h36c2ea0_1    conda-forge\\r\\n     libspatialindex           1.9.3                h9c3ff4c_4    conda-forge\\r\\n     libspatialite             5.0.1               h221c8f1_23    conda-forge\\r\\n     libsqlite                 3.40.0               h753d276_0    conda-forge\\r\\n     libssh2                   1.10.0               hf14f497_3    conda-forge\\r\\n     libstdcxx-devel_linux-64  9.5.0               h0a57e50_19    conda-forge\\r\\n     libstdcxx-ng              12.2.0              h46fd767_19    conda-forge\\r\\n     libthrift                 0.16.0               he500d00_2    conda-forge\\r\\n     libtiff                   4.5.0                h6adf6a1_2    conda-forge\\r\\n     libutf8proc               2.8.0                h166bdaf_0    conda-forge\\r\\n     libuuid                   2.32.1            h7f98852_1000    conda-forge\\r\\n     libuv                     1.44.2               h166bdaf_0    conda-forge\\r\\n     libwebp-base              1.2.4                h166bdaf_0    conda-forge\\r\\n     libxcb                    1.13              h7f98852_1004    conda-forge\\r\\n     libxml2                   2.10.3               h7463322_0    conda-forge\\r\\n     libxslt                   1.1.37               h873f0b0_0    conda-forge\\r\\n     libzip                    1.9.2                hc929e4a_1    conda-forge\\r\\n     libzlib                   1.2.13               h166bdaf_4    conda-forge\\r\\n     littleutils               0.2.2                      py_0    conda-forge\\r\\n     livereload                2.6.3              pyh9f0ad1d_0    conda-forge\\r\\n     llvm-openmp               15.0.7               h0cdce71_0    conda-forge\\r\\n     llvmlite                  0.39.1           py38h38d86a4_1    conda-forge\\r\\n     locket                    1.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     lxml                      4.9.2            py38h215a2d7_0    conda-forge\\r\\n     lz4                       4.2.0            py38hd012fdc_0    conda-forge\\r\\n     lz4-c                     1.9.3                h9c3ff4c_1    conda-forge\\r\\n     make                      4.3                  hd18ef5c_1    conda-forge\\r\\n     makefun                   1.15.0             pyhd8ed1ab_0    conda-forge\\r\\n     mapclassify               2.5.0              pyhd8ed1ab_1    conda-forge\\r\\n     markdown                  3.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     markdown-it-py            2.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     markupsafe                2.1.2            py38h1de0b5d_0    conda-forge\\r\\n     matplotlib-base           3.6.3            py38hd6c3c57_0    conda-forge\\r\\n     matplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge\\r\\n     mdit-py-plugins           0.3.3              pyhd8ed1ab_0    conda-forge\\r\\n     mdurl                     0.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     mimesis                   7.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     mistune                   2.0.4              pyhd8ed1ab_0    conda-forge\\r\\n     mkl                       2022.2.1         h84fe81f_16997    conda-forge\\r\\n     moto                      4.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     mpc                       1.3.1                hfe3b2da_0    conda-forge\\r\\n     mpfr                      4.1.0                h9202a9a_1    conda-forge\\r\\n     mpi                       1.0                     openmpi    conda-forge\\r\\n     mpi4py                    3.1.4                    pypi_0    pypi\\r\\n     msgpack-python            1.0.4            py38h43d8883_1    conda-forge\\r\\n     multidict                 6.0.4            py38h1de0b5d_0    conda-forge\\r\\n     multipledispatch          0.6.0                      py_0    conda-forge\\r\\n     multiprocess              0.70.14          py38h0a891b7_3    conda-forge\\r\\n     munch                     2.5.0                      py_0    conda-forge\\r\\n     munkres                   1.1.4              pyh9f0ad1d_0    conda-forge\\r\\n     myst-nb                   0.17.1             pyhd8ed1ab_0    conda-forge\\r\\n     myst-parser               0.18.1             pyhd8ed1ab_0    conda-forge\\r\\n     nbclassic                 0.4.8              pyhd8ed1ab_0    conda-forge\\r\\n     nbclient                  0.5.13             pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert                 7.2.9              pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert-core            7.2.9              pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert-pandoc          7.2.9              pyhd8ed1ab_0    conda-forge\\r\\n     nbformat                  5.7.3              pyhd8ed1ab_0    conda-forge\\r\\n     nbsphinx                  0.8.12             pyhd8ed1ab_0    conda-forge\\r\\n     nccl                      2.14.3.1             h0800d71_0    conda-forge\\r\\n     ncurses                   6.3                  h27087fc_1    conda-forge\\r\\n     nest-asyncio              1.5.6              pyhd8ed1ab_0    conda-forge\\r\\n     networkx                  3.0                pyhd8ed1ab_0    conda-forge\\r\\n     ninja                     1.11.0               h924138e_0    conda-forge\\r\\n     nltk                      3.8.1              pyhd8ed1ab_0    conda-forge\\r\\n     nodeenv                   1.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     notebook                  6.5.2              pyha770c72_1    conda-forge\\r\\n     notebook-shim             0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     nspr                      4.35                 h27087fc_0    conda-forge\\r\\n     nss                       3.82                 he02c5a1_0    conda-forge\\r\\n     numba                     0.56.4           py38h9a4aae9_0    conda-forge\\r\\n     numpy                     1.23.5           py38h7042d01_0    conda-forge\\r\\n     numpydoc                  1.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     nvcc_linux-64             11.8                ha67cc55_22    conda-forge\\r\\n     nvtx                      0.2.3            py38h0a891b7_2    conda-forge\\r\\n     ogb                       1.3.5              pyhd8ed1ab_0    conda-forge\\r\\n     openapi-schema-validator  0.2.3              pyhd8ed1ab_0    conda-forge\\r\\n     openapi-spec-validator    0.4.0              pyhd8ed1ab_1    conda-forge\\r\\n     openjpeg                  2.5.0                hfec8fc6_2    conda-forge\\r\\n     openmpi                   4.1.4              ha1ae619_102    conda-forge\\r\\n     openssl                   3.0.7                h0b41bf4_2    conda-forge\\r\\n     orc                       1.8.2                hfdbbad2_0    conda-forge\\r\\n     outdated                  0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     packaging                 23.0               pyhd8ed1ab_0    conda-forge\\r\\n     pandas                    1.5.3            py38hdc8b05c_0    conda-forge\\r\\n     pandoc                    1.19.2                        0    conda-forge\\r\\n     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     paramiko                  3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     parquet-cpp               1.5.1                         2    conda-forge\\r\\n     parso                     0.8.3              pyhd8ed1ab_0    conda-forge\\r\\n     partd                     1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     patsy                     0.5.3              pyhd8ed1ab_0    conda-forge\\r\\n     pcre2                     10.40                hc3806b6_0    conda-forge\\r\\n     pexpect                   4.8.0              pyh1a96a4e_2    conda-forge\\r\\n     pickleshare               0.7.5                   py_1003    conda-forge\\r\\n     pillow                    9.4.0            py38hb32c036_0    conda-forge\\r\\n     pip                       23.0               pyhd8ed1ab_0    conda-forge\\r\\n     pixman                    0.40.0               h36c2ea0_0    conda-forge\\r\\n     platformdirs              2.6.2              pyhd8ed1ab_0    conda-forge\\r\\n     pluggy                    1.0.0              pyhd8ed1ab_5    conda-forge\\r\\n     pooch                     1.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     poppler                   23.01.0              h091648b_0    conda-forge\\r\\n     poppler-data              0.4.11               hd8ed1ab_0    conda-forge\\r\\n     postgresql                15.1                 h3248436_3    conda-forge\\r\\n     pre-commit                3.0.2            py38h578d9bd_0    conda-forge\\r\\n     proj                      9.1.1                h8ffa02c_2    conda-forge\\r\\n     prometheus_client         0.16.0             pyhd8ed1ab_0    conda-forge\\r\\n     prompt-toolkit            3.0.36             pyha770c72_0    conda-forge\\r\\n     protobuf                  4.21.12          py38h8dc9893_0    conda-forge\\r\\n     psutil                    5.9.4            py38h0a891b7_0    conda-forge\\r\\n     pthread-stubs             0.4               h36c2ea0_1001    conda-forge\\r\\n     ptxcompiler               0.7.0            py38h241159d_3    conda-forge\\r\\n     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\\r\\n     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     py                        1.11.0             pyh6c4a22f_0    conda-forge\\r\\n     py-cpuinfo                9.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     pyarrow                   10.0.1          py38hf05218d_6_cpu    conda-forge\\r\\n     pyasn1                    0.4.8                      py_0    conda-forge\\r\\n     pycparser                 2.21               pyhd8ed1ab_0    conda-forge\\r\\n     pydantic                  1.10.4           py38h1de0b5d_1    conda-forge\\r\\n     pydata-sphinx-theme       0.12.0             pyhd8ed1ab_0    conda-forge\\r\\n     pygments                  2.14.0             pyhd8ed1ab_0    conda-forge\\r\\n     pynacl                    1.5.0            py38h0a891b7_2    conda-forge\\r\\n     pynndescent               0.5.8              pyh1a96a4e_0    conda-forge\\r\\n     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyopenssl                 23.0.0             pyhd8ed1ab_0    conda-forge\\r\\n     pyorc                     0.8.0            py38h4492b77_2    conda-forge\\r\\n     pyparsing                 3.0.9              pyhd8ed1ab_0    conda-forge\\r\\n     pyproj                    3.4.1            py38h58d5fe2_1    conda-forge\\r\\n     pyrsistent                0.19.3           py38h1de0b5d_0    conda-forge\\r\\n     pysocks                   1.7.1              pyha2e5f31_6    conda-forge\\r\\n     pytest                    7.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     pytest-benchmark          4.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     pytest-cases              3.6.13             pyhd8ed1ab_0    conda-forge\\r\\n     pytest-cov                4.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     pytest-xdist              3.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     python                    3.8.15          he550d4f_1_cpython    conda-forge\\r\\n     python-confluent-kafka    1.7.0            py38h497a2fe_2    conda-forge\\r\\n     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\\r\\n     python-fastjsonschema     2.16.2             pyhd8ed1ab_0    conda-forge\\r\\n     python-jose               3.3.0              pyh6c4a22f_1    conda-forge\\r\\n     python-json-logger        2.0.4              pyhd8ed1ab_0    conda-forge\\r\\n     python-louvain            0.16               pyhd8ed1ab_0    conda-forge\\r\\n     python-snappy             0.6.1            py38h1ddbb56_0    conda-forge\\r\\n     python-xxhash             3.2.0            py38h1de0b5d_0    conda-forge\\r\\n     python_abi                3.8                      3_cp38    conda-forge\\r\\n     pytorch                   1.11.0              py3.8_cpu_0    pytorch\\r\\n     pytorch-mutex             1.0                         cpu    pytorch\\r\\n     pytz                      2022.7.1           pyhd8ed1ab_0    conda-forge\\r\\n     pywin32-on-windows        0.1.0              pyh1179c8e_3    conda-forge\\r\\n     pyyaml                    6.0              py38h0a891b7_5    conda-forge\\r\\n     pyzmq                     25.0.0           py38he24dcef_0    conda-forge\\r\\n     re2                       2022.06.01           h27087fc_1    conda-forge\\r\\n     readline                  8.1.2                h0f457ee_0    conda-forge\\r\\n     recommonmark              0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     regex                     2022.10.31       py38h0a891b7_0    conda-forge\\r\\n     requests                  2.28.2             pyhd8ed1ab_0    conda-forge\\r\\n     responses                 0.21.0             pyhd8ed1ab_0    conda-forge\\r\\n     rfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge\\r\\n     rfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge\\r\\n     rhash                     1.4.3                h166bdaf_0    conda-forge\\r\\n     rsa                       4.9                pyhd8ed1ab_0    conda-forge\\r\\n     rtree                     1.0.1            py38h02d302b_1    conda-forge\\r\\n     s2n                       1.3.31               h3358134_0    conda-forge\\r\\n     s3fs                      2023.1.0           pyhd8ed1ab_0    conda-forge\\r\\n     s3transfer                0.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     sacremoses                0.0.53             pyhd8ed1ab_0    conda-forge\\r\\n     scikit-build              0.16.6             pyh56297ac_0    conda-forge\\r\\n     scikit-learn              1.2.1            py38h1e1a916_0    conda-forge\\r\\n     scipy                     1.10.0           py38h10c12cc_0    conda-forge\\r\\n     seaborn                   0.12.2               hd8ed1ab_0    conda-forge\\r\\n     seaborn-base              0.12.2             pyhd8ed1ab_0    conda-forge\\r\\n     sed                       4.8                  he412f7d_0    conda-forge\\r\\n     send2trash                1.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     setuptools                67.0.0                   pypi_0    pypi\\r\\n     shapely                   2.0.1            py38hd07e089_0    conda-forge\\r\\n     six                       1.16.0             pyh6c4a22f_0    conda-forge\\r\\n     snappy                    1.1.9                hbd366e4_2    conda-forge\\r\\n     sniffio                   1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     snowballstemmer           2.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     soupsieve                 2.3.2.post1        pyhd8ed1ab_0    conda-forge\\r\\n     sparse                    0.13.0             pyhd8ed1ab_0    conda-forge\\r\\n     spdlog                    1.8.5                h4bd325d_1    conda-forge\\r\\n     sphinx                    5.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     sphinx-autobuild          2021.3.14          pyhd8ed1ab_0    conda-forge\\r\\n     sphinx-copybutton         0.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     sphinx-markdown-tables    0.0.17             pyh6c4a22f_0    conda-forge\\r\\n     sphinxcontrib-applehelp   1.0.4              pyhd8ed1ab_0    conda-forge\\r\\n     sphinxcontrib-devhelp     1.0.2                      py_0    conda-forge\\r\\n     sphinxcontrib-htmlhelp    2.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     sphinxcontrib-jsmath      1.0.1                      py_0    conda-forge\\r\\n     sphinxcontrib-qthelp      1.0.3                      py_0    conda-forge\\r\\n     sphinxcontrib-serializinghtml 1.1.5              pyhd8ed1ab_2    conda-forge\\r\\n     sphinxcontrib-websupport  1.2.4              pyhd8ed1ab_1    conda-forge\\r\\n     sqlalchemy                1.4.46           py38h1de0b5d_0    conda-forge\\r\\n     sqlite                    3.40.0               h4ff8645_0    conda-forge\\r\\n     sshpubkeys                3.3.1              pyhd8ed1ab_0    conda-forge\\r\\n     stack_data                0.6.2              pyhd8ed1ab_0    conda-forge\\r\\n     statsmodels               0.13.5           py38h26c90d9_2    conda-forge\\r\\n     streamz                   0.6.4              pyh6c4a22f_0    conda-forge\\r\\n     sysroot_linux-64          2.17                h4a8ded7_13    conda-forge\\r\\n     tabulate                  0.9.0              pyhd8ed1ab_1    conda-forge\\r\\n     tbb                       2021.7.0             h924138e_1    conda-forge\\r\\n     tblib                     1.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     terminado                 0.17.1             pyh41d4057_0    conda-forge\\r\\n     threadpoolctl             3.1.0              pyh8a188c0_0    conda-forge\\r\\n     tiledb                    2.13.2               hd532e3d_0    conda-forge\\r\\n     tinycss2                  1.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     tk                        8.6.12               h27826a3_0    conda-forge\\r\\n     tokenizers                0.13.1           py38h8bed557_2    conda-forge\\r\\n     toml                      0.10.2             pyhd8ed1ab_0    conda-forge\\r\\n     tomli                     2.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     toolz                     0.12.0             pyhd8ed1ab_0    conda-forge\\r\\n     tornado                   6.2              py38h0a891b7_1    conda-forge\\r\\n     tqdm                      4.64.1             pyhd8ed1ab_0    conda-forge\\r\\n     traitlets                 5.9.0              pyhd8ed1ab_0    conda-forge\\r\\n     transformers              4.24.0             pyhd8ed1ab_0    conda-forge\\r\\n     treelite                  3.1.0            py38h2820b77_0    conda-forge\\r\\n     treelite-runtime          3.1.0                    pypi_0    pypi\\r\\n     typing-extensions         4.4.0                hd8ed1ab_0    conda-forge\\r\\n     typing_extensions         4.4.0              pyha770c72_0    conda-forge\\r\\n     tzcode                    2022g                h166bdaf_0    conda-forge\\r\\n     tzdata                    2022g                h191b570_0    conda-forge\\r\\n     ucx                       1.13.1               h538f049_1    conda-forge\\r\\n     ucx-proc                  1.0.0                       gpu    rapidsai\\r\\n     ucx-py                    0.30.00a230131  py38_ga21f62a_17    rapidsai-nightly\\r\\n     ukkonen                   1.0.1            py38h43d8883_3    conda-forge\\r\\n     umap-learn                0.5.3            py38h578d9bd_0    conda-forge\\r\\n     unicodedata2              15.0.0           py38h0a891b7_0    conda-forge\\r\\n     urllib3                   1.26.14            pyhd8ed1ab_0    conda-forge\\r\\n     virtualenv                20.17.1          py38h578d9bd_0    conda-forge\\r\\n     wcwidth                   0.2.6              pyhd8ed1ab_0    conda-forge\\r\\n     webencodings              0.5.1                      py_1    conda-forge\\r\\n     websocket-client          1.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     werkzeug                  2.1.2              pyhd8ed1ab_1    conda-forge\\r\\n     wheel                     0.38.4             pyhd8ed1ab_0    conda-forge\\r\\n     wrapt                     1.14.1           py38h0a891b7_1    conda-forge\\r\\n     xerces-c                  3.2.4                h55805fa_1    conda-forge\\r\\n     xmltodict                 0.13.0             pyhd8ed1ab_0    conda-forge\\r\\n     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge\\r\\n     xorg-libice               1.0.10               h7f98852_0    conda-forge\\r\\n     xorg-libsm                1.2.3             hd9c2040_1000    conda-forge\\r\\n     xorg-libx11               1.7.2                h7f98852_0    conda-forge\\r\\n     xorg-libxau               1.0.9                h7f98852_0    conda-forge\\r\\n     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\\r\\n     xorg-libxext              1.3.4                h7f98852_1    conda-forge\\r\\n     xorg-libxrender           0.9.10            h7f98852_1003    conda-forge\\r\\n     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge\\r\\n     xorg-xextproto            7.3.0             h7f98852_1002    conda-forge\\r\\n     xorg-xproto               7.0.31            h7f98852_1007    conda-forge\\r\\n     xxhash                    0.8.1                h0b41bf4_0    conda-forge\\r\\n     xyzservices               2022.9.0           pyhd8ed1ab_0    conda-forge\\r\\n     xz                        5.2.6                h166bdaf_0    conda-forge\\r\\n     yaml                      0.2.5                h7f98852_2    conda-forge\\r\\n     yarl                      1.8.2            py38h0a891b7_0    conda-forge\\r\\n     zeromq                    4.3.4                h9c3ff4c_1    conda-forge\\r\\n     zict                      2.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     zipp                      3.12.0             pyhd8ed1ab_0    conda-forge\\r\\n     zlib                      1.2.13               h166bdaf_4    conda-forge\\r\\n     zstd                      1.5.2                h3eb15da_6    conda-forge\\r\\n\\r\\n</pre></details>\\ncreatedAt: 2023-02-01T16:02:50Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 205}),\n",
       " Document(page_content=': 491\\ntitle: [BUG] `IndexedFrame._split` is inconsistent for empty dataframes\\nbody: This came up while reviewing #12704.\\r\\n\\r\\nQuoth the documentation:\\r\\n\\r\\n> Split a frame with split points in ``splits``. Returns a list of Frames of length `len(splits) + 1`.\\r\\n\\r\\nWhich is true, except if the input dataframe is empty:\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\ndf = cudf.DataFrame({\"a\": []})\\r\\nprint(df._split([0])) # => []\\r\\n```\\r\\n\\r\\nThis makes writing generic code difficult, since we\\'re expecting to get back a list of N+1 things to iterate over, but in this case we don\\'t.\\r\\n\\r\\nSlicing empty dataframes works fine (and reproduces semantically what you \"expect\" from slicing empty python lists):\\r\\n\\r\\n```python\\r\\ndf[:0], df[0:] # => (Empty DataFrame, Empty DataFrame)\\r\\n```\\r\\n\\r\\n(Arguably slicing with an out of bounds index should raise an `IndexError`, but that ship has sailed.)\\r\\n\\r\\nWhat I would like:\\r\\n\\r\\n```python\\r\\nsplits = [...]\\r\\n\\r\\nassert df._split(splits) == [df[s:e] for s, e in zip([None] + splits, splits + [None])]\\r\\n```\\ncreatedAt: 2023-02-07T10:42:25Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 206}),\n",
       " Document(page_content=': 492\\ntitle: [FEA] cudf.Series.agg support\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n`cudf.Series.agg` matching https://pandas.pydata.org/docs/reference/api/pandas.Series.agg.html\\r\\n\\r\\n```\\r\\n>>> import cudf, pandas\\r\\n>>> cudf.__version__\\r\\n\\'23.02.00a+310.g58e0fde346\\'\\r\\n>>> pandas.__version__\\r\\n\\'1.5.3\\'\\r\\n>>> cudf.Series([1, 1, 42, 1984]).agg(\\'mean\\')\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\nAttributeError: \\'Series\\' object has no attribute \\'agg\\'\\r\\n>>> pandas.Series([1, 1, 42, 1984]).agg(\\'mean\\')\\r\\n507.0\\r\\n```\\ncreatedAt: 2023-02-07T13:02:41Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 207}),\n",
       " Document(page_content=\": 493\\ntitle: [FEA] cudf.Series.add support for NaN\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n```\\r\\n>>> import cudf, pandas\\r\\n>>> cudf.__version__\\r\\n'23.02.00a+310.g58e0fde346'\\r\\n>>> pandas.__version__\\r\\n'1.5.3'\\r\\n>>> import numpy as np\\r\\n>>> cudf.Series([1,1, np.NaN, 9]).add([0, 1, 1, np.NaN])\\r\\nNotImplemented\\r\\n>>> pandas.Series([1,1, np.NaN, 9]).add([0, 1, 1, np.NaN])\\r\\n0    1.0\\r\\n1    2.0\\r\\n2    NaN\\r\\n3    NaN\\r\\ndtype: float64\\r\\n```\\ncreatedAt: 2023-02-07T13:05:33Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 208}),\n",
       " Document(page_content=': 494\\ntitle: [BUG] NA handling inconsistent in DataFrame/Series.replace\\nbody: **Describe the bug**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\n>>> import cudf, pandas, numpy\\r\\n>>> cudf.__version__\\r\\n\\'23.02.00a+310.g58e0fde346\\'\\r\\n>>> pandas.__version__\\r\\n\\'1.5.3\\'\\r\\n\\r\\n>>> cudf.Series([1, 2, numpy.nan]).replace(numpy.nan, -1)\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.8/contextlib.py\", line 75, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/series.py\", line 2180, in replace\\r\\n    return super().replace(to_replace, value, *args, **kwargs)\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.8/contextlib.py\", line 75, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/indexed_frame.py\", line 765, in replace\\r\\n    copy_data[name] = col.find_and_replace(\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column/numerical.py\", line 483, in find_and_replace\\r\\n    to_replace_col = _normalize_find_and_replace_input(\\r\\n  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column/numerical.py\", line 771, in _normalize_find_and_replace_input\\r\\n    col_to_normalize_casted = input_column_dtype.type(\\r\\nValueError: cannot convert float NaN to integer\\r\\n>>> pandas.Series([1, 2, numpy.nan]).replace(numpy.nan, -1)\\r\\n0    1.0\\r\\n1    2.0\\r\\n2   -1.0\\r\\ndtype: float64\\r\\n```\\ncreatedAt: 2023-02-07T13:40:55Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 209}),\n",
       " Document(page_content=': 496\\ntitle: [FEA] Update IO benchmarks for consistency between formats\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n- [x] #12678\\r\\n- [x] #12675 \\r\\n- [x] add device buffer data source to CSV reader benchmark ([code pointer](https://github.com/rapidsai/cudf/blob/c20c8b42215e38bee207b49dad6e28ea04ccbd8c/cpp/benchmarks/io/csv/csv_reader_input.cpp#L102))\\r\\n- [x] migrate CSV writer to nvbench. Currently using gbench.\\r\\n- [x] add JSON writer benchmark. This benchmark could be modeled after CSV writer.\\r\\n- [x] add JSON reader benchmark with file data source ([NESTED_JSON](https://github.com/rapidsai/cudf/blob/branch-23.04/cpp/benchmarks/io/json/nested_json.cpp) only does parsing and only on device buffers). This benchmark could be modeled after `BM_csv_read_io`\\r\\n- [x] ~#12700~\\r\\n- [x] ~#12674 -> add compression to `BM_csv_read_io` (?)~\\r\\n- [x] add benchmark coverage for parquet chunked reader. Perhaps modeled after [parquet_read_io_compression](https://github.com/rapidsai/cudf/blob/c20c8b42215e38bee207b49dad6e28ea04ccbd8c/cpp/benchmarks/io/parquet/parquet_reader_input.cpp#L143)\\r\\n- [x] for reader benchmarks, verify that the roundtripped table matches the starting table\\r\\n- [x] convert `compression` and `io` to string axis type. [see this discussion in nvbench](https://github.com/NVIDIA/nvbench/issues/137). the goal is to choose other values from the CLI without having to run all values in automation.\\r\\n- [ ] rename `pmu`, `efs`, `trc` in ORC writer chunks to `peak_memory_usage`, `encoded_file_size`, `total_rows`, to conform with the other ORC, PQ, CSV, text benchmarks\\r\\n\\r\\n**Additional context**\\r\\nThe initial set of topics came from a comparison of file read throughput across the supported formats in cuIO.\\r\\n<img width=\"518\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12725111/217667722-a5024218-61fb-410d-941d-9f9eed4f4c5a.png\">\\r\\nWe are also preparing for a comparison of memory footprint across cuIO, especially with Zstd compression/decompression.\\ncreatedAt: 2023-02-08T22:43:38Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 210}),\n",
       " Document(page_content=': 497\\ntitle: [ENH]: cudf options that map onto pandas ones should have identical names\\nbody: A followup to #12619; to enable copy-on-write in pandas one says `set_option(\"mode.copy_on_write\", True)`, whereas to enable in cudf one must say `set_option(\"copy_on_write\", True)`.\\r\\n\\r\\nThere might be other cases, but where cudf exposes the same configuration options as pandas, the names should match as a principle of least surprise.\\ncreatedAt: 2023-02-13T13:00:48Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 211}),\n",
       " Document(page_content=': 500\\ntitle: [BUG] cudf.cut fails on example from documentation\\nbody: **Describe the bug**\\r\\nlast example in https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.cut.html\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nIn [1]: import cudf\\r\\n\\r\\nIn [2]: cudf.__version__\\r\\nOut[2]: \\'23.02.00\\'\\r\\n\\r\\nIn [3]: import numpy as np\\r\\n\\r\\nIn [4]: s = cudf.Series(np.array([2, 4, 6, 8, 10]), index=[\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\'])\\r\\n   ...: cudf.cut(s, 3)\\r\\nOut[4]: ---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj)\\r\\n    700                 type_pprinters=self.type_printers,\\r\\n    701                 deferred_pprinters=self.deferred_printers)\\r\\n--> 702             printer.pretty(obj)\\r\\n    703             printer.flush()\\r\\n    704             return stream.getvalue()\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj)\\r\\n    392                         if cls is not object \\\\\\r\\n    393                                 and callable(cls.__dict__.get(\\'__repr__\\')):\\r\\n--> 394                             return _repr_pprint(obj, self, cycle)\\r\\n    395 \\r\\n    396             return _default_pprint(obj, self, cycle)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle)\\r\\n    698     \"\"\"A pprint that just redirects to the normal repr function.\"\"\"\\r\\n    699     # Find newlines and replace them with p.break_()\\r\\n--> 700     output = repr(obj)\\r\\n    701     lines = output.splitlines()\\r\\n    702     with p.group():\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/series.py in __repr__(self)\\r\\n   1323                 )\\r\\n   1324             else:\\r\\n-> 1325                 pd_series = preprocess.to_pandas()\\r\\n   1326             output = pd_series.to_string(\\r\\n   1327                 name=self.name,\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     73         def inner(*args, **kwds):\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n     77 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/series.py in to_pandas(self, index, nullable, **kwargs)\\r\\n   1900         if index is True:\\r\\n   1901             index = self.index.to_pandas()\\r\\n-> 1902         s = self._column.to_pandas(index=index, nullable=nullable)\\r\\n   1903         s.name = self.name\\r\\n   1904         return s\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column/categorical.py in to_pandas(self, index, **kwargs)\\r\\n    913         else:\\r\\n    914             categories = col.categories.dropna(drop_nan=True).to_pandas()\\r\\n--> 915         data = pd.Categorical.from_codes(\\r\\n    916             codes, categories=categories, ordered=col.ordered\\r\\n    917         )\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype)\\r\\n    685         Categories (2, object): [\\'a\\' < \\'b\\']\\r\\n    686         \"\"\"\\r\\n--> 687         dtype = CategoricalDtype._from_values_or_dtype(\\r\\n    688             categories=categories, ordered=ordered, dtype=dtype\\r\\n    689         )\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype)\\r\\n    297             # Note: This could potentially have categories=None and\\r\\n    298             # ordered=None.\\r\\n--> 299             dtype = CategoricalDtype(categories, ordered)\\r\\n    300 \\r\\n    301         return cast(CategoricalDtype, dtype)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered)\\r\\n    184 \\r\\n    185     def __init__(self, categories=None, ordered: Ordered = False) -> None:\\r\\n--> 186         self._finalize(categories, ordered, fastpath=False)\\r\\n    187 \\r\\n    188     @classmethod\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath)\\r\\n    338 \\r\\n    339         if categories is not None:\\r\\n--> 340             categories = self.validate_categories(categories, fastpath=fastpath)\\r\\n    341 \\r\\n    342         self._categories = categories\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath)\\r\\n    534                 raise ValueError(\"Categorical categories cannot be null\")\\r\\n    535 \\r\\n--> 536             if not categories.is_unique:\\r\\n    537                 raise ValueError(\"Categorical categories must be unique\")\\r\\n    538 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__()\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/core/indexes/base.py in is_unique(self)\\r\\n   2384         Return if the index has unique values.\\r\\n   2385         \"\"\"\\r\\n-> 2386         return self._engine.is_unique\\r\\n   2387 \\r\\n   2388     @final\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.is_unique.__get__()\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine._do_unique_check()\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine._ensure_mapping_populated()\\r\\n\\r\\npandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.map_locations()\\r\\n\\r\\nTypeError: unhashable type: \\'dict\\'\\r\\n```\\ncreatedAt: 2023-02-16T15:38:22Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 212}),\n",
       " Document(page_content=': 501\\ntitle: [BUG] cudf.cut does not accept sequence of scalars\\nbody: **Describe the bug**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'23.02.00\\'\\r\\n\\r\\nIn [3]: import numpy as np\\r\\n\\r\\nIn [4]: df = pd.DataFrame({\\'a\\': range(100)})\\r\\n\\r\\nIn [5]: pd.cut(df.a, bins=np.linspace(0, 100, num=6))\\r\\n---------------------------------------------------------------------------\\r\\nTypeError                                 Traceback (most recent call last)\\r\\n<ipython-input-5-1d55c0477181> in <module>\\r\\n----> 1 pd.cut(df.a, bins=np.linspace(0, 100, num=6))\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/cut.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)\\r\\n    168                 mn = min(x)\\r\\n    169                 mx = max(x)\\r\\n--> 170             bins = np.linspace(mn, mx, bins + 1, endpoint=True)\\r\\n    171             adj = (mx - mn) * 0.001\\r\\n    172             if right:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/numpy/core/overrides.py in linspace(*args, **kwargs)\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/numpy/core/function_base.py in linspace(start, stop, num, endpoint, retstep, dtype, axis)\\r\\n    118 \\r\\n    119     \"\"\"\\r\\n--> 120     num = operator.index(num)\\r\\n    121     if num < 0:\\r\\n    122         raise ValueError(\"Number of samples, %s, must be non-negative.\" % num)\\r\\n\\r\\nTypeError: only integer scalar arrays can be converted to a scalar index\\r\\n\\r\\nIn [6]: import pandas\\r\\n\\r\\nIn [7]: pandas.cut(df.to_pandas().a, bins=np.linspace(0, 100, num=6))\\r\\nOut[7]: \\r\\n0               NaN\\r\\n1       (0.0, 20.0]\\r\\n2       (0.0, 20.0]\\r\\n3       (0.0, 20.0]\\r\\n4       (0.0, 20.0]\\r\\n          ...      \\r\\n95    (80.0, 100.0]\\r\\n96    (80.0, 100.0]\\r\\n97    (80.0, 100.0]\\r\\n98    (80.0, 100.0]\\r\\n99    (80.0, 100.0]\\r\\nName: a, Length: 100, dtype: category\\r\\nCategories (5, interval[float64, right]): [(0.0, 20.0] < (20.0, 40.0] < (40.0, 60.0] <\\r\\n                                           (60.0, 80.0] < (80.0, 100.0]]\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nhttps://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.cut.html\\r\\n![image](https://user-images.githubusercontent.com/112653/219417718-173071c7-55c3-4bc0-9b4f-425bd0b0ee81.png)\\ncreatedAt: 2023-02-16T15:52:39Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 213}),\n",
       " Document(page_content=\": 502\\ntitle: [ENH]: Reworking of `iloc` and `loc` indexing\\nbody: ## Status quo\\n\\nIndexing of dataframes and series happens through six user-facing routes:\\n\\n- `DataFrame.__setitem__`/`DataFrame.__getitem__`\\n- `DataFrame.iloc.__setitem__`/`DataFrame.iloc.__getitem__`\\n- `DataFrame.loc.__setitem__`/`DataFrame.loc.__getitem__`\\n- `Series.__setitem__`/`Series.__getitem__`\\n- `Series.iloc.__setitem__`/`Series.iloc.__getitem__`\\n- `Series.loc.__setitem__`/`Series.loc.__getitem__`\\n\\nThese all have slightly different semantics (to match pandas behaviour), but there is still quite a lot of (possibly unnecessary) code duplication and a number of bugs around indexing. Many of these look to be because the business logic of handling slicing/gather-by-mask/indexing is intertwined with error handling and determining exactly what to slice. There's also logic effectively repeated between the loc and iloc versions in both cases.\\n\\nIt would be nice if the number of different paths into indexing was reduced, perhaps it is a pipe dream to share between Series and DataFrame (since a DataFrame is not just a collection of Series), but it feels like it should be possible to share more between iloc/loc/__setgetitem__.\\n\\nRelated issues:\\n\\n```[tasklist]\\n### `iloc` bugs\\n- [ ] #12748 \\n- [ ] #13013\\n- [ ] #13015\\n- [ ] #13265\\n- [ ] #13266 \\n- [ ] #13267\\n- [ ] #13515\\n- [ ] #13293\\n```\\n```[tasklist]\\n### Index bugs\\n- [ ] #12954\\n```\\n\\n```[tasklist]\\n### `loc` bugs\\n- [ ] #7448\\n- [ ] #8585\\n- [ ] #8693\\n- [ ] #11298\\n- [ ] #11944\\n- [ ] #12259\\n- [ ] #12286\\n- [ ] #12504\\n- [ ] #12505\\n- [ ] #12801\\n- [ ] #12833\\n- [ ] #13014\\n- [ ] #13015\\n- [ ] #13031\\n- [ ] #13268\\n- [ ] #13269\\n- [ ] #13270\\n- [ ] #13379\\n- [ ] https://github.com/rapidsai/cudf/issues/13653\\n- [ ] https://github.com/rapidsai/cudf/issues/13658\\n- [ ] https://github.com/rapidsai/cudf/issues/13652\\n```\\n```[tasklist]\\n### Views vs. copies\\n- [ ] #7374\\n- [ ] #11085\\n- [ ] #11990 \\n```\\n\\n```[tasklist]\\n### Other (mostly dtype-related)\\n- [ ] #2684\\n- [ ] #8184\\n- [ ] #11477\\n- [ ] #12039\\n- [ ] #13532\\n```\\n\\nYour issue here.\\n\\nAs we can see from this classification, `loc`-based indexing is definitely the harder nut to crack. The edge-cases that provoke most of the issues are cases where the values used in the indexing are _not_ in the index.\\ncreatedAt: 2023-02-16T16:49:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 214}),\n",
       " Document(page_content=': 503\\ntitle: [FEA] broadcast assignment through loc[]\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nworking with `import cudf as pd`\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\nIn [1]: import cudf as pd\\r\\n\\r\\nIn [2]: pd.__version__\\r\\nOut[2]: \\'23.02.00\\'\\r\\n\\r\\nIn [3]: df = pd.DataFrame({\\'a\\': range(10)})\\r\\n\\r\\nIn [4]: df.loc[df.a > 5, [\\'b\\']] = \\'ok\\'\\r\\n---------------------------------------------------------------------------\\r\\nKeyError                                  Traceback (most recent call last)\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in _setitem_tuple_arg(self, key, value)\\r\\n    318         try:\\r\\n--> 319             columns_df = self._frame._get_columns_by_label(key[1])\\r\\n    320         except KeyError:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in _get_columns_by_label(self, labels, downcast)\\r\\n   1902         \"\"\"\\r\\n-> 1903         new_data = super()._get_columns_by_label(labels, downcast)\\r\\n   1904         if downcast:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/frame.py in _get_columns_by_label(self, labels, downcast)\\r\\n    417         \"\"\"\\r\\n--> 418         return self._data.select_by_label(labels)\\r\\n    419 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column_accessor.py in select_by_label(self, key)\\r\\n    349         elif pd.api.types.is_list_like(key) and not isinstance(key, tuple):\\r\\n--> 350             return self._select_by_label_list_like(key)\\r\\n    351         else:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column_accessor.py in _select_by_label_list_like(self, key)\\r\\n    464     def _select_by_label_list_like(self, key: Any) -> ColumnAccessor:\\r\\n--> 465         data = {k: self._grouped_data[k] for k in key}\\r\\n    466         if self.multiindex:\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/column_accessor.py in <dictcomp>(.0)\\r\\n    464     def _select_by_label_list_like(self, key: Any) -> ColumnAccessor:\\r\\n--> 465         data = {k: self._grouped_data[k] for k in key}\\r\\n    466         if self.multiindex:\\r\\n\\r\\nKeyError: \\'b\\'\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nValueError                                Traceback (most recent call last)\\r\\n<ipython-input-4-18a695e97af4> in <module>\\r\\n----> 1 df.loc[df.a > 5, [\\'b\\']] = \\'ok\\'\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in __setitem__(self, key, value)\\r\\n    148         if not isinstance(key, tuple):\\r\\n    149             key = (key, slice(None))\\r\\n--> 150         return self._setitem_tuple_arg(key, value)\\r\\n    151 \\r\\n    152     @_cudf_nvtx_annotate\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/contextlib.py in inner(*args, **kwds)\\r\\n     73         def inner(*args, **kwds):\\r\\n     74             with self._recreate_cm():\\r\\n---> 75                 return func(*args, **kwds)\\r\\n     76         return inner\\r\\n     77 \\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/dataframe.py in _setitem_tuple_arg(self, key, value)\\r\\n    334             new_col = cudf.Series(value, index=idx)\\r\\n    335             if not self._frame.empty:\\r\\n--> 336                 new_col = new_col._align_to_index(\\r\\n    337                     self._frame.index, how=\"right\"\\r\\n    338                 )\\r\\n\\r\\n/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/core/indexed_frame.py in _align_to_index(self, index, how, sort, allow_non_unique)\\r\\n   2274         if not allow_non_unique:\\r\\n   2275             if not self.index.is_unique or not index.is_unique:\\r\\n-> 2276                 raise ValueError(\"Cannot align indices with non-unique values\")\\r\\n   2277 \\r\\n   2278         lhs = cudf.DataFrame._from_data(self._data, index=self.index)\\r\\n\\r\\nValueError: Cannot align indices with non-unique values\\r\\n\\r\\nIn [5]: pdf = df.to_pandas()\\r\\n\\r\\nIn [6]: pdf.loc[pdf.a > 5, [\\'b\\']] = \\'ok\\'\\r\\n\\r\\nIn [7]: pdf\\r\\nOut[7]: \\r\\n   a    b\\r\\n0  0  NaN\\r\\n1  1  NaN\\r\\n2  2  NaN\\r\\n3  3  NaN\\r\\n4  4  NaN\\r\\n5  5  NaN\\r\\n6  6   ok\\r\\n7  7   ok\\r\\n8  8   ok\\r\\n9  9   ok\\r\\n```\\ncreatedAt: 2023-02-17T14:16:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matthew Farrellee\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 215}),\n",
       " Document(page_content=': 506\\ntitle: [DEP]: Remove `line_terminator` from `to_csv`\\nbody: Followup to #12896, remove the deprecated keyword argument.\\ncreatedAt: 2023-03-07T17:19:48Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 216}),\n",
       " Document(page_content=\": 508\\ntitle: dask_cudf.read_csv doesn't support StringIO\\nbody: `dask_cudf.read_csv()` is calling `cudf.read_csv()` internally.\\r\\nHowever, dask_cudf.read_csv() doesn't support StringIO input.\\r\\n\\r\\nDescription of api mislead (it seems copied over from cudf.read_csv())\\r\\n```\\r\\n    path : str, path object, or file-like object\\r\\n        Either a path to a file (a str, pathlib.Path, or\\r\\n        py._path.local.LocalPath), URL (including http, ftp, and S3 locations),\\r\\n        or any object with a read() method (such as builtin open() file\\r\\n        handler function or StringIO).\\r\\n```\\r\\nCurrently, StringIO input falls into https://github.com/rapidsai/cudf/blob/branch-23.04/python/dask_cudf/dask_cudf/io/csv.py#L99\\ncreatedAt: 2023-03-08T16:55:39Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 217}),\n",
       " Document(page_content=\": 510\\ntitle: [BUG] Slow performance with high cardinality category columns\\nbody: **Describe the bug**\\r\\nI'm not sure if it is a bug or just limitation of cuDF architecture.\\r\\nPlease correct me. \\r\\n \\r\\nI have DataFrames with lot of columns and some of columns are strings with type **category**.\\r\\nMy data sets have about 5_000_000 rows. And category columns have more than 500_000 unique values. \\r\\nWhat I'm wondering is that copy of categorical columns (CPU -> GPU) takes a lot time in comparison the same data  not categorized. \\r\\nMore strange is that **groupby** function on categorical columns is many times slower that on non categorical columns. (Same content)   \\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\ncreate 2 arrays with categorical data. There are 500_000 unique values\\r\\n```\\r\\ncat1 = [ 'col1_cat_' + str(i)  for i in range(1, 500_000)] \\r\\ncat2 = [ 'col2_cat_' + str(i)  for i in range(1, 500_000)]\\r\\n```\\r\\ninitialize Panda DataFrame with 5_000_000 rows\\r\\n```\\r\\nrng = np.random.default_rng()\\r\\ncol1 = np.random.choice(a=cat1,  size=5_000_000)  \\r\\ncol2 = np.random.choice(a=cat2,  size=5_000_000)  \\r\\n\\r\\ndf = pd.DataFrame( {  'col1': col1,  'col2': col2,  'col3': col1,  'col4': col2  })\\r\\n```\\r\\n\\r\\nsize of DataFrame is about 1.5 GB\\r\\n```\\r\\n>> df.memory_usage(deep=True) / 1024 / 1024\\r\\nIndex      0.000122\\r\\ncol1     342.262686\\r\\ncol2     342.264298\\r\\ncol3     342.262686\\r\\ncol4     342.264298\\r\\ndtype: float64\\r\\n```\\r\\nWe execute groupby on CPU.  \\r\\n```\\r\\n%%time\\r\\ndf.groupby(['col1']).count()\\r\\n```\\r\\n*CPU times: user 2.43 s, sys: 23.8 ms, total: 2.46 s\\r\\nWall time: 2.46 s*\\r\\n\\r\\nNow we convert string data to category type.\\r\\n```\\r\\ndf_cat = df[['col1', 'col2', 'col3', 'col4']].astype('category')\\r\\n>>df_cat.memory_usage(deep=True) / 1024 / 1024\\r\\nIndex     0.000122\\r\\ncol1     69.423543\\r\\ncol2     69.423198\\r\\ncol3     69.423543\\r\\ncol4     69.423198\\r\\ndtype: float64\\r\\n```\\r\\nDF size is about 300 MB\\r\\n```\\r\\n%%time\\r\\ndf_cat.groupby(['col1']).count()\\r\\n```\\r\\n*CPU times: user 50.5 ms, sys: 8.29 ms, total: 58.8 ms\\r\\nWall time: 57.7 ms*\\r\\n\\r\\nWith categorical data we are __40 times__ faster that with non categorical data. That is expected performance.\\r\\nNow we copy non categorized data to the GPU\\r\\n```\\r\\n%%time\\r\\ngdf = cudf.DataFrame.from_pandas(df)\\r\\n```\\r\\n*CPU times: user 511 ms, sys: 221 ms, total: 731 ms\\r\\nWall time: 730 ms*\\r\\nCopy of date takes about 700ms for 1.5GB\\r\\n\\r\\n```\\r\\n%%time\\r\\ngdf.groupby(['col1']).count()\\r\\n```\\r\\n*CPU times: user 30.6 ms, sys: 3.8 ms, total: 34.4 ms\\r\\nWall time: 33 ms*\\r\\n**groupby** is about 70 times faster that on CPU (2.46s). Very good performance. IMPORTANT data is **NOT CATEGORIZED**\\r\\n\\r\\nNow we copy categorized data to the GPU and execute **groupby**\\r\\n```\\r\\n%%time\\r\\ngdf_cat = cudf.DataFrame.from_pandas(df_cat)\\r\\n```\\r\\n*CPU times: user 711 ms, sys: 136 ms, total: 847 ms\\r\\nWall time: 846 ms*\\r\\n```\\r\\n%%time\\r\\ngdf_cat.groupby(['col1']).count()\\r\\n```\\r\\n*CPU times: user 134 ms, sys: 55.8 ms, total: 190 ms\\r\\nWall time: 189 ms*\\r\\n\\r\\nAmount of data is about 300MB. cuDf needs more time to copy the data to the GPU: 846ms (730ms by non categorized 1.5 GB raw strings)\\r\\nBut really strange behaviour is that **groupby**  on categorized data is more than 5 times slower than with raw string data!!!\\r\\n**Even groupby on CPU is faster that on GPU by categorical data 57ms --> 189ms!!!!!**\\r\\n\\r\\nWhy is performance of cuDF groupy with categorical data so poor?\\r\\n\\r\\n**Expected behavior**\\r\\n**groupby** function on GPU should work faster or at least equal than on CPU\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\nCPU RAM: 64 GB\\r\\nGPU RAM: 8GB\\r\\n\\r\\n**Environment details**\\r\\ntested on 3 different systems with 3 different NVIDIA cards\\r\\n\\r\\n**Additional context**\\r\\nIn attachments you can find my Jupiter Notebook with example. \\r\\n[category.ipynb.zip](https://github.com/rapidsai/cudf/files/10936367/category.ipynb.zip)\\ncreatedAt: 2023-03-09T21:53:26Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Slava\\ncompany: TriasDev\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 218}),\n",
       " Document(page_content=': 512\\ntitle: [BUG] Issues while loading TimeStamp columns\\nbody: ```\\r\\nIn [2]: import cudf\\r\\n\\r\\nIn [3]: cudf.read_orc(\\'tsrepro.orc\\')\\r\\n---------------------------------------------------------------------------\\r\\nRuntimeError                              Traceback (most recent call last)\\r\\nCell In[3], line 1\\r\\n----> 1 cudf.read_orc(\\'tsrepro.orc\\')\\r\\n\\r\\nFile /conda/envs/rapids-23.02/lib/python3.10/site-packages/cudf/io/orc.py:370, in read_orc(filepath_or_buffer, engine, columns, filters, stripes, skiprows, num_rows, use_index, timestamp_type, use_python_file_object, storage_options, bytes_per_thread)\\r\\n    366         stripes = selected_stripes\\r\\n    368 if engine == \"cudf\":\\r\\n    369     return DataFrame._from_data(\\r\\n--> 370         *liborc.read_orc(\\r\\n    371             filepaths_or_buffers,\\r\\n    372             columns,\\r\\n    373             stripes,\\r\\n    374             skiprows,\\r\\n    375             num_rows,\\r\\n    376             use_index,\\r\\n    377             timestamp_type,\\r\\n    378         )\\r\\n    379     )\\r\\n    380 else:\\r\\n    382     def read_orc_stripe(orc_file, stripe, columns):\\r\\n\\r\\nFile orc.pyx:84, in cudf._lib.orc.read_orc()\\r\\n\\r\\nFile orc.pyx:121, in cudf._lib.orc.read_orc()\\r\\n\\r\\nRuntimeError: CUDF failure at: /opt/conda/conda-bld/work/cpp/src/io/orc/timezone.cpp:138: Failed to open the timezone file.\\r\\n```\\r\\n\\r\\n[tsrepro.orc.zip](https://github.com/rapidsai/cudf/files/10946593/tsrepro.orc.zip)\\ncreatedAt: 2023-03-13T02:21:39Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lahir Marni\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 219}),\n",
       " Document(page_content=\": 517\\ntitle: [BUG] `is_list_like` does not match pandas equivalent for cupy arrays\\nbody: **Describe the bug**\\r\\n\\r\\n`is_list_like` does not match pandas equivalent for cupy array objects\\r\\n\\r\\nhttps://pandas.pydata.org/docs/reference/api/pandas.api.types.is_list_like.html\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\n```python\\r\\nimport pandas as pd\\r\\nimport numpy as np\\r\\nimport cudf\\r\\nimport cupy as cp\\r\\n\\r\\npd.api.types.is_list_like(np.array([1]))  # => True\\r\\npd.api.types.is_list_like(cp.array([1]))  # => True\\r\\n\\r\\ncudf.api.types.is_list_like(np.array([1]))  # => True\\r\\ncudf.api.types.is_list_like(cp.array([1]))  # => False\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nI'd expect `is_list_like` to return True matching the equivalent pandas function when called with a cupy or numpy array containing a list of values\\r\\n\\r\\n```python\\r\\ncudf.api.types.is_list_like(cp.array([1]))  # => True\\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: docker\\r\\n - Method of cuDF install: pip\\ncreatedAt: 2023-03-20T15:04:26Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Oliver Holworthy\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 220}),\n",
       " Document(page_content=': 518\\ntitle: [BUG] loc indexing with length-1 Categorical not possible\\nbody: **Describe the bug**\\r\\n```python\\r\\nimport cudf\\r\\nimport pandas as pd\\r\\nf = pd.Series([1, 2, 3], index=pd.CategoricalIndex([0, 1, 2]))\\r\\nf.loc[pd.Categorical([1])] # => second row.\\r\\ncf = cudf.from_pandas(f)\\r\\ncf.loc[pd.Categorical([1])] # => KeyErrror\\r\\n```\\r\\n\\r\\nI think this is similar to #13013 in that length-one categoricals are treated as scalars in some cases.\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nProbably this lookup should work.\\ncreatedAt: 2023-03-27T10:28:01Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 221}),\n",
       " Document(page_content=': 519\\ntitle: [FEA] Performance issue with the Parquet reader for very large schemas (especially when containing strings)\\nbody: For parquet files that contain very large schemas with strings (either large numbers of columns, or large numbers of nested columns) we pay a very heavy price postprocessing the string data after the core decode kernels runs.  \\r\\n\\r\\nEssentially, the \"decode\" process for strings is just emitting a large array of pointer/size pairs that are then passed to other cudf functions to reconstruct actual columns.    The problem is that we are doing this with no batching - each output string column results in an entire cudf function call (`make_strings_column`) with multiple internal kernel calls each.  In situations with thousands of columns, this gets very expensive.\\r\\n\\r\\n![image](https://user-images.githubusercontent.com/56695930/228312025-67ea3177-9d67-4e84-84e5-cb317c895001.png)\\r\\n\\r\\nIn the image above, the green span represents the time spent in the decode kernel and the time spent in all of the `make_strings_column` calls afterwards.  The time is totally dominated by the many many calls to `make_strings_column` (the red span).  \\r\\n\\r\\nIdeally, we would have some kind of batched interface to `make_strings_column`  (`make_strings_columns` ?) that can do the work for the thousands of output columns coalesced into fewer kernels.  \\r\\n\\r\\n\\r\\nOn a related note, the area under the blue line represents a similar problem involving preprocessing the file (thousands of calls to `thrust::reduce` and `thrust::exclusive_scan_by_key`).   This has been largely addressed by this PR  https://github.com/rapidsai/cudf/pull/12931\\ncreatedAt: 2023-03-28T17:01:42Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 222}),\n",
       " Document(page_content=\": 520\\ntitle: [BUG] loc-based setitem with dataframe/series as rvalue doesn't match pandas\\nbody: **Describe the bug**\\r\\n\\r\\nWhen performing `loc`-based setitem, pandas aligns the indices of the rvalue to match that of the lvalue. Consequently, the indexed lvalue and rvalue don't have to have the same shape (or even match indices).\\r\\n\\r\\n```python\\r\\nimport pandas as pd\\r\\ns = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\\r\\no1 = pd.Series([5, 6, 7], index=['a', 'b', 'c'])\\r\\no2 = pd.Series([10])\\r\\ns.loc[['a', 'c']] = o1\\r\\ns # => [5, 2, 7]\\r\\ns.loc[['a', 'b', 'c']] = o2\\r\\ns # => [Nan, Nan, Nan]\\r\\n```\\r\\n\\r\\nIn contrast, cudf complains in both cases.\\r\\n\\r\\nFor the former: `ValueError: Size mismatch: cannot set value of size 3 to indexing result of size 2`\\r\\n\\r\\nFor the latter: `align_to_index` fails (because the int index cannot be merged with the string index). If `o2` has a string index, it fails because the pruned aligned series is not the right length.\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nProbably this should behave as pandas. I think the case where the index types are different will probably need to be special-cased.\\ncreatedAt: 2023-03-29T14:38:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 223}),\n",
       " Document(page_content=': 522\\ntitle: Span tests have hard-coded values\\nbody: Vukasin pointed out in code review of 12981 that the span tests are using some hard-coded magic numbers. These should be addressed.\\r\\n\\r\\n_Originally posted by @vuule in https://github.com/rapidsai/cudf/pull/12981#discussion_r1149684948_\\ncreatedAt: 2023-03-29T17:37:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Mike Wilson\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 224}),\n",
       " Document(page_content=': 523\\ntitle: [QST] `dask_cudf.read_parquet` failed with \"NotImplementedError: large_string\"\\nbody: I am a new user of `dask`/`dask_cudf`.\\r\\nI have parquet files of various sizes (11GB, 2.5GB, 1.1GB), all of which failed with `NotImplementedError: large_string`. \\r\\n\\r\\nMy `dask.dataframe` backend is `cudf`. When the backend is `pandas`, `read.parquet` works fine.\\r\\n\\r\\nHere\\'s an exerpt of what my data looks like in `csv` format:\\r\\n\\r\\n    Symbol,Date,Open,High,Low,Close,Volume\\r\\n    AADR,17-Oct-2017 09:00,57.47,58.3844,57.3645,58.3844,2094\\r\\n    AADR,17-Oct-2017 10:00,57.27,57.2856,57.25,57.27,627\\r\\n    AADR,17-Oct-2017 11:00,56.99,56.99,56.99,56.99,100\\r\\n    AADR,17-Oct-2017 12:00,56.98,57.05,56.98,57.05,200\\r\\n    AADR,17-Oct-2017 13:00,57.14,57.16,57.14,57.16,700\\r\\n    AADR,17-Oct-2017 14:00,57.13,57.13,57.13,57.13,100\\r\\n    AADR,17-Oct-2017 15:00,57.07,57.07,57.07,57.07,200\\r\\n    AAMC,17-Oct-2017 09:00,87,87,87,87,100\\r\\n    AAU,17-Oct-2017 09:00,1.1,1.13,1.0832,1.121,67790\\r\\n    AAU,17-Oct-2017 10:00,1.12,1.12,1.12,1.12,100\\r\\n    AAU,17-Oct-2017 11:00,1.125,1.125,1.125,1.125,200\\r\\n    AAU,17-Oct-2017 12:00,1.1332,1.15,1.1332,1.15,27439\\r\\n    AAU,17-Oct-2017 13:00,1.15,1.15,1.13,1.13,8200\\r\\n    AAU,17-Oct-2017 14:00,1.1467,1.1467,1.14,1.1467,1750\\r\\n    AAU,17-Oct-2017 15:00,1.1401,1.1493,1.1401,1.1493,4100\\r\\n    AAU,17-Oct-2017 16:00,1.13,1.13,1.13,1.13,100\\r\\n    ABE,17-Oct-2017 09:00,14.64,14.64,14.64,14.64,200\\r\\n    ABE,17-Oct-2017 10:00,14.67,14.67,14.66,14.66,1200\\r\\n    ABE,17-Oct-2017 11:00,14.65,14.65,14.65,14.65,600\\r\\n    ABE,17-Oct-2017 15:00,14.65,14.65,14.65,14.65,836\\r\\n\\r\\n\\r\\nWhat I did was really simple:\\r\\n\\r\\n    import dask.dataframe as dd\\r\\n    import cudf\\r\\n    import dask_cudf\\r\\n    \\r\\n    # Failed with large_string error\\r\\n    dask_cudf.read_parquet(\\'path/to/my.parquet\\')\\r\\n    # Failed with large_string error\\r\\n    dd.read_parquet(\\'path/to/my.parquet\\')\\r\\n\\r\\nThe only large string I could think of is the timestamp string.\\r\\n\\r\\nIs there a way around this in `cudf` as it is not implemented yet? The format is `2023-03-12 09:00:00+00:00`.\\ncreatedAt: 2023-03-30T16:14:30Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: QiuxiaoMu\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 225}),\n",
       " Document(page_content=': 524\\ntitle: [QST] convert column of datetime string to column of datetime object\\nbody: I am a new user of Dask and RapidsAI.\\r\\nAn exerpt of my data (in `csv` format):\\r\\n\\r\\n    Symbol,Date,Open,High,Low,Close,Volume\\r\\n    AADR,17-Oct-2017 09:00,57.47,58.3844,57.3645,58.3844,2094\\r\\n    AADR,17-Oct-2017 10:00,57.27,57.2856,57.25,57.27,627\\r\\n    AADR,17-Oct-2017 11:00,56.99,56.99,56.99,56.99,100\\r\\n    AADR,17-Oct-2017 12:00,56.98,57.05,56.98,57.05,200\\r\\n    AADR,17-Oct-2017 13:00,57.14,57.16,57.14,57.16,700\\r\\n    AADR,17-Oct-2017 14:00,57.13,57.13,57.13,57.13,100\\r\\n    AADR,17-Oct-2017 15:00,57.07,57.07,57.07,57.07,200\\r\\n    AAMC,17-Oct-2017 09:00,87,87,87,87,100\\r\\n    AAU,17-Oct-2017 09:00,1.1,1.13,1.0832,1.121,67790\\r\\n    AAU,17-Oct-2017 10:00,1.12,1.12,1.12,1.12,100\\r\\n    AAU,17-Oct-2017 11:00,1.125,1.125,1.125,1.125,200\\r\\n    AAU,17-Oct-2017 12:00,1.1332,1.15,1.1332,1.15,27439\\r\\n    AAU,17-Oct-2017 13:00,1.15,1.15,1.13,1.13,8200\\r\\n    AAU,17-Oct-2017 14:00,1.1467,1.1467,1.14,1.1467,1750\\r\\n    AAU,17-Oct-2017 15:00,1.1401,1.1493,1.1401,1.1493,4100\\r\\n    AAU,17-Oct-2017 16:00,1.13,1.13,1.13,1.13,100\\r\\n    ABE,17-Oct-2017 09:00,14.64,14.64,14.64,14.64,200\\r\\n    ABE,17-Oct-2017 10:00,14.67,14.67,14.66,14.66,1200\\r\\n    ABE,17-Oct-2017 11:00,14.65,14.65,14.65,14.65,600\\r\\n    ABE,17-Oct-2017 15:00,14.65,14.65,14.65,14.65,836\\r\\n\\r\\nNote `Date` column is of type string.\\r\\n\\r\\nI have some example stock market timeseries data (i.e., DOHLCV) in csv files and I read them into a `dask_cudf` dataframe (my `dask.dataframe` backend is cudf and `read.csv` is a creation dispacther that conveniently gives me a `cudf.dataframe`). \\r\\n\\r\\n    import dask_cudf \\r\\n    import cudf\\r\\n    from dask import dataframe as dd\\r\\n    \\r\\n    ddf = dd.read_csv(\\'path/to/my/data/*.csv\\')\\r\\n    ddf\\r\\n    # output\\r\\n    <dask_cudf.DataFrame | 450 tasks | 450 npartitions>\\r\\n    \\r\\n    \\r\\n    # test csv data above can be retrieved using following statements\\r\\n    # df = pd.read_clipboard(sep=\",\")\\r\\n    # cdf = cudf.from_pandas(df)\\r\\n    # ddf = dask_cudf.from_cudf(cdf, npartitions=2)\\r\\n\\r\\nI then try to convert datetime string into real datetime object (`np.datetime64[ns]` or anything equivalent in `cudf`/`dask` world). I then failed with error.\\r\\n\\r\\n    df[\"Date\"] = dd.to_datetime(df[\"Date\"], format=\"%d-%b-%Y %H:%M\").head(5)\\r\\n    df.set_index(\"Date\", inplace=True) # This failed with different error, will raise in a different SO thread.\\r\\n    # Following statement gives me same error.\\r\\n    # cudf.to_datetime(df[\"Date\"], format=\"%d-%b-%Y %H:%M\")\\r\\n\\r\\nFull error log is to the end.\\r\\n\\r\\nThe error message seems to suggest that I\\'d need to `compute` the `dask_cudf.dataframe`, turning it into a real `cudf` object, then I\\r\\ncan do as I would in `pandas`:\\r\\n\\r\\n    df[\"Date\"] = cudf.to_datetime(df.Date)\\r\\n    df = df.set_index(df.Date)\\r\\n\\r\\nThis apparently isn\\'t ideal and it very much is the thing that `dask` is for: we\\'d delay this and only calculate the ultimate number we need.\\r\\n\\r\\nwhat is the `dask`/`dask_cudf` way to convert a string column to datetime column in `dask_cudf`? As far as I can see, if the backend is `pandas`, the conversion is done smoothly and rarely has problem. \\r\\n\\r\\nOr, is it that `cudf` or GPU world in general, is not supposed to do much with date types like `datetime`, `string` ? (e.g., ideally GPU is geared towards expensive numerical computations). \\r\\n\\r\\nMy use case involves some filtering to do with `string` and `datetime`, therefore I need to set up the `dataframe` with proper `datetime` object.\\r\\n\\r\\n#### Error Log\\r\\n\\r\\n    TypeError                                 Traceback (most recent call last)\\r\\n    Cell In[52], line 1\\r\\n    ----> 1 dd.to_datetime(df[\"Date\"], format=\"%d-%b-%Y %H:%M\").head(2)\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/dataframe/core.py:1268, in _Frame.head(self, n, npartitions, compute)\\r\\n       1266 # No need to warn if we\\'re already looking at all partitions\\r\\n       1267 safe = npartitions != self.npartitions\\r\\n    -> 1268 return self._head(n=n, npartitions=npartitions, compute=compute, safe=safe)\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/dataframe/core.py:1302, in _Frame._head(self, n, npartitions, compute, safe)\\r\\n       1297 result = new_dd_object(\\r\\n       1298     graph, name, self._meta, [self.divisions[0], self.divisions[npartitions]]\\r\\n       1299 )\\r\\n       1301 if compute:\\r\\n    -> 1302     result = result.compute()\\r\\n       1303 return result\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/base.py:314, in DaskMethodsMixin.compute(self, **kwargs)\\r\\n        290 def compute(self, **kwargs):\\r\\n        291     \"\"\"Compute this dask collection\\r\\n        292 \\r\\n        293     This turns a lazy Dask collection into its in-memory equivalent.\\r\\n       (...)\\r\\n        312     dask.base.compute\\r\\n        313     \"\"\"\\r\\n    --> 314     (result,) = compute(self, traverse=False, **kwargs)\\r\\n        315     return result\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/base.py:599, in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\\r\\n        596     keys.append(x.__dask_keys__())\\r\\n        597     postcomputes.append(x.__dask_postcompute__())\\r\\n    --> 599 results = schedule(dsk, keys, **kwargs)\\r\\n        600 return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/threaded.py:89, in get(dsk, keys, cache, num_workers, pool, **kwargs)\\r\\n         86     elif isinstance(pool, multiprocessing.pool.Pool):\\r\\n         87         pool = MultiprocessingPoolExecutor(pool)\\r\\n    ---> 89 results = get_async(\\r\\n         90     pool.submit,\\r\\n         91     pool._max_workers,\\r\\n         92     dsk,\\r\\n         93     keys,\\r\\n         94     cache=cache,\\r\\n         95     get_id=_thread_get_id,\\r\\n         96     pack_exception=pack_exception,\\r\\n         97     **kwargs,\\r\\n         98 )\\r\\n        100 # Cleanup pools associated to dead threads\\r\\n        101 with pools_lock:\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/local.py:511, in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\\r\\n        509         _execute_task(task, data)  # Re-execute locally\\r\\n        510     else:\\r\\n    --> 511         raise_exception(exc, tb)\\r\\n        512 res, worker_id = loads(res_info)\\r\\n        513 state[\"cache\"][key] = res\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/local.py:319, in reraise(exc, tb)\\r\\n        317 if exc.__traceback__ is not tb:\\r\\n        318     raise exc.with_traceback(tb)\\r\\n    --> 319 raise exc\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/local.py:224, in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\\r\\n        222 try:\\r\\n        223     task, data = loads(task_info)\\r\\n    --> 224     result = _execute_task(task, data)\\r\\n        225     id = get_id()\\r\\n        226     result = dumps((result, id))\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/core.py:119, in _execute_task(arg, cache, dsk)\\r\\n        115     func, args = arg[0], arg[1:]\\r\\n        116     # Note: Don\\'t assign the subtask results to a variable. numpy detects\\r\\n        117     # temporaries by their reference count and can execute certain\\r\\n        118     # operations in-place.\\r\\n    --> 119     return func(*(_execute_task(a, cache) for a in args))\\r\\n        120 elif not ishashable(arg):\\r\\n        121     return arg\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/optimization.py:990, in SubgraphCallable.__call__(self, *args)\\r\\n        988 if not len(args) == len(self.inkeys):\\r\\n        989     raise ValueError(\"Expected %d args, got %d\" % (len(self.inkeys), len(args)))\\r\\n    --> 990 return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/core.py:149, in get(dsk, out, cache)\\r\\n        147 for key in toposort(dsk):\\r\\n        148     task = dsk[key]\\r\\n    --> 149     result = _execute_task(task, cache)\\r\\n        150     cache[key] = result\\r\\n        151 result = _execute_task(out, cache)\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/core.py:119, in _execute_task(arg, cache, dsk)\\r\\n        115     func, args = arg[0], arg[1:]\\r\\n        116     # Note: Don\\'t assign the subtask results to a variable. numpy detects\\r\\n        117     # temporaries by their reference count and can execute certain\\r\\n        118     # operations in-place.\\r\\n    --> 119     return func(*(_execute_task(a, cache) for a in args))\\r\\n        120 elif not ishashable(arg):\\r\\n        121     return arg\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/utils.py:72, in apply(func, args, kwargs)\\r\\n         41 \"\"\"Apply a function given its positional and keyword arguments.\\r\\n         42 \\r\\n         43 Equivalent to ``func(*args, **kwargs)``\\r\\n       (...)\\r\\n         69 >>> dsk = {\\'task-name\\': task}  # adds the task to a low level Dask task graph\\r\\n         70 \"\"\"\\r\\n         71 if kwargs:\\r\\n    ---> 72     return func(*args, **kwargs)\\r\\n         73 else:\\r\\n         74     return func(*args)\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/dataframe/core.py:6821, in apply_and_enforce(*args, **kwargs)\\r\\n       6819 func = kwargs.pop(\"_func\")\\r\\n       6820 meta = kwargs.pop(\"_meta\")\\r\\n    -> 6821 df = func(*args, **kwargs)\\r\\n       6822 if is_dataframe_like(df) or is_series_like(df) or is_index_like(df):\\r\\n       6823     if not len(df):\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1100, in to_datetime(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\\r\\n       1098         result = _convert_and_box_cache(argc, cache_array)\\r\\n       1099     else:\\r\\n    -> 1100         result = convert_listlike(argc, format)\\r\\n       1101 else:\\r\\n       1102     result = convert_listlike(np.array([arg]), format)[0]\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:413, in _convert_listlike_datetimes(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\\r\\n        410         return idx\\r\\n        411     raise\\r\\n    --> 413 arg = ensure_object(arg)\\r\\n        414 require_iso8601 = False\\r\\n        416 if infer_datetime_format and format is None:\\r\\n    \\r\\n    File pandas/_libs/algos_common_helper.pxi:33, in pandas._libs.algos.ensure_object()\\r\\n    \\r\\n    File ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/cudf/core/frame.py:451, in Frame.__array__(self, dtype)\\r\\n        450 def __array__(self, dtype=None):\\r\\n    --> 451     raise TypeError(\\r\\n        452         \"Implicit conversion to a host NumPy array via __array__ is not \"\\r\\n        453         \"allowed, To explicitly construct a GPU matrix, consider using \"\\r\\n        454         \".to_cupy()\\\\nTo explicitly construct a host matrix, consider \"\\r\\n        455         \"using .to_numpy().\"\\r\\n        456     )\\r\\n    \\r\\n    TypeError: Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()\\r\\n    To explicitly construct a host matrix, consider using .to_numpy().\\ncreatedAt: 2023-03-30T16:25:12Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: QiuxiaoMu\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 226}),\n",
       " Document(page_content=\": 526\\ntitle: [FEA] Story - Improve performance with long strings\\nbody: Many [strings APIs in libcudf](https://docs.rapids.ai/api/libcudf/stable/group__strings__apis.html) use thread-per-string parallelism in their implementation. This approach works great for processing smaller strings of relatively consistent length. However, for long strings (roughly 256 bytes and above) the performance of thread-per-string algorithms begins to degrade. Some strings APIs are compatible with data-parallel algorithms and can be refactored to improve performance for long strings, while other strings APIs are difficult to refactor with data-parallel algorithms. \\r\\n\\r\\nLet's use this issue to track the progression: \\r\\n✅ - this API works well with long strings\\r\\n🟢 - we think this API will be straightforward to refactor\\r\\n🟡 - we have some ideas on how to refactor this API, and we'll need to experiment\\r\\n🔴 - we think this will be very difficult to refactor!\\r\\n⚪ - long string support is not a priority for this API\\r\\n\\r\\n|Module|Function|Status|Notes|\\r\\n|---|---|---|---|\\r\\n| [Case](https://docs.rapids.ai/api/libcudf/nightly/group__strings__case.html) | capitalize <br> title <br> is_title <br> to_lower <br> to_upper <br> swapcase | 🟡 <br> 🟡 <br> 🟡 <br> ✅#13142 <br> ✅#13142 <br>✅#13142  | |\\r\\n| [Character Types](https://docs.rapids.ai/api/libcudf/nightly/group__strings__types.html) | all_characters_of_type <br> filter_characters_of_type | ✅#13259 <br> 🔴 | |\\r\\n| [Combining](https://docs.rapids.ai/api/libcudf/nightly/group__strings__combine.html) | join_strings <br> concatenate <br> join_list_elements | ✅#13283 <br> 🟡 <br> 🔴 | |\\r\\n| [Searching](https://docs.rapids.ai/api/libcudf/nightly/group__strings__contains.html) | contains_re <br> matches_re <br> count_re <br> like <br> find_all | 🟡 <br> ⚪ <br> 🔴 <br> 🟢#13594 <br> 🔴 |  |\\r\\n| [Converting](https://docs.rapids.ai/api/libcudf/nightly/group__strings__convert.html) | to_XXXX <br> from_XXXX  | ⚪ <br> ⚪ | these are rarely long strings|\\r\\n| [Copying](https://docs.rapids.ai/api/libcudf/nightly/group__strings__copy.html) | repeat_string <br> repeat_strings | ✅ <br> ✅ | One [overload](https://docs.rapids.ai/api/libcudf/nightly/group__strings__copy.html#ga160c075327cb4fb081db19884dba294c) is an exception  |\\r\\n| [Slicing](https://docs.rapids.ai/api/libcudf/nightly/group__strings__slice.html) | slice_strings | ✅#13057 | One [overload](https://docs.rapids.ai/api/libcudf/nightly/group__strings__slice.html#ga2bc738cebebcf6d1331d6e9d13d4cd28) allows for skipping characters. <br>Long string support is not a priority for <br> `step > 1 or step < 0` |\\r\\n| [Finding](https://docs.rapids.ai/api/libcudf/nightly/group__strings__find.html) | find <br> rfind <br> contains <br> starts_with <br> ends_with <br> find_multiple | ✅#13226 <br> ✅#13226 <br> ✅#10739 <br> ⚪ <br> ⚪ <br> 🟢  | |\\r\\n| [Modifying](https://docs.rapids.ai/api/libcudf/nightly/group__strings__modify.html) | pad <br> zfill <br> reverse <br> strip <br> translate <br> filter_characters <br> wrap | 🟡 <br> ⚪ <br> 🟡 <br> ✅ <br> 🟡 <br> 🔴 <br> 🔴 |  |\\r\\n| [Replacing](https://docs.rapids.ai/api/libcudf/nightly/group__strings__replace.html) | replace  <br> replace_slice <br> replace_re  <br> replace_with_backrefs | ✅#12858 <br> 🟡 <br> 🔴 <br> 🔴 | |\\r\\n| [Splitting](https://docs.rapids.ai/api/libcudf/nightly/group__strings__split.html) | partition <br> split <br> split_record <br> split_re <br> split_record_re | 🟡 <br> ✅#4922 #13680 <br> ✅#12729 <br> 🔴 <br> 🔴 | |\\r\\n| other | count_characters  <br> count_bytes| ✅#12779 <br> 🟢 | | \\r\\n\\r\\nLibcudf also includes [NVText](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__apis.html) APIs that will benefit from improvements in performance when processing long strings. Generally long string performance is even more important for our text APIs, where each row could represent a sentence, paragraph or document.\\r\\n\\r\\n|Module|Function|Status|Notes|\\r\\n|---|---|---|---|\\r\\n| [NGrams](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__ngrams.html) | generate_ngrams <br> generate_character_ngrams <br> ngrams_tokenize|  ⚪  <br> 🟢 <br> 🟢#13480 | these are generally not long strings |\\r\\n| [Normalizing](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__normalize.html) | normalize_characters <br> normalize_spaces  |  🟢 <br> 🟢#13480  |  |\\r\\n| [Stemming](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__stemmer.html) | is_letter <br> porter_stemmer_measure  |   🟢 <br>🟢  | |\\r\\n| [Edit Distance](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__edit__distance.html) | edit_distance <br> edit_distance_matrix | ⚪ <br> ⚪  | these are generally not long strings |\\r\\n| [Tokenizing](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__tokenize.html) | byte_pair_encoding <br> subword_tokenize <br> tokenize <br> count_tokens <br> character_tokenize <br> detokenize  | 🟡 <br>🟡 <br>🟢#13480 <br>🟢#13480 <br>🟡 <br>🟡  |  |\\r\\n| [Replacing](https://docs.rapids.ai/api/libcudf/stable/group__nvtext__replace.html) | replace_tokens <br> filter_tokens | 🟢#13480 <br>🟢#13480 |  |\\r\\n| [MinHashing](https://docs.rapids.ai/api/libcudf/nightly/group__nvtext__minhash.html) | minhash  | ✅#13333 |  |\\ncreatedAt: 2023-04-03T17:58:26Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 227}),\n",
       " Document(page_content=\": 530\\ntitle: [FEA] Async mode for cudf.series operations\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nWe get wide dataframes in situations like machine learning (easily 1-5K cols) and genomics (10K+ cols), and while there is some speedup from cudf (say 2-3X), it'd be easy to get to the 10X+ level with much higher GPU utilization if we could spawn concurrent tasks for each column . Getting this all the way to the df level seems tricky, but async primitives at the column level would get us far. \\r\\n\\r\\nOne Python-native idea is doing via `async/await`, when one cudf operation is getting scheduled, allocated, & run, we can be scheduling the next, and ideally, cudf can run them independently . It smoothed out 2-3 years ago in python + javascript as a popular native choice, and has since been  a lot more popular in pydata, e.g., langchain just rewrote to support async versions of all methods. Ex: https://trends.google.com/trends/explore?date=all&q=async%20await&hl=en . Separately, there's heightened value for pydata dashboarding scenarios like plotly, streamlit, etc as these ecosystem increasingly build for async io underneath as well.\\r\\n\\r\\n(Another idea with precedent is a lazy mode similar to haskell or dask, discussed below as well)\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nI'd like to be do something like:\\r\\n\\r\\n```python\\r\\n\\r\\nasync def f(s: cudf.Series) -> cudf.Series:\\r\\n    # async mode for core series operations lets other f() calls proceed while this runs\\r\\n    s2 = await  s.stra.hex_to_int('AABBCC')\\r\\n   \\r\\n    # math can be clean and enable the same\\r\\n    # if we're super clever, this may even unlock query plan optimizations like fusion in the future\\r\\n    async with cudf.async.binop_mode:\\r\\n        s3_a = s2 + 1 / 3\\r\\n        s3 = await s3_a\\r\\n\\r\\n   return s3\\r\\n  \\r\\ncols2 = await async.gather([  f(df[col]) for col in df ])\\r\\n```\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\n1. Use existing abstractions\\r\\n\\r\\nIn theory we can setup threads or multiple dask workers, but (1) both are super awkward, (2) underneath, cudf will not do concurrent jobs\\r\\n\\r\\n2. Lazy cudf\\r\\n\\r\\nAnother thought is to create a lazy mode for cudf. This has precedent with Haskell, and in modern pydata land, more so with polars. Dask does this too, and we'd use it if that can work, but it's awkward -- I haven't used, but polars sounds to be more friendly in practice:\\r\\n\\r\\n```python\\r\\n\\r\\ndef f(s: cudf.Series) -> cudf.Series:\\r\\n    # explicitly lazy ops\\r\\n    s2 = s.str_lazy.hex_to_int('AABBCC')\\r\\n\\r\\n    # binops know they're lazy\\r\\n    s3 = s2 + 1 / 3\\r\\n\\r\\n    return s3\\r\\n\\r\\n# force with async friendliness  \\r\\ncols2 = await cudf_client.compute_async([  f(df[col]) for col in df ])\\r\\n```\\r\\n\\r\\nUnderneath, cudf can reinvent async/io, dask, or whatever\\r\\n\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nSlack thread: https://rapids-goai.slack.com/archives/C5E06F4DC/p1680710488795869\\ncreatedAt: 2023-04-07T17:09:44Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: Graphistry\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 228}),\n",
       " Document(page_content=': 534\\ntitle: [FEA] Add 64-bit size type option at build-time for libcudf\\nbody: Many libcudf users have expressed interest in using a 64-bit size type (see #3958 for reference). The `cudf::size_type` uses a `int32_t` data type that limits the number of elements in libcudf columns to `INT_MAX` (2.1 billion) elements. For string columns this imposes a ~2 GB limit, for int32 columns this imposes a ~8 GB limit, and for list columns this imposes a leaf element count <2.1 billion. Downstream libraries must partition their data to avoid these limits.\\r\\n\\r\\nWe expect that using a 64-bit size type will incur significant penalties to memory footprint and data throughput. Memory footprint will double for all offset vectors, and runtime of most functions will increase due to the larger data sizes. Kernel performance may degrade even further due to increased register count and unoptimized shared memory usage.\\r\\n\\r\\nAs GPUs increase in memory, the limit from a 32-bit `cudf::size_type` will force data partitions to become smaller fractions of device memory. Excessive data partitioning also leads to performance penalties, so libcudf should enable its community to start experimenting with a 64-bit size type. Scoping for 64-bit size types in the cuDF-python layer will be tracked in a separate issue (#TBD).\\r\\n\\r\\n- [ ] Consult with thrust/cub experts about outstanding issues with 64-bit indexing. Some libcudf functions may depend on upstream changes in CCCL, please see [cccl/47](https://github.com/NVIDIA/cccl/issues/47), [thrust/1271](https://github.com/NVIDIA/cccl/issues/744), and [cub/212](https://github.com/NVIDIA/cub/issues/212). `copy_if`, `reduce`, `parallel_for`, `merge` and `sort` may have unresolved issues.\\r\\n- [ ] Consult with thrust/cub experts about making 32-bit kernels optional. Currently the 64-bit kernels and disabled in libcudf builds. Disabling the 32-bit kernels would avoid large increases in compile time and binary size when we enable 64-bit thrust/cub kernels.\\r\\n- [ ] Verify compatibility of 64-bit size type with cuco data structures (needs additional scoping)\\r\\n- [ ] Audit custom kernels in libcudf for the impact of a 64-big size type. Introduce conditional logic to adjust shared memory allocations and threads per block as needed based on the size type. Identify implementation details that take a 32-bit size type for granted.\\r\\n- [ ] Audit cuIO size types and their interaction with `cudf::size_type`\\r\\n- [ ] Resolve compilation errors from using a 64-bit size type\\r\\n- [ ] Resolve test failures from using a 64-bit size type\\r\\n- [ ] Review performance impact of a 64-bit size type using libcudf microbenchmark results \\r\\n- [ ] Add a build-time option for advanced users to use a 64-bit size type instead of a 32-bit size type.\\r\\n- [ ] Add a CI step to build and test the 64-bit size type option.\\r\\n\\r\\nFrom this stage we will have a better sense of the impact and value of using a 64-bit size type with libcudf.\\ncreatedAt: 2023-04-17T23:18:55Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 229}),\n",
       " Document(page_content=': 536\\ntitle: [DOC] Document cuDF\\'s spilling option\\nbody: cuDF can optionally spill buffers to host memory when running short of device memory via `cudf.set_option(\"spill\", True)`. We should document this option, similar to how we document copy-on-write: https://docs.rapids.ai/api/cudf/nightly/user_guide/copy-on-write.html\\ncreatedAt: 2023-04-18T11:45:49Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 230}),\n",
       " Document(page_content=\": 538\\ntitle: [FEA] Support aggregations/scans on lists via groupby\\nbody: This is related to https://github.com/rapidsai/cudf/issues/10408.\\r\\n\\r\\nIt's possible to use a combination of `explode()` and `groupby()` to support common aggregations on `list` columns:\\r\\n\\r\\n```python\\r\\nIn [23]: df\\r\\nOut[23]:\\r\\n            a\\r\\n0   [1, 3, 2]\\r\\n1      [1, 4]\\r\\n2  [9, 0, -1]\\r\\n\\r\\nIn [24]: df.explode('a').groupby(level=0).max()\\r\\nOut[24]:\\r\\n   a\\r\\n0  3\\r\\n1  4\\r\\n2  9\\r\\n```\\r\\n\\r\\nScans can similarly be computed via an additional call to `groupby-collect()`:\\r\\n\\r\\n```python\\r\\nIn [33]: df.explode('a').groupby(level=0).cummax().groupby(level=0).collect()\\r\\nOut[33]:\\r\\n           a\\r\\n0  [1, 3, 3]\\r\\n1     [1, 4]\\r\\n2  [9, 9, 9]\\r\\n```\\r\\n\\r\\nWhen an aggregation/scan supported by groupby, like `.max()` or `.min()` is called on a list column, we could transparently use this combination of explode + groupby to support that operation. That could look something like:\\r\\n\\r\\n```python\\r\\n>>> df\\r\\n            a\\r\\n0   [1, 3, 2]\\r\\n1      [1, 4]\\r\\n2  [9, 0, -1]\\r\\n\\r\\n>>> df['a'].list.max()\\r\\n0    3\\r\\n1    4\\r\\n2    9\\r\\nName: a, dtype: int64\\r\\n\\r\\n>>> df['a'].list.cummax()\\r\\n0    [1, 3, 3]\\r\\n1       [1, 4]\\r\\n2    [9, 9, 9]\\r\\nName: a, dtype: list\\r\\n```\\ncreatedAt: 2023-04-24T19:29:51Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 231}),\n",
       " Document(page_content=': 539\\ntitle: [BUG] dask_cudf  - aggregate -  to_csv memory error\\nbody: **Describe the bug**\\r\\nA clear and concise description of what the bug is.\\r\\nI am loading a large dataframe (~60M x 300) by csv via dask_cudf,  then looking to do a groupby and sum, and resave this to csv. I get an OOM error - I am using an A100-80GB gpu along with 200GB of RAM. \\r\\n\\r\\nAll rows are numerical values, besides the groupby row left as the index. Thus, this error should be reproducible via a random dataframe. \\r\\nI noted a similar issue [@10426](https://github.com/rapidsai/cudf/issues/10426), however this error message is different, therefore I was unsure if this was the case.\\r\\nAdditionally, I do repeatedly get a high cpu garbage collection message, however I assume that is because of the size of the dataframe and many read/writes, correct me if that is not the case.\\r\\n**Steps/Code to reproduce bug**\\r\\nFollow this guide http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports to craft a minimal bug report. This helps us reproduce the issue you\\'re having and resolve the issue more quickly.\\r\\n\\r\\n```\\r\\nimport numpy as np\\r\\nimport pandas as pd\\r\\nimport cudf\\r\\nimport cupy\\r\\nfrom dask_cuda import LocalCUDACluster\\r\\nfrom dask.distributed import Client\\r\\nfrom dask.utils import parse_bytes\\r\\nimport dask_cudf\\r\\n\\r\\ncluster = LocalCUDACluster(jit_unspill=True,\\r\\n                           rmm_pool_size=parse_bytes(\"64 GB\"),\\r\\n                           n_workers = 1,\\r\\n                           device_memory_limit=parse_bytes(\"160 GB\"),\\r\\n                           local_directory=\\'local_temp\\',\\r\\n                           threads_per_worker=32)\\r\\nclient = Client(cluster)\\r\\n\\r\\n\\r\\ndf = dask_cudf.read_csv(\\'../02_all_study/02_tad_80_cluster_ref.tsv\\',sep = \\'\\\\t\\')\\r\\ndf2 = df.drop(\\'Contig\\',axis=1)\\r\\nres = df2.groupby(\\'ref90_cluster\\').sum()\\r\\nres.to_csv(\\'04_cluster_groups_csv\\')\\r\\n```\\r\\n\\r\\nOutput (I think the error message is repeating after nanny restarts, but I have included the entire error message for thoroughness (attached as file for size):\\r\\n[dask_to_csv_error.txt](https://github.com/rapidsai/cudf/files/11327385/dask_to_csv_error.txt)\\r\\n\\r\\n\\r\\n**Expected behavior**\\r\\nA clear and concise description of what you expected to happen.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: [Bare-metal, Docker, Cloud(specify cloud provider)] RHEL server\\r\\n - Method of cuDF install: [conda, Docker, or from source] conda (mamba)\\r\\n   - If method of install is [Docker], provide `docker pull` & `docker run` commands used\\r\\n\\r\\n**Environment details**\\r\\nPlease run and paste the output of the `cudf/print_env.sh` script here, to gather any other relevant environment details\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n\\r\\n     **git***\\r\\n     Not inside a git repository\\r\\n\\r\\n     ***OS Information***\\r\\n     NAME=\"Red Hat Enterprise Linux Server\"\\r\\n     VERSION=\"7.9 (Maipo)\"\\r\\n     ID=\"rhel\"\\r\\n     ID_LIKE=\"fedora\"\\r\\n     VARIANT=\"Server\"\\r\\n     VARIANT_ID=\"server\"\\r\\n     VERSION_ID=\"7.9\"\\r\\n     PRETTY_NAME=\"Red Hat Enterprise Linux Server 7.9 (Maipo)\"\\r\\n     ANSI_COLOR=\"0;31\"\\r\\n     CPE_NAME=\"cpe:/o:redhat:enterprise_linux:7.9:GA:server\"\\r\\n     HOME_URL=\"https://www.redhat.com/\"\\r\\n     BUG_REPORT_URL=\"https://bugzilla.redhat.com/\"\\r\\n\\r\\n     REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 7\"\\r\\n     REDHAT_BUGZILLA_PRODUCT_VERSION=7.9\\r\\n     REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\"\\r\\n     REDHAT_SUPPORT_PRODUCT_VERSION=\"7.9\"\\r\\n     Red Hat Enterprise Linux Server release 7.9 (Maipo)\\r\\n     Red Hat Enterprise Linux Server release 7.9 (Maipo)\\r\\n     Linux atl1-1-01-006-7-0.pace.gatech.edu 3.10.0-1160.49.1.el7.x86_64 #1 SMP Tue Nov 9 16:09:48 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\\r\\n\\r\\n     ***GPU Information***\\r\\n     Tue Apr 25 18:48:17 2023\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\\r\\n     |-------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                               |                      |               MIG M. |\\r\\n     |===============================+======================+======================|\\r\\n     |   0  NVIDIA A100 80G...  On   | 00000000:25:00.0 Off |                    0 |\\r\\n     | N/A   33C    P0    61W / 300W |  72218MiB / 81920MiB |      0%      Default |\\r\\n     |                               |                      |             Disabled |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | Processes:                                                                  |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n     |        ID   ID                                                   Usage      |\\r\\n     |=============================================================================|\\r\\n     |    0   N/A  N/A     26580      C   ...s/rapids-23.04/bin/python    10315MiB |\\r\\n     |    0   N/A  N/A     27149      C   ...s/rapids-23.04/bin/python    61901MiB |\\r\\n     +-----------------------------------------------------------------------------+\\r\\n\\r\\n     ***CPU***\\r\\n     Architecture:          x86_64\\r\\n     CPU op-mode(s):        32-bit, 64-bit\\r\\n     Byte Order:            Little Endian\\r\\n     CPU(s):                64\\r\\n     On-line CPU(s) list:   0-63\\r\\n     Thread(s) per core:    1\\r\\n     Core(s) per socket:    32\\r\\n     Socket(s):             2\\r\\n     NUMA node(s):          8\\r\\n     Vendor ID:             AuthenticAMD\\r\\n     CPU family:            25\\r\\n     Model:                 1\\r\\n     Model name:            AMD EPYC 7513 32-Core Processor\\r\\n     Stepping:              1\\r\\n     CPU MHz:               2600.000\\r\\n     CPU max MHz:           2600.0000\\r\\n     CPU min MHz:           1500.0000\\r\\n     BogoMIPS:              5200.16\\r\\n     Virtualization:        AMD-V\\r\\n     L1d cache:             32K\\r\\n     L1i cache:             32K\\r\\n     L2 cache:              512K\\r\\n     L3 cache:              32768K\\r\\n     NUMA node0 CPU(s):     0-7\\r\\n     NUMA node1 CPU(s):     8-15\\r\\n     NUMA node2 CPU(s):     16-23\\r\\n     NUMA node3 CPU(s):     24-31\\r\\n     NUMA node4 CPU(s):     32-39\\r\\n     NUMA node5 CPU(s):     40-47\\r\\n     NUMA node6 CPU(s):     48-55\\r\\n     NUMA node7 CPU(s):     56-63\\r\\n     Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc art rep_good nopl nonstop_tsc extd_apicid aperfmperf eagerfpu pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_l2 cpb cat_l3 cdp_l3 invpcid_single hw_pstate sme retpoline_amd ssbd ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif umip pku ospke vaes vpclmulqdq overflow_recov succor smca\\r\\n\\r\\n     ***CMake***\\r\\n     /bin/cmake\\r\\n     cmake version 2.8.12.2\\r\\n\\r\\n     ***g++***\\r\\n     /usr/lib64/ccache/g++\\r\\n     g++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\\r\\n     Copyright (C) 2015 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n\\r\\n\\r\\n     ***nvcc***\\r\\n     /usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2022 NVIDIA Corporation\\r\\n     Built on Tue_May__3_18:49:52_PDT_2022\\r\\n     Cuda compilation tools, release 11.7, V11.7.64\\r\\n     Build cuda_11.7.r11.7/compiler.31294372_0\\r\\n\\r\\n     ***Python***\\r\\n     /storage/home/hcoda1/6/rridley3/data/dir/anaconda3/envs/rapids-23.04/bin/python\\r\\n     Python 3.10.10\\r\\n\\r\\n     ***Environment Variables***\\r\\n     PATH                            : /usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/extras/qd/bin:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/comm_libs/mpi/bin:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/bin:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/cuda/bin:/usr/local/pace-apps/spack/packages/linux-rhel7-x86_64/gcc-4.8.5/cuda-11.7.0-7sdye3id7ahz34mzhyzzqbxowjxgxkhu/bin:/storage/home/hcoda1/6/rridley3/.cargo/bin:/storage/home/hcoda1/6/rridley3/data/dir/anaconda3/envs/rapids-23.04/bin:/storage/home/hcoda1/6/rridley3/data/dir/apps:/storage/home/hcoda1/6/rridley3/.aspera/connect/bin:/opt/pace-common/bin:/opt/slurm/current/bin:/opt/pace-system/bin:/usr/lpp/mmfs/bin:/usr/lib64/ccache:/sbin:/bin:/usr/sbin:/usr/bin:/opt/iozone/bin:/storage/home/hcoda1/6/rridley3/edirect\\r\\n     LD_LIBRARY_PATH                 : /usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/comm_libs/nvshmem/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/comm_libs/nccl/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/comm_libs/mpi/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/math_libs/lib64:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/compilers/extras/qd/lib:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/cuda/extras/CUPTI/lib64:/usr/local/pace-apps/manual/packages/nvhpc/Linux_x86_64/22.11/cuda/lib64:/usr/local/pace-apps/spack/packages/linux-rhel7-x86_64/gcc-4.8.5/cuda-11.7.0-7sdye3id7ahz34mzhyzzqbxowjxgxkhu/lib64:/opt/slurm/current/lib::\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /storage/home/hcoda1/6/rridley3/data/dir/anaconda3/envs/rapids-23.04\\r\\n     PYTHON_PATH                     :\\r\\n\\r\\n     conda not found\\r\\n     ***pip packages***\\r\\n     /storage/home/hcoda1/6/rridley3/data/dir/anaconda3/envs/rapids-23.04/bin/pip\\r\\n     Package                       Version\\r\\n     ----------------------------- -----------\\r\\n     aiofiles                      22.1.0\\r\\n     aiohttp                       3.8.4\\r\\n     aiosignal                     1.3.1\\r\\n     aiosqlite                     0.18.0\\r\\n     anyio                         3.6.2\\r\\n     aplus                         0.11.0\\r\\n     appdirs                       1.4.4\\r\\n     argon2-cffi                   21.3.0\\r\\n     argon2-cffi-bindings          21.2.0\\r\\n     arrow                         1.2.3\\r\\n     asciitree                     0.3.3\\r\\n     astropy                       5.2.2\\r\\n     asttokens                     2.2.1\\r\\n     async-timeout                 4.0.2\\r\\n     attrs                         22.2.0\\r\\n     Babel                         2.12.1\\r\\n     backcall                      0.2.0\\r\\n     backports.functools-lru-cache 1.6.4\\r\\n     beautifulsoup4                4.12.2\\r\\n     blake3                        0.2.1\\r\\n     bleach                        6.0.0\\r\\n     bokeh                         2.4.3\\r\\n     bqplot                        0.12.39\\r\\n     branca                        0.6.0\\r\\n     brotlipy                      0.7.0\\r\\n     cached-property               1.5.2\\r\\n     cachetools                    5.3.0\\r\\n     certifi                       2022.12.7\\r\\n     cffi                          1.15.1\\r\\n     charset-normalizer            2.1.1\\r\\n     click                         8.1.3\\r\\n     click-plugins                 1.1.1\\r\\n     cligj                         0.7.2\\r\\n     cloudpickle                   2.2.1\\r\\n     colorama                      0.4.6\\r\\n     colorcet                      3.0.1\\r\\n     comm                          0.1.3\\r\\n     confluent-kafka               1.7.0\\r\\n     contourpy                     1.0.7\\r\\n     cryptography                  40.0.2\\r\\n     cubinlinker                   0.2.2\\r\\n     cucim                         23.4.1\\r\\n     cuda-python                   11.8.1\\r\\n     cudf                          23.4.0\\r\\n     cudf-kafka                    23.4.0\\r\\n     cugraph                       23.4.0\\r\\n     cuml                          23.4.0\\r\\n     cupy                          11.6.0\\r\\n     cusignal                      23.4.0\\r\\n     cuspatial                     23.4.0\\r\\n     custreamz                     23.4.0\\r\\n     cuxfilter                     23.4.0\\r\\n     cycler                        0.11.0\\r\\n     cytoolz                       0.12.0\\r\\n     dask                          2023.3.2\\r\\n     dask-cuda                     23.4.0\\r\\n     dask-cudf                     23.4.0\\r\\n     dask-labextension             6.1.0\\r\\n     datashader                    0.14.4\\r\\n     datashape                     0.5.4\\r\\n     debugpy                       1.6.7\\r\\n     decorator                     5.1.1\\r\\n     defusedxml                    0.7.1\\r\\n     distributed                   2023.3.2.1\\r\\n     entrypoints                   0.4\\r\\n     executing                     1.2.0\\r\\n     fastapi                       0.95.1\\r\\n     fastavro                      1.7.3\\r\\n     fasteners                     0.18\\r\\n     fastjsonschema                2.16.3\\r\\n     fastrlock                     0.8\\r\\n     filelock                      3.12.0\\r\\n     Fiona                         1.9.1\\r\\n     flit_core                     3.8.0\\r\\n     folium                        0.14.0\\r\\n     fonttools                     4.39.3\\r\\n     fqdn                          1.5.1\\r\\n     frozendict                    2.3.7\\r\\n     frozenlist                    1.3.3\\r\\n     fsspec                        2023.4.0\\r\\n     future                        0.18.3\\r\\n     GDAL                          3.6.2\\r\\n     geopandas                     0.12.2\\r\\n     graphviz                      0.20.1\\r\\n     h5py                          3.8.0\\r\\n     holoviews                     1.15.4\\r\\n     idna                          3.4\\r\\n     imagecodecs                   2023.1.23\\r\\n     imageio                       2.27.0\\r\\n     importlib-metadata            6.5.0\\r\\n     importlib-resources           5.12.0\\r\\n     ipycytoscape                  1.3.3\\r\\n     ipydatawidgets                4.3.2\\r\\n     ipykernel                     6.22.0\\r\\n     ipyleaflet                    0.17.2\\r\\n     ipympl                        0.9.3\\r\\n     ipython                       8.12.0\\r\\n     ipython-genutils              0.2.0\\r\\n     ipyvolume                     0.6.1\\r\\n     ipyvue                        1.8.0\\r\\n     ipyvuetify                    1.8.4\\r\\n     ipywebrtc                     0.6.0\\r\\n     ipywidgets                    8.0.6\\r\\n     isoduration                   20.11.0\\r\\n     jedi                          0.18.2\\r\\n     Jinja2                        3.1.2\\r\\n     joblib                        1.2.0\\r\\n     json5                         0.9.5\\r\\n     jsonpointer                   2.3\\r\\n     jsonschema                    4.17.3\\r\\n     jupyter_client                8.2.0\\r\\n     jupyter_core                  5.3.0\\r\\n     jupyter-events                0.6.3\\r\\n     jupyter_server                2.5.0\\r\\n     jupyter_server_fileid         0.9.0\\r\\n     jupyter-server-proxy          3.2.2\\r\\n     jupyter_server_terminals      0.4.4\\r\\n     jupyter_server_ydoc           0.8.0\\r\\n     jupyter-ydoc                  0.2.3\\r\\n     jupyterlab                    3.6.3\\r\\n     jupyterlab-pygments           0.2.2\\r\\n     jupyterlab_server             2.22.1\\r\\n     jupyterlab-widgets            3.0.7\\r\\n     kiwisolver                    1.4.4\\r\\n     lazy_loader                   0.2\\r\\n     llvmlite                      0.39.1\\r\\n     locket                        1.0.0\\r\\n     lz4                           4.3.2\\r\\n     mapclassify                   2.5.0\\r\\n     Markdown                      3.4.3\\r\\n     markdown-it-py                2.2.0\\r\\n     MarkupSafe                    2.1.2\\r\\n     matplotlib                    3.7.1\\r\\n     matplotlib-inline             0.1.6\\r\\n     mdurl                         0.1.0\\r\\n     mistune                       2.0.5\\r\\n     msgpack                       1.0.5\\r\\n     multidict                     6.0.4\\r\\n     multipledispatch              0.6.0\\r\\n     munch                         2.5.0\\r\\n     munkres                       1.1.4\\r\\n     nbclassic                     0.5.5\\r\\n     nbclient                      0.7.3\\r\\n     nbconvert                     7.3.1\\r\\n     nbformat                      5.8.0\\r\\n     nest-asyncio                  1.5.6\\r\\n     networkx                      3.1\\r\\n     notebook                      6.5.4\\r\\n     notebook_shim                 0.2.3\\r\\n     numba                         0.56.4\\r\\n     numcodecs                     0.11.0\\r\\n     numexpr                       2.8.4\\r\\n     numpy                         1.23.5\\r\\n     nvtx                          0.2.5\\r\\n     packaging                     23.1\\r\\n     pandas                        1.5.3\\r\\n     pandocfilters                 1.5.0\\r\\n     panel                         0.14.1\\r\\n     param                         1.13.0\\r\\n     parso                         0.8.3\\r\\n     partd                         1.4.0\\r\\n     patsy                         0.5.3\\r\\n     pexpect                       4.8.0\\r\\n     pickleshare                   0.7.5\\r\\n     Pillow                        9.4.0\\r\\n     pip                           23.1\\r\\n     pkgutil_resolve_name          1.3.10\\r\\n     platformdirs                  3.2.0\\r\\n     pooch                         1.7.0\\r\\n     progressbar2                  4.2.0\\r\\n     prometheus-client             0.16.0\\r\\n     prompt-toolkit                3.0.38\\r\\n     protobuf                      4.21.12\\r\\n     psutil                        5.9.5\\r\\n     ptxcompiler                   0.7.0\\r\\n     ptyprocess                    0.7.0\\r\\n     pure-eval                     0.2.2\\r\\n     pyarrow                       10.0.1\\r\\n     pycparser                     2.21\\r\\n     pyct                          0.4.6\\r\\n     pydantic                      1.10.7\\r\\n     pydeck                        0.5.0\\r\\n     pyee                          8.1.0\\r\\n     pyerfa                        2.0.0.3\\r\\n     Pygments                      2.15.1\\r\\n     pylibcugraph                  23.4.0\\r\\n     pylibraft                     23.4.0\\r\\n     pynvml                        11.4.1\\r\\n     pyOpenSSL                     23.1.1\\r\\n     pyparsing                     3.0.9\\r\\n     pyppeteer                     1.0.2\\r\\n     pyproj                        3.4.0\\r\\n     pyrsistent                    0.19.3\\r\\n     PySocks                       1.7.1\\r\\n     python-dateutil               2.8.2\\r\\n     python-json-logger            2.0.7\\r\\n     python-utils                  3.5.2\\r\\n     pythreejs                     2.4.2\\r\\n     pytz                          2023.3\\r\\n     pyviz-comms                   2.2.1\\r\\n     PyWavelets                    1.4.1\\r\\n     PyYAML                        6.0\\r\\n     pyzmq                         25.0.2\\r\\n     raft-dask                     23.4.0\\r\\n     requests                      2.28.2\\r\\n     rfc3339-validator             0.1.4\\r\\n     rfc3986-validator             0.1.1\\r\\n     rich                          13.3.4\\r\\n     rmm                           23.4.0\\r\\n     Rtree                         1.0.1\\r\\n     scikit-image                  0.20.0\\r\\n     scikit-learn                  1.2.2\\r\\n     scipy                         1.10.1\\r\\n     seaborn                       0.12.2\\r\\n     Send2Trash                    1.8.0\\r\\n     setuptools                    67.6.1\\r\\n     shapely                       2.0.1\\r\\n     simpervisor                   0.4\\r\\n     six                           1.16.0\\r\\n     sniffio                       1.3.0\\r\\n     sortedcontainers              2.4.0\\r\\n     soupsieve                     2.3.2.post1\\r\\n     spectate                      1.0.1\\r\\n     stack-data                    0.6.2\\r\\n     starlette                     0.26.1\\r\\n     statsmodels                   0.13.5\\r\\n     streamz                       0.6.4\\r\\n     tables                        3.7.0\\r\\n     tabulate                      0.9.0\\r\\n     tblib                         1.7.0\\r\\n     terminado                     0.17.1\\r\\n     threadpoolctl                 3.1.0\\r\\n     tifffile                      2023.4.12\\r\\n     tiledb                        0.21.2\\r\\n     tinycss2                      1.2.1\\r\\n     tomli                         2.0.1\\r\\n     toolz                         0.12.0\\r\\n     tornado                       6.3\\r\\n     tqdm                          4.65.0\\r\\n     traitlets                     5.9.0\\r\\n     traittypes                    0.2.1\\r\\n     treelite                      3.2.0\\r\\n     treelite-runtime              3.2.0\\r\\n     typing_extensions             4.5.0\\r\\n     ucx-py                        0.31.0\\r\\n     unicodedata2                  15.0.0\\r\\n     uri-template                  1.2.0\\r\\n     urllib3                       1.26.15\\r\\n     vaex-astro                    0.9.3\\r\\n     vaex-core                     4.16.1\\r\\n     vaex-hdf5                     0.14.1\\r\\n     vaex-jupyter                  0.8.1\\r\\n     vaex-ml                       0.18.1\\r\\n     vaex-server                   0.8.1\\r\\n     vaex-viz                      0.5.4\\r\\n     wcwidth                       0.2.6\\r\\n     webcolors                     1.13\\r\\n     webencodings                  0.5.1\\r\\n     websocket-client              1.5.1\\r\\n     websockets                    10.4\\r\\n     wheel                         0.40.0\\r\\n     widgetsnbextension            4.0.7\\r\\n     xarray                        2023.4.1\\r\\n     xgboost                       1.7.5\\r\\n     xyzservices                   2023.2.0\\r\\n     y-py                          0.5.9\\r\\n     yarl                          1.8.2\\r\\n     ypy-websocket                 0.8.2\\r\\n     zarr                          2.14.2\\r\\n     zict                          3.0.0\\r\\n     zipp                          3.15.0\\r\\n\\r\\n</pre></details>\\r\\n\\r\\n\\r\\n\\r\\n**Additional context**\\r\\nAdd any other context about the problem here.\\ncreatedAt: 2023-04-25T22:55:47Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Rodney Ridley\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 232}),\n",
       " Document(page_content=\": 540\\ntitle: [BUG] Crash running parquet reader benchmarks.\\nbody: The PARQUET_READER_NVBENCH crashes (segfault) at exit on some machines.   It doesn't seem to happen consistently for everyone, but it tends to be reproducible once it starts happening.\\r\\n\\r\\nTo reproduce, run PARQUET_READER_NVBENCH and you should get a segfault right at the end after it has printed out all of it's results.\\r\\n\\r\\nI've narrowed it down to something specific to the `parquet_read_io_compression` suite.  In addition, `compute-sanitizer` does not turn anything up so this seems to be something purely cpu-side.\\ncreatedAt: 2023-04-26T18:24:44Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 233}),\n",
       " Document(page_content=': 543\\ntitle: [BUG] DataFrame iloc indexing is incorrect for repeated index entries in the \"columns\" part of the key\\nbody: **Describe the bug**\\r\\n```python\\r\\nimport cudf\\r\\nimport pandas as pd\\r\\nimport numpy as np\\r\\ndf = pd.DataFrame(np.arange(4).reshape(2, 2))\\r\\ncdf = cudf.from_pandas(df)\\r\\n\\r\\ndf.iloc[:, [0, 1, 0]]\\r\\n#    0  1  0\\r\\n# 0  0  1  0\\r\\n# 1  2  3  2\\r\\n\\r\\ncdf.iloc[:, [0, 1, 0]]\\r\\n#    0  1\\r\\n# 0  0  1\\r\\n# 1  2  3\\r\\n```\\r\\n\\r\\nThis is because `ColumnAccessor.select_by_index` uniquifies input index arguments.\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nThis should match pandas.\\ncreatedAt: 2023-05-02T10:33:16Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 234}),\n",
       " Document(page_content=': 544\\ntitle: [BUG] Series and DataFrame loc indexing does not handle `Ellipsis`\\nbody: **Describe the bug**\\r\\n\\r\\nThis is the same as #13267 really, but `loc`-based indexing goes down a different code path, so I will end up fixing it separately.\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\nimport pandas as pd\\r\\nimport numpy as np\\r\\ndf = pd.DataFrame(np.arange(4).reshape(2, 2))\\r\\ncdf = cudf.from_pandas(df)\\r\\n\\r\\ndf.loc[..., 0]\\r\\n# 0    0\\r\\n# 1    2\\r\\n# Name: 0, dtype: int64\\r\\n\\r\\ncdf.loc[..., 0] # => TypeError\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nShould match pandas.\\ncreatedAt: 2023-05-02T10:50:15Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 235}),\n",
       " Document(page_content=': 545\\ntitle: [BUG] DataFrame `loc` indexing is incorrect with repeated column labels.\\nbody: **Describe the bug**\\r\\n\\r\\nThis is basically #13266 but for `loc`, I will fix it separately due to different code paths.\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\nimport pandas as pd\\r\\nimport numpy as np\\r\\ndf = pd.DataFrame(np.arange(4).reshape(2, 2))\\r\\ncdf = cudf.from_pandas(df)\\r\\n\\r\\ndf.loc[:, [0, 1, 0]]\\r\\n#    0  1  0\\r\\n# 0  0  1  0\\r\\n# 1  2  3  2\\r\\n\\r\\ncdf.loc[:, [0, 1, 0]]\\r\\n#    0  1\\r\\n# 0  0  1\\r\\n# 1  2  3\\r\\n```\\r\\n\\r\\nThis is because `ColumnAccessor.select_by_label` uniquifies input label arguments.\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nThis should match pandas.\\ncreatedAt: 2023-05-02T11:04:17Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 236}),\n",
       " Document(page_content=': 546\\ntitle: [BUG] dataframe construction silently drops data with duplicate column names\\nbody: **Describe the bug**\\r\\n\\r\\nIn pandas, it is allowable to construct a dataframe where the same name is used for more than one of the columns (seems unlikely you would _want_ to do this, but OK).\\r\\n\\r\\nIn cudf, in contrast, duplicate column names are _not_ allowed. However, this restriction is only checked in a few APIs (`from_pandas` complains, for example, but `DataFrame.__init__` doesn\\'t).\\r\\n\\r\\nThis is rather nefarious because operations succeed but silently drop data.\\r\\n\\r\\nExample:\\r\\n```python\\r\\nimport pandas as pd\\r\\nimport numpy as np\\r\\nimport cudf\\r\\n\\r\\ndf = pd.DataFrame(np.arange(4).reshape(2, 2), columns=[\"A\", \"A\"])\\r\\nassert df.sum().sum() == 6 # succeeds\\r\\ncdf = cudf.DataFrame(np.arange(4).reshape(2, 2), columns=[\"A\", \"A\"]) # succeeds, but throws away first column\\r\\n\\r\\nassert cdf.sum().sum() == 6 # fails\\r\\ncdf2 = cudf.from_pandas(df) # raises ValueError\\r\\n```\\r\\n\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nEither\\r\\n\\r\\n1. Support this use case (probably a big job)\\r\\n2. Raise `ValueError` in all cases (easier, minimal sufficient requirement for xdf).\\ncreatedAt: 2023-05-02T15:23:13Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 237}),\n",
       " Document(page_content=\": 548\\ntitle: [BUG] Error when printing large CategoricalIndex\\nbody: Printing a `CategoricalIndex` with more than 200 elements results in the following error:\\r\\n\\r\\n```\\r\\nTypeError: Cannot interpret 'interval[float64, right]' as a data type\\r\\n```\\r\\n\\r\\nReproducer\\r\\n\\r\\n```\\r\\nimport cudf\\r\\nimport cupy\\r\\n\\r\\np = cudf.cut(cupy.arange(201), 3)\\r\\n\\r\\n# this works\\r\\nprint(p[:200])\\r\\n\\r\\n# this doesn't\\r\\nprint(p)\\r\\n```\\r\\n\\r\\nwith cudf version 23.04.01 and cupy version 11.6.0\\ncreatedAt: 2023-05-03T20:41:26Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Filippo Simini\\ncompany: Argonne National Laboratory\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 238}),\n",
       " Document(page_content=': 549\\ntitle: [FEA] Support non-broadcasting (non-scalar) assignment on list columns\\nbody: Consider\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\n\\r\\ns = cudf.Series([[1], [2], [3]])\\r\\ng = cudf.Series([[4], [5]])\\r\\n\\r\\ns.iloc[:2] = g\\r\\n```\\r\\n\\r\\nI would expect this to work and produce `[[4], [5], [3]]`. Instead, we get an error:\\r\\n```\\r\\nValueError: Can not set <cudf.core.column.lists.ListColumn object at 0x7fea4b0f5cc0>\\r\\n[\\r\\n  [\\r\\n    4\\r\\n  ],\\r\\n  [\\r\\n    5\\r\\n  ]\\r\\n]\\r\\ndtype: list into ListColumn\\r\\n```\\r\\n\\r\\nIndeed, the only things we can `__setitem__` into list columns are `cudf.NA` and a singleton list (treated as a `cudf.Scalar`) that is broadcast to all entries.\\ncreatedAt: 2023-05-04T15:42:15Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 239}),\n",
       " Document(page_content=': 550\\ntitle: [BUG] Setitem on struct columns picks out incorrect pieces when indexing of rvalue is not from zero.\\nbody: **Describe the bug**\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\n\\r\\ns = cudf.Series([{\"a\": 1}, {\"a\": 2}, {\"a\": 3}])\\r\\ng = cudf.Series([{\"a\": 4}, {\"a\": 5}, {\"a\": 6}])\\r\\n\\r\\ns.iloc[1:2] = g.iloc[2:3]\\r\\n\\r\\ns.iloc[1:2]\\r\\n# 1    {\\'a\\': 4}\\r\\n# dtype: struct\\r\\n\\r\\ng.iloc[2:3]\\r\\n# 2    {\\'a\\': 6}\\r\\n# dtype: struct\\r\\n\\r\\n# An even more fun:\\r\\n\\r\\nx = g.iloc[2:3].copy(deep=True)\\r\\n\\r\\ns.iloc[1] = x.iloc[0]\\r\\n\\r\\ns.iloc[1] # => {\\'a\\': 6} Good!\\r\\n\\r\\ns.iloc[1] = x.iloc[:]\\r\\n\\r\\ns.iloc[1] # => {\\'a\\': 4} What!\\r\\n```\\r\\n\\r\\nOops.\\ncreatedAt: 2023-05-04T16:59:24Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 240}),\n",
       " Document(page_content=': 551\\ntitle: [BUG] `__repr__` for a high cardinality categorical can take a very long time\\nbody: Because it involves copying data to Pandas, just printing a high-cardinality CategoricalIndex can take a very long time:\\r\\n\\r\\n```python\\r\\ndt = pd.CategoricalIndex(range(100_000_000))\\r\\nprint(dt)  # almost instantaneous\\r\\n\\r\\ndt = cudf.CategoricalIndex(range(100_000_000))\\r\\nprint(dt)  # can take several seconds\\r\\n```\\r\\n\\r\\nWe should figure out if we can do this by copying only the minimum amount of data to Pandas (or not copying to Pandas at all).\\ncreatedAt: 2023-05-04T21:46:48Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 241}),\n",
       " Document(page_content=\": 555\\ntitle: [ENH] Indices are immutable by definition and should take advantage of that\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nIndices advertise a bunch of properties (for example `is_monotonic_increasing`). These are implemented by inheriting from `Frame` or `SingleColumnFrame`. But those latter classes are _mutable_, and so their implementation of the property must recompute every time.\\r\\n\\r\\nFor an index, this is not the case, and so we lose some performance (for example, every time we do a slice `.loc` we'll run a libcudf kernel to check if the index is sorted).\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nIndex properties (especially where they return scalars, and therefore the memory footprint is negligible) should use `functools.cached_property` to provide their (immutable) properties.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\nNone\\ncreatedAt: 2023-05-16T15:34:03Z\\nn_body_reactions_thumbs_up: 2\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 242}),\n",
       " Document(page_content=': 556\\ntitle: [FEA] Expand string operator support in libcudf ASTs\\nbody: After adding string scalar support in #13061, libcudf now supports string column and string scalar operands, plus comparison operators.\\r\\n\\r\\nThere are additional operators that would be useful for string types, and this issue will track the most-requested operators.\\r\\n\\r\\nin scope:\\r\\nstring contains, startswith, endswith\\r\\nlength, find, rfind\\r\\n\\r\\nout of scope for now:\\r\\ncasting to and from string to other AST types\\r\\nregex support\\r\\nconcatenation\\r\\n\\r\\n(Also see background issue #8858)\\ncreatedAt: 2023-05-16T16:20:49Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 243}),\n",
       " Document(page_content=\": 559\\ntitle: [FEA] Rename `filters=` argument to `row_group_filters=` in `read_parquet` and `read_orc` and provide examples that show its use\\nbody: The `filters=` argument to the `read_parquet` and `read_orc` functions is misleading in its name. Because it filters by row _group_, rather than by row, I think we should rename it to `row_group_filters=`.\\r\\n\\r\\nAdditionally, the description for this kwarg is complicated and laden with jargon. I think we should simplify and provide some examples that clarify the use of this keyword:\\r\\n\\r\\n```\\r\\n    If not None, specifies a filter predicate used to filter out row groups\\r\\n    using statistics stored for each row group as Parquet metadata. Row groups\\r\\n    that do not match the given filter predicate are not read. The\\r\\n    predicate is expressed in disjunctive normal form (DNF) like\\r\\n    `[[('x', '=', 0), ...], ...]`. DNF allows arbitrary boolean logical\\r\\n    combinations of single column predicates. The innermost tuples each\\r\\n    describe a single column predicate. The list of inner predicates is\\r\\n    interpreted as a conjunction (AND), forming a more selective and\\r\\n    multiple column predicate. Finally, the outermost list combines\\r\\n    these filters as a disjunction (OR). Predicates may also be passed\\r\\n    as a list of tuples. This form is interpreted as a single conjunction.\\r\\n    To express OR in predicates, one must use the (preferred) notation of\\r\\n    list of lists of tuples\\r\\n```\\ncreatedAt: 2023-05-17T19:02:46Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 244}),\n",
       " Document(page_content=\": 560\\ntitle: [FEA] Support self comparisons in `cudf::experimental::row::lexicographic::two_table_comparator`\\nbody: As showcased in https://github.com/rapidsai/cudf/pull/13347, there's a need for `{lhs, lhs}` and `{rhs, rhs}` comparisons in an instance of `two_table_comparator`.\\r\\n\\r\\nThis can't simply be achieved by adding more overloads because `left` and `right` terminology is [baked into the comparator](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L1141-L1157) when it's constructed at the host-side. In a device function, the [strongly typed indices](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L1012-L1039) now work with the assumption that a `comp(i, j)` that is called in a device function operates on `{lhs, rhs}` or `{rhs, lhs}`.\\r\\n\\r\\nWe need to settle on a design that lets us refactor the row operators such that the assumption of working on two different tables can be removed.\\r\\n\\r\\nDo we strongly type `device_row_comparator::operator()` [over here](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L541-L542) such that we can decide which columns of which tables to pass along to the `element_comparator` over [here](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L568-L575)?\\r\\n\\r\\nI see the design looking something like this:\\r\\n```\\r\\nclass device_row_comparator {\\r\\n  class element_comparator {\\r\\n    operator() (size_type lhs_index, size_type rhs_index);\\r\\n  };\\r\\n  dispatch_element_operator(lhs_col, rhs_col, lhs_index, rhs_index);\\r\\n\\r\\n  // these call dispatch_element_operator with the correct columns and indices\\r\\n  operator() (lhs_index_type lhs_index, rhs_index_type rhs_index);\\r\\n  operator() (lhs_index_type lhs_index, lhs_index_type rhs_index);\\r\\n  operator() (rhs_index_type lhs_index, rhs_index_type rhs_index);\\r\\n};\\r\\n\\r\\n// the template `Comparator` here and below will be an instance of `device_row_comparator`,\\r\\n// such that the strongly type indices can be passed along directly\\r\\ntemplate <typename Comparator, weak_ordering... values>\\r\\nclass single_table_ordering {\\r\\n  operator() (size_type lhs_index, size_type rhs_index) {\\r\\n    return comparator(lhs_index_type{lhs_index}, lhs_index_type{rhs_index});\\r\\n};\\r\\n\\r\\ntemplate <typename Comparator, weak_ordering... values>\\r\\nclass two_table_ordering {\\r\\n// same as current version of strong_index_comparator with added overloads for {lhs, lhs} and {rhs, rhs}\\r\\n};\\r\\n\\r\\nclass self_comparator {\\r\\n  auto less() {\\r\\n    return less_comparator{single_table_ordering{device_row_comparator{...}}};\\r\\n  }\\r\\n};\\r\\n\\r\\nclass two_table_comparator {\\r\\n  auto less() {\\r\\n    return less_comparator{two_table_ordering{device_row_comparator{...}}};\\r\\n  }\\r\\n};\\r\\n```\\r\\nNote: In this example, [weak_ordering_comparator_impl](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L612-L626) will be removed and it's functionality will instead be baked into `single_table_ordering` and `two_table_ordering`. [less_comparator](https://github.com/rapidsai/cudf/blob/76ec53fae9dad71398c115bc405317a918036e52/cpp/include/cudf/table/experimental/row_operators.cuh#L634-L644) will then be reworked with CRTP such that:\\r\\n```\\r\\ntemplate <typename Comparator>\\r\\nclass less_comparator : Comparator<weak_ordering::LESS>\\r\\n```\\ncreatedAt: 2023-05-17T19:21:59Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Divye Gala\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 245}),\n",
       " Document(page_content=\": 561\\ntitle: [FEA] Pass dataframe as a parameter to .apply_rows\\nbody: looking the apply_rows, how can I pass in a cudf dataframe as an argument  so something like \\r\\n```\\r\\nimport cudf\\r\\nimport numpy as np\\r\\n\\r\\ndfA = cudf.DataFrame({'A': [0, 1, 2, 3, 4],\\r\\n                   'B': [5, 6, 7, 8, 9],\\r\\n                   'C': ['a', 'b', 'c', 'd', 'e']})\\r\\ndfA\\r\\n\\r\\ndfB = cudf.DataFrame({'A': [0, 1, 2, 3, 4],\\r\\n                   'B': [5, 6, 7, 8, 9],\\r\\n                   'C': ['a', 'b', 'c', 'd', 'e']})\\r\\n\\r\\ndef fn(A, B, out1,k1):\\r\\n    for i, (a, b) in enumerate(zip(A, B)):\\r\\n        out1[i] = 1 # awesome work done here that uses all k1\\r\\n\\r\\ndfB.apply_rows(fn, incols = ['A','B'], outcols = dict(out1=np.float64), kwargs=dict(k1=dfA))\\r\\n```\\ncreatedAt: 2023-05-18T03:28:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 246}),\n",
       " Document(page_content=': 562\\ntitle: [BUG] `loc`-based indexing of DataFrames silently discards missing keys if at least one key is present in indexer\\nbody: **Describe the bug**\\r\\n\\r\\nWhen performing `loc` indexing of a `DataFrame`, if one asks for a missing key, pandas raises a `KeyError`. In constrast,  cudf only does so if none of the requested keys are in the index. If at least one requested key is present then the subsetted data frame with that key is returned and the missing keys are silently dropped. \\r\\n\\r\\nSeries `loc` indexing does the right thing here and raises `KeyError` if any keys are missing.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\n```python\\r\\nimport pandas as pd\\r\\nimport cudf\\r\\n\\r\\n# same failure with rangeindex too.\\r\\ndf = pd.DataFrame({\"A\": range(5)}, index=list(range(5)))\\r\\ncdf = cudf.from_pandas(df)\\r\\n\\r\\ndf.loc[[0, 5]] # 5 is missing, raises KeyError\\r\\n\\r\\ncdf.loc[[0, 5]]\\r\\n#    A\\r\\n# 0  0\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nShould match pandas behaviour and raise `KeyError`.\\ncreatedAt: 2023-05-18T10:13:54Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 247}),\n",
       " Document(page_content=': 563\\ntitle: `tz_convert` sometimes returns results different from Pandas (but same as `zoneinfo`)\\nbody: `tz_convert` returns a result different from Pandas for this pre-1900 example:\\r\\n\\r\\n```python\\r\\n>>> pd.Series([\"1899-01-01 12:00\"], dtype=\"datetime64[s]\").dt.tz_localize(\"Europe/Paris\").dt.tz_convert(\"America/New_York\")\\r\\n0   1899-01-01 06:55:00-04:56\\r\\ndtype: datetime64[ns, America/New_York]\\r\\n\\r\\n>>> cudf.Series([\"1899-01-01 12:00\"], dtype=\"datetime64[s]\").dt.tz_localize(\"Europe/Paris\").dt.tz_convert(\"America/New_York\")\\r\\n0   1899-01-01 06:50:39-04:56\\r\\ndtype: datetime64[s, America/New_York]\\r\\n```\\r\\n\\r\\nHowever, our result is the same as you would get with `zoneinfo`:\\r\\n\\r\\n```python\\r\\n>>> datetime(1899, 1, 1, 12, 0, tzinfo=ZoneInfo(\"Europe/Paris\")).astimezone(ZoneInfo(\"America/New_York\"))\\r\\ndatetime.datetime(1899, 1, 1, 6, 50, 39, tzinfo=zoneinfo.ZoneInfo(key=\\'America/New_York\\'))\\r\\n```\\r\\n\\r\\n@mroeschke I\\'m curious if this aligns with your experience with the difference between Pandas (pytz) and zoneinfo?\\r\\n\\r\\n_Originally posted by @shwina in https://github.com/rapidsai/cudf/pull/13328#discussion_r1196584991_\\ncreatedAt: 2023-05-18T10:27:08Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 248}),\n",
       " Document(page_content=': 566\\ntitle: [ENH] Avoid repeated bounds-checking in `take` when arguments are known in bounds\\nbody: As noted in #13419, there are likely places where we call `take` on a column with a gather map that is known to be in-bounds. We should therefore avoid an (unnecessary) bounds-check in these cases where we know this by passing `check_bounds=False`.\\r\\n\\r\\n_Originally posted by @bdice in https://github.com/rapidsai/cudf/pull/13419#discussion_r1203131049_\\r\\n            \\r\\n```[tasklist]\\r\\n### Tasks\\r\\n- [ ] parquet.py `_get_groups_and_offsets`\\r\\n- [ ] `_DataFrameLocIndexer._getitem_tuple_arg`\\r\\n- [ ] `CategoricalColumn._get_decategorized_column`\\r\\n- [ ] `ColumnBase.slice`\\r\\n- [ ] `Rangindex._gather` ?\\r\\n- [ ] `Groupby.agg`\\r\\n- [ ] timezones.py `utc_to_local` and `local_to_utc`\\r\\n- [ ] `MultiIndex.__repr__`\\r\\n```\\ncreatedAt: 2023-05-26T09:08:20Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 249}),\n",
       " Document(page_content=': 572\\ntitle: [FEA] Support V2 encodings in Parquet reader and writer\\nbody: Parquet V1 format supports three types of page encodings: PLAIN, DICTIONARY, and RLE (run-length encoded) ([reference from Spark Jira](https://issues.apache.org/jira/browse/SPARK-36879)). The newer and evolving Parquet V2 specification adds support for several [additional encodings](https://parquet.apache.org/docs/file-format/data-pages/encodings/), including DELTA_BINARY_PACKED for `INT32` and `INT64` types, DELTA_BYTE_ARRAY for `strings` logical type, and DELTA_LENGTH_BYTE_ARRAY for `strings` logical type. \\r\\n\\r\\nIn the parquet reader and writer, libcudf should support V2 metadata as well as the three variants of DELTA encoding.\\r\\n\\r\\n| Feature | Status | Notes | \\r\\n|---|---|---|\\r\\n| Add V2 reader support |  ✅ #11778 | |\\r\\n| Multi-warp decode of Dremel data streams | ✅ #13203 |  | \\r\\n| Use efficient strings column factory in decoder | ✅ #13302 |  | \\r\\n| Implement DELTA_BINARY_PACKED decoding |  ✅  #13637 | see #12948 for reference |\\r\\n| Implement DELTA_BYTE_ARRAY decoding | ✅ #14101 | see #12948 for reference |\\r\\n| Add V2 writer support | ✅ #13751 | |\\r\\n| Implement DELTA_BINARY_PACKED encoding | ✅ #14100 | | \\r\\n| Add python bindings for V2 header and options | ✅ #14316 | |\\r\\n| Implement DELTA_BYTE_ARRAY encoding | ✅ #15239 | some outdated reviews in #14938 |\\r\\n| Implement DELTA_LENGTH_BYTE_ARRAY encoding and decoding for unsorted data | ✅ #14590 | |\\r\\n| Add C++ API support for specifying encodings | ✅ #15081 | |\\r\\n| Add cuDF-python API support for specifying encodings |  | |\\r\\n| Add BYTE_STREAM_SPLIT encoding and decoding  | ✅ #15311 | see issue #15226 and [parquet reference](https://github.com/apache/parquet-format/blob/master/Encodings.md#byte-stream-split-byte_stream_split--9) |\\ncreatedAt: 2023-06-02T03:38:40Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 250}),\n",
       " Document(page_content=': 575\\ntitle: [FEA] JSON reader improvements for Spark-RAPIDS\\nbody: libcudf includes a GPU-accelerated JSON reader that uses a finite-state transducer parser combined with token-processing tree algorithms to transform character buffers into columnar data. This issue tracks the technical work leading up to the launch of libcudf\\'s JSON reader as a default component of the Spark-RAPIDS plugin. Please also refer to the [Nested JSON reader milestone](https://github.com/rapidsai/cudf/milestone/13) and [Spark-RAPIDS JSON epic](https://github.com/NVIDIA/spark-rapids/issues/9458).\\r\\n\\r\\n\\r\\n### Spark compatibility issues: Blockers\\r\\n| Status | Impact for Spark | Change to libcudf |\\r\\n|---|---|---|\\r\\n| ✅ #13344  | #12532, Blocker: if any line has an error, libcudf throws an exception  | Rework state machine to include error states and scrub tokens from lines with error | \\r\\n| ✅ #14252 | #14227, Blocker: Incorrect parsing | Fix bug in error recovery state transitions |  \\r\\n✅ #14279 | #14226, Blocker: requesting alternate error recovery behavior from #13344, where valid data before an error state are preserved  | Changes in JSON parser pushdown automaton for JSON_LINES_RECOVER option  | \\r\\n| ✅ #14936 | #14288, Blocker: libcudf does not have an efficient representation for map types in Spark |  libcudf does not support map types, and modeling the map types as structs results in poor performance due to one child column per unique key. We will return the struct data that represents map types as string and then the plugin can use [unify_json_strings](https://github.com/NVIDIA/spark-rapids-jni/blob/54ef9991f46fa873d580315212aeae345da7152a/src/main/cpp/src/map_utils.cu#L63-L112) to parse tokens |\\r\\n| ✅ #14572  | #14239, Blocker: fields with mixed types raise an exception | add libcudf reader option to return mixed types as strings. Also see improvements in  #15236 and  #14939 | \\r\\n| ✅ #14545 | #10004, Blocker: Can\\'t parse data with single quote variant of JSON when `allowSingleQuotes` is enabled in Spark | Introduce a preprocessing function to normalize single and double quotes as double quotes | \\r\\n| ✅ #15324 | #15303, escaped single quotes have their escapes dropped during quote normalization | Adjust quote normalization FST |\\r\\n| 🔄 #15419 | #15390 + #15409, Blocker: race conditions found in nested JSON reader | Solve synchronization problems in nested JSON reader  |\\r\\n| | #15260, Blocker: crash in mixed type support | |\\r\\n| 🔄 | #15278, Blocker: allow list type to be coerced to string, also see #14239. Without this, Spark-RAPIDS will fallback when user requests a field as \"string\" | Support List types coercion to string | \\r\\n| | #15277, Blocker: we need to support multi-line JSON objects. Also see #10267 | libcudf is scoping a \"multi-object\" reader |  \\r\\n\\r\\n\\r\\n\\r\\n### Spark compatibility issues: non-blockers\\r\\n\\r\\n| Status  | Impact for Spark | Change to libcudf  | \\r\\n|---|---|---|\\r\\n| | #15222, compatibility problems with leading zeros, \"NAN\" and escape options | None for now. This feature should live in Spark-RAPIDS as a post-processing option for now, based on the approach for `get_json_object` modeled after Spark CPU code (see https://github.com/NVIDIA/spark-rapids-jni/pull/1836). Then the plugin can set to null any entries from objects that Spark would treat as invalid. Later we could provide Spark-RAPIDS access to raw tokens that they could run through a more efficient validator.  |\\r\\n| ✅ #15033 |  #14865, Strip whitespace from JSON inputs, otherwise Spark will have to add this in post-processing the coerced strings types | Create new normalization pre-processing tool for whitespace | \\r\\n| 🔄 #14996 | #13473, Performance: only process columns in the schema | Skip parsing and column creation for keys not specified in the schema |\\r\\n| 🔄 #15124 | Reader option performance is unknown | #15041, add JSON reader option benchmarking | |\\r\\n| | Performance: Avoid preprocessing to replace empty lines with `{}`. Also see #5712 |  libcudf provides strings column data source | \\r\\n|  | #15280 find a solution when whitespace normalization fixes a line that originally was invalid | We could move whitespace normalization after tokenization. Also we would like to address #15277 so that we can remove unquoted newline characters as well. |\\r\\n| | n/a, Spark-RAPIDS doesn\\'t use byte range reading | #15185, reduce IO overhead in JSON byte range reading |\\r\\n| | n/a, Spark-RAPIDS doesn\\'t use byte range reading | #15186, address data loss edge case for byte range reading |\\r\\n|  | reduce peak memory usage | add chunking to the JSON reader | \\r\\n| | #15222, Spark-RAPIDS must return null if any field is invalid | Provide token stream to Spark-RAPIDS for validation, including checks or leading zeros, special string numbers like `NaN`, `+INF`, `-INF`, and optional limits for which characters can be escaped |\\ncreatedAt: 2023-06-07T16:30:32Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 251}),\n",
       " Document(page_content=': 576\\ntitle: [FEA] Use table_view interface in scatter-by-foo API in CUDF\\nbody: Both the scatter-like and gather-like Cython interfaces to libcudf\\'s copying API accept a list of source and target columns as a \"table\". This feature is, however, only _used_ in the front-facing API by the gather-like calls.\\r\\n\\r\\nFor scatter-like calls on a dataframe, the final result is usually achieved by creating series for each column to scatter to/from and calling the singleton scatter on the series before reconstructing. This is more wasteful than it needs to be and we should probably instead just create the list of columns we wish to scatter and scatter that instead.\\r\\n\\r\\nFor example, the low-level Cython interface to scatter accepts a list of source and target columns:\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/blob/8055c2db6f80286b64d36f3927510bcf2e0eec02/python/cudf/cudf/_lib/copying.pyx#L240\\r\\n\\r\\nHowever, the only caller in the python codebase is `ColumnBase._scatter_by_column` https://github.com/rapidsai/cudf/blob/8055c2db6f80286b64d36f3927510bcf2e0eec02/python/cudf/cudf/core/column/column.py#L647-L682 where we only have a single column to hand and hence can only pass one column.\\r\\n\\r\\nThis is usage is a consequence of `__setitem__` on `DataFrame`s ultimately being implemented by spinning over the columns (as series) and calling setitem on each series in turn. For example, `DataFrameIlocIndexer.__setitem__` has this code (when setting columns using a dataframe as the rvalue):\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/blob/8055c2db6f80286b64d36f3927510bcf2e0eec02/python/cudf/cudf/core/dataframe.py#L466-L477\\r\\n\\r\\nThis calls (on line 474) `Series.__setitem__` on each which either goes to `series.iloc.__setitem__` or `series.loc.__setitem__`, and eventually devolves to `ColumnBase.__setitem__`.\\r\\n\\r\\n(Aside, this is actually a bug, since `iloc.__setitem__` should not do index alignment which `loc` will do).\\r\\n\\r\\nIgnoring that bug issue, this code is somewhat wasteful in a number of ways:\\r\\n\\r\\n1. we eventually throw away the `Series` object when reconstructing the dataframe, so should just operate on columns\\r\\n2. at this point in `DataFrame.iloc.__setitem__` we _already know_ everything about the key (and hence which low-level libcudf operation to dispatch to) so we should do that rather than going through the front door of `Series.__setitem__` which will endeavour to rediscover everything we already know.\\r\\n3. we call into libcudf n times (once for each column), rather than once with n columns, which negates the ability to use the stream parallelism that is implemented in the `scatter` code in libcudf\\r\\n\\r\\nTo fix this, I propose that `DataFrame` and `Series` should both get a new set of methods. Here\\'s a first pass at what these should be called/their interface. These are internal and should do no argument normalisation or bounds-checking (it being the responsibility of the caller to sanitise appropriately), this includes kind/dtype casting as appropriate of the source and target.\\r\\n\\r\\n- `_scatter_by_indices(self, source_columns, index_column, *, keep_index=True)`\\r\\n- `_scatter_by_mask(self, source_columns, mask_column, *, keep_index=True)`\\r\\n- `_scatter_by_slice(self, source_columns, slice, *, keep_index=True)`\\r\\n\\r\\nSince there is also a broadcasting `scatter_from_scalar` operation in libcudf we\\'ll probably need to support that too. This should be done with a `value_type` tag in the interface (rather than isinstancing on the `source_columns`) since, again, the caller must have already determined this information.\\ncreatedAt: 2023-06-07T16:46:17Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 252}),\n",
       " Document(page_content=': 577\\ntitle: [BUG] `Column._scatter_by_slice` doesn\\'t handle negative-stride slices correctly.\\nbody: **Describe the bug**\\r\\n\\r\\n```python\\r\\nIn [49]: col = cudf.core.column.as_column([1, 2, 3, 4])\\r\\n\\r\\nIn [50]: col\\r\\nOut[50]: \\r\\n<cudf.core.column.numerical.NumericalColumn object at 0x7fcd07e6c4c0>\\r\\n[\\r\\n  1,\\r\\n  2,\\r\\n  3,\\r\\n  4\\r\\n]\\r\\ndtype: int64\\r\\n\\r\\nIn [51]: col[::-1] = cudf.Scalar(7)\\r\\n\\r\\nIn [52]: col\\r\\nOut[52]: \\r\\n<cudf.core.column.numerical.NumericalColumn object at 0x7fcd07e6c4c0>\\r\\n[\\r\\n  1,\\r\\n  2,\\r\\n  3,\\r\\n  4\\r\\n]\\r\\ndtype: int64\\r\\n```\\r\\n\\r\\nThis eventually calls `_scatter_by_slice`, which does this:\\r\\n\\r\\n```python\\r\\n    def _scatter_by_slice(\\r\\n        self,\\r\\n        key: builtins.slice,\\r\\n        value: Union[cudf.core.scalar.Scalar, ColumnBase],\\r\\n    ) -> Optional[Self]:\\r\\n        \"\"\"If this function returns None, it\\'s either a no-op (slice is empty),\\r\\n        or the inplace replacement is already performed (fill-in-place).\\r\\n        \"\"\"\\r\\n        start, stop, step = key.indices(len(self))\\r\\n        if start >= stop:\\r\\n            return None\\r\\n        num_keys = len(range(start, stop, step))\\r\\n\\r\\n```\\r\\n\\r\\nBut that first check is not right to determine if the slice is empty.\\r\\n\\r\\n```python\\r\\n# x[::-1]\\r\\nslice(None, None, -1).indices(3)\\r\\n# => (2, -1, -1)\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nThis should work.\\ncreatedAt: 2023-06-08T08:50:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 253}),\n",
       " Document(page_content=': 578\\ntitle: [ENH]: Reimagining cudf user-input boundaries\\nbody: tl;dr: If you squint, everything is really a compiler problem in disguise.\\r\\n\\r\\n\\r\\n## Overview\\r\\n\\r\\nThe pandas API is very broad and has numerous places where \"best effort\" attempts are made to DWIM (do what I mean). One example is during dataframe indexing, where a significant effort is made to \"desugar\" the user input into a canonical form.\\r\\n\\r\\nFor example, turning `df.loc[[1, 2, 3]]` into `df.loc[[1, 2, 3], :]` (that is, a single entry on a dataframe is equivalent to taking rows and *all* the columns).\\r\\n\\r\\nThis pattern is pervasive, to take another different example, `read_parquet` accepts as the \"file\" object:\\r\\n\\r\\n1.  a string (indicating a file to open)\\r\\n2.  a Path object\\r\\n3.  raw bytes\\r\\n4.  Anything with a `read` method\\r\\n5.  A list (maybe sequence?) of the above\\r\\n\\r\\n\\r\\n## The status quo\\r\\n\\r\\nTo handle this kind of multi-modal unstructured input, the user-visible API of cudf carries out inspection and validation of the inputs before dispatching to appropriate lower-level routines. By the time we reach libcudf, all decisions must have been made.\\r\\n\\r\\nThis works, but has a number of problems:\\r\\n\\r\\n1.  It is not always clear *whose* job it is to do the validation. Is any \"pseudo-public\" method required to validate correctness of its inputs? Or is it always the job of the definitively public API to validate all inputs before handing off. One sees this in private `Frame` methods like `_gather` which have an explicit `check_bounds` flag (which often is not set when it could be, because the only *safe* default is `True`).\\r\\n2.  Validation just checks for valid inputs and then returns types unchanged (so defensive programming requires consumers of the input to assume worst-case scenarios and check things again).\\r\\n3.  Consequently, validation and inspection often occur (on any given input): \\r\\n    i. More than once \\r\\n    ii. Inconsistently (generally this is not deliberate, it\\'s just hard to keep track).\\r\\n\\r\\n\\r\\n## Proposal\\r\\n\\r\\nI propose that we take a leaf out of the type-driven design crowd\\'s book and treat the user-facing input validation as a *parsing* rather than *validating* problem. What does this mean? Rather than just checking input in user-facing API functions and dispatching to internal functions that *receive the same type* we should tighten the types as we go, \"parsing\" the unstructured user input into more structured data as we transit through the call stack.\\r\\n\\r\\nThis has, I think, a number of advantages:\\r\\n\\r\\n1.  It clarifies *where* in the implementation validation in dispatch takes place (any time a type changes), separating the business logic of making sense of the input from the concrete implementation for the different paths.\\r\\n2.  It makes cross-calling between internal APIs that *don\\'t* do validation safe. For example, rather than `_gather` having the signature `a -> Column -> Maybe a` for some dataframe type `a` and always having to check that the provided column is inbounds as a gather map, we would tighten the type to `a -> InBoundsFor a Column -> a`. Now the gather map comes with a \"proof\" that it is inbounds for the dataframe we are gathering, and we therefore do not have to do bounds checking[^1]. Now, we can\\'t statically enforce this (in the sense that in the implementation, someone will be able to conjure the \"proof\" out of thin air if they really want to), but type checking will at least indicate when we don\\'t promise an in-bounds column.\\r\\n3.  By separating the business logic from the backend dispatch we keep the good work we\\'ve done in producing a pandas-like API and make it *easier* to (on the long term) slot in other backends (for example a distributed, multi-node, backend underneath the cudf front-facing API).\\r\\n\\r\\n\\r\\n[^1]: In a statically typed language with rank-N types you can actually make these proofs [part of the type system](https://kataskeue.com/gdp.pdf), though we can\\'t here in Python.\\r\\n\\r\\n## Further reading\\r\\n\\r\\n- A nice overview of this idea with more examples: https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/\\r\\n- Similar ideas as the \"typestate\" pattern: https://cliffle.com/blog/rust-typestate/\\r\\n- \"Make illegal states unrepresentable\": https://buttondown.email/hillelwayne/archive/making-illegal-states-unrepresentable/\\ncreatedAt: 2023-06-09T17:26:44Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 254}),\n",
       " Document(page_content=': 579\\ntitle: When the amount of data is not small,The parameter Num of the parallel process becomes larger, but the running time becomes longer\\nbody: **Describe the bug**\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nimport cudf\\r\\nfrom multiprocessing import get_context\\r\\nimport time\\r\\npdf = cudf.DataFrame({\\r\\n        \\'low\\':[i for i in range(1000)],\\r\\n        \\'close\\':[i for i in range(1000)],\\r\\n    })\\r\\n\\r\\ndef get_df(idx):\\r\\n    return idx.rolling(5).mean()\\r\\n\\r\\nif __name__ == \"__main__\":\\r\\n    ctx = get_context(\"spawn\")\\r\\n    start = time.time()\\r\\n    num =1\\r\\n    with ctx.Pool(num) as pool:\\r\\n        cudf.concat(pool.map(get_df, [pdf.a[i:] for i in range(100, 200)]))\\r\\n    print(time.time()-start)\\r\\n\\r\\n```\\r\\n\\r\\nnum =1 ,time 3.2659552097320557\\r\\nnum =2, time 7.382307291030884\\ncreatedAt: 2023-06-10T15:14:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 255}),\n",
       " Document(page_content=': 580\\ntitle: [ENH] Audit `argsort + gather/scatter` patterns for missing performance\\nbody: During review of #13419 we noted a few places where there is a pattern like:\\r\\n\\r\\n```python\\r\\nsome_frame = ...\\r\\nindices = some_frame.some_column.argsort()\\r\\nnew_frame = some_frame.take(indices)\\r\\n```\\r\\n\\r\\nAs well as the unnecessary bounds-check (see #13456), this is a pattern that is captured by libcudf\\'s [`sort_by_key`](https://docs.rapids.ai/api/libcudf/stable/group__column__sort.html#ga6db0403a43150b3bca0fbb9b2fbd68a3) and [`stable_sort_by_key`](https://docs.rapids.ai/api/libcudf/stable/group__column__sort.html#gaea04f441fe246b5a7e4f6420864024d4) functions (we would want to use the latter in pandas-compat mode).\\r\\n\\r\\nAt present, libcudf implements this as a `argsort` of the key columns followed by a gather. But that\\'s an implementation detail (there may in the future be updates to that implementation). In the Python layer we should \"say what we mean\" and call into the appropriate libcudf API.\\r\\n\\r\\nA cursory search shows:\\r\\n\\r\\n```\\r\\n/usr/bin/rg -U -e argsort.\\\\*\\'     \\r\\n\\'.\\\\*take\\r\\n\\r\\ncore/_base_index.py\\r\\n1305:        indices = self.argsort(ascending=ascending, na_position=na_position)\\r\\n1306:        index_sorted = self.take(indices)\\r\\n\\r\\ncore/indexed_frame.py\\r\\n2464:                # double-argsort to map back from sorted to unsorted positions\\r\\n2465:                df = df.take(index.argsort(ascending=True).argsort())\\r\\n\\r\\ncore/column/column.py\\r\\n1382:        order = order.take(left_gather_map, check_bounds=False).argsort()\\r\\n1383:        codes = codes.take(order)\\r\\n\\r\\ncore/groupby/groupby.py\\r\\n686:            gather_map = ordering.take(to_take).argsort()\\r\\n687:            return result.take(gather_map)\\r\\n```\\r\\n\\r\\nOf these, the calls in `_base_index.py`, `_column.py`, and `groupby.py` can definitely be replaced by `sort_by_key`. Note also that none of these calls pass `check_bounds=False` to `take` so incur an unnecessary kernel launch to check in-boundsness for something that is guaranteed in bounds.\\r\\n\\r\\nThe `take(argsort().argsort())` pattern is not a `sort_by_key`, however, we can elide one of the argsorts by noticing that `take` is a gather operation and for a permutation, the dual to gather is scatter. So this should be implemented as `df.scatter(index.argsort())` instead...\\r\\n\\r\\nThese are just the cases where an argsort is _immediately_ followed by a take, probably more diligent searching would find more.\\r\\n```[tasklist]\\r\\n### Tasks\\r\\n- [ ] `RollingGroupby.__init__`\\r\\n- [ ] `Groupby._head_tail`\\r\\n- [ ] `IndexedFrame.interpolate`\\r\\n- [ ] `IndexedFrame.sort_index`\\r\\n- [ ] `IndexedFrame._reindex`\\r\\n- [ ] `IndexedFrame.sort_values`\\r\\n- [ ] `IndexedFrame._n_largest_or_smallest`\\r\\n- [ ] `BaseIndex.sort_values`\\r\\n- [ ] `MultiIndex.__repr__`\\r\\n```\\ncreatedAt: 2023-06-13T10:57:12Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 256}),\n",
       " Document(page_content=': 582\\ntitle: [FEA] Support indicator=True in cudf.DataFrame.merge\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nI wish dask_cudf dataframes would support the `indicator=True` option in the merge function\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nIn dask dataframe the code:\\r\\n```python\\r\\nimport pandas as pd\\r\\nimport dask.dataframe as dd\\r\\n\\r\\ndfa = pd.DataFrame({\"id\":[1,2,2,4], \"a\":[\"a\",\"b\",\"c\",\"d\"]})\\r\\ndfb = pd.DataFrame({\"id\":[2,3,3,4], \"b\":[\"e\",\"f\",\"g\",\"h\"]})\\r\\nddfa = dd.from_pandas(dfa, npartitions=1)\\r\\nddfb = dd.from_pandas(dfb, npartitions=1)\\r\\n\\r\\nddf = ddfa.merge(ddfb, on=\"id\", how=\"outer\", indicator=True)\\r\\nprint(ddf.compute())\\r\\n```\\r\\nreturns:\\r\\n```\\r\\n   id    a    b      _merge\\r\\n0   1    a  NaN   left_only\\r\\n1   2    b    e        both\\r\\n2   2    c    e        both\\r\\n3   4    d    h        both\\r\\n4   3  NaN    f  right_only\\r\\n5   3  NaN    g  right_only\\r\\n```\\r\\n\\r\\nbut in dask_cudf:\\r\\n```python\\r\\nimport cudf\\r\\nimport dask_cudf as dd\\r\\n\\r\\ndfa = cudf.DataFrame({\"id\":[1,2,2,4], \"a\":[\"a\",\"b\",\"c\",\"d\"]})\\r\\ndfb = cudf.DataFrame({\"id\":[2,3,3,4], \"b\":[\"e\",\"f\",\"g\",\"h\"]})\\r\\nddfa = dd.from_cudf(dfa, npartitions=1)\\r\\nddfb = dd.from_cudf(dfb, npartitions=1)\\r\\n\\r\\nddf = ddfa.merge(ddfb, on=\"id\", how=\"outer\", indicator=True)\\r\\nprint(ddf.compute())\\r\\n```\\r\\nthis throws a `NotImplementedError`:\\r\\n```\\r\\nTraceback (most recent call last):                                                                                                                             \\r\\n  File \"/raid/cjarrett/dask-sql/min.py\", line 13, in <module>     \\r\\n    ddf = ddfa.merge(ddfb, on=\"id\", how=\"outer\", indicator=True)\\r\\n  File \"/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/nvtx/nvtx.py\", line 101, in inner\\r\\n    result = func(*args, **kwargs)\\r\\n  File \"/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/dask_cudf/core.py\", line 121, in merge\\r\\n    return super().merge(\\r\\n  File \"/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/dask/dataframe/core.py\", line 5644, in merge\\r\\n    return merge(\\r\\n  File \"/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/dask/dataframe/multi.py\", line 724, in merge\\r\\n    return hash_join(\\r\\n  File \"/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/dask/dataframe/multi.py\", line 398, in hash_join\\r\\n    meta = _lhs_meta.merge(_rhs_meta, **kwargs)\\r\\n  File \"/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/nvtx/nvtx.py\", line 101, in inner\\r\\n    result = func(*args, **kwargs)\\r\\n  File \"/raid/cjarrett/mambaforge/envs/dsql-6-6/lib/python3.10/site-packages/cudf/core/dataframe.py\", line 3969, in merge\\r\\n    raise NotImplementedError(\\r\\nNotImplementedError: Only indicator=False is currently supported\\r\\n```\\ncreatedAt: 2023-06-14T21:07:36Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 257}),\n",
       " Document(page_content=': 583\\ntitle: Let `size_in_bits` take a `bytes` argument, rather than just being a templated function to multiply `sizeof(T)` by `CHAR_BIT`.\\nbody: As noted by [@harrism in #13577](https://github.com/rapidsai/cudf/pull/13577#discussion_r1230283942_).\\r\\n \\r\\n> I would agree with you @bdice  if `size_in_bits` took a size in bytes argument. But as it is, you have to write `data_buffer->size() * size_in_bits<std::byte>()`, which is kinda dumb.  `size_in_bits(data_buffer->size())` would be OK.  I think `* CHAR_BIT` is OK too.\\r\\n\\r\\nThis could be solved by removing the template argument from `size_in_bits` and just implementing it as a `constexpr` function that multiplies its argument by `CHAR_BIT`. All of the usages in `static_assert`s would still work (since the call would just change from `size_in_bits<T>()` to `size_in_bits(sizeof(T))`).\\ncreatedAt: 2023-06-19T08:50:37Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 258}),\n",
       " Document(page_content=': 587\\ntitle: [FEA] Add Parquet and ORC unit tests based on Apache sample files\\nbody: During the 23.06 release, we encountered several important Parquet and ORC writer issues that risked data corruption. These issues included:\\r\\n* Rare failure with page size estimator (PQ writer, [Report](https://github.com/rapidsai/cudf/issues/13250), [Fix](https://github.com/rapidsai/cudf/pull/13364))\\r\\n* Failure with >1GB tables (PQ writer, [Report](https://github.com/rapidsai/cudf/issues/13414), [Fix](https://github.com/rapidsai/cudf/pull/13438)) \\r\\n* Failure with 10k nulls followed by >5 valid values (ORC Writer, [Report](https://github.com/rapidsai/cudf/issues/13460), [Fix](https://github.com/rapidsai/cudf/pull/13466))\\r\\n\\r\\nAfter discussion with the team we agreed on these additions to our testing suite to help prevent similar issues in the future:\\r\\n* Based on test files in [parquet-testing/data](https://github.com/apache/parquet-testing/tree/b2e7cc755159196e3a068c8594f7acbaecfdaaac/data), verify that \"read\" versus \"read-write-read\" result in identical tables\\r\\n* Based on test files in [orc/examples](https://github.com/apache/orc/tree/main/examples), verify that \"read\" versus \"read-write-read\" result in identical tables\\r\\n* Based on test files in [parquet-testing/data](https://github.com/apache/parquet-testing/tree/b2e7cc755159196e3a068c8594f7acbaecfdaaac/data), verify that \"read\" versus \"read_with_Arrow-convert_to_cudf\" result in identical tables\\r\\n* Based on test files in [orc/examples](https://github.com/apache/orc/tree/main/examples), verify that \"read\" versus \"read_with_Arrow-convert_to_cudf\" result in identical tables\\r\\n\\r\\nNote: please also see (#12739), for reader benchmarks, verify that the roundtripped table matches the starting table\\ncreatedAt: 2023-06-27T19:58:33Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 259}),\n",
       " Document(page_content=\": 588\\ntitle: [ENH] benchmark gather then sort vs sort then gather in merge with `sort=True`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nWhen we request `sort=True` in a `cudf.merge`, the current implementation does:\\r\\n\\r\\n1. deduce left and right join columns\\r\\n2. join, producing left and right gather maps\\r\\n3. gather left and right columns, and merge results\\r\\n4. deduce key columns to sort by\\r\\n5. argsort the key columns\\r\\n6. gather the result using the argsort return value\\r\\n\\r\\nTrivially, steps 5 and 6 can be merged into a `sort_by_key` (that's #13557). However, this order probably does more data movement than it needs to. This makes two calls to gather, and one sort-by-key, at the cost of moving the full dataframe through memory twice (once in step 3, once in step 6).\\r\\n\\r\\nInstead, we could (if sorting) first gather only the key columns we will sort by, argsort those and then use that ordering to sort the left and right gather maps.\\r\\n\\r\\n1. deduce left and right join columns\\r\\n2. join, producing left and right gather maps\\r\\n3. deduce left and right key columns to order by\\r\\n4. gather left key columns with left map, right key columns with right map\\r\\n5. sort-by-key the left and right gather maps with the columns from step 4\\r\\n6. gather left and right columns with new gather maps and merge\\r\\n\\r\\nThis makes four calls to gather and one sort-by-key, but only moves the full dataframe through memory once (in step 6). For dataframes with many non-key columns this might well be an advantage. The latency will be a bit higher, but the total data movement will be less. For example, consider (for simplicity) a left join with one key column and 10 total columns in both left and right dataframes.\\r\\n\\r\\nThe current approach (once the left and right gather maps have been determined) gathers 20 columns in step 3, argsorts one column, then gathers 20 columns again (sort-by-key merges the sort + gather into argsort + gather at the libcudf level).\\r\\n\\r\\nThe proposed alternative would gather 1 column in step 4, sorts-by-key two columns (the two gather maps), then gathers 20 columns. So we move effectively 23 columns through memory rather than 41.\\ncreatedAt: 2023-06-28T11:56:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 260}),\n",
       " Document(page_content=\": 589\\ntitle: [BUG] loc-based indexing fails when looking up array like with ordered categorical index\\nbody: **Describe the bug**\\r\\n\\r\\nWhen a frame's index is a `CategoricalIndex` that is _ordered_, looking up an array-like list of indices fails with `TypeError: Merging on categorical variables with mismatched ordering is ambiguous`.\\r\\n\\r\\nThis occurs because to perform the merge between the index and the to-be-looked-up values (to find matches), the values are turned into a categorical column, but the default category dtype is un-ordered.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```python\\r\\nimport cudf\\r\\ns = cudf.Series([1, 2, 3, 4, 5], index=cudf.CategoricalIndex([1, 2, 3, 4, 5], categories=[1, 2, 3, 4, 5], ordered=True))\\r\\ns.loc[[1, 4]] # => KeyError\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\n```python\\r\\ns.to_pandas().loc[[1, 4]]\\r\\n# 1    1\\r\\n# 4    4\\r\\n# dtype: int64\\r\\n```\\r\\n\\r\\nI note actually that pandas doesn't care at all about ordered-ness of categoricals in lookup. Which kind of makes sense because you're just looking up values.\\r\\n\\r\\nSo probably the solution is to merge the decategorized index column with the asked-for labels.\\ncreatedAt: 2023-07-03T12:04:54Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 261}),\n",
       " Document(page_content=\": 590\\ntitle: [BUG] Scalar loc-based lookup in integer categorical indices is incorrect\\nbody: **Describe the bug**\\r\\n\\r\\n`loc`-based lookup does (I think incorrect) fallback to positional indexing rather than label-based lookup when the index is a categorical one with integer values.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```python\\r\\nimport cudf\\r\\n\\r\\ns = cudf.Series([1, 2], index=cudf.CategoricalIndex([3, 4], categories=[3, 4]))\\r\\ns.loc[3] # IndexError: single positional indexer is out-of-bounds\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\n```python\\r\\ns.to_pandas().loc[3]\\r\\n# 1\\r\\n```\\r\\n\\r\\n~Annoyingly, one can't just stop doing positional indexing fallback in all cases because if the index is (say) a string index then integer indexing _does_ fall back to positional.~ This is for `Series.__getitem__` and the behaviour is deprecated in pandas 2.\\ncreatedAt: 2023-07-03T12:11:57Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 262}),\n",
       " Document(page_content=': 592\\ntitle: [FEA] Support nested fields for `filter` in `cudf.read_parquet()`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nI wish I could use the `filter` argument of `cudf.read_parquet()` on nested columns. The in-progress GeoArrow specification is considering allowing a `struct<x: double, y: double>` coordinate representation which provides out-of-the-box column statistics for the inner `x` and `y`. Linestrings, polygons, and multipolygons involve layers of `list<>` nesting that still produce column statistics for the coordinates that would be nice to use with a bounding box filter (see example below).\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nIt would be nice if the left-hand side of a filter expression could be a tuple instead of a string to specify a nested field. I imagine the nested field of a list is more complicated here but even a nested struct field would be helpful.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\n\\r\\nThe current workaround I\\'ve used is to flatten the fields before writing the parquet. This is OK but looses the extension type metadata (e.g., CRS) and doesn\\'t scale to the nested types (e.g., linestring, polygon, multipolygon).\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nA small illustration with some test data:\\r\\n\\r\\n```python\\r\\n>>> import pyarrow as pa\\r\\n>>> import pyarrow.parquet as pq\\r\\n>>> \\r\\n>>> \\r\\n>>> xs = pa.array([0.0, 1.0, 2.0, 3.0])\\r\\n>>> ys = pa.array([1.0, 2.0, 3.0, 4.0])\\r\\n>>> xys = pa.array([\\r\\n...     {\"x\": 0.0, \"y\": 1.0}, \\r\\n...     {\"x\": 1.0, \"y\": 2.0}, \\r\\n...     {\"x\": 2.0, \"y\": 3.0}, \\r\\n...     {\"x\": 3.0, \"y\": 4.0}, \\r\\n... ])\\r\\n>>> table = pa.table([xs, ys, xys], names=[\"x\", \"y\", \"xy\"])\\r\\n>>> pq.write_table(table, \"test.parquet\")\\r\\n>>> \\r\\n>>> # Works!\\r\\n>>> bounds = [0.5, 1.5, 2.5, 3.5]\\r\\n>>> cudf.read_parquet(\\r\\n...     \"test.parquet\",\\r\\n...     filters=[\\r\\n...         [\\r\\n...             (\\'x\\', \\'>=\\', bounds[0]),\\r\\n...             (\\'y\\', \\'>=\\', bounds[1]),\\r\\n...             (\\'x\\', \\'<=\\', bounds[2]),\\r\\n...             (\\'y\\', \\'<=\\', bounds[3])\\r\\n...         ]\\r\\n...     ]\\r\\n... )\\r\\n     x    y                    xy\\r\\n0  1.0  2.0  {\\'x\\': 1.0, \\'y\\': 2.0}\\r\\n1  2.0  3.0  {\\'x\\': 2.0, \\'y\\': 3.0}\\r\\n>>> \\r\\n>>> # Doesn\\'t work:\\r\\n>>> cudf.read_parquet(\\r\\n...     \"test.parquet\",\\r\\n...     filters=[\\r\\n...         [\\r\\n...             ((\\'xy\\', \\'x\\'), \\'>=\\', bounds[0]),\\r\\n...             ((\\'xy\\', \\'y\\'), \\'>=\\', bounds[1]),\\r\\n...             ((\\'xy\\', \\'x\\'), \\'<=\\', bounds[2]),\\r\\n...             ((\\'xy\\', \\'y\\'), \\'<=\\', bounds[3])\\r\\n...         ]\\r\\n...     ]\\r\\n... )\\r\\n.conda/lib/python3.10/site-packages/cudf/io/parquet.py:674: UserWarning: Row-wise filtering failed in read_parquet for [[((\\'xy\\', \\'x\\'), \\'>=\\', 0.5), ((\\'xy\\', \\'y\\'), \\'>=\\', 1.5), ((\\'xy\\', \\'x\\'), \\'<=\\', 2.5), ((\\'xy\\', \\'y\\'), \\'<=\\', 3.5)]]\\r\\n  warnings.warn(\\r\\n     x    y                    xy\\r\\n0  0.0  1.0  {\\'x\\': 0.0, \\'y\\': 1.0}\\r\\n1  1.0  2.0  {\\'x\\': 1.0, \\'y\\': 2.0}\\r\\n2  2.0  3.0  {\\'x\\': 2.0, \\'y\\': 3.0}\\r\\n3  3.0  4.0  {\\'x\\': 3.0, \\'y\\': 4.0}\\r\\n```\\ncreatedAt: 2023-07-11T01:39:09Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Dewey Dunnington\\ncompany: @voltrondata', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 263}),\n",
       " Document(page_content=': 593\\ntitle: [FEA] Support left-semi and left-anti joins in `cudf::hash_join`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\n`cudf::hash_join` makes it possible to build the hash table once and probe it multiple times. But it only supports inner join, left join and full join. I wish `cudf::hash_join` can support left-semi and left-anti join as well.\\ncreatedAt: 2023-07-16T00:38:38Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 264}),\n",
       " Document(page_content=': 598\\ntitle: [FEA] Increase maximum characters in strings columns\\nbody: In libcudf, strings columns have child columns containing character data and offsets, and the offsets child column uses a 32-bit signed size type. This limits strings columns to containing ~2.1 billion characters. For LLM training, documents have up to 1M characters, and a median around 3K characters. Due to the size type limit, LLM training pipelines have to carefully batch the data down to a few thousand rows to stay comfortably within the size type limit. We have a general issue open to explore a 64-bit size type in libcudf (#13159). For size issues with LLM training pipelines, we should consider a targeted change to only address the size limit for strings columns.\\r\\n\\r\\n### Requirements\\r\\n* We must maintain or improve throughput for functions processing strings columns with <2.1 billion characters. This requirement prevents us from using 64-bit offsets for all strings columns. It does not prevent us from using 64-bit offsets for strings columns with >2.1 billion characters.\\r\\n* We must not introduce a new data type or otherwise increase compile times significantly. This requirement prevents us from dispatching between \"strings\" types and \"large strings\" types. \\r\\n\\r\\n### Proposed solution\\r\\nOne idea that satisfies these requirements would be to represent the character data as an `int64` typed column instead of an `int8` typed column. This would allow us to store 8x more bytes of character data. To access the character bytes, we would use an offset-normalizing iterator (inspired by [\"indexalator\"](https://github.com/rapidsai/cudf/blob/branch-23.08/cpp/include/cudf/detail/indexalator.cuh)) to identify byte positions using an `int64` iterator output. Please note that the row count 32-bit size type would still apply to the proposed \"large strings\" columns.\\r\\n\\r\\nWe should also consider an \"unbounded\" character data allocation that is not typed, but rather a single buffer up to 2^64 bytes in size. The 64-bit offset type would be able to index into much larger allocations.\\r\\n\\r\\nPlease note that this solution will not impact the offsets for list columns. We believe that the best design to allow for more than 2.1B elements in lists will be to use 64-bit size type in libcudf as discussed in #13159.\\r\\n\\r\\n### Creating strings columns\\r\\nStrings columns factories would choose child column types at the time of column creation, based on the size of the character data. This change would impact strings column factories, as well as algorithms that use strings column utilities or generate their own offsets buffers. At column creation time, the constructor will choose between `int32` offsets with `int8` character data and `int64` offsets with `int64` character data, based on the size of the character data. Any function that calls [make_offsets_child_column](https://github.com/rapidsai/cudf/blob/9e099cef25b11821c6307bb9c231656a2bae700f/cpp/include/cudf/detail/sizes_to_offsets_iterator.cuh#L298-L302) will need to be aware of the alternate child column types for large strings.\\r\\n\\r\\n### Accessing strings data\\r\\nThe offset-normalizing iterator would always return `int64` type so that strings column consumers would not need to support both `int32` and `int64` offset types. See [cudf::detail::sizes_to_offsets_iterator](https://github.com/rapidsai/cudf/pull/12180) for an example of how an iterator operating on `int32` data can output `int64` data.\\r\\n\\r\\n### Interoperability with Arrow\\r\\nThe new strings column variant with `int64` offsets with `int64` character data may already be Arrow-compatible. This requires more testing and some changes to our Arrow interop utilities.\\r\\n\\r\\n### Part 1: libcudf changes to support large strings columns\\r\\n\\r\\nDefinitions:\\r\\n\"strings column\": `int8` character data and `int32` offset data (2.1B characters) \\r\\n\"large strings column\": `int8` character data up to 2^64 bytes and `int64` offset data (18400T characters)\\r\\n\\r\\n| Step | PR | Notes | \\r\\n|---|---|---|\\r\\n| Replace `offset_type` references with `size_type` | ✅ #13788 | offsets generated by the offset-normalizing iterator will have type `int64_t` | \\r\\n| <s> Add new data-size member to `cudf::column_view`, `cudf::mutable_column_view` and `cudf::column_device_view` </s> | ❌ #14031 | solution for character counts greater than `int32` | \\r\\n| Create an offset-normalizing iterator over character data that always outputs 64-bit offsets| ✅ #14206 <br> ✅ #14234 | First step in #14043 |\\r\\n| * Add the character data buffer to the parent strings column, rather than as a child column <br> * Also refactor algorithms such as concat, contiguous split and gather which access character data <br> * Update code in cuDF-python that interact with character child columns <br> * Update code in cudf-java that interact with character child columns | ✅ #14202 | See performance blocker resolved in ✅ #14540 |\\r\\n| Deprecate unneeded factories and use strings column factories consistently | ✅ | #14461, #14771, #14695, #14612, +one more | \\r\\n| Introduce an environment variable to control the threshold for converting to 64-bit indices, to enable testing on smaller strings columns | ✅ `LIBCUDF_LARGE_STRINGS_THRESHOLD` added | part of #14612 | \\r\\n| Transition strings APIs to use the offset-normalizing iterator (\"offsetalator\") | ✅ | See #14611, #14700, #14744, #14745, #14757, #14783, #14824  | \\r\\n| Remove references to `strings_column_view::offsets_begin()` in libcudf since it hardcodes the return type as int32. | ✅ | See #15112 #15077  | \\r\\n| Remove references to `create_chars_child_column` in libcudf since it wraps a column around chars data. | ✅ | #15241 | \\r\\n| Change the current `make_strings_children` to return a uvector for chars instead of a column | ✅ | See #15171  | \\r\\n| Introduce an environment variable `LIBCUDF_LARGE_STRINGS_ENABLED` to let users force libcudf to throw rather than start using 64-bit offsets, to allow try-catch-repartitioning instead | ✅ |  #15195  | \\r\\n| Introduce an environment variable `LIBCUDF_LARGE_STRINGS_THRESHOLD` | ✅ |  #14612 | \\r\\n| Rework `concatenate` to produce large strings when `LIBCUDF_LARGE_STRINGS_ENABLED` and character count is above the `LIBCUDF_LARGE_STRINGS_THRESHOLD` | ✅ |  See #15195  |\\r\\n| cuDF-python testing. use concat to create a large string column. We should be able to operate on this column, as long as we aren\\'t creating a large string. Can we: (1) returns int/bool, like, contains, (2) slice (3) returns smaller strings. | 🔄 | |\\r\\n| Add an `experimental` version of `make_strings_children` that generates 64-bit offsets when the total character length exceeds the threshold | ✅ |#15363 | \\r\\n| Add a large strings test fixture that stores large columns between unit tests and controls the environment variables | ✅ | #15513  | \\r\\n| Check appropriate cudf tests pass with `LIBCUDF_LARGE_STRINGS_THRESHOLD` at zero  | | |\\r\\n| benchmark regressions analyzed and approved | | |\\r\\n| Spark-RAPIDS tests pass | | |\\r\\n| Remove `experimental` namespace. Replace `make_strings_children` with implementation with the `experimental` namespace version. | ✅ | #15702  | \\r\\n| Live session with cuDF-python expert to start producing and operating on large strings | | |\\r\\n| Ensure that we can interop strings columns with 64-bit offsets to arrow as LARGE_STRING type | | Also see #15093 about `large_strings` compatibility for pandas-2.2 |\\r\\n\\r\\n### Part 2: cuIO changes to read and write large strings columns\\r\\n\\r\\n| Step | PR | Notes |\\r\\n|---|---|---| \\r\\n| Add functionality to JSON reader to construct large string columns | | Could require building a chunked JSON reader |\\r\\n| Add functionality to Parquet reader to construct large string columns | | | \\r\\n| to be continued... | | |\\ncreatedAt: 2023-07-22T20:58:01Z\\nn_body_reactions_thumbs_up: 2\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 265}),\n",
       " Document(page_content=': 599\\ntitle: [BUG] `cudf.read_text` throws an exception when reading a host buffer\\nbody: **Describe the bug**\\r\\n`cudf.read_text` throws an exception when reading a host buffer, unlike the CSV, Parquet, ORC and JSON readers. Hopefully it is straightforward to enable `cudf.read_text` to read from host buffers. \\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nHere is a small code snippet that shows the exception:\\r\\n```\\r\\nfrom io import BytesIO\\r\\nimport cudf\\r\\n\\r\\ndf = cudf.DataFrame({\\'a\\':[\\'aaaa\\',\\'bbbb\\']})\\r\\n\\r\\nbuf = BytesIO()\\r\\ndf.to_csv(buf, index=False)\\r\\ndf2 = cudf.read_csv(buf) # this is ok\\r\\nprint(df2)\\r\\n\\r\\nbuf = BytesIO()\\r\\ndf.to_csv(buf, index=False)\\r\\ndf2 = cudf.read_text(buf, delimiter=\\'\\\\n\\') # this crashes\\r\\nprint(df2)\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nI expect that `read_text` would support host buffers correctly in the python layer. \"multibyte_split\" works fine with HOST_BUFFER data source in the libcudf benchmarks.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\nnightly docker image from 23.08, A100 DGX workstation\\ncreatedAt: 2023-07-22T21:20:47Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 266}),\n",
       " Document(page_content=': 600\\ntitle: [FEA] Add `bytes_per_second` to all libcudf benchmarks\\nbody: Many libcudf benchmarks report the `bytes_per_second` processed as part of the output data. This value is useful for comparing benchmarks because it normalizes the increasing execution time from processing more data. Also, `bytes_per_second` and `real_time_s` together let us compute `bytes_processed` values which serve as a useful Y-axis.\\r\\n\\r\\nAs of the end of 23.12 development, many benchmarks still do not report `bytes_per_second` in the output data. Here is a figure summarizing the metrics reported by the benchmark suite.\\r\\n\\r\\n![image](https://github.com/rapidsai/cudf/assets/12725111/aeb8176c-e869-4200-83aa-074aa4aaee5a)\\r\\n\\r\\n| benchmark | status | notes | \\r\\n|---|---|---|\\r\\n|`APPLY_BOOLEAN_MASK` | | see #13937 | \\r\\n| `BINARYOP` | | see #13938 |\\r\\n| `COPY_IF_ELSE` | | see #13960 |\\r\\n| `GROUPBY` | | see #13984 |\\r\\n| `GROUPBY_NV` | | |\\r\\n| `HASHING` | | see #13967, #13965|\\r\\n| `JOIN` | | |\\r\\n| `JOIN_NV` | | |\\r\\n| `QUANTILES` | | |\\r\\n| `REDUCTION` | | |\\r\\n| `REPLACE` | | |\\r\\n| `SEARCH` | | |\\r\\n| `SEARCH_NV` | | |\\r\\n| `SET_OPS_NV` | | |\\r\\n| `SHIFT` | | see #13950 |\\r\\n| `SORT` | | |\\r\\n| `SORT_NV` | | |\\r\\n| `STREAM_COMPACTION_NV` | | see #14172 |\\r\\n| `TRANSPOSE` | | see #14170 |\\r\\n\\r\\n\\r\\nNote: For this tracking list, cuIO benchmarks are omitted because \"encoded file size\" serves a similar purpose.\\ncreatedAt: 2023-07-23T21:11:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 267}),\n",
       " Document(page_content=': 607\\ntitle: [BUG]The cudf to_csv interface cannot read files larger than 2GB and displays a negative size error.\\nbody: **Describe the bug**\\r\\nThe cudf to_csv interface cannot write files larger than 2GB and displays a negative size error.\\r\\n\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nimport cudf\\r\\n\\r\\ndf = cudf.read_csv(\"3G.csv\")\\r\\ndf.to_csv(\"result.csv\")\\r\\n\\r\\n\\r\\n**Expected behavior**\\r\\ni hope df.to_csv() create a 3G size csv\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: [Bare-metal, Docker, Cloud(specify cloud provider)]\\r\\n - Method of cuDF install: [conda, Docker, or from source]\\r\\n   - If method of install is [Docker], provide `docker pull` & `docker run` commands used\\r\\n\\r\\n**Environment details**\\r\\nPlease run and paste the output of the `cudf/print_env.sh` script here, to gather any other relevant environment details\\r\\n\\r\\n**Additional context**\\r\\nAdd any other context about the problem here.\\ncreatedAt: 2023-07-31T03:21:24Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 268}),\n",
       " Document(page_content=\": 609\\ntitle: [BUG] The hasNull in ORC Statistics is incorrect\\nbody: **Describe the bug**\\r\\nThe ORC Statistics show hasNull is true but the column values are all non-nulls.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nRefer to the reproduce in [13793](https://github.com/rapidsai/cudf/issues/13793), RAPIDS Accelerator bug is:[8826](https://github.com/NVIDIA/spark-rapids/issues/8826)\\r\\n\\r\\n```\\r\\n$ orc-tool meta TestAllNulls.orc\\r\\nProcessing data file TestAllNulls.orc [length: 267]\\r\\nStructure for TestAllNulls.orc\\r\\nFile Version: 0.12 with ORIGINAL by ORC Java \\r\\nRows: 3\\r\\nCompression: SNAPPY\\r\\nCompression size: 262144\\r\\nCalendar: Julian/Gregorian\\r\\nType: struct<c1:string,c2:double>\\r\\n\\r\\nStripe Statistics:\\r\\n  Stripe 1:\\r\\n    Column 0: count: 3 hasNull: true\\r\\n    Column 1: count: 3 hasNull: true min: 1 max: 3 sum: 3\\r\\n    Column 2: count: 0 hasNull: true\\r\\n\\r\\nFile Statistics:\\r\\n  Column 0: count: 3 hasNull: true\\r\\n  Column 1: count: 3 hasNull: true min: 1 max: 3 sum: 3\\r\\n  Column 2: count: 0 hasNull: true\\r\\n\\r\\nStripes:\\r\\n  Stripe: offset: 3 data: 19 rows: 3 tail: 71 index: 50\\r\\n    Stream: column 0 section ROW_INDEX start: 3 length 7\\r\\n    Stream: column 1 section ROW_INDEX start: 10 length 26\\r\\n    Stream: column 2 section ROW_INDEX start: 36 length 17\\r\\n    Stream: column 1 section DATA start: 53 length 6\\r\\n    Stream: column 1 section LENGTH start: 59 length 5\\r\\n    Stream: column 2 section PRESENT start: 64 length 5\\r\\n    Stream: column 2 section DATA start: 69 length 3\\r\\n    Encoding column 0: DIRECT\\r\\n    Encoding column 1: DIRECT_V2\\r\\n    Encoding column 2: DIRECT\\r\\n\\r\\nFile length: 267 bytes\\r\\nPadding length: 0 bytes\\r\\nPadding ratio: 0%\\r\\n```\\r\\n\\r\\nThis static is wrong:  \\r\\nColumn 1: count: 3 hasNull: true min: 1 max: 3 sum: 3\\r\\nThis column values are 1,2,3. The hasNull should be false.\\r\\n\\r\\n**Expected behavior**\\r\\nStripe Statistics and File Statistics report correct hasNull info.\\r\\n\\r\\n**Additional context**\\r\\nI'm checking the `count` statistics for nested types, seems also has problem. I'll report another issue after one more check.\\ncreatedAt: 2023-08-04T02:42:34Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Chong Gao\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 269}),\n",
       " Document(page_content=': 610\\ntitle: [FEA] Reduce page faults when using managed memory\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nIn cuDF-python and RMM, it\\'s easy to opt into [managed memory](https://docs.rapids.ai/api/rmm/stable/api/#rmm.reinitialize) (also known as Unified Memory, UM, and Unified Virtual Memory, UVM). However, libcudf is not optimized for use with managed memory and encounters many \"[just too late](https://www.nextplatform.com/2019/01/24/unified-memory-the-final-piece-of-the-gpu-programming-puzzle/)\" page faults when the \"[oversubscription factor](https://developer.nvidia.com/blog/improving-gpu-memory-oversubscription-performance/)\" is >1.\\r\\n\\r\\n### Hinting options and strategies\\r\\n* Use hinting with [cudaMemPrefetchAsync](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42) before operating on a column_view. I believe this hint will eagerly migrate the data to device. Open questions include: does it require an extra sync? do kernels page fault for a while until the data fully migrates? \\r\\n* Use hinting with [cudaMemAdviseSetAccessedBy](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c85750a22279bce0dc29956ad4f257084623). This hinting also does not eagerly migrate the data, and seems to be focused on preventing faults between devices on the same node. It also allows direct memory access (DMA) from the device to pinned host buffers.\\r\\n* Use hinting with [cudaMemAdviseSetPreferredLocation](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857a4a2bc3c7d218dcd9a1b425b432759eb). This does not eagerly migrate the data, instead it influences the page migration system. If we set the preferred location to device, I believe this hint would prevent those allocations from being evicted and could lead to poor performance of the page migration engine.  \\r\\n*  Use hinting with [cudaMemAdviseSetReadMostly](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0). For column_view data, processing in libcudf algorithms will be read-only by design. We can communicate this to UVM, but for libcudf\\'s common access pattern - read once and then write a new allocation for the results - I don\\'t think \"read mostly\" hinting will give us higher throughput or reduced faulting.\\r\\n* Use host-pinned buffers and use direct memory access (DMA) from the device to extend working memory ([see.\"zero-copy\" in this blog](https://developer.nvidia.com/blog/improving-gpu-memory-oversubscription-performance/)). To execute this strategy we hint \"preferred location\" to host and \"accessed by\" to device. Memory throughput will be lower using DMA to host than using device memory, but stalling kernels on page faults will be much slower than waiting on DMA. We still need to design how and when we would choose to leave data on the host and access by DMA (always??? except intermediate allocations).\\r\\n* In addition to preventing page faults, we may also want to prevent evictions by preemptively clearing device memory. There does not appear to be a mechanism for eagerly migrating data from device to host. Perhaps preferred location hinting can also drive evictions on groups of pages instead of one page at a time.\\r\\n\\r\\n### Implementation ideas for libcudf\\r\\n* Where would this hinting be located in the repository? We could implement a RAII \"advisor\" class that takes a (non-owning) reference to a column_view and performs the appropriate hinting. The advisor class would only perform hinting for column_views created using managed memory resources. It may be difficult to add hinting to column_view because the column_view object can\\'t tell if it\\'s underlying data was a managed or unmanaged allocation.\\r\\n* Is a way to identify from a device pointer if the associated allocation is managed or unmanaged? Perhaps [cuPointerGetAttribute()](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html) should return  CU_MEMORYTYPE_UNIFIED as [CU_POINTER_ATTRIBUTE_MEMORY_TYPE](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc2cce590e35080745e72633dfc6e0b600409e16293b60b383f30a9b417b2917c) for managed memory. Is there a runtime API for accessing device pointer attributes? (TBD)\\r\\n\\r\\n\\r\\n### Useful reference for cudaMemAdvise\\r\\n![image](https://github.com/rapidsai/cudf/assets/12725111/9ff97f3c-3e42-4664-b6b6-fcfdfc07dc90)\\r\\n\\r\\n<br>\\r\\n<br>\\r\\n<br>\\r\\n\\r\\n_Please note: Using managed memory in libcudf is in early stages of scoping. This issue will improve over time._\\r\\n\\r\\n<br>\\r\\n<br>\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nI would like to add a libcudf benchmark for studying managed memory performance, and then some targeted experiments (with profiling) to observe the impact of different hinting strategies. When we have identified a promising design, we will open a more targeted issue.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nContinue to let Dask and Spark-RAPIDS catch and retry when there are device OOM errors.\\r\\n\\r\\n**Additional context**\\r\\nPlease note that with managed memory pools, the pool allocation is lazy. This is different from unmanaged memory pools where we allocate the full pool upfront, trading slightly longer startup time for much faster algorithm allocations.\\r\\n\\r\\nUseful blog posts:\\r\\nhttps://developer.nvidia.com/blog/unified-memory-cuda-beginners/\\r\\nhttps://developer.nvidia.com/blog/improving-gpu-memory-oversubscription-performance/\\r\\nhttps://developer.nvidia.com/blog/maximizing-unified-memory-performance-in-cuda/\\r\\nhttps://developer.nvidia.com/blog/beyond-gpu-memory-limits-unified-memory-pascal/\\ncreatedAt: 2023-08-04T18:50:40Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 270}),\n",
       " Document(page_content=': 611\\ntitle: [FEA] Increase reader throughput by pipelining IO and compute\\nbody: -- this is a draft, please do not comment yet -- \\r\\n\\r\\nThe end-to-end throughput of a file reader is limited by the sequential read speed of the underlying data source. We can use \"pipelining\" to overlap processing data on the device with reading data from the data source. Pipelining works by processing the data in batches, so that the previous chunk can be processed as the next chunk is reading. Pipelined readers show higher end-to-end throughput if the overlap between reading and processing is greater than the overhead from processing smaller batches. \\r\\n\\r\\nIn cuIO, `multibyte_split` used a pipelined design that reads text data in ~33 MB chunks (2^25 bytes) into a pinned host buffer, copies the data to device, and then generates offsets data. Here\\'s a profile reading \"Common Crawl\" document data with `cudf.read_text` from a 410 MB file:\\r\\n![image](https://github.com/rapidsai/cudf/assets/12725111/0c2c8b2d-f23b-4688-8ef7-fe3286da4a72)\\r\\n\\r\\nNote how the `get_next_chunk` function includes the OS `read` and `Memcopy HtoD`, and how the `Memcpy HtoD` overlaps with the next OS `read`. Stream-ordered kernel launches also overlap with the next OS `read`. For each 10 ms OS `read`, there is 1.5 ms of overlapping copy/compute work and 0.2 ms of overhead between each OS `read`. \\r\\n\\r\\nWe can applying pipelining to the Parquet reader as well. Parquet reading includes several major steps: raw IO, header decoding, decompression, and data decoding. The runtime of each step varies based on the properties of the data in the file, including the data types, encoding efficiency, and compression efficiency. Furthermore Parquet files have [internal row group and page structure](https://github.com/apache/parquet-format#file-format) that restricts how the file can be split. Here is an example profile reading the same \"Common Crawl\" data as above, but from a 240 MB Snappy-compressed Parquet file:\\r\\n![image](https://github.com/rapidsai/cudf/assets/12725111/a1f6700a-ab9f-42bd-bd70-eb285a042770)\\r\\n\\r\\nNote how 90 ms is spent in OS read on the file and ~20 ms is spent processing, with decompression taking most (11.5 ms) of the processing time. Also note the GPU utilization data during the `read_parquet` function, with zero GPU utilization during the copy followed by good good SM utilization and moderate warp utilization during the compute.\\r\\n\\r\\nWe\\'ve completed prototyping work in #12358, experimenting with several approaches for pipelining the Parquet reader. Here are some performance analysis ideas for the next time we tackle this feature:\\r\\n* Curate a library of real world (not generated) data files and use that to evaluate the performance of pipelining approach\\r\\n* Analyze the copying, decompression, decoding times in the curated library and track which files show the biggest benefit from pipelining\\r\\n* Consider setting a floor (such as 200 MB of compressed data) before pipelining kicks in, to make sure we aren\\'t accruing too much overhead\\r\\n* Evaluate network-attached storage in addition to local NVMe data sources\\r\\n\\r\\nAs far as pipelining approaches, here are some areas to consider:\\r\\n| Stream usage | Chunking pattern | Notes | \\r\\n|---|---|---|\\r\\n| entire read per stream | row group | tbd |\\r\\n| decompression stream and decoding stream | row group | tbd |\\r\\n\\r\\n-- this is a draft, please do not comment yet --\\ncreatedAt: 2023-08-07T19:43:53Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 271}),\n",
       " Document(page_content=': 613\\ntitle: [BUG] ORC file count statistic for nested type is wrong\\nbody: **Describe the bug**\\r\\nThe GPU ORC file statistics show that the count for nested type is wrong while the CPU ORC file is correct.\\r\\n\\r\\nGPU file shows different counts for nested type:\\r\\nGPU:  \\r\\n```\\r\\nFile Statistics:\\r\\n  Column 0: count: 8 hasNull: true\\r\\n  Column 1: count: 1 hasNull: true\\r\\n```\\r\\nCPU: \\r\\n```\\r\\nFile Statistics:\\r\\n  Column 0: count: 8 hasNull: false\\r\\n  Column 1: count: 8 hasNull: false\\r\\n```\\r\\nThe data in both files are:\\r\\n```\\r\\n+------------+\\r\\n|    struct_s|\\r\\n+------------+\\r\\n|{null, null}|\\r\\n|      {1, 1}|\\r\\n|{null, null}|\\r\\n|      {3, 3}|\\r\\n|{null, null}|\\r\\n|      {5, 5}|\\r\\n|{null, null}|\\r\\n|      {7, 7}|\\r\\n+------------+\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n##### Generate GPU file\\r\\n```cpp\\r\\nTEST_F(OrcWriterTest, NestedColumnSelection)\\r\\n{\\r\\n  auto const num_rows  = 8;\\r\\n  std::vector<int> child_col1_data(num_rows);\\r\\n  std::vector<int> child_col2_data(num_rows);\\r\\n  for (int i = 0; i < num_rows; ++i) {\\r\\n    child_col1_data[i] = i;\\r\\n    child_col2_data[i] = i;\\r\\n  }\\r\\n\\r\\n  auto validity = cudf::detail::make_counting_transform_iterator(0, [](auto i) { return i % 2; });\\r\\n  int32_col child_col1{child_col1_data.begin(), child_col1_data.end(), validity};\\r\\n  int32_col child_col2{child_col2_data.begin(), child_col2_data.end(), validity};\\r\\n  struct_col s_col{child_col1, child_col2};\\r\\n  cudf::table_view expected({s_col});\\r\\n\\r\\n  cudf::io::table_input_metadata expected_metadata(expected);\\r\\n  expected_metadata.column_metadata[0].set_name(\"struct_s\");\\r\\n  expected_metadata.column_metadata[0].child(0).set_name(\"field_a\");\\r\\n  expected_metadata.column_metadata[0].child(1).set_name(\"field_b\");\\r\\n\\r\\n  auto filepath = \"/tmp/test-count-for-nested-type-gpu.orc\";\\r\\n  cudf::io::orc_writer_options out_opts =\\r\\n    cudf::io::orc_writer_options::builder(cudf::io::sink_info{filepath}, expected)\\r\\n      .metadata(std::move(expected_metadata));\\r\\n  cudf::io::write_orc(out_opts);\\r\\n}\\r\\n```\\r\\n\\r\\nRead the GPU file\\r\\nSPARK_HOME/bin/pyspark\\r\\n\\r\\nspark.read.orc(\"/tmp/test-count-for-nested-type-gpu.orc\").show()\\r\\n+------------+\\r\\n|    struct_s|\\r\\n+------------+\\r\\n|{null, null}|\\r\\n|      {1, 1}|\\r\\n|{null, null}|\\r\\n|      {3, 3}|\\r\\n|{null, null}|\\r\\n|      {5, 5}|\\r\\n|{null, null}|\\r\\n|      {7, 7}|\\r\\n+------------+\\r\\n\\r\\n##### Generate CPU file\\r\\nSPARK_HOME/bin/pyspark\\r\\n\\r\\n```python\\r\\nfrom pyspark.sql.types import *\\r\\nschema = StructType([StructField(\"struct_s\",\\r\\n    StructType([\\r\\n        StructField(\"field_a\", IntegerType()),\\r\\n        StructField(\"field_b\", IntegerType()),\\r\\n]))])\\r\\n\\r\\ndef get_value(i):\\r\\n  if i % 2 == 0:\\r\\n    return None\\r\\n  else:\\r\\n    return i\\r\\n\\r\\ndata = [\\r\\n    ({ \\'field_a\\': get_value(i), \\'field_b\\': get_value(i) }, ) for i in range(0, 8)\\r\\n]\\r\\ndf = spark.createDataFrame(\\r\\n        SparkContext.getOrCreate().parallelize(data, numSlices=1),\\r\\n        schema)\\r\\n\\r\\npath = \\'/tmp/test-count-for-nested-type-cpu.orc\\'\\r\\ndf.coalesce(1).write.mode(\"overwrite\").orc(path)\\r\\nspark.read.orc(path).show()\\r\\n```\\r\\n\\r\\n```\\r\\n+------------+\\r\\n|    struct_s|\\r\\n+------------+\\r\\n|{null, null}|\\r\\n|      {1, 1}|\\r\\n|{null, null}|\\r\\n|      {3, 3}|\\r\\n|{null, null}|\\r\\n|      {5, 5}|\\r\\n|{null, null}|\\r\\n|      {7, 7}|\\r\\n+------------+\\r\\n```\\r\\n\\r\\n##### print count statistic for GPU file\\r\\n```\\r\\n$ orc-tool meta test-count-for-nested-type-gpu.orc\\r\\nProcessing data file test-count-for-nested-type-gpu.orc [length: 360]\\r\\nStructure for test-count-for-nested-type-gpu.orc\\r\\nFile Version: 0.12 with ORIGINAL by ORC Java \\r\\nRows: 8\\r\\nCompression: SNAPPY\\r\\nCompression size: 262144\\r\\nCalendar: Julian/Gregorian\\r\\nType: struct<struct_s:struct<field_a:int,field_b:int>>\\r\\n\\r\\nStripe Statistics:\\r\\n  Stripe 1:\\r\\n    Column 0: count: 8 hasNull: true\\r\\n    Column 1: count: 1 hasNull: true\\r\\n    Column 2: count: 4 hasNull: true min: 1 max: 7 sum: 16\\r\\n    Column 3: count: 4 hasNull: true min: 1 max: 7 sum: 16\\r\\n\\r\\nFile Statistics:\\r\\n  Column 0: count: 8 hasNull: true\\r\\n  Column 1: count: 1 hasNull: true\\r\\n  Column 2: count: 4 hasNull: true min: 1 max: 7 sum: 16\\r\\n  Column 3: count: 4 hasNull: true min: 1 max: 7 sum: 16\\r\\n\\r\\nStripes:\\r\\n  Stripe: offset: 3 data: 24 rows: 8 tail: 92 index: 70\\r\\n    Stream: column 0 section ROW_INDEX start: 3 length 7\\r\\n    Stream: column 1 section ROW_INDEX start: 10 length 11\\r\\n    Stream: column 2 section ROW_INDEX start: 21 length 26\\r\\n    Stream: column 3 section ROW_INDEX start: 47 length 26\\r\\n    Stream: column 2 section PRESENT start: 73 length 5\\r\\n    Stream: column 2 section DATA start: 78 length 7\\r\\n    Stream: column 3 section PRESENT start: 85 length 5\\r\\n    Stream: column 3 section DATA start: 90 length 7\\r\\n    Encoding column 0: DIRECT\\r\\n    Encoding column 1: DIRECT\\r\\n    Encoding column 2: DIRECT_V2\\r\\n    Encoding column 3: DIRECT_V2\\r\\n\\r\\nFile length: 360 bytes\\r\\nPadding length: 0 bytes\\r\\nPadding ratio: 0%\\r\\n```\\r\\n\\r\\n##### print count statistic for CPU file\\r\\n```\\r\\n$ orc-tool meta /tmp/test-count-for-nested-type-cpu.orc \\r\\nProcessing data file file:/tmp/test-count-for-nested-type-cpu.orc/part-00000-6b490836-0c65-4355-9d0e-fbaff96aec33-c000.snappy.orc [length: 388]\\r\\nStructure for file:/tmp/test-count-for-nested-type-cpu.orc/part-00000-6b490836-0c65-4355-9d0e-fbaff96aec33-c000.snappy.orc\\r\\nFile Version: 0.12 with ORC_14 by ORC Java 1.7.4\\r\\nRows: 8\\r\\nCompression: SNAPPY\\r\\nCompression size: 262144\\r\\nCalendar: Julian/Gregorian\\r\\nType: struct<struct_s:struct<field_a:int,field_b:int>>\\r\\n\\r\\nStripe Statistics:\\r\\n  Stripe 1:\\r\\n    Column 0: count: 8 hasNull: false\\r\\n    Column 1: count: 8 hasNull: false\\r\\n    Column 2: count: 4 hasNull: true bytesOnDisk: 12 min: 1 max: 7 sum: 16\\r\\n    Column 3: count: 4 hasNull: true bytesOnDisk: 12 min: 1 max: 7 sum: 16\\r\\n\\r\\nFile Statistics:\\r\\n  Column 0: count: 8 hasNull: false\\r\\n  Column 1: count: 8 hasNull: false\\r\\n  Column 2: count: 4 hasNull: true bytesOnDisk: 12 min: 1 max: 7 sum: 16\\r\\n  Column 3: count: 4 hasNull: true bytesOnDisk: 12 min: 1 max: 7 sum: 16\\r\\n\\r\\nStripes:\\r\\n  Stripe: offset: 3 data: 24 rows: 8 tail: 71 index: 76\\r\\n    Stream: column 0 section ROW_INDEX start: 3 length 11\\r\\n    Stream: column 1 section ROW_INDEX start: 14 length 11\\r\\n    Stream: column 2 section ROW_INDEX start: 25 length 27\\r\\n    Stream: column 3 section ROW_INDEX start: 52 length 27\\r\\n    Stream: column 2 section PRESENT start: 79 length 5\\r\\n    Stream: column 2 section DATA start: 84 length 7\\r\\n    Stream: column 3 section PRESENT start: 91 length 5\\r\\n    Stream: column 3 section DATA start: 96 length 7\\r\\n    Encoding column 0: DIRECT\\r\\n    Encoding column 1: DIRECT\\r\\n    Encoding column 2: DIRECT_V2\\r\\n    Encoding column 3: DIRECT_V2\\r\\n\\r\\nFile length: 388 bytes\\r\\nPadding length: 0 bytes\\r\\nPadding ratio: 0%\\r\\n\\r\\nUser Metadata:\\r\\n  org.apache.spark.version=3.3.0\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n**Expected behavior**\\r\\nThe all statistics should be correct, including the `hasNull`, refer to this [issue](https://github.com/rapidsai/cudf/issues/13817)\\r\\n\\r\\n**Environment details**\\r\\nEnvironment details\\r\\ncuDF 23.08 branch\\r\\nSpark 3.3.0\\r\\norc-core-1.7.4.jar\\r\\n\\r\\n**Additional context**\\ncreatedAt: 2023-08-09T05:57:28Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Chong Gao\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 272}),\n",
       " Document(page_content=': 621\\ntitle: [FEA] Improve ORC reader filtering and performance\\nbody: ### Background\\r\\n\\r\\nlibcudf includes readers and writers for two popular binary formats for columnar data: [Apache Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) and [Apache ORC](https://en.wikipedia.org/wiki/Apache_ORC). These formats were originally introduced in 2013, and both have open source specifications ([ORC](https://orc.apache.org/specification/ORCv1/), [PQ](https://github.com/apache/parquet-format)) and reference implementations ([ORC](https://github.com/apache/orc), [PQ](https://github.com/apache/parquet-mr)) maintained by Apache. ORC also serves as the foundation for [Meta’s variant DWRF and their new format \"Alpha\"](https://www.cidrdb.org/cidr2023/papers/p77-chattopadhyay.pdf).\\r\\n\\r\\nBoth formats have hierarchical data layouts, support encoding and compression, include fully-featured type systems, and find widespread use in database systems and data warehousing. Please refer to [this paper](https://arxiv.org/pdf/2304.05028.pdf) by Zeng et al for a detailed comparison of the concepts, features and performance of Parquet and ORC binary formats. Please note that Parquet files are composed of “row groups” (~128 MB) and “pages” (~1 MB), and ORC files are composed of “stripes” (~70 MB) and “row groups” (10K rows). \\r\\n\\r\\nSome of the differences include:\\r\\n* finer granularity in data buffers by default in ORC (better for filtered IO and targeted lookups)\\r\\n* finer granularity in bloom filters in ORC (supported at \"row group\" level in ORC, but not at the \"page\" level in Parquet)\\r\\n* Dremel-encoding for list types in Parquet (faster decoding for >8 levels of nesting)\\r\\n* support for [ACID transaction tables](https://orc.apache.org/docs/acid.html) in ORC datasets (enabling data updates without full re-write)\\r\\n* In Parquet the data \"page\" is also the unit of encoding and compression, whereas in ORC each encoding \"stream\" and \"compression chunk\" often includes multiple \"row groups\".\\r\\n\\r\\n### Expanding functionality of the ORC reader\\r\\n\\r\\nThe libcudf Parquet reader has gained functionality in key areas, including the chunked reader (release 22.12) to control how much of a table is materialized, and AST-based filtering (release 23.08) to avoid reading row groups that aren’t needed. Filtered IO (including bloom filters) is even more important to ORC users thanks to the fine granularity of ORC row groups (10k rows per row group). We should align our Parquet and ORC reader designs and separate shared utilities from format-specific details wherever possible.\\r\\n\\r\\n| Topic | Status | Notes\\r\\n|---|---|---|\\r\\n| Add AST-based stripe filtering to the ORC reader | | #13348 added AST-based row group filtering to the Parquet reader. For this topic, we should accept an AST filter parameter, use it to determine matches stripes, read only those strips, and then post-filter the rows in the resulting table. We already have a `read_raw_orc_statistics` function to support these steps. We may refactor some of the AST + min/max stats tools to `utilities`. Also see issue #12512 | \\r\\n| Add chunked reader for ORC | | See #12228 about this topic from Spark-RAPIDS. Chunked readers are useful because they allow for partial materialization of tables from their binary representation. #11867 added chunking for Parquet decoding, which means the compressed row groups were fully read and decompressed and then decoded up to a requested size in bytes. (tbd) is extending chunking to include Parquet decompression as well. Chunking helps libcudf applications avoid two limits: the [size_type](https://github.com/rapidsai/cudf/issues/13159)  limit on row count and the GPU working memory limit for each worker |  \\r\\n| Support [bloom filters](https://en.wikipedia.org/wiki/Bloom_filter) in ORC reader | | See #4410. Due to ORC’s common usage for data lookup and filtered IO, supporting bloom filters in reads is especially important for ORC. This feature would allow the caller to specify equality conditions and check against ORC bloom filters.  | \\r\\n| Support index roundtripping in ORC | | See #8708, a request from cuDF-python to preserve the index when writing+reading a file | \\r\\n\\r\\n### Performance optimizations for binary format reading\\r\\n\\r\\n| Topic | Status | Notes\\r\\n|---|---|---|\\r\\n| Optimize ORC reader performance for list data | ✅ #13708 | We observed poor performance with singlely-nested lists and high row counts |\\r\\n| Optimize ORC reader performance for decimal data | | See #13251, we need a parallel algorithm to replace the single-thread decoding of the variable-width encoded representation |\\r\\n| Evaluate multi-kernel decoding in ORC | | See #13622 for experiments with multiple decode kernels, and #13302 for an example of a specialized strings decode kernel | \\r\\n| Experiment with pipelining ORC reads | | See #13828 for information about reader pipelining |\\ncreatedAt: 2023-08-15T04:13:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 273}),\n",
       " Document(page_content=': 623\\ntitle: [FEA] Modernize CSV reader and expand reader options\\nbody: ### Background\\r\\n\\r\\nThe CSV reader in cuDF/libcudf is a common IO interface for ingesting raw data, and is frequently the first IO interface that new users test when getting started with RAPIDS. There have been many improvements to the CSV reader over the years, but much of the implementation has remained the same from its introduction in #3213 and rework in #5024. We see several opportunities to address the [CSV reader continuous improvement](https://github.com/rapidsai/cudf/milestone/12) milestone, and this story associates open issues with particular functions and kernels in the CSV reading process.\\r\\n\\r\\n### Step 1: Decompression and preprocessing\\r\\nThe CSV reader begins with host-side processing in `select_data_and_row_offsets`. With the exception of decompression, we would like to migrate this processing to be done device side and refactor this function to use a kvikIO data source. Note, this refactor could also include adding support for the `header` parameter and `byte_range` at the same time ([code pointer](https://github.com/rapidsai/cudf/blob/b798a70d608cbbe2c7f372a8c21354455ba56f74/cpp/src/io/csv/reader_impl.cu#L442)).\\r\\n\\r\\nThe initial processing interacts with several issues:\\r\\n* #13797 is small story issue about this topic\\r\\n* #4999 batch the full read as small chunks\\r\\n* #5142 \\r\\n* #11728 describes how the initial byte range parsing to find the first row assumes the byte_range starts in an unquoted state. If a user provides a byte_range that starts in a quoted field, then the reader will fail! The solution described in this issue interacts the next step \"identify row offsets\". \\r\\n* #12255 needs investigation\\r\\n* #12582 return empty `metadata.schema_info` when column names are autogenerated\\r\\n\\r\\n### Step 2: Identify row offsets (delimiters)\\r\\nThe next step is identifying record delimiters and computing row offsets in `load_data_and_gather_row_offsets` (invoked by `select_data_and_row_offsets`). This algorithm operates in three main steps: `gather_row_offsets` called with empty data, `select_row_context`, and `gather_row_offsets` called with row context data. The row context state machine is difficult to refactor because it uses a custom data representation that stores several logical values within a single 32-bit or 64-bit physical type ([code pointer](https://github.com/rapidsai/cudf/blob/b798a70d608cbbe2c7f372a8c21354455ba56f74/cpp/src/io/csv/csv_gpu.hpp#L64)). The row context tracks whether the content is in a comment block or in a quoted block. \\r\\n* `gather_row_offsets` runs a [4-state](https://github.com/rapidsai/cudf/blob/b798a70d608cbbe2c7f372a8c21354455ba56f74/cpp/src/io/csv/csv_gpu.hpp#L40) \"row context\" state machine over 16 KB blocks of characters and returns the number of un-quoted, un-commented record delimiters from the block given each possible initial state\\r\\n* `select_row_context` is invoked in a host-side loop over `row_ctr` data for each 16 KB block, starting from a `state 0` initial context. \\r\\n* `gather_row_offsets` is called in a second pass with a valid `all_row_offsets` data parameter.\\r\\n\\r\\nMajor design topics:\\r\\n* We should consider a larger refactor of the \"identify row offsets\" code based on using a new FST instance ([code pointer](https://github.com/rapidsai/cudf/tree/branch-23.10/cpp/src/io/fst)). Using an FST instance would easily allow us to add additional states beyond the existing 4-state machine. Please refer to the [ParPaRaw paper](https://arxiv.org/pdf/1905.13415.pdf) from Elias Stehle et al for more information about parallel algorithms for CSV parsing.\\r\\n* To unblock Spark-RAPIDS usage of the CSV, we may also choose to support user-provided `all_row_offsets` parameter to the read function or as a reader option. This would allow Spark to bypass the first `gather_row_offsets` pass and `select_row_context` in `load_data_and_gather_row_offsets`. When calling `read_csv` on a strings column, Spark already has the row offsets. \\r\\n* Also note that refactoring the interface to provide row offsets is relevant to #11728, where we would want to provide pre-computed offsets. For this issue we might prefer a new detail API rather than new parameters in the public API - more design work is needed.\\r\\n\\r\\nThe row offsets algorithm interacts with several open issues:\\r\\n* #6572 complex preprocessing or changes to the row context state machine. \\r\\n* (Spark blocker) #11984 Pandas and Spark don\\'t have the same escaping conventions, and the row offset state machine doesn\\'t have an escaped state. Needs confirmation - does this impact the row offsets step?\\r\\n* (Spark blocker) #11948 to handle misplaced quotes. The issue shows a file getting truncated so fields with misplaced quotes seem to compromise the row offset data. #2398 suggests a workaround\\r\\n* #6305 another quoting/escaping issue \\r\\n* #13856 commented lines should not emit row offsets\\r\\n* Issue n/a: Add unit tests for `gather_row_offsets` kernel\\r\\n\\r\\n### Step 3: Determine column types\\r\\nThe next step is determining the data types for each column that does not map to a user-provided data type. The function `determine_column_types` completes this work by collecting the user-provided data types, and then calling `infer_column_types` to handle the unspecified data types. `infer_column_types` invokes the `detect_column_types`->`data_type_detection` kernel to collect statistics about the data in each field, and then use the conventions of the pandas CSV reader to select a column type. \\r\\n* We should consider refactoring the \"determine\", \"infer\", and \"detect\" function names to improve clarity\\r\\n* (good first issue) #14066 update thread indexing\\r\\n* #5080 performance improvements for type inference\\r\\n* (Spark blocker) #11984 `seek_field_end` supports escape characters within data fields. perhaps field traversal is already Spark-compatible\\r\\n* (Spark blocker) #11948 misplaced quotes could fail with `seek_field_end`\\r\\n* #6313 pandas doesn\\'t infer as `float` if there are any nulls\\r\\n* #9987 would change `seek_field_end`, maybe not much else\\r\\n* Issue n/a: Add unit tests for `seek_field_end` kernel\\r\\n\\r\\n### Step 4: Decode data and populate device buffers\\r\\nThe final step, `decode_data`, does another pass over the data to decode values according to the determined columns types. The kernel is `decode_row_column_data`->`convert_csv_to_cudf`\\r\\n* (Spark blocker) #13892 trim white space . Probably a modest change to `trim_whitespaces_quotes`. Related to #6659\\r\\n* (Spark blocker) #12145 add option to decode `\"\"` as empty strings or `null`. Probably an additional parsing option.\\r\\n* (Spark blocker) #11984 `convert_csv_to_cudf` also uses `seek_field_end` which nominally supports escape characters\\r\\n* (Spark blocker) #11948 misplaced quotes could fail with `seek_field_end`\\r\\n* #4001 support additional `nanValue` options\\r\\n* #10599 float parsing consistency, this is probably a `wontfix`\\ncreatedAt: 2023-08-18T19:27:48Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 274}),\n",
       " Document(page_content=': 631\\ntitle: [QST] Dask-cudf/Xgboost out of memory error\\nbody: I\\'m trying to train an xgboost model on a machine with 8xA100 GPUs with 80GB memory each but I\\'m getting an out of memory error:\\r\\n`MemoryError(\\'std::bad_alloc: out_of_memory: CUDA error at: .../include/rmm/mr/device/cuda_memory_resource.hpp\\')`. The error is slightly different if I use `rmm_pool_size` parameter but it is still a memory error `\"MemoryError(\\'std::bad_alloc: out_of_memory: RMM failure at:../include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded\\')`\\r\\n\\r\\nI\\'m using a `LocalCUDACluster` to distribute the workload amongst the 8 GPUs. I can tell by looking at the dask dashboard, that the data is mostly loading into a single GPU and all of the other GPUs are sitting empty and idle. \\r\\n\\r\\nI read the data using `dask_cudf.read_parquet(file_name, blocksize=int(2e4))` and it is a dataframe of size `(20459297, 213)`. Though I would like to try it with much larger datasets.  The training completes successfully with a smaller dataframe of size `(16304159, 213)` and fewer workers but it still mostly uses a single GPU. \\r\\n\\r\\nEdit: Here\\'s a screenshot of the dashboard when the model is successfully training - note this is with only 2 GPUs and the smaller dataframe noted above\\r\\n\\r\\n<img width=\"1672\" alt=\"Screenshot\" src=\"https://github.com/rapidsai/cudf/assets/18453604/98706b71-19e3-4266-9c9c-23472994675c\">\\r\\n\\r\\nThe GPUs are running CUDA 12.0 and driver  525.60.13\\r\\nHere are the versions of some relevant packages\\r\\n\\r\\n```\\r\\nxgboost                   1.7.4           rapidsai_py310h1395376_6    rapidsai\\r\\nrapids                    23.08.00        cuda12_py310_230809_g2a5b6f0_0    rapidsai\\r\\npython                    3.10.12         hd12c33a_0_cpython    conda-forge\\r\\nrapids-xgboost            23.08.00        cuda12_py310_230809_g2a5b6f0_0    rapidsai\\r\\ncuda-version              12.0                 hffde075_2    conda-forge\\r\\ncudf                      23.08.00        cuda12_py310_230809_g8150d38e08_0    rapidsai\\r\\ndask                      2023.7.1           pyhd8ed1ab_0    conda-forge\\r\\ndask-core                 2023.7.1           pyhd8ed1ab_0    conda-forge\\r\\ndask-cuda                 23.08.00        py310_230809_gefbd6ca_0    rapidsai\\r\\ndask-cudf                 23.08.00        cuda12_py310_230809_g8150d38e08_0    rapidsai\\r\\n```\\r\\n\\r\\nAny help on the memory issue would be much appreciated\\ncreatedAt: 2023-08-31T08:34:47Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 275}),\n",
       " Document(page_content=\": 634\\ntitle: [FEA] provide external libraries a way of getting a `DeviceBuffer` pointer that can become spillable again\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nWhen running in a multi-gpu setting, message passing with ucx-py takes a `DeviceBuffer` and obtains the device memory pointer through the `__cuda_array_interface__`. This, correctly, marks the buffer as unspillable. \\r\\n\\r\\nIt would be nice if there were a way to expose a pointer that is marked as unspillable until the external library drops the reference (kind of like `acquire_spill_lock`). `ucx-py` could then use it, and scope the pointer use to the lifetime of the message request (once the request is completed, the pointer can be dropped and is available for spilling again).\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nIf we were to hand back an object that had a `weakref.finalize(obj, unmark_spillable)` callback, when it was dropped, we could let the buffer be spillable again.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\nMaking ucx-py aware of cudf and using `acquire_spill_lock`.\\r\\n\\r\\ncc @madsbk / @vyasr / @galipremsagar\\ncreatedAt: 2023-09-01T16:35:34Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 276}),\n",
       " Document(page_content=': 639\\ntitle: [FEA] Parallelize gpuInitStringDescriptors when Parquet input type is FIXED_LEN_BYTE_ARRAY\\nbody: As part of the preprocessing of PLAIN encoded string data in the parquet reader, a pass through the page data is performed to either gather string sizes, or initialize `{ptr, length}` tuples for use by the decoder. For variable width string data, this pass must be performed by a single thread. But in the case of fixed width data, all threads in the warp should be able to participate.\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/blob/1bfeee7575e137bc75741cb2caf015e55ecab2cd/cpp/src/io/parquet/page_decode.cuh#L409\\ncreatedAt: 2023-09-14T22:18:22Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ed Seidl\\ncompany: @LLNL', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 277}),\n",
       " Document(page_content=': 645\\ntitle: [BUG] Sanitizer reports misaligned error when doing reduction on short type values in cuda12 ENV\\nbody: **Describe the bug**\\r\\nSanitizer reports misaligned error when doing reduction on short type values in cuda12 ENV\\r\\n\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nCode:\\r\\n```cpp\\r\\n#include <cudf/types.hpp>\\r\\n#include <cudf/aggregation.hpp>\\r\\n#include <cudf/reduction.hpp>\\r\\n#include <cudf_test/base_fixture.hpp>\\r\\n#include <cudf_test/column_wrapper.hpp>\\r\\n\\r\\ntemplate <typename T, typename SourceElementT = T>\\r\\nusing column_wrapper =\\r\\n  typename std::conditional<std::is_same_v<T, cudf::string_view>,\\r\\n                            cudf::test::strings_column_wrapper,\\r\\n                            cudf::test::fixed_width_column_wrapper<T, SourceElementT>>::type;\\r\\nusing int16_col   = column_wrapper<int16_t>;\\r\\n\\r\\nstruct MyReductionTest : public cudf::test::BaseFixture {};\\r\\nTEST_F(MyReductionTest, AlignmentIssue)\\r\\n{\\r\\n  std::vector<int16_t> v({1, 2, 3});\\r\\n  int16_col col(v.begin(), v.end());\\r\\n  \\r\\n  auto const output_dtype                 = cudf::data_type{cudf::type_id::INT16};\\r\\n  auto min_agg = cudf::make_min_aggregation();\\r\\n  std::unique_ptr<cudf::scalar> reduction1 = cudf::reduce(col, *dynamic_cast<cudf::reduce_aggregation *>(&(*min_agg)), output_dtype);\\r\\n\\r\\n  auto const output_dtype2                 = cudf::data_type{cudf::type_id::BOOL8};\\r\\n  auto any_agg = cudf::make_any_aggregation();\\r\\n  std::unique_ptr<cudf::scalar> reduction2 = cudf::reduce(col, *dynamic_cast<cudf::reduce_aggregation *>(&(*any_agg)), output_dtype2);\\r\\n}\\r\\n\\r\\n```\\r\\n\\r\\nCompile and Run with sanitizer:\\r\\n```\\r\\ncompute-sanitizer --tool memcheck \\\\\\r\\n    --launch-timeout 600 \\\\\\r\\n    --error-exitcode -2 \\\\\\r\\n    --log-file \"./sanitizer_for_pid_%p.log\" \\\\\\r\\n    ./my-exe\\r\\n```\\r\\n\\r\\nPrint sanitizer log:\\r\\n```\\r\\nhead sanitizer_for_pid_42.log \\r\\n========= COMPUTE-SANITIZER\\r\\n========= Invalid __shared__ read of size 16 bytes\\r\\n=========     at 0x38c0 in void cub::CUB_101702_600_700_750_800_860_900_NS::DeviceReduceSingleTileKernel<cub::CUB_101702_600_700_750_800_860_900_NS::DeviceReducePolicy<short, short, int, cudf::DeviceMin>::Policy600, thrust::transform_iterator<thrust::identity<short>, thrust::transform_iterator<cudf::detail::value_accessor<short>, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, thrust::use_default, thrust::use_default>, thrust::use_default, thrust::use_default>, short *, int, cudf::DeviceMin, short>(T2, T3, T4, T5, T6)\\r\\n=========     by thread (0,0,0) in block (0,0,0)\\r\\n=========     Address 0x8 is misaligned\\r\\n=========     Saved host backtrace up to driver entry point at kernel launch time\\r\\n=========     Host Frame: [0x2d18f2]\\r\\n=========                in /usr/lib64/libcuda.so.1\\r\\n=========     Host Frame:__cudart1049 [0xd9bd3b]\\r\\n=========                in /home/chongg/code/spark-rapids-jni/target/cmake-build/gtests/./my-exe\\r\\n```\\r\\n\\r\\nThe main errors are:\\r\\n```\\r\\nInvalid __shared__ read of size 16 bytes\\r\\nAddress 0x8 is misaligned\\r\\n```\\r\\n\\r\\nOthers:\\r\\n```\\r\\nThere are 2 reductions in the code.\\r\\nIf another reduction follows a min reduction, then errors occur.\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nFix Sanitizer error.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Docker\\r\\n - Method of cuDF install: from source\\r\\n\\r\\n**Environment details**\\r\\nDocker image:  urm.nvidia.com/sw-spark-docker/plugin-jni:centos7-cuda12.0.1-blossom\\r\\nCUDA 12, for more details, refer to https://github.com/NVIDIA/spark-rapids-jni/issues/1349\\r\\n\\r\\n**Additional context**\\r\\nRefer to https://github.com/NVIDIA/spark-rapids-jni/issues/1349\\ncreatedAt: 2023-09-26T09:42:13Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Chong Gao\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 278}),\n",
       " Document(page_content=': 647\\ntitle: [BUG] Potential for use-after-free on libcudf/cudf interface boundaries\\nbody: **Describe the bug**\\r\\n\\r\\nThis comes out of [a review of #14133](https://github.com/rapidsai/cudf/pull/14133#discussion_r1338480398) which introduces a new `Scalar` type on the python side in pylibcudf, but I think that the issues are pervasive.\\r\\n\\r\\n## Background\\r\\n\\r\\n`libcudf` uses RMM for all memory allocations, this happens through a `memory_resource` object. Allocating `libcudf` functions all take an explicit `memory_resource` argument (as a raw pointer) that is defaulted to `rmm::get_current_device_resource()` (the resource set by `rmm::set_per_device_resource`). RMM `device_buffer`s hold a raw pointer of their allocating memory resource (needed for deallocation), and it is the user\\'s (in this case `libcudf`\\'s) responsibility to keep that `memory_resource` alive until the `device_buffer` has been dropped:\\r\\n\\r\\nThis is fine:\\r\\n```c++\\r\\nmemory_resource mr = ...;\\r\\n{\\r\\n    device_buffer buf{..., &mr};\\r\\n    ... // do things with buf\\r\\n   ~buf(); // called here, fine.\\r\\n}\\r\\n```\\r\\n\\r\\nThis is not (this is not a real example, since I think the `device_buffer` constructors don\\'t allow exactly this, but bear with me):\\r\\n```c++\\r\\ndevice_buffer buf;\\r\\n{\\r\\n   memory_resource mr = ...;\\r\\n   buf = {..., &mr};\\r\\n   ... // do things with buf\\r\\n   ~mr(); // called here, boom;\\r\\n}\\r\\nbuf no longer valid\\r\\n```\\r\\n\\r\\n### How does `get_current_device_resource` work?\\r\\n\\r\\n`set_per_device_resource` stores a raw pointer to a memory resource in a `std::unordered_map` and `get_current_device_resource` just looks up in the map. Again, the user is responsible for keeping the `mr` alive.\\r\\n\\r\\n### How does this work in cudf (python) land?\\r\\n\\r\\nThe Cython wrappers in RMM expose memory resources, and `set/get_current_device_resource`. `set_per_device_memory_resource` sets the value in both the C++ level `std::unordered_map` _and_ a Python level dict (https://github.com/rapidsai/rmm/blob/5f07014db51535902f8cdb515596af162d1ae6ca/python/rmm/_lib/memory_resource.pyx#L1041-L1049). `get_current_device_resource` looks up in the Python dict (https://github.com/rapidsai/rmm/blob/5f07014db51535902f8cdb515596af162d1ae6ca/python/rmm/_lib/memory_resource.pyx#L1013-1026). `DeviceBuffer`s keep the \"current\" memory resource alive by storing a reference: https://github.com/rapidsai/rmm/blob/5f07014db51535902f8cdb515596af162d1ae6ca/python/rmm/_lib/device_buffer.pyx#L93-L93, but when taking ownership of a C++-level device buffer https://github.com/rapidsai/rmm/blob/5f07014db51535902f8cdb515596af162d1ae6ca/python/rmm/_lib/device_buffer.pyx#L161-L171, we don\\'t use the mr stored in the C++ struct.\\r\\n\\r\\nThe Python level dict is \"necessary\" due to the usual expected way in which people will use things from python. That is they will expect that: `set_per_device_resource(device, CudaMemoryResource())` keeps the created memory resource alive. \\r\\n\\r\\nIf a C++ library calls `set_per_device_resource` at some point, C++-land (`libcudf`) and Python-land (cudf) can end up disagreeing about what the current memory resource is (because Python-level `get_current_device_resource` doesn\\'t look at the C++-level map).\\r\\n\\r\\n## So what\\'s the problem?\\r\\n\\r\\nIf `libcudf` ever allocates memory that it hands off to cudf with a memory resource that is _not_ managed by cudf, we have the potential for use-after-free, because cudf has no way of taking (or sharing) ownership of that memory resource from the RMM buffer.\\r\\n\\r\\nAFAICT, cudf never explicitly passes a memory resource into `libcudf`, and so the allocation behaviour is always relying on C++ and Python agreeing about what `get_current_device_resource` returns, _and_ that cudf was the creator of that resource. Effectively the pattern is:\\r\\n\\r\\n```python\\r\\n# In python\\r\\n...\\r\\n1. mr = rmm.get_current_device_resource()\\r\\n# No mr passed here, so C++-level get_current_device_resource() is used\\r\\n2. new_column = libcudf.some_algorithm(existing_data)\\r\\n# take ownership of the data, fingers crossed that new_column.data.mr is mr\\r\\n3. cudf_column = Column.from_unique_ptr(new_column, mr)\\r\\n```\\r\\n\\r\\nIf _either_ someone in C++ has set a different per-device resource _or_ the current thread is pre-empted between lines 1 and 2 (and the current device resource is changed), then line 3 will take \"ownership\" of the data, but not be keeping the correct memory resource for the data alive.\\r\\n\\r\\n## How can we fix this?\\r\\n\\r\\nIf the Cython layer in cudf always explicitly passes a memory resource to `libcudf` algorithms, this problem goes away. We can then always guarantee that the memory resource we have on the Python side is the one used to allocate the data in libcudf so we can keep it alive.\\r\\n\\r\\nAlternately, if the memory_resource pointers in RMM were smart pointers it might be possible to keep things alive that way. Right now we can\\'t make Python and C++ always agree on what the current default resource is (because on the C++ side RMM doesn\\'t have a smart pointer stored, because it doesn\\'t take ownership).\\ncreatedAt: 2023-09-28T17:29:46Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 279}),\n",
       " Document(page_content=': 649\\ntitle: [FEA] Add option to read JSON field as unparsed string\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nWhen reading JSON in Spark, if a field has mixed types,  Spark will infer the type as String to avoid data loss due to the uncertainty of the actual data type.\\r\\n\\r\\nFor example, given this input file, Spark will read column `bar` as a numeric type and column `foo` as a string type.\\r\\n\\r\\n```\\r\\n$ cat test.json\\r\\n{ \"foo\": [1,2,3], \"bar\": 123 }\\r\\n{ \"foo\": { \"a\": 1 }, \"bar\": 456 }\\r\\n```\\r\\n\\r\\nHere is the Spark code that demonstrates this:\\r\\n\\r\\n```\\r\\nscala> val df = spark.read.json(\"test.json\")\\r\\ndf: org.apache.spark.sql.DataFrame = [bar: bigint, foo: string]                 \\r\\n\\r\\nscala> df.show\\r\\n+---+-------+\\r\\n|bar|    foo|\\r\\n+---+-------+\\r\\n|123|[1,2,3]|\\r\\n|456|{\"a\":1}|\\r\\n+---+-------+\\r\\n```\\r\\n\\r\\nCurrently, Spark RAPIDS fails for this example because cuDF does not support mixed types in a column:\\r\\n\\r\\n```\\r\\nCaused by: ai.rapids.cudf.CudfException: CUDF failure at: /home/jenkins/agent/workspace/jenkins-spark-rapids-jni_nightly-pre_release-181-cuda11/thirdparty/cudf/cpp/src/io/json/json_column.cu:577: A mix of lists and structs within the same column is not supported\\r\\n  at ai.rapids.cudf.Table.readJSON(Native Method)\\r\\n```\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nI would like the ability to specify to read certain columns as unparsed strings.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nI am also exploring some workarounds in the Spark RAPIDS plugin.\\r\\n\\r\\n**Additional context**\\ncreatedAt: 2023-09-29T21:37:44Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Andy Grove\\ncompany: @Apple', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 280}),\n",
       " Document(page_content=': 659\\ntitle: [BUG] AST Limitation: Unable to Handle Single String Literal Expressions\\nbody: **Describe the bug**\\r\\n\\r\\nThe AST evaluator currently encounters a limitation where it is unable to handle an expression consisting of just one string literal, this is not a problem with other data types. While this scenario may be considered an edge case, it would be nice to address it for consistency with how other libraries, such as Pandas, handle similar situations.  \\r\\n\\r\\n```\\r\\ndf.eval(\" \\'alex\\' \")\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\n  File \"/home/alexander/envs/cudf_dev/lib/python3.10/site-packages/nvtx/nvtx.py\", line 101, in inner\\r\\n    result = func(*args, **kwargs)\\r\\n  File \"/home/alexander/envs/cudf_dev/lib/python3.10/site-packages/cudf/core/dataframe.py\", line 7065, in eval\\r\\n    None: libcudf.transform.compute_column(\\r\\n  File \"/home/alexander/envs/cudf_dev/lib/python3.10/contextlib.py\", line 79, in inner\\r\\n    return func(*args, **kwds)\\r\\n  File \"transform.pyx\", line 196, in cudf._lib.transform.compute_column\\r\\nRuntimeError: CUDF failure at: /opt/mambaforge/conda-bld/libcudf-ext_1692118605400/work/cpp/src/column/column_factories.cpp:161: Invalid, non-fixed-width type.\\r\\n\\r\\n```\\r\\n**Steps/Code to reproduce bug**\\r\\n```\\r\\nimport cudf\\r\\ndf = cudf.DataFrame({\\'A\\': [], \\'B\\': []})\\r\\ndf.eval(\" \\'alex\\' \")\\r\\n```\\r\\n\\r\\n`RuntimeError: CUDF failure at: /opt/mambaforge/conda-bld/libcudf-ext_1692118605400/work/cpp/src/column/column_factories.cpp:161: Invalid, non-fixed-width type.`\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nFor a similar  example but with other data types. \\r\\n\\r\\n```\\r\\nimport cudf\\r\\ndf = cudf.DataFrame({\\'A\\': [], \\'B\\': []})\\r\\ndf.eval(\" 123 \")\\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: conda\\r\\n - Method of cuDF install: conda\\r\\n -  branch-23.10, origin/branch-23.10\\ncreatedAt: 2023-10-24T20:46:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Alexander Ocsa\\ncompany: @voltrondata', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 281}),\n",
       " Document(page_content=': 660\\ntitle: [FEA][JNI] Throw specific exception from `Table.readJSON` instead of `AssertionError`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nPer the discussion at https://github.com/NVIDIA/spark-rapids/pull/9304#discussion_r1372291170, the Spark plugin currently has to parse the error message from an `AssertionError`, which is an anti-pattern. This happens when the plugin calls `Table.readJSON` where the input is not JSON format.\\r\\n\\r\\nThis exception is thrown in the constructor for `Table`:\\r\\n\\r\\n```java\\r\\n  public Table(long[] cudfColumns) {\\r\\n    assert cudfColumns != null && cudfColumns.length > 0 : \"CudfColumns can\\'t be null or empty\";\\r\\n```\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nWe should throw a specific exception instead.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nNone\\r\\n\\r\\n**Additional context**\\r\\nNone\\ncreatedAt: 2023-10-25T21:10:05Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Andy Grove\\ncompany: @Apple', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 282}),\n",
       " Document(page_content=\": 662\\ntitle: [FEA] center implementation for rolling window\\nbody: Hi, \\r\\n\\r\\nI am currently doing some feature engineering on a timeseries. My index is a datetime and I want to apply a rolling window. \\r\\nFYI the pandas code is running. \\r\\n`df['feature'] = df['feature'].rolling(f'{120}s', center=True, min_periods=1).sum()`\\r\\n\\r\\nwhich leads to the following error: \\r\\n\\r\\n`NotImplementedError: center is not implemented for offset-based windows`\\r\\n\\r\\nbasically, I want to change to cudf for runtime optimization. As I have a datetime as an index, rolling operation with centring is much appreciated due to the fact of handling missing values, just shifting by timestamp is not trivial as discussed [here.](https://github.com/pandas-dev/pandas/issues/20012) \\r\\n\\r\\nI would appreciate if you could take a look. (Maybe it occurs due to some changes in the API interface)\\ncreatedAt: 2023-10-26T16:19:44Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Marc\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 283}),\n",
       " Document(page_content=': 663\\ntitle: [BUG] Inconsistent Results Between AST and Pandas Evaluators for Expressions with Nullable Columns\\nbody: ## Describe the bug\\r\\n\\r\\nThe AST evaluator and pandas evaluator are yielding divergent outcomes when evaluating expressions that include nullable columns.\\r\\n \\r\\nSteps/Code to reproduce bug\\r\\n\\r\\n```\\r\\nimport cudf\\r\\nimport pandas as pd\\r\\nfrom io import StringIO\\r\\n\\r\\n# Your CSV data as a string\\r\\ncsv_data = \"\"\"\\\\\\r\\nBrand#32,MED PKG,,,754.84,4428,3537.78\\r\\nBrand#53,MED BOX,,,3.98,1646,23333.44\\r\\nBrand#41,WRAP BAG,1,8,763.34,3547,14687.36\\r\\nBrand#43,SM BOX,2,46,15.45,6523,72572.36\\r\\nBrand#42,WRAP PKG,3,31,778.19,3849,33608.96\\r\\nBrand#23,LG JAR,4,43,101.93,4592,50407.61\\r\\n\"\"\"\\r\\ndtype_schema = {\\r\\n    \\'p_brand\\': \\'string\\',   \\r\\n    \\'p_container\\': \\'string\\', \\r\\n    \\'l_linenumber\\': \\'float64\\',\\r\\n    \\'l_quantity\\': \\'float64\\',  \\r\\n    \\'ps_supplycost\\': \\'float64\\',   \\r\\n    \\'ps_availqty\\': \\'float64\\',  \\r\\n    \\'l_extendedprice\\': \\'float64\\'\\r\\n}\\r\\n\\r\\ndf = pd.read_csv(StringIO(csv_data), header=None, delimiter=\\',\\', dtype=dtype_schema, names=[name for name in dtype_schema])\\r\\n\\r\\ndf.eval(\"(p_brand == \\'Brand#23\\' or p_container == \\'MED BOX\\') or (l_quantity < ps_supplycost)\").value_counts()\\r\\ngdf = cudf.from_pandas(df)\\r\\n\\r\\ngdf.eval(\"(p_brand == \\'Brand#23\\' or p_container == \\'MED BOX\\') or (l_quantity < ps_supplycost)\").value_counts()\\r\\n``` \\r\\n\\r\\n## Expected behavior\\r\\n\\r\\nThe cuDF AST evaluator is expected to yield results consistent with those produced by the pandas evaluator.\\r\\n\\r\\nSee: \\r\\n```\\r\\n>>> df.eval(\"(p_brand == \\'Brand#23\\' or p_container == \\'MED BOX\\') or (l_quantity < ps_supplycost)\").value_counts()\\r\\nTrue     4\\r\\nFalse     2\\r\\ndtype: int64\\r\\n\\r\\n>>> gdf = cudf.from_pandas(df)\\r\\n>>> gdf.eval(\"(p_brand == \\'Brand#23\\' or p_container == \\'MED BOX\\') or (l_quantity < ps_supplycost)\").value_counts()\\r\\nTrue     3\\r\\nFalse     1\\r\\ndtype: int32\\r\\n\\r\\n>>> df[ ((df[\\'p_brand\\'] == \\'Brand#23\\') | (df[\\'p_container\\'] == \\'MED BOX\\')) | (df[\\'l_quantity\\'] < df[\\'ps_supplycost\\']) ]\\r\\n    p_brand p_container  l_linenumber  l_quantity  ps_supplycost  ps_availqty  l_extendedprice\\r\\n1  Brand#53     MED BOX           NaN         NaN           3.98       1646.0         23333.44\\r\\n2  Brand#41    WRAP BAG           1.0         8.0         763.34       3547.0         14687.36\\r\\n4  Brand#42    WRAP PKG           3.0        31.0         778.19       3849.0         33608.96\\r\\n5  Brand#23      LG JAR           4.0        43.0         101.93       4592.0         50407.61\\r\\n>>> gdf[ ((gdf[\\'p_brand\\'] == \\'Brand#23\\') | (gdf[\\'p_container\\'] == \\'MED BOX\\')) | (gdf[\\'l_quantity\\'] < gdf[\\'ps_supplycost\\']) ]\\r\\n    p_brand p_container  l_linenumber  l_quantity  ps_supplycost  ps_availqty  l_extendedprice\\r\\n2  Brand#41    WRAP BAG           1.0         8.0         763.34       3547.0         14687.36\\r\\n4  Brand#42    WRAP PKG           3.0        31.0         778.19       3849.0         33608.96\\r\\n5  Brand#23      LG JAR           4.0        43.0         101.93       4592.0         50407.61\\r\\n>>>\\r\\n```\\r\\n\\r\\n\\r\\nEnvironment overview  \\r\\n\\r\\nEnvironment location: conda\\r\\nMethod of cuDF install: conda\\r\\nbranch-23.10, origin/branch-23.10\\ncreatedAt: 2023-11-04T00:47:47Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Alexander Ocsa\\ncompany: @voltrondata', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 284}),\n",
       " Document(page_content=\": 665\\ntitle: [FEA] Respect `set_output_as_binary` in ORC writer\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThe cuDF ORC writer does not follow the `set_output_as_binary` option added for Parquet to write a string column with binary type.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nTo respect the `set_output_as_binary` option added in #6816 for the ORC writer as well.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nWe could copy the table to host and use the Arrow ORC writer or similar instead, but this would mean more copying.\\r\\n\\r\\n**Additional context**\\r\\nQuick demo using libcudf 23.10: https://github.com/lidavidm/cudf-orc-binary-feature-request\\ncreatedAt: 2023-11-08T14:58:57Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: David Li\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 285}),\n",
       " Document(page_content=\": 667\\ntitle: [FEA] need multibyte_split support stream\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nwant to use cuda multi stream (pool)  read a big file.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\njust add a new `multibyte_split` method with  ` rmm::cuda_stream_view stream` param  to public use.\\r\\n\\r\\nhead: https://github.com/rapidsai/cudf/blob/branch-23.12/cpp/include/cudf/io/text/multibyte_split.hpp\\r\\n```\\r\\nstd::unique_ptr<cudf::column> multibyte_split(\\r\\n  data_chunk_source const& source,\\r\\n  std::string const& delimiter,\\r\\n  parse_options options               = {},\\r\\n  rmm::cuda_stream_view stream = cudf::get_default_stream(),\\r\\n  rmm::mr::device_memory_resource* mr = rmm::mr::get_current_device_resource());\\r\\n```\\r\\n\\r\\nsrc: https://github.com/rapidsai/cudf/blob/branch-23.12/cpp/src/io/text/multibyte_split.cu\\r\\n```\\r\\nstd::unique_ptr<cudf::column> multibyte_split(cudf::io::text::data_chunk_source const& source,\\r\\n                                              std::string const& delimiter,\\r\\n                                              parse_options options,\\r\\n                                              rmm::cuda_stream_view stream,\\r\\n                                              rmm::mr::device_memory_resource* mr)\\r\\n{\\r\\n  auto result = detail::multibyte_split(\\r\\n    source, delimiter, options.byte_range, options.strip_delimiters, stream, mr);\\r\\n\\r\\n  return result;\\r\\n}\\r\\n```\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\n**Additional context**\\ncreatedAt: 2023-11-09T13:50:28Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: weedge\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 286}),\n",
       " Document(page_content=': 668\\ntitle: [QST] Respecting pandas options that affect default behaviors\\nbody: **What is your question?**\\r\\nHow should pandas global options interact with cudf.pandas? These can change the behavior/result of pandas operations _without_ changing the call being made.\\r\\n\\r\\nFor example, pandas has a `use_inf_as_na` option that makes inf behave like nulls. Should the pandas-path be forced if cudf.pandas detects a global option that isn\\'t supported?\\r\\n\\r\\n```python\\r\\n# with %load_ext cudf.pandas\\r\\n\\r\\nIn [3]: ser = pd.Series([np.inf, np.nan])\\r\\n\\r\\nIn [4]: ser\\r\\nOut[4]:\\r\\n0     Inf\\r\\n1    <NA>\\r\\ndtype: float64\\r\\n\\r\\n# Incorrect\\r\\nIn [5]: ser.dropna()\\r\\nOut[5]:\\r\\n0    inf\\r\\ndtype: float64\\r\\n\\r\\nIn [6]: pd.options.mode.use_inf_as_na = True\\r\\n\\r\\nIn [7]: ser\\r\\nOut[7]:\\r\\n0     Inf\\r\\n1    <NA>\\r\\ndtype: float64\\r\\n\\r\\nIn [8]: ser.dropna()\\r\\nOut[8]:\\r\\n0    inf\\r\\ndtype: float64\\r\\n\\r\\n# if we try setting this option in a non-cudf supported way we get a different (incorrect) answer\\r\\nIn [10]: with pd.option_context(\"use_inf_as_na\", True):\\r\\n    ...:     print(ser.dropna())\\r\\n    ...:\\r\\n0   NaN\\r\\ndtype: float64\\r\\n```\\r\\n\\r\\nThe pandas result is:\\r\\n\\r\\n```\\r\\n>>> import pandas as pd; import numpy as np\\r\\n>>> ser = pd.Series([np.inf, np.nan])\\r\\n>>> pd.options.mode.use_inf_as_na = True\\r\\n>>> ser.dropna()\\r\\nSeries([], dtype: float64)\\r\\n```\\ncreatedAt: 2023-11-14T13:57:47Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 287}),\n",
       " Document(page_content=\": 669\\ntitle: Report results of running pandas unit tests in CI and fail the job when necessary\\nbody: Every PR runs a job called `pandas-tests` that run the Pandas unit tests using `cudf.pandas`. Currently, there are two issues with this job:\\r\\n\\r\\n- the results of those tests aren't reported in the job summary or anywhere convenient to look at\\r\\n- the job always passes, regardless of how many tests were passed or failed\\r\\n\\r\\nIdeally, we should post the results as a job summary and fail the job if the number of tests passed relative to the development branch falls below a threshold (say, 0.1%).\\ncreatedAt: 2023-11-14T14:24:16Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 288}),\n",
       " Document(page_content=': 670\\ntitle: [QST] How how to expose __dict__ when `cudf.pandas` is enabled?\\nbody: Some of the pandas tests spelunk the `__dict__` of a module to determine what to collect. E.g. `tests/dtypes/test_generic.py` does:\\r\\n```\\r\\nfrom pandas.core.dtypes import generic as gt\\r\\n...\\r\\n    @pytest.mark.parametrize(\"abctype\", [e for e in gt.__dict__ if e.startswith(\"ABC\")])\\r\\n    def test_abc_coverage(self, abctype):\\r\\n```\\r\\n\\r\\nwith `cudf.pandas` enabled:\\r\\n```\\r\\nfrom pandas.core.dtypes import generic as gt\\r\\ngt.__dict__.keys() # does _not_ contain ABCCategorical\\r\\n```\\ncreatedAt: 2023-11-14T14:35:41Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 289}),\n",
       " Document(page_content=': 671\\ntitle: Groupby hash aggregations use sort-based implementation if nested-type columns are used as values\\nbody: We should be able to use nested-type columns as values and still be able to invoke a hash-based groupby, as hash-based is generally faster so we do not want to be silently using sort-based. https://github.com/rapidsai/cudf/blob/abc0d41d1d9033d581948ae19384e0aa0f33da77/cpp/src/groupby/hash/groupby.cu#L654-L656\\r\\n\\r\\nReference thread: https://github.com/rapidsai/cudf/pull/13795#discussion_r1373454172\\ncreatedAt: 2023-11-14T19:44:30Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Divye Gala\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 290}),\n",
       " Document(page_content=\": 672\\ntitle: `read_json` does not compile if using `std::string_view` instead of `std::string`\\nbody: Reference thread: https://github.com/rapidsai/cudf/pull/13795#discussion_r1373437533\\r\\n\\r\\nError:\\r\\n```/home/nfs/dgala/cudf/cpp/examples/nested_types/deduplication.cpp: In function 'cudf::io::table_with_metadata read_json(std::string_view)':\\r\\n/home/nfs/dgala/cudf/cpp/examples/nested_types/deduplication.cpp:66:52: error: no matching function for call to 'cudf::io::source_info::source_info(std::string_view&)'\\r\\n   66 |   auto source_info = cudf::io::source_info(filepath);```\\ncreatedAt: 2023-11-14T19:47:51Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Divye Gala\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 291}),\n",
       " Document(page_content=\": 673\\ntitle: [FEA] The C++ tests for parquet don't test row group selection very well.\\nbody: There's only a very basic row group selection test in the C++ gtests.  It would probably be useful to have a more thorough set of tests.\\ncreatedAt: 2023-11-15T21:29:37Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 292}),\n",
       " Document(page_content=\": 677\\ntitle: [FEA] Parquet reader:  replace skip_rows / num_rows with start_row / end_row\\nbody: Our external interface to the parquet reader allows the user to specify `skip_rows` / `num_rows` parameters when calling it.  Internally, we use the same values.  But it is a very unwieldy way to think about things.  I think it would be easier to immediately convert those values to `start_row` and `end_row` and use that everywhere.  It's a nontrivial amount of work to do this without causing bugs but I think the code would be more natural (in the std::algorithms / iterator sense of the word).\\ncreatedAt: 2023-11-21T20:35:55Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 293}),\n",
       " Document(page_content=\": 678\\ntitle: [FEA] Check dtype requirements on multiindex codes\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\n(Seen as part of a review of #14470).\\r\\n\\r\\nMultiindex codes and levels are effectively a categorical encoding of the columns of the multiindex entries. The codes are used to index the levels. As such, they should probably have type equivalent to `cudf::size_type`. Currently, however, they are a int64. This is a larger memory footprint than necessary. Moreover, it (in some constructor circumstances) necessitates more copies than necessary.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nUse correct dtype. Since the public `codes` and `levels` properties wrap the results in pandas `FrozenList` objects to mimic the pandas API, it may be possible to just store the codes/levels pairs as `CategoricalColumn`s internally, rather than the current structure.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\nn/a\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nn/a\\ncreatedAt: 2023-11-22T14:23:32Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 294}),\n",
       " Document(page_content=\": 679\\ntitle: [ENH] Audit cudf APIs for use of inappropriate algorithms\\nbody: **Is your feature request related to a problem? Please describe.**\\n\\nHistorically (I think) certain features were available in libcudf before others. For example, while hash joins appeared quite early on `cudf::contains` was only factored out of the semi join infrastructure in #11100.\\n\\nAs a result, there are a number of places in cudf where an API was implemented using a sub-optimal approach (be that in terms of memory footprint or performance) just because it was needed in the Python API.\\n\\nFor example in #14478, we replace a sub-optimal (in both memory _and_ performance) inner join, with a call to `cudf::contains` now that it is available.\\n\\n**Describe the solution you'd like**\\n\\nWe should go through and check for other instances of this historical anti-pattern and either:\\n\\n- replace with calls to appropriate (existing) libcudf primitives\\n- gather feature requests for new libcudf primitives based on the usage we observe.\\n\\n**Describe alternatives you've considered**\\n\\nn/a\\n\\n**Additional context**\\n\\nIt is probable that candidates can be found by looking calls to `merge` in the cudf codebase. As well as argsort/scatter/gather patterns (that's #13557).\\n```[tasklist]\\n### Tasks\\n- [ ] https://github.com/rapidsai/cudf/issues/13557\\n- [ ] https://github.com/rapidsai/cudf/pull/14478\\n- [ ] https://github.com/rapidsai/cudf/issues/14480\\n- [ ] https://github.com/rapidsai/cudf/issues/14485\\n- [ ] https://github.com/rapidsai/cudf/issues/14486\\n- [ ] https://github.com/rapidsai/cudf/issues/13630\\n- [ ] https://github.com/rapidsai/cudf/issues/13565\\n- [ ] https://github.com/rapidsai/cudf/issues/13456\\n- [ ] https://github.com/rapidsai/cudf/issues/14487\\n```\\ncreatedAt: 2023-11-22T18:58:02Z\\nn_body_reactions_thumbs_up: 2\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 295}),\n",
       " Document(page_content=': 680\\ntitle: [FEA] Remove special-case implementation of `MultiIndex.isin`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\n`isin` is implemented \"by-hand\" for `MultiIndex` by going via the frame representation and then calling `merge`. This means that any updates to correctness/performance of `DataFrame.isin` must be hand-ported to the `MultiIndex` case.\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\n`MultiIndex.isin` should do necessary pre-/post-processing and call `DataFrame.isin` rather than re-implementing the core algorithm.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\n\\r\\nn/a\\ncreatedAt: 2023-11-22T19:05:26Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 296}),\n",
       " Document(page_content=': 683\\ntitle: [FEA] Implement column-wise hashes\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\ncudf columns are mutable and therefore do not (or should not) implement `__hash__` (in the same way that numpy arrays do not do so).\\r\\n\\r\\n_However_, there are circumstances under which we would nonetheless like to be able to compute a hash of a column:\\r\\n\\r\\n1. When the wrapping object is actually an immutable one (for example `Index` objects) and so `__hash__` is safe;\\r\\n2. When tokenizing keys for dask task graphs (see https://github.com/rapidsai/cudf/pull/13695), where the objects may be mutable, but the required semantics are \"two objects that compare equal should hash the same\". This enables dask to perform some amount of optimisation on the task graph for repeated execution and task merging.\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nI would like to be able to hash a column with a libcudf call and receive a single $k$-bit hash. The first point above does not need to worry excessively about collisions, and python hash values are 64bit ints, so a 64-bit murmur- or xx-hash is likely sufficient. For dask, collisions are more problematic, so a 128-bit md5 would be better (this is what dask uses for pandas dataframes).\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\n\\r\\nCompute row-wise hashes of columns (on dataframes) to produce a single column of hashes and then copy to host to hash there.\\ncreatedAt: 2023-11-23T11:09:38Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 297}),\n",
       " Document(page_content=': 684\\ntitle: [PERF/ENH] `Series.map` sorts a larger dataset than it needs to\\nbody: `Series.map` which substitutes values in `self` that match some key with its corresponding value does:\\r\\n```\\r\\n            lhs = cudf.DataFrame({\"x\": self, \"orig_order\": arange(len(self))})\\r\\n            rhs = cudf.DataFrame(\\r\\n                {\\r\\n                    \"x\": arg.keys(),\\r\\n                    \"s\": arg.values(),\\r\\n                    \"bool\": full(len(arg), True, dtype=self.dtype),\\r\\n                }\\r\\n            )\\r\\n            res = lhs.merge(rhs, on=\"x\", how=\"left\").sort_values(\\r\\n                by=\"orig_order\"\\r\\n            )\\r\\n            result = res[\"s\"]\\r\\n            result.name = self.name\\r\\n            result.index = self.index\\r\\n```\\r\\n\\r\\nSo the order is the same as the input.\\r\\n\\r\\nThis has two pessimisations:\\r\\n\\r\\n1. In pandas-compat mode (since #14428) this merge doesn\\'t need sorting\\r\\n2. Since we only return `s`, we can get away with `sort_by_key` of `res[\"s\"]` rather than sorting a multi-column dataframe\\ncreatedAt: 2023-11-23T15:12:00Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 298}),\n",
       " Document(page_content=\": 685\\ntitle: [PERF/ENH] `Index.intersection` does more hashing work than necessary\\nbody: Index intersection performs an inner merge of the unique values of the left and right indices (the unique is done so that indices with repeated values don't blow up the memory footprint). This does a full hash of both indices, then the merge (hashing again). Finally, if requested, the result is sorted.\\r\\n\\r\\nThis could be replaced, I think with positive performance effect by either:\\r\\n\\r\\n- `leftsemi` join + `drop_duplicates`\\r\\n- `libcudf.search.contains` + `apply_boolean_mask` + `drop_duplicates`\\r\\n\\r\\nOne would have to think through the consequences of either of these wrt any ordering guarantees we might want when `sort=False` (possibly gated behind pandas-compat mode).\\r\\n\\r\\nThis applies _mutatis mutandis_ to `MultiIndex.intersection` too.\\ncreatedAt: 2023-11-23T17:08:58Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 299}),\n",
       " Document(page_content=\": 686\\ntitle: [BUG] `Index.union` does not match pandas for indexes with duplicate entries\\nbody: **Describe the bug**\\r\\n\\r\\nPandas treats, for `Index.union` only, indexes with duplicate entries as [multisets](https://en.wikipedia.org/wiki/Multiset#Basic_properties_and_operations), for which the union operation produces multiplicities that are the max of the left and right multiplicities. I've asked for clarification of this here https://github.com/pandas-dev/pandas/issues/56137, since it is _only_ `union` that uses the multiset definitions.\\r\\n\\r\\ncudf, in contrast, performs the union as an outer join. Which produces multiplicities that are the product of the multiplicities of the left and right indexes (with identity for missing values of 1). This matches the pandas behaviour in the case where all entries have multiplicity greater than one in exactly one of the left or right indexes. However, if an entry has a multiplicity larger than one in both left and right indexes, we get the wrong answer.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\n```\\r\\nimport cudf\\r\\nimport pandas as pd\\r\\n\\r\\nleft = pd.Index([1, 1])\\r\\nright = pd.Index([1, 2, 1, 1])\\r\\nprint(left.union(right))\\r\\n\\r\\ncleft = cudf.from_pandas(left)\\r\\ncright = cudf.from_pandas(right)\\r\\n\\r\\nprint(cleft.union(cright))\\r\\n# Int64Index([1, 1, 1, 2], dtype='int64')\\r\\n# Int64Index([1, 1, 1, 1, 1, 1, 2], dtype='int64')\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nMatch pandas.\\r\\n\\r\\nThis can be done with `value_counts`/`merge`/`repeat` in some combo, but there's probably a slightly smarter way.\\r\\n\\r\\n**Notes**\\r\\n\\r\\nAlso applies to `MultiIndex`.\\ncreatedAt: 2023-11-23T17:23:39Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 300}),\n",
       " Document(page_content=\": 687\\ntitle: [FEA] Remove inconsistencies in cython wrappers when  handling order/null-precedence\\nbody: Where libcudf search/sort functions accept a `table_view` as input, one must specify the order (ascending or descending) and null precedence (beginning or end) as a `std::vector` of length equal to the number of columns in the `table_view` (or else an empty such vector to used libcudf's defaults).\\r\\n\\r\\nIn the cudf cython wrapping of these functions we are, in contrast, inconsistent in the way we handle these arguments. Some functions accept a list for both order and null precedence (e.g. `libcudf.sort.sort`); some accept a list for order but only a single value for null precedence (e.g. `libcudf.sort.order_by`); some accept a list for neither order nor null precedence (e.g. `libcudf.search.search_sorted`).\\r\\n\\r\\nThis should be cleaned up and all such functions should uniformly accept a list for both order and null precedence. Higher-level python functions that operate on single columns and call the table interfaces should be responsible for any argument munging.\\ncreatedAt: 2023-11-24T14:53:40Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 301}),\n",
       " Document(page_content=\": 688\\ntitle: [BUG] codecov doesn't include tests run in `cudf_pandas_tests/` when generating report\\nbody: The codecov report generated in every PR doesn't consider the tests in `cudf_pandas_tests/` when generating its coverage report.  To fix this, we should update our invocation here:\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/blob/branch-24.02/ci/cudf_pandas_scripts/run_tests.sh#L52\\r\\n\\r\\nto match the ones we use when running other python tests:\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/blob/branch-24.02/ci/test_python_cudf.sh#L17\\r\\n\\r\\n(in particular, all the `--cov*` arguments)\\ncreatedAt: 2023-11-27T17:31:24Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 302}),\n",
       " Document(page_content=\": 691\\ntitle: [QST] cudf.pandas prefer using CPU over GPU in some cases\\nbody: Hi,\\r\\nI'm trying to move from a basic pandas to cudf.pandas and I faced with the issue. It's not clear how cudf decides to use **CPU** or **GPU** in calculations.\\r\\nHere is the example when I have a dataframe with around 280kk rows and 9 columns.\\r\\nThe steps:\\r\\n1) I perform `.groupby.sum() `for the original df. I takes too much time and the profiler show that all calculations were on **CPU** not GPU.\\r\\n2) I cut df like `[:100000000]` so that there are 100kk rows left.\\r\\n3)  I perform `.groupby.sum() `for the modified df and... it takes 0.1 sec and the profiler says **GPU** was using for that.\\r\\n\\r\\nSo, here is some question.\\r\\n- what's the reason that 100kk df is being calculated on GPU and 280kk df on CPU? Hard to belive that the size is the reason.\\r\\n- If not the size then what's the criteria for that?\\r\\n\\r\\nThanks in advance.\\r\\np.s. I also tried `.sort_values()` and there were the same.\\r\\n\\r\\n```\\r\\nCOM_ORDER_LINE.shape\\r\\n(284125143, 9)\\r\\n```\\r\\n```\\r\\nCOM_ORDER_LINE.head()\\r\\n\\r\\nCODE | ORDER_CODE | VERSION_CODE | ID_WARE | QTY_ORDERED | CATALOG_PRICE | PRICE | TO_PAY | DISCOUNT_TOTAL\\r\\n10000006215177 | 10000006215175 | 10000006215176 | 1.787585e+11 | 1 | 3799.0 | 2659.0 | 2659.0 | 1140.0\\r\\n10000006215189 | 10000006215187 | 10000006215188 | 1.736505e+11 | 1 | 9999.0 | 6999.0 | 6999.0 | 3000.0\\r\\n10000006215364 | 10000006215362 | 10000006215363 | 1.736709e+11 | 1 | 1399.0 | 980.0 | 980.0 | 419.0\\r\\n```\\r\\n```\\r\\n%%cudf.pandas.profile\\r\\ndf=COM_ORDER_LINE.groupby(['ID_WARE'])['PRICE'].sum()\\r\\n```\\r\\n\\r\\n\\r\\n```\\r\\nTotal time elapsed: 31.764 seconds                                    \\r\\n                                          0 GPU function calls in 0.000 seconds                                   \\r\\n                                          3 CPU function calls in 23.186 seconds                                  \\r\\n                                                                                                                  \\r\\n                                                          Stats                                                   \\r\\n                                                                                                                  \\r\\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\\r\\n┃ Function                     ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃\\r\\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\\r\\n│ DataFrame.groupby            │ 0          │ 0.000       │ 0.000       │ 1          │ 2.929       │ 2.929       │\\r\\n│ DataFrameGroupBy.__getitem__ │ 0          │ 0.000       │ 0.000       │ 1          │ 2.915       │ 2.915       │\\r\\n│ SeriesGroupBy.sum            │ 0          │ 0.000       │ 0.000       │ 1          │ 17.341      │ 17.341      │\\r\\n└──────────────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\\r\\n\\r\\nNot all pandas operations ran on the GPU. The following functions required CPU fallback:\\r\\n\\r\\n- DataFrame.groupby\\r\\n- DataFrameGroupBy.__getitem__\\r\\n- SeriesGroupBy.sum\\r\\n```\\r\\n\\r\\n```\\r\\nCOM_ORDER_LINE_100KK = COM_ORDER_LINE[:100000000]\\r\\nCOM_ORDER_LINE_100KK.shape\\r\\n(100000000, 9)\\r\\n```\\r\\n\\r\\n```\\r\\n%%cudf.pandas.profile\\r\\ndf=COM_ORDER_LINE_100KK.groupby(['ID_WARE'])['PRICE'].sum()\\r\\n```\\r\\n\\r\\n```\\r\\nTotal time elapsed: 0.109 seconds                                     \\r\\n                                          3 GPU function calls in 0.082 seconds                                   \\r\\n                                          0 CPU function calls in 0.000 seconds                                   \\r\\n                                                                                                                  \\r\\n                                                          Stats                                                   \\r\\n                                                                                                                  \\r\\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\\r\\n┃ Function                     ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃\\r\\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\\r\\n│ DataFrame.groupby            │ 1          │ 0.000       │ 0.000       │ 0          │ 0.000       │ 0.000       │\\r\\n│ DataFrameGroupBy.__getitem__ │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │\\r\\n│ SeriesGroupBy.sum            │ 1          │ 0.081       │ 0.081       │ 0          │ 0.000       │ 0.000       │\\r\\n└──────────────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\\r\\n```\\ncreatedAt: 2023-11-27T18:14:30Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Andrey Komrakov\\ncompany: Sportmaster Ltd.\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 303}),\n",
       " Document(page_content=\": 696\\ntitle: [FEA] Add GZIP compression support to parquet writer\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThe parquet format in Apache Spark supports many compression codecs ([link](https://spark.apache.org/docs/2.4.3/sql-data-sources-parquet.html#configuration)), including: none, uncompressed, snappy, gzip, lzo, brotli, lz4, zstd. \\r\\n\\r\\ncuDF has both internal implementation and an nvCOMP integration to provide compression and decompression codecs.  For the parquet format, GZIP compression is [DEFLATE](https://developer.nvidia.com/blog/accelerating-load-times-for-directx-games-and-apps-with-gdeflate-for-directstorage/) plus a header. nvCOMP does not support the deflate version with this header, so the reader still uses the internal gzip decompression implementation. We don't have internal gzip compression implementation. To support GZIP in the PQ writer we would need to use nvCOMP GDEFLATE codec + write the header on our own.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nAdd support for GZIP compressioning to the cuDF parquet writer by adding a header writing implementation and using nvCOMP deflate.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nn/a\\r\\n\\r\\n**Additional context**\\r\\nAlso see Spark-RAPIDS request here: https://github.com/NVIDIA/spark-rapids/issues/9718\\ncreatedAt: 2023-11-28T05:27:35Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 304}),\n",
       " Document(page_content=': 697\\ntitle: [FEA] Expose `negative_index_policy` from `cudf::detail::gather` in public `cudf::gather` API\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nThe libcudf detail API for `gather` allows one to separately specify how negative indices are handled (whether or not a negative index `i` should map to `i + length(column)`) and how out of bounds indices are handled (whether they should be nullified or not checked for).\\r\\n\\r\\nIn contrast, the public API only allows specifying the policy for out-of-bounds indices explicitly, whether or not negative indices are wrapped is a function of the signedness of the input map column: if the map is an unsigned type, then \"negative\" indices are not allowed, if the type is signed then wrapping occurs.\\r\\n\\r\\nIn cudf, there are cases where we ingest data where pandas specifies that the marker for \"missing\" data is `-1`. For example `MultiIndex` construction can take `levels` and `codes` where `codes` indexes levels and `-1` means \"produce a null\". Right now we use `cudf::gather` to produce the indexed levels, but must first pre-process the `codes` column to replace `-1` with an actually out of bounds size type. This requires an extra pass over the input (and copy to set values).\\r\\n\\r\\nWhenever we perform a join, we obtain gather maps from libcudf which store signed entries (`cudf::size_type`). The entries are guaranteed to either be positive and in-bounds or the sentinel value `std::numeric_limits<size_type>::min()` indicating that an output row should be nullified. Despite this knowledge, since the column we\\'re using for the gather map is a signed type, we have no way of performing the gather without paying the cost of wrapping negative indices, which we _know_ will be a no-op.\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nI\\'d like to be able to specify the treatment of negative indices independently of the signedness of the gather map when calling `cudf::gather`.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\n\\r\\nFor data ingest, we could just build the user input as an unsigned type. However, that has the disadvantage that they then don\\'t see what they might \"expect\" if inspecting the result that cudf delivers.\\r\\n\\r\\nFor the join case, I don\\'t think there is a way without copying the gather map (since it is UB to `reinterpret_cast` between pointers of different types).\\ncreatedAt: 2023-11-28T13:09:37Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 305}),\n",
       " Document(page_content=\": 698\\ntitle: [FEA] Allow control of mask state in return value of `cudf::contains`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\n`cudf::contains`, specifically the column overload, searches for a bunch of needles in a haystack. If any of the needles are null, the return value has nulls in the same location. The detail API has finer-grained control over whether nulls should compare equal (so that if the haystack contains a null and one of needles is null, the output column has a `true` value in that slot).\\r\\n\\r\\nIt would be nice to be able to control whether the bitmask is copied from the needles to the result or not. In Python cudf, we use `contains` to implement `Series.isin` where the semantics are that nulls are just treated as any other value. So if the needles contain a null, the result is true or false depending on whether the haystack also has a null. Right now, we call contains, and then must perform some post-processing to obtain a result that internally has already been computed.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nA flag specifying whether `contains` masks its output.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\nAbove-board, I do this in Python with:\\r\\n\\r\\n```\\r\\nif needles.null_count > 0:\\r\\n    result.fillna(haystack.null_count > 0)\\r\\n```\\r\\nThis is an extra allocation + kernel launch.\\r\\n\\r\\nThe cheap way of doing it is to obtain the result, and then drop the mask on the floor. This happens to work due to the way `cudf::contains` is implemented. However, I would rather not do this because libcudf explicitly does not guarantee that the masked out entries of a column contain valid data, so I am relying on an implementation detail which could change.\\ncreatedAt: 2023-11-28T17:13:09Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 306}),\n",
       " Document(page_content=': 700\\ntitle: [BUG] Treatment of logical and bitwise binops in `DataFrame.eval` does not match pandas\\nbody: **Describe the bug**\\r\\n\\r\\nIn pandas, `eval` treats `a op b` as always meaning the bitwise version `op in {and, or, &, |, ^}`. In cudf, due to the way we parse the expression without type information (and the dispatching scheme to the AST interpreter in libcudf), `and` and `or` mean \"logical\" and `&`, `|`, and `^` mean \"bitwise\". There\\'s a final wrinkle that (like spark) for bools only, masked values are treated as `False`.\\r\\n\\r\\nThis can cause differences in the result between calling `eval` with pandas and with cudf. Although the docstring mentions these differences, when using `cudf.pandas`, we don\\'t see the cudf docstring (only the pandas one).\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nEventually, we should match pandas. I think this should be done by running a type inference pass on the user-provided expression and rewriting to an appropriate combination of bitwise and logical operations. This would have the nice side-effect of also allowing mixed-type operands in `eval` expressions by cudf upcasting before passing off to libcudf.\\r\\n\\r\\nIn the short term, we should probably raise a `NotImplementedError` when running in pandas-compat mode if the expression contains logical/bitwise binops.\\ncreatedAt: 2023-11-28T18:15:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 307}),\n",
       " Document(page_content=': 707\\ntitle: [FEA] Proxy ndarrays don\\'t pass an `instancecheck()` for `np.ndarray`\\nbody: There\\'s a lot of code out there that does something like:\\r\\n\\r\\n```python\\r\\nif not isinstance(x, np.ndarray):\\r\\n    raise TypeError(\"Not a numpy array\")\\r\\n```\\r\\n\\r\\nThis is a problem for `cudf.pandas`, because proxy ndarray types, such as those returned by `pd.Series.values` do not pass the `isinstance()` check.\\r\\n\\r\\nIdeally, more projects would avoid doing a hard `isinstance()` check and instead use something like EAFP:\\r\\n\\r\\n```python\\r\\nnp.asarray(x)\\r\\n```\\r\\n\\r\\n..but that is not the world we live in today. Too many third-party libraries that people want to use with `cudf.pandas` use the pattern above, so it\\'s on us to solve the problem right now.\\ncreatedAt: 2023-11-30T17:23:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 308}),\n",
       " Document(page_content=': 708\\ntitle: [BUG] Parquet column selection by name with schemas including   list<struct<X, Y>> does not work.\\nbody: If you have a schema that contains a list-of-struct, selecting a subset of the inner columns doesn\\'t work.  Example\\r\\n\\r\\n`list<struct<int, float>>`\\r\\nIf the schema for this column was\\r\\n\\r\\n```\\r\\nA           (list)\\r\\n   B        (struct)\\r\\n       C    (int)\\r\\n       D    (float)\\r\\n```\\r\\nAttempting to select \"A.B.C\" would not work.  I believe this is being caused by some schema preprocessing that we are doing that is injecting fake schema elements to ease schema interpretation.  Essentially we see a schema that looks like this:\\r\\n\\r\\n```\\r\\nA            (list)\\r\\n  list       (the fake element\\r\\n     B       (struct)\\r\\n        C    (int)\\r\\n        D    (float)\\r\\n```\\r\\nSo \"A.B.C\" doesn\\'t actually exist, only \"A.list.B.C\" and the code returns 0 columns.\\ncreatedAt: 2023-11-30T21:30:21Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 309}),\n",
       " Document(page_content=': 709\\ntitle: [BUG] `MultiIndex.equals` does not match pandas for numerical indexes with unequal dtypes\\nbody: **Describe the bug**\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\n\\r\\nleft = cudf.MultiIndex.from_tuples([(1,)])\\r\\nright = cudf.MultiIndex.from_tuples([(1.0,)])\\r\\n\\r\\nprint(left.equals(right)) # => False\\r\\n\\r\\nprint(left.to_pandas().equals(right.to_pandas())) # => True\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nThis should match pandas. Note that `Index.equals` does do dtype casting.\\ncreatedAt: 2023-12-05T15:58:40Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 310}),\n",
       " Document(page_content=': 710\\ntitle: [BUG] merge join key matching is too eager to cast strings\\nbody: **Describe the bug**\\r\\n\\r\\n```\\r\\nimport cudf\\r\\n\\r\\nleft = cudf.DataFrame({\"key\": [1, 2, 3]})\\r\\nright = cudf.DataFrame({\"key\": [\"1\", \"4\", \"5\"]})\\r\\n\\r\\n# Casts both key columns to float64 and merges\\r\\ngot = left.merge(right, on=\"key\", how=\"outer\")\\r\\n\\r\\n# raises ValueError (merging on int + string column)\\r\\nexpect = left.to_pandas().merge(right.to_pandas(), on=\"key\", how=\"outer\")\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nThis should match pandas. A consequence, since merge is also used for Index setops, `union`, `intersection`, and `difference` are buggy.\\ncreatedAt: 2023-12-05T17:34:17Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 311}),\n",
       " Document(page_content=\": 711\\ntitle: [FEA] Add Avro reader benchmarks to the cuIO benchmarking suite\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nWe have reader benchmarks for CSV, JSON, Parquet and ORC in the cuIO nvbench benchmarking suite. We should add benchmarking for the Avro reader. \\r\\n\\r\\nThe cuIO benchmarks are located here:\\r\\nhttps://github.com/rapidsai/cudf/tree/branch-24.02/cpp/benchmarks/io\\r\\n\\r\\nUnfortunately, we don't have an Avro writer implementation in libcudf, so the naive approach of modeling benchmarks after [json_reader_input.cpp](https://github.com/rapidsai/cudf/blob/branch-24.02/cpp/benchmarks/io/json/json_reader_input.cpp) will not work. \\r\\n\\r\\n**Describe the solution you'd like**\\r\\nOur options would be:\\r\\n* add an MVP Avro writer to libcudf\\r\\n* add/use a dependency to write Avro files \\r\\n* maintain a repository of large Avro files (>100 MB) for benchmarking purposes\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nContinue without automated benchmarks for the Avro reader\\r\\n\\r\\n**Additional context**\\r\\nThe libcudf Avro reader does not support nested types so the benchmarks should start by only covering primitive types.\\ncreatedAt: 2023-12-05T19:34:27Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 312}),\n",
       " Document(page_content=': 712\\ntitle: [FEA] Support canonical arrow extension types: FixedShapeTensorType and VariableShapeTensorType\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nFeeding data from the CPU to the GPU is a bottleneck especially for computer vision. I\\'d like to store satellite images as parquet with georeferencing information in some columns and a column with Arrow\\'s new FixedShapeTensorType extension array and then load it with cudf and get zero copy benefits when passing the tensor to the GPU and pytorch.\\r\\n\\r\\nHowever it looks like cudf can\\'t interpret this type.\\r\\n```\\r\\nimport pyarrow as pa\\r\\n\\r\\ntensor_type = pa.fixed_shape_tensor(pa.int32(), (2, 2))\\r\\narr = [[1, 2, 3, 4], [10, 20, 30, 40], [100, 200, 300, 400]]\\r\\nstorage = pa.array(arr, pa.list_(pa.int32(), 4))\\r\\ntensor_array = pa.ExtensionArray.from_storage(tensor_type, storage)\\r\\n\\r\\ndata = [\\r\\n     pa.array([1, 2, 3]),\\r\\n     pa.array([\\'foo\\', \\'bar\\', None]),\\r\\n     tensor_array,\\r\\n]\\r\\nmy_schema = pa.schema([(\\'f0\\', pa.int8()),\\r\\n                        (\\'f1\\', pa.string()),\\r\\n                        (\\'tensors_int\\', tensor_type)])\\r\\ntable = pa.Table.from_arrays(data, schema=my_schema)\\r\\n\\r\\ntable.cast(table.schema)\\r\\n```\\r\\n\\r\\n```\\r\\nimport cudf\\r\\n\\r\\ncudf.DataFrame.from_arrow(table)\\r\\n```\\r\\n\\r\\n```\\r\\n---------------------------------------------------------------------------\\r\\nRuntimeError                              Traceback (most recent call last)\\r\\nCell In[2], line 3\\r\\n      1 import cudf\\r\\n----> 3 cudf.DataFrame.from_arrow(table)\\r\\n\\r\\nFile ~/miniforge3/envs/rapids-23.10/lib/python3.10/site-packages/nvtx/nvtx.py:115, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n    112 @wraps(func)\\r\\n    113 def inner(*args, **kwargs):\\r\\n    114     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 115     result = func(*args, **kwargs)\\r\\n    116     libnvtx_pop_range(self.domain.handle)\\r\\n    117     return result\\r\\n\\r\\nFile ~/miniforge3/envs/rapids-23.10/lib/python3.10/site-packages/cudf/core/dataframe.py:5322, in DataFrame.from_arrow(cls, table)\\r\\n   5319         for col_meta in table.schema.pandas_metadata[\"column_indexes\"]:\\r\\n   5320             col_index_names.append(col_meta[\"name\"])\\r\\n-> 5322 out = super().from_arrow(table)\\r\\n   5323 if col_index_names is not None:\\r\\n   5324     out._data._level_names = col_index_names\\r\\n\\r\\nFile ~/miniforge3/envs/rapids-23.10/lib/python3.10/site-packages/nvtx/nvtx.py:115, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n    112 @wraps(func)\\r\\n    113 def inner(*args, **kwargs):\\r\\n    114     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 115     result = func(*args, **kwargs)\\r\\n    116     libnvtx_pop_range(self.domain.handle)\\r\\n    117     return result\\r\\n\\r\\nFile ~/miniforge3/envs/rapids-23.10/lib/python3.10/site-packages/cudf/core/frame.py:1053, in Frame.from_arrow(cls, data)\\r\\n   1036     cudf_category_frame = {\\r\\n   1037         name: build_categorical_column(\\r\\n   1038             cudf_dictionaries_columns[name],\\r\\n   (...)\\r\\n   1046         )\\r\\n   1047     }\\r\\n   1049 # Handle non-dict arrays\\r\\n   1050 cudf_non_category_frame = {\\r\\n   1051     name: col\\r\\n   1052     for name, col in zip(\\r\\n-> 1053         data.column_names, libcudf.interop.from_arrow(data)\\r\\n   1054     )\\r\\n   1055 }\\r\\n   1057 result = {**cudf_non_category_frame, **cudf_category_frame}\\r\\n   1059 # There are some special cases that need to be handled\\r\\n   1060 # based on metadata.\\r\\n\\r\\nFile ~/miniforge3/envs/rapids-23.10/lib/python3.10/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile interop.pyx:199, in cudf._lib.interop.from_arrow()\\r\\n\\r\\nRuntimeError: CUDF failure at:/opt/conda/conda-bld/work/cpp/src/interop/from_arrow.cu:87: Unsupported type_id conversion to cudf\\r\\n```\\r\\n\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nI want to be able to load parquet files with cudf that contain a column with this tensor type and then easily hand it off from cudf to pytorch.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nThere are other formats like zarr for N-D arrays and direct loading to gpu, but I don\\'t think zero copy between cpu and gpu is supported https://xarray.dev/blog/xarray-kvikio\\r\\n\\r\\nOr I can continue loading parquet files with references to cloud optimized geotiff files, which is a lot slower.\\r\\n\\r\\n**Additional context**\\r\\ndocs for the type are here: https://arrow.apache.org/docs/python/generated/pyarrow.FixedShapeTensorArray.html\\r\\nand others are looking at implementing it for dataloading https://github.com/huggingface/datasets/issues/5272\\r\\nthere\\'s also a variable shape equal dimension number type which would be very useful for efficiently loading satellite imagery time series where the time length can vary a lot depending on the sample, or the height and width can vary a lot depending on the sensor resolution: https://arrow.apache.org/docs/format/CanonicalExtensions.html#variable-shape-tensor\\ncreatedAt: 2023-12-06T21:04:04Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ryan Avery\\ncompany: @wherobots', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 313}),\n",
       " Document(page_content=': 713\\ntitle: [FEA] Tighten up promotion when merging with non-equal key column dtypes\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nTo date, cudf has attempted to match pandas semantics when matching join keys in a merge. libcudf does not perform merges between mismatching table dtypes. Consequently, the first step of a merge in cudf is to determine a \"common\" dtype for each pair of columns used as keys in the merge.\\r\\n\\r\\nThe pandas rules are mostly (though not completely since there is some under the table work that happens in the join algorithm) encoded in https://github.com/pandas-dev/pandas/blob/f7c73a5f1aaf0724598e60c0cc5732604ec842a8/pandas/core/reshape/merge.py#L1340\\r\\n\\r\\nThere are a few problems when trying to match these in cudf:\\r\\n\\r\\n- not all column types in pandas can be represented in cudf (we do not have an `object` column for example)\\r\\n- it is difficult to unambiguously determine the type promotion rules since they are not written down anywhere\\r\\n    - for example, promotion rules for categorical columns differ depending on whether the categorical is the left or right key.\\r\\n\\r\\nMoreover, there are other, correctness, problems. The current type promotion rules admit lossy conversions that can result in false positive matches in merges.\\r\\n\\r\\nExample:\\r\\n```\\r\\nleft = cudf.DataFrame({\"key\": [1, 2, 2**53]})\\r\\nright = cudf.DataFrame({\"key\": [2**53 + 1, 10]})\\r\\nright[\"key\"] = right.key.astype(\"uint64\")\\r\\nleft.merge(right, on=\"key\", how=\"inner\")\\r\\n#            key\\r\\n# 0  9.007199e+15\\r\\nleft\\r\\n#                key\\r\\n# 0                 1\\r\\n# 1                 2\\r\\n# 2  9007199254740992\\r\\nright\\r\\n#                key\\r\\n# 0  9007199254740993\\r\\n# 1                10\\r\\n```\\r\\n\\r\\nPandas is also susceptible to this, but produces a different wrong result.\\r\\n\\r\\nI would like to tighten up the rules in cudf, so that it is impossible for the user to get a \"surprising\" result without some explicit intervention on their behalf. We would also try and match pandas more closely where that is possible, but my preference is to be correct in a subset of cases over dubiously correct in a larger set.\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nThere are, I think, three levels of things we could do:\\r\\n\\r\\n1. Push the burden of dtype matching completely on to the user: complain (raise) if merge keys do not match dtypes _exactly_\\r\\n2. Promote keys whose dtypes allow so safely (without needing to inspect values), and raise for cases where that is not possible. The user can still perform the merge by intentionally casting to matching types. But then they must know that it is safe.\\r\\n3. Try and match pandas promotions as closely as possible and accept that there might be false positives.\\r\\n\\r\\nI would like to go for (2). (1) is easiest; (3) is difficult, probably a moving target and can result in false positives without the user explicitly \"requesting\" them.\\r\\n\\r\\nWith cudf-pandas (2), I think, skates the line between ease of use and correctness reasonably well. We can run as much on the GPU as possible and raise (possibly providing a warning in pandas-compat mode) with fallback to CPU. When using cudf directly, users will hopefully be willing to accept a few more edge cases in the name of consistency. \\r\\n\\r\\n\\r\\nConcretely this would mean:\\r\\n\\r\\n- No casting for strings\\r\\n- No casting for lists\\r\\n- No casting for structs\\r\\n- Categoricals:\\r\\n    - if both columns are categorical and match, no casting\\r\\n    - if both columns are categorical and _do not_ match, raise[^1]\\r\\n    - if one column is categorical, unwrap, and go round again[^2]\\r\\n - No casting for decimals\\r\\n - No casting for datetimes[^3]\\r\\n - For numeric types, use a type promotion lattice that has lossless least upper bounds for all types[^4]\\r\\n\\r\\nFor numeric types, that means that we would only promote pairs of types where there exists a wider type whose values are uniquely and unambiguously mapped onto from the narrower types.\\r\\n\\r\\nFor example `(int32, uint32) -> int64` would be allowed, but merging a pair `(int32, uint64)` would raise (since there is no signed 128bit int that we could use). Similarly, we would safely be able to promote `(intX, floatY)` pairs (and similarly with `uintX`) as long as the integer type is 32 or fewer bits wide[^5].\\r\\n\\r\\n\\r\\n\\r\\n[^1]: I could also be convinced to unwrap and go round again, but that would lose information about the categorical nature of the inputs\\r\\n[^2]: Pandas behaviour in this case depends on whether the left or right key is categorical (and which merge type it is): it casts the non-categorical to object, and the categorical to its underlying dtype, then imperfectly goes through its matching process again\\r\\n[^3]: I haven\\'t looked at what pandas does here, but I guess the other thing one could do is promote when one can losslessly convert\\r\\n[^4]: See, for example https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html though I disagree with their approach of selecting a \"weak\" float64 as the least upper bound for `(int64, uint64)`\\r\\n[^5]: Merging between float and int columns is kind of weird, so I could also be convinced to raise when merging between mismatching numeric kinds.\\ncreatedAt: 2023-12-07T19:04:54Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 314}),\n",
       " Document(page_content=': 714\\ntitle: [BUG] DIV on decimal types appears to lose fractional part\\nbody: **Describe the bug**\\r\\n\\r\\nDividing two decimal columns with equal scale N results in 0 fractional digits in the output (i.e. the result is truncated). I would expect that if division returns a result of scale N, then we should have N fractional digits of output. Instead, the number of fractional digits computed appears to be `LHS.scale - RHS.scale`, so dividing equal scale decimals always truncates the fractional part. It\\'s possible I\\'m misunderstanding how scale is handled here, though. (It looks vaguely like cuDF is just doing the raw integer division, then possibly rescaling? IIRC, PyArrow rescales before and after)\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\n```python\\r\\nfrom decimal import Decimal\\r\\n\\r\\nimport cudf\\r\\nimport pyarrow\\r\\nimport pyarrow.compute\\r\\n\\r\\nprint(\"cuDF version: \", cudf.__version__)\\r\\nprint(\"PyArrow version: \", pyarrow.__version__)\\r\\n\\r\\nlhs_py = [Decimal(\"1.0\"), Decimal(\"2.0\")]\\r\\nrhs_py = [Decimal(\"2.0\"), Decimal(\"3.0\")]\\r\\n\\r\\nprint(\"* cuDF:\")\\r\\nlhs = cudf.Series(lhs_py, dtype=cudf.Decimal128Dtype(precision=10, scale=4))\\r\\nrhs = cudf.Series(rhs_py, dtype=cudf.Decimal128Dtype(precision=10, scale=4))\\r\\n\\r\\n# There are 0 actual fractional digits in the result, although the dtype\\r\\n# indicates precision=25, scale=15.\\r\\nresult = lhs / rhs\\r\\nprint(result)\\r\\nprint(repr(result.dtype))\\r\\n\\r\\n# If we arbitrarily add more fractional digits to the LHS, we get (LHS.scale -\\r\\n# RHS.scale) fractional digits in the result.\\r\\nresult = lhs.astype(cudf.Decimal128Dtype(precision=10, scale=8)) / rhs\\r\\nprint(result)\\r\\nprint(repr(result.dtype))\\r\\n\\r\\nprint(\"* PyArrow\")\\r\\nlhs = pyarrow.array(lhs_py, type=pyarrow.decimal128(10, 4))\\r\\nrhs = pyarrow.array(rhs_py, type=pyarrow.decimal128(10, 4))\\r\\n\\r\\n# PyArrow computes 11 fractional digits, and the result scale is 11.\\r\\nresult = pyarrow.compute.divide(lhs, rhs)\\r\\nprint(result)\\r\\nprint(result.type)\\r\\n```\\r\\n\\r\\nThe result:\\r\\n\\r\\n```\\r\\ncuDF version:  23.12.00a717\\r\\nPyArrow version:  14.0.1\\r\\n* cuDF:\\r\\n0    0E-15\\r\\n1    0E-15\\r\\ndtype: decimal128\\r\\nDecimal128Dtype(precision=25, scale=15)\\r\\n0    0.5000000000000000000\\r\\n1    0.6666000000000000000\\r\\ndtype: decimal128\\r\\nDecimal128Dtype(precision=25, scale=19)\\r\\n* PyArrow\\r\\n[\\r\\n  0.50000000000,\\r\\n  0.66666666666\\r\\n]\\r\\ndecimal128(21, 11)\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nA clear and concise description of what you expected to happen.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Bare-metal\\r\\n - Method of cuDF install: conda\\r\\n\\r\\n<details>\\r\\n<summary><tt>conda list</tt></summary>\\r\\n\\r\\n```\\r\\n# packages in environment at /home/lidavidm/miniforge3/envs/cudf:\\r\\n#\\r\\n# Name                    Version                   Build  Channel\\r\\n_libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n_openmp_mutex             4.5                       2_gnu    conda-forge\\r\\naws-c-auth                0.7.8                h538f98c_2    conda-forge\\r\\naws-c-cal                 0.6.9                h5d48c4d_2    conda-forge\\r\\naws-c-common              0.9.10               hd590300_0    conda-forge\\r\\naws-c-compression         0.2.17               h7f92143_7    conda-forge\\r\\naws-c-event-stream        0.3.2                h0bcb0bb_8    conda-forge\\r\\naws-c-http                0.7.14               hd268abd_3    conda-forge\\r\\naws-c-io                  0.13.36              he0cd244_2    conda-forge\\r\\naws-c-mqtt                0.9.10               h35285c7_2    conda-forge\\r\\naws-c-s3                  0.4.4                h0448019_0    conda-forge\\r\\naws-c-sdkutils            0.1.13               h7f92143_0    conda-forge\\r\\naws-checksums             0.1.17               h7f92143_6    conda-forge\\r\\naws-crt-cpp               0.24.11              h5bdc202_2    conda-forge\\r\\naws-sdk-cpp               1.11.210             h967ea9e_4    conda-forge\\r\\nbzip2                     1.0.8                hd590300_5    conda-forge\\r\\nc-ares                    1.23.0               hd590300_0    conda-forge\\r\\nca-certificates           2023.11.17           hbcca054_0    conda-forge\\r\\ncachetools                5.3.2              pyhd8ed1ab_0    conda-forge\\r\\ncubinlinker               0.3.0           py310hfdf336d_1    rapidsai-nightly\\r\\ncuda-python               11.8.3          py310h70a93da_0    conda-forge\\r\\ncuda-version              11.8                 h70ddcb2_2    conda-forge\\r\\ncudatoolkit               11.8.0              h4ba93d1_12    conda-forge\\r\\ncudf                      23.12.00a717    cuda11_py310_231212_gfd2f6a6fd1_717    rapidsai-nightly\\r\\ncupy                      12.3.0          py310hf4db66c_0    conda-forge\\r\\ndlpack                    0.5                  h9c3ff4c_0    conda-forge\\r\\nfastrlock                 0.8.2           py310hc6cd4ac_1    conda-forge\\r\\nfmt                       10.1.1               h00ab1b0_1    conda-forge\\r\\nfsspec                    2023.12.2          pyhca7485f_0    conda-forge\\r\\ngflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\nglog                      0.6.0                h6f12383_0    conda-forge\\r\\ngmock                     1.14.0               ha770c72_1    conda-forge\\r\\ngtest                     1.14.0               h00ab1b0_1    conda-forge\\r\\nicu                       73.2                 h59595ed_0    conda-forge\\r\\nkeyutils                  1.6.1                h166bdaf_0    conda-forge\\r\\nkrb5                      1.21.2               h659d440_0    conda-forge\\r\\nld_impl_linux-64          2.40                 h41732ed_0    conda-forge\\r\\nlibabseil                 20230802.1      cxx17_h59595ed_0    conda-forge\\r\\nlibarrow                  14.0.1           h0f82fcc_9_cpu    conda-forge\\r\\nlibarrow-acero            14.0.1           h59595ed_9_cpu    conda-forge\\r\\nlibarrow-dataset          14.0.1           h59595ed_9_cpu    conda-forge\\r\\nlibarrow-flight           14.0.1           h120cb0d_9_cpu    conda-forge\\r\\nlibarrow-flight-sql       14.0.1           h61ff412_9_cpu    conda-forge\\r\\nlibarrow-gandiva          14.0.1           hacb8726_9_cpu    conda-forge\\r\\nlibarrow-substrait        14.0.1           h61ff412_9_cpu    conda-forge\\r\\nlibblas                   3.9.0           20_linux64_openblas    conda-forge\\r\\nlibbrotlicommon           1.1.0                hd590300_1    conda-forge\\r\\nlibbrotlidec              1.1.0                hd590300_1    conda-forge\\r\\nlibbrotlienc              1.1.0                hd590300_1    conda-forge\\r\\nlibcblas                  3.9.0           20_linux64_openblas    conda-forge\\r\\nlibcrc32c                 1.1.2                h9c3ff4c_0    conda-forge\\r\\nlibcudf                   23.12.00a717    cuda11_231212_gfd2f6a6fd1_717    rapidsai-nightly\\r\\nlibcufile                 1.4.0.31                      0    nvidia\\r\\nlibcufile-dev             1.4.0.31                      0    nvidia\\r\\nlibcurl                   8.5.0                hca28451_0    conda-forge\\r\\nlibedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\nlibev                     4.33                 hd590300_2    conda-forge\\r\\nlibevent                  2.1.12               hf998b51_1    conda-forge\\r\\nlibffi                    3.4.2                h7f98852_5    conda-forge\\r\\nlibgcc-ng                 13.2.0               h807b86a_3    conda-forge\\r\\nlibgfortran-ng            13.2.0               h69a702a_3    conda-forge\\r\\nlibgfortran5              13.2.0               ha4646dd_3    conda-forge\\r\\nlibgomp                   13.2.0               h807b86a_3    conda-forge\\r\\nlibgoogle-cloud           2.12.0               h5206363_4    conda-forge\\r\\nlibgrpc                   1.59.3               hd6c4280_0    conda-forge\\r\\nlibiconv                  1.17                 hd590300_1    conda-forge\\r\\nlibkvikio                 23.12.00a       cuda11_231212_g26efdd1_23    rapidsai-nightly\\r\\nliblapack                 3.9.0           20_linux64_openblas    conda-forge\\r\\nlibllvm14                 14.0.6               hcd5def8_4    conda-forge\\r\\nlibllvm15                 15.0.7               hb3ce162_4    conda-forge\\r\\nlibnghttp2                1.58.0               h47da74e_1    conda-forge\\r\\nlibnsl                    2.0.1                hd590300_0    conda-forge\\r\\nlibnuma                   2.0.16               h0b41bf4_1    conda-forge\\r\\nlibopenblas               0.3.25          pthreads_h413a1c8_0    conda-forge\\r\\nlibparquet                14.0.1           h352af49_9_cpu    conda-forge\\r\\nlibprotobuf               4.24.4               hf27288f_0    conda-forge\\r\\nlibre2-11                 2023.06.02           h7a70373_0    conda-forge\\r\\nlibrmm                    23.12.00             h4725429_0    conda-forge\\r\\nlibsqlite                 3.44.2               h2797004_0    conda-forge\\r\\nlibssh2                   1.11.0               h0841786_0    conda-forge\\r\\nlibstdcxx-ng              13.2.0               h7e041cc_3    conda-forge\\r\\nlibthrift                 0.19.0               hb90f79a_1    conda-forge\\r\\nlibutf8proc               2.8.0                h166bdaf_0    conda-forge\\r\\nlibuuid                   2.38.1               h0b41bf4_0    conda-forge\\r\\nlibxml2                   2.12.2               h232c23b_0    conda-forge\\r\\nlibzlib                   1.2.13               hd590300_5    conda-forge\\r\\nllvmlite                  0.40.1          py310h1b8f574_0    conda-forge\\r\\nlz4-c                     1.9.4                hcb278e6_0    conda-forge\\r\\nmarkdown-it-py            3.0.0              pyhd8ed1ab_0    conda-forge\\r\\nmdurl                     0.1.0              pyhd8ed1ab_0    conda-forge\\r\\nncurses                   6.4                  h59595ed_2    conda-forge\\r\\nnumba                     0.57.1          py310h0f6aa51_0    conda-forge\\r\\nnumpy                     1.24.4          py310ha4c1d20_0    conda-forge\\r\\nnvcomp                    3.0.4                h838ba91_1    conda-forge\\r\\nnvtx                      0.2.8           py310h2372a71_1    conda-forge\\r\\nopenssl                   3.2.0                hd590300_1    conda-forge\\r\\norc                       1.9.2                h4b38347_0    conda-forge\\r\\npackaging                 23.2               pyhd8ed1ab_0    conda-forge\\r\\npandas                    1.5.3           py310h9b08913_1    conda-forge\\r\\npip                       23.3.1             pyhd8ed1ab_0    conda-forge\\r\\nprotobuf                  4.24.4          py310h620c231_0    conda-forge\\r\\nptxcompiler               0.8.1           py310h70a93da_2    conda-forge\\r\\npyarrow                   14.0.1          py310hf9e7431_9_cpu    conda-forge\\r\\npygments                  2.17.2             pyhd8ed1ab_0    conda-forge\\r\\npython                    3.10.13         hd12c33a_0_cpython    conda-forge\\r\\npython-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\\r\\npython_abi                3.10                    4_cp310    conda-forge\\r\\npytz                      2023.3.post1       pyhd8ed1ab_0    conda-forge\\r\\nrdma-core                 49.0                 hd3aeb46_1    conda-forge\\r\\nre2                       2023.06.02           h2873b5e_0    conda-forge\\r\\nreadline                  8.2                  h8228510_1    conda-forge\\r\\nrich                      13.7.0             pyhd8ed1ab_0    conda-forge\\r\\nrmm                       23.12.00        cuda11_py310_231206_g2db5cbb3_0    rapidsai\\r\\ns2n                       1.4.0                h06160fa_0    conda-forge\\r\\nsetuptools                68.2.2             pyhd8ed1ab_0    conda-forge\\r\\nsix                       1.16.0             pyh6c4a22f_0    conda-forge\\r\\nsnappy                    1.1.10               h9fff704_0    conda-forge\\r\\nspdlog                    1.12.0               hd2e6256_2    conda-forge\\r\\ntk                        8.6.13          noxft_h4845f30_101    conda-forge\\r\\ntyping_extensions         4.9.0              pyha770c72_0    conda-forge\\r\\ntzdata                    2023c                h71feb2d_0    conda-forge\\r\\nucx                       1.15.0               hae80064_1    conda-forge\\r\\nwheel                     0.42.0             pyhd8ed1ab_0    conda-forge\\r\\nxz                        5.2.6                h166bdaf_0    conda-forge\\r\\nzstd                      1.5.5                hfc55251_0    conda-forge\\r\\n```\\r\\n\\r\\n</details>\\r\\n\\r\\n**Environment details**\\r\\n\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n     \\r\\n     **git***\\r\\n     Not inside a git repository\\r\\n     \\r\\n     ***OS Information***\\r\\n     PRETTY_NAME=\"Debian GNU/Linux 12 (bookworm)\"\\r\\n     NAME=\"Debian GNU/Linux\"\\r\\n     VERSION_ID=\"12\"\\r\\n     VERSION=\"12 (bookworm)\"\\r\\n     VERSION_CODENAME=bookworm\\r\\n     ID=debian\\r\\n     HOME_URL=\"https://www.debian.org/\"\\r\\n     SUPPORT_URL=\"https://www.debian.org/support\"\\r\\n     BUG_REPORT_URL=\"https://bugs.debian.org/\"\\r\\n     Linux debian 6.1.0-12-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.52-1 (2023-09-07) x86_64 GNU/Linux\\r\\n     \\r\\n     ***GPU Information***\\r\\n     Tue Dec 12 14:17:51 2023\\r\\n     +---------------------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\\r\\n     |-----------------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                                         |                      |               MIG M. |\\r\\n     |=========================================+======================+======================|\\r\\n     |   0  Quadro T2000 with Max-Q ...    On  | 00000000:01:00.0 Off |                  N/A |\\r\\n     | N/A   49C    P8               1W /  40W |      5MiB /  4096MiB |      0%      Default |\\r\\n     |                                         |                      |                  N/A |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     \\r\\n     +---------------------------------------------------------------------------------------+\\r\\n     | Processes:                                                                            |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\\r\\n     |        ID   ID                                                             Usage      |\\r\\n     |=======================================================================================|\\r\\n     |    0   N/A  N/A      1347      G   /usr/lib/xorg/Xorg                            4MiB |\\r\\n     +---------------------------------------------------------------------------------------+\\r\\n     \\r\\n     ***CPU***\\r\\n     Architecture:                       x86_64\\r\\n     CPU op-mode(s):                     32-bit, 64-bit\\r\\n     Address sizes:                      39 bits physical, 48 bits virtual\\r\\n     Byte Order:                         Little Endian\\r\\n     CPU(s):                             16\\r\\n     On-line CPU(s) list:                0-15\\r\\n     Vendor ID:                          GenuineIntel\\r\\n     Model name:                         Intel(R) Core(TM) i9-10885H CPU @ 2.40GHz\\r\\n     CPU family:                         6\\r\\n     Model:                              165\\r\\n     Thread(s) per core:                 2\\r\\n     Core(s) per socket:                 8\\r\\n     Socket(s):                          1\\r\\n     Stepping:                           2\\r\\n     CPU(s) scaling MHz:                 64%\\r\\n     CPU max MHz:                        5300.0000\\r\\n     CPU min MHz:                        800.0000\\r\\n     BogoMIPS:                           4800.00\\r\\n     Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp pku ospke md_clear flush_l1d arch_capabilities\\r\\n     Virtualization:                     VT-x\\r\\n     L1d cache:                          256 KiB (8 instances)\\r\\n     L1i cache:                          256 KiB (8 instances)\\r\\n     L2 cache:                           2 MiB (8 instances)\\r\\n     L3 cache:                           16 MiB (1 instance)\\r\\n     NUMA node(s):                       1\\r\\n     NUMA node0 CPU(s):                  0-15\\r\\n     Vulnerability Gather data sampling: Mitigation; Microcode\\r\\n     Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled\\r\\n     Vulnerability L1tf:                 Not affected\\r\\n     Vulnerability Mds:                  Not affected\\r\\n     Vulnerability Meltdown:             Not affected\\r\\n     Vulnerability Mmio stale data:      Mitigation; Clear CPU buffers; SMT vulnerable\\r\\n     Vulnerability Retbleed:             Mitigation; Enhanced IBRS\\r\\n     Vulnerability Spec rstack overflow: Not affected\\r\\n     Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl\\r\\n     Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\r\\n     Vulnerability Spectre v2:           Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence\\r\\n     Vulnerability Srbds:                Mitigation; Microcode\\r\\n     Vulnerability Tsx async abort:      Not affected\\r\\n     \\r\\n     ***CMake***\\r\\n     \\r\\n     ***g++***\\r\\n     /usr/bin/g++\\r\\n     g++ (Debian 12.2.0-14) 12.2.0\\r\\n     Copyright (C) 2022 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n     \\r\\n     \\r\\n     ***nvcc***\\r\\n     /usr/local/cuda-11.8/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2022 NVIDIA Corporation\\r\\n     Built on Wed_Sep_21_10:33:58_PDT_2022\\r\\n     Cuda compilation tools, release 11.8, V11.8.89\\r\\n     Build cuda_11.8.r11.8/compiler.31833905_0\\r\\n     \\r\\n     ***Python***\\r\\n     /home/lidavidm/miniforge3/envs/cudf/bin/python\\r\\n     Python 3.10.13\\r\\n     \\r\\n     ***Environment Variables***\\r\\n     PATH                            : /home/lidavidm/miniforge3/envs/cudf/bin:/home/lidavidm/miniforge3/condabin:/usr/local/cuda-11.8/bin:/home/lidavidm/go/bin:/home/lidavidm/.local/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\\r\\n     LD_LIBRARY_PATH                 :\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /home/lidavidm/miniforge3/envs/cudf\\r\\n     PYTHON_PATH                     :\\r\\n     \\r\\n     ***conda packages***\\r\\n     /home/lidavidm/miniforge3/condabin/conda\\r\\n     # packages in environment at /home/lidavidm/miniforge3/envs/cudf:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                       2_gnu    conda-forge\\r\\n     aws-c-auth                0.7.8                h538f98c_2    conda-forge\\r\\n     aws-c-cal                 0.6.9                h5d48c4d_2    conda-forge\\r\\n     aws-c-common              0.9.10               hd590300_0    conda-forge\\r\\n     aws-c-compression         0.2.17               h7f92143_7    conda-forge\\r\\n     aws-c-event-stream        0.3.2                h0bcb0bb_8    conda-forge\\r\\n     aws-c-http                0.7.14               hd268abd_3    conda-forge\\r\\n     aws-c-io                  0.13.36              he0cd244_2    conda-forge\\r\\n     aws-c-mqtt                0.9.10               h35285c7_2    conda-forge\\r\\n     aws-c-s3                  0.4.4                h0448019_0    conda-forge\\r\\n     aws-c-sdkutils            0.1.13               h7f92143_0    conda-forge\\r\\n     aws-checksums             0.1.17               h7f92143_6    conda-forge\\r\\n     aws-crt-cpp               0.24.11              h5bdc202_2    conda-forge\\r\\n     aws-sdk-cpp               1.11.210             h967ea9e_4    conda-forge\\r\\n     bzip2                     1.0.8                hd590300_5    conda-forge\\r\\n     c-ares                    1.23.0               hd590300_0    conda-forge\\r\\n     ca-certificates           2023.11.17           hbcca054_0    conda-forge\\r\\n     cachetools                5.3.2              pyhd8ed1ab_0    conda-forge\\r\\n     cubinlinker               0.3.0           py310hfdf336d_1    rapidsai-nightly\\r\\n     cuda-python               11.8.3          py310h70a93da_0    conda-forge\\r\\n     cuda-version              11.8                 h70ddcb2_2    conda-forge\\r\\n     cudatoolkit               11.8.0              h4ba93d1_12    conda-forge\\r\\n     cudf                      23.12.00a717    cuda11_py310_231212_gfd2f6a6fd1_717    rapidsai-nightly\\r\\n     cupy                      12.3.0          py310hf4db66c_0    conda-forge\\r\\n     dlpack                    0.5                  h9c3ff4c_0    conda-forge\\r\\n     fastrlock                 0.8.2           py310hc6cd4ac_1    conda-forge\\r\\n     fmt                       10.1.1               h00ab1b0_1    conda-forge\\r\\n     fsspec                    2023.12.2          pyhca7485f_0    conda-forge\\r\\n     gflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\n     glog                      0.6.0                h6f12383_0    conda-forge\\r\\n     gmock                     1.14.0               ha770c72_1    conda-forge\\r\\n     gtest                     1.14.0               h00ab1b0_1    conda-forge\\r\\n     icu                       73.2                 h59595ed_0    conda-forge\\r\\n     keyutils                  1.6.1                h166bdaf_0    conda-forge\\r\\n     krb5                      1.21.2               h659d440_0    conda-forge\\r\\n     ld_impl_linux-64          2.40                 h41732ed_0    conda-forge\\r\\n     libabseil                 20230802.1      cxx17_h59595ed_0    conda-forge\\r\\n     libarrow                  14.0.1           h0f82fcc_9_cpu    conda-forge\\r\\n     libarrow-acero            14.0.1           h59595ed_9_cpu    conda-forge\\r\\n     libarrow-dataset          14.0.1           h59595ed_9_cpu    conda-forge\\r\\n     libarrow-flight           14.0.1           h120cb0d_9_cpu    conda-forge\\r\\n     libarrow-flight-sql       14.0.1           h61ff412_9_cpu    conda-forge\\r\\n     libarrow-gandiva          14.0.1           hacb8726_9_cpu    conda-forge\\r\\n     libarrow-substrait        14.0.1           h61ff412_9_cpu    conda-forge\\r\\n     libblas                   3.9.0           20_linux64_openblas    conda-forge\\r\\n     libbrotlicommon           1.1.0                hd590300_1    conda-forge\\r\\n     libbrotlidec              1.1.0                hd590300_1    conda-forge\\r\\n     libbrotlienc              1.1.0                hd590300_1    conda-forge\\r\\n     libcblas                  3.9.0           20_linux64_openblas    conda-forge\\r\\n     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge\\r\\n     libcudf                   23.12.00a717    cuda11_231212_gfd2f6a6fd1_717    rapidsai-nightly\\r\\n     libcufile                 1.4.0.31                      0    nvidia\\r\\n     libcufile-dev             1.4.0.31                      0    nvidia\\r\\n     libcurl                   8.5.0                hca28451_0    conda-forge\\r\\n     libedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\n     libev                     4.33                 hd590300_2    conda-forge\\r\\n     libevent                  2.1.12               hf998b51_1    conda-forge\\r\\n     libffi                    3.4.2                h7f98852_5    conda-forge\\r\\n     libgcc-ng                 13.2.0               h807b86a_3    conda-forge\\r\\n     libgfortran-ng            13.2.0               h69a702a_3    conda-forge\\r\\n     libgfortran5              13.2.0               ha4646dd_3    conda-forge\\r\\n     libgomp                   13.2.0               h807b86a_3    conda-forge\\r\\n     libgoogle-cloud           2.12.0               h5206363_4    conda-forge\\r\\n     libgrpc                   1.59.3               hd6c4280_0    conda-forge\\r\\n     libiconv                  1.17                 hd590300_1    conda-forge\\r\\n     libkvikio                 23.12.00a       cuda11_231212_g26efdd1_23    rapidsai-nightly\\r\\n     liblapack                 3.9.0           20_linux64_openblas    conda-forge\\r\\n     libllvm14                 14.0.6               hcd5def8_4    conda-forge\\r\\n     libllvm15                 15.0.7               hb3ce162_4    conda-forge\\r\\n     libnghttp2                1.58.0               h47da74e_1    conda-forge\\r\\n     libnsl                    2.0.1                hd590300_0    conda-forge\\r\\n     libnuma                   2.0.16               h0b41bf4_1    conda-forge\\r\\n     libopenblas               0.3.25          pthreads_h413a1c8_0    conda-forge\\r\\n     libparquet                14.0.1           h352af49_9_cpu    conda-forge\\r\\n     libprotobuf               4.24.4               hf27288f_0    conda-forge\\r\\n     libre2-11                 2023.06.02           h7a70373_0    conda-forge\\r\\n     librmm                    23.12.00             h4725429_0    conda-forge\\r\\n     libsqlite                 3.44.2               h2797004_0    conda-forge\\r\\n     libssh2                   1.11.0               h0841786_0    conda-forge\\r\\n     libstdcxx-ng              13.2.0               h7e041cc_3    conda-forge\\r\\n     libthrift                 0.19.0               hb90f79a_1    conda-forge\\r\\n     libutf8proc               2.8.0                h166bdaf_0    conda-forge\\r\\n     libuuid                   2.38.1               h0b41bf4_0    conda-forge\\r\\n     libxml2                   2.12.2               h232c23b_0    conda-forge\\r\\n     libzlib                   1.2.13               hd590300_5    conda-forge\\r\\n     llvmlite                  0.40.1          py310h1b8f574_0    conda-forge\\r\\n     lz4-c                     1.9.4                hcb278e6_0    conda-forge\\r\\n     markdown-it-py            3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     mdurl                     0.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     ncurses                   6.4                  h59595ed_2    conda-forge\\r\\n     numba                     0.57.1          py310h0f6aa51_0    conda-forge\\r\\n     numpy                     1.24.4          py310ha4c1d20_0    conda-forge\\r\\n     nvcomp                    3.0.4                h838ba91_1    conda-forge\\r\\n     nvtx                      0.2.8           py310h2372a71_1    conda-forge\\r\\n     openssl                   3.2.0                hd590300_1    conda-forge\\r\\n     orc                       1.9.2                h4b38347_0    conda-forge\\r\\n     packaging                 23.2               pyhd8ed1ab_0    conda-forge\\r\\n     pandas                    1.5.3           py310h9b08913_1    conda-forge\\r\\n     pip                       23.3.1             pyhd8ed1ab_0    conda-forge\\r\\n     protobuf                  4.24.4          py310h620c231_0    conda-forge\\r\\n     ptxcompiler               0.8.1           py310h70a93da_2    conda-forge\\r\\n     pyarrow                   14.0.1          py310hf9e7431_9_cpu    conda-forge\\r\\n     pygments                  2.17.2             pyhd8ed1ab_0    conda-forge\\r\\n     python                    3.10.13         hd12c33a_0_cpython    conda-forge\\r\\n     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\\r\\n     python_abi                3.10                    4_cp310    conda-forge\\r\\n     pytz                      2023.3.post1       pyhd8ed1ab_0    conda-forge\\r\\n     rdma-core                 49.0                 hd3aeb46_1    conda-forge\\r\\n     re2                       2023.06.02           h2873b5e_0    conda-forge\\r\\n     readline                  8.2                  h8228510_1    conda-forge\\r\\n     rich                      13.7.0             pyhd8ed1ab_0    conda-forge\\r\\n     rmm                       23.12.00        cuda11_py310_231206_g2db5cbb3_0    rapidsai\\r\\n     s2n                       1.4.0                h06160fa_0    conda-forge\\r\\n     setuptools                68.2.2             pyhd8ed1ab_0    conda-forge\\r\\n     six                       1.16.0             pyh6c4a22f_0    conda-forge\\r\\n     snappy                    1.1.10               h9fff704_0    conda-forge\\r\\n     spdlog                    1.12.0               hd2e6256_2    conda-forge\\r\\n     tk                        8.6.13          noxft_h4845f30_101    conda-forge\\r\\n     typing_extensions         4.9.0              pyha770c72_0    conda-forge\\r\\n     tzdata                    2023c                h71feb2d_0    conda-forge\\r\\n     ucx                       1.15.0               hae80064_1    conda-forge\\r\\n     wheel                     0.42.0             pyhd8ed1ab_0    conda-forge\\r\\n     xz                        5.2.6                h166bdaf_0    conda-forge\\r\\n     zstd                      1.5.5                hfc55251_0    conda-forge\\r\\n     \\r\\n</pre></details>\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nI\\'m actually using C++, but chose Python to reproduce.\\ncreatedAt: 2023-12-12T19:27:33Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: David Li\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 315}),\n",
       " Document(page_content=': 715\\ntitle: [BUG] `as_column` of pandas timestamps delivers different resolution datetime depending on whether we pass a scalar or list\\nbody: **Describe the bug**\\r\\n\\r\\n```\\r\\nimport pandas as pd\\r\\nfrom cudf.core.column import as_column\\r\\n\\r\\ndata = pd.Timestamp(\"2000-01-01\")\\r\\n\\r\\nfrom_scalar = as_column(data)\\r\\nfrom_list = as_column([data])\\r\\n\\r\\nassert from_scalar.dtype == from_list.dtype # False\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nThe resolution should be inferred consistently. Note that `cudf.Scalar(data)` infers the same (nanosecond) resolution as `as_column([data])`.\\ncreatedAt: 2023-12-14T11:33:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 316}),\n",
       " Document(page_content=': 716\\ntitle: [QST] Calling cudf.dataframe.apply from c++ or porting to libcudf\\nbody: Dear Rapids.Ai Team,\\r\\n\\r\\nin the cuDF python API documentation there are several methods which are not in libcudf for c++:\\r\\ncudf.dataframe.apply\\r\\ncudf.dataframe.applymap\\r\\ncudf.dataframe.apply_rows\\r\\ncudf.dataframe.apply_chunks\\r\\n\\r\\n1) Is there any chance that those functions will be made available in libcudf for c++ ?\\r\\n2) Is there a way we could call the cuDF python functions from libcudf c++ context or from a general c++ context using pybind11 or  python c-api ?\\r\\n3) Could you enhance the examples section with such a code which shows how to call python cuDF from c++ ?\\r\\n\\r\\nBest regards\\r\\nDeveloper\\ncreatedAt: 2023-12-14T13:10:54Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: Freelancer', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 317}),\n",
       " Document(page_content=': 717\\ntitle: [BUG] For certain parquet list schemas, the root PageNestingInfo struct can end up uninitialized.\\nbody: Inside of the `allocate_nesting_info` function, we allocate PageNestingInfo and PageNestingDecodeInfo structs and initialize them.  However, the logic for traversing the schema in the file can sometimes leave the 0th element uninitialized.  This is a mild bug that leads to a slightly wrong size calculating for output chunk sizes in the chunked reader.  \\r\\n\\r\\nThe easiest way to repro is with the file `python/cudf/cudf/tests/data/parquet/one_level_list.parquet`\\ncreatedAt: 2023-12-14T21:40:52Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 318}),\n",
       " Document(page_content=\": 718\\ntitle: [QST] How'd this work with multi-threading pandas ?\\nbody: **What is your question?**\\r\\nI have a multi-thread pandas process to divide large dataset by date ranges  then combine them,  trying cudf now for speed . \\r\\n\\r\\nIt does something like this ,  args contains the start/end_dt for each segment, run to process segments\\r\\nwhile Pool() as pool : \\r\\n   result = pool.starmap(run,  args)\\r\\n\\r\\nHowever , running in cudf it  threw this error just now. \\r\\n__pickle.PicklingError: Can't pickle <built-in function _timedelta_unpickle>: it's not the same object as pandas._libs.tslibs.timedeltas._timedelta_unpickle_\\ncreatedAt: 2023-12-20T07:47:29Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Henry Zhang\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 319}),\n",
       " Document(page_content=': 720\\ntitle: [QST] Does the read_json() method support GPU acceleration?\\nbody: At first, I see this article: [GPU-Accelerated JSON Data Processing with RAPIDS](https://developer.nvidia.com/blog/gpu-accelerated-json-data-processing-with-rapids/)\\r\\nI follow it to use the cudf.read_json(), but I get the warning\\r\\n`UserWarning: Using CPU via Pandas to read JSON dataset, this may be GPU accelerated in the future` \\r\\nand I use `%%cudf.pandas.line_profile`, it shows there is no GPU TIME.\\r\\n![image](https://github.com/rapidsai/cudf/assets/76741680/e96c4355-e6f9-430e-be36-71a78159ebd7)\\r\\n\\r\\nBut, when I load the cudf before by running `%load_ext cudf.pandas`\\r\\nand I change `import cudf as pd` to `import pandas as pd`\\r\\nIt still has the warning, but show the GPU TIME.\\r\\nSo I want to know does the read_json() method support GPU acceleration?\\r\\n![image](https://github.com/rapidsai/cudf/assets/76741680/5d4465aa-7b41-47af-bfbf-9692ff1025c8)\\ncreatedAt: 2023-12-25T10:13:46Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: TX\\ncompany: NJUPT', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 320}),\n",
       " Document(page_content=': 721\\ntitle: [BUG] The read_json() method of cudf can\\'t parse the string like \"5-0\"\\nbody: **Describe the bug**\\r\\nThe read_json() method of cudf can\\'t parse the string like \"5-0\".\\r\\nIt seems that the number in front cannot be larger than the number in the back.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nrun code\\r\\n```\\r\\nimport cudf as pd\\r\\n\\r\\ndata = \\'\\'\\'[{\"id\":\"1\",\"Col_01\":\"test\",\"Col_02\":\"77\"},\\r\\n\\r\\n{\"id\":\"2\",\"Col_01\":\"test\",\"Col_02\":\"1355-0652142\"}]\\r\\n\\'\\'\\'\\r\\n\\r\\ndf = pd.read_json(data, orient = \"records\")\\r\\n\\r\\ndf\\r\\n```\\r\\nget error\\r\\n![image](https://github.com/rapidsai/cudf/assets/76741680/b8998b5d-a4e6-4ea3-83d0-4474dccfc39b)\\r\\n\\r\\nIf I use the normal pandas, it can get the correct answer.\\r\\n```\\r\\nimport pandas as pd\\r\\n\\r\\ndata = \\'\\'\\'[{\"id\":\"1\",\"Col_01\":\"test\",\"Col_02\":\"77\"},\\r\\n\\r\\n{\"id\":\"2\",\"Col_01\":\"test\",\"Col_02\":\"1355-0652142\"}]\\r\\n\\'\\'\\'\\r\\n\\r\\ndf = pd.read_json(data, orient = \"records\")\\r\\n\\r\\ndf\\r\\n```\\r\\nIf I change the `5-0` to `5-5` and still use cudf, it also right.\\r\\n```\\r\\nimport cudf as pd\\r\\n\\r\\ndata = \\'\\'\\'[{\"id\":\"1\",\"Col_01\":\"test\",\"Col_02\":\"77\"},\\r\\n\\r\\n{\"id\":\"2\",\"Col_01\":\"test\",\"Col_02\":\"1355-5652142\"}]\\r\\n\\'\\'\\'\\r\\n\\r\\ndf = pd.read_json(data, orient = \"records\")\\r\\n\\r\\ndf\\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Bare-metal\\r\\n - Method of cuDF install: pip\\ncreatedAt: 2023-12-25T10:32:51Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: TX\\ncompany: NJUPT', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 321}),\n",
       " Document(page_content=': 722\\ntitle: [BUG] Type checks fail with cuDF pandas objects\\nbody: **Describe the bug**\\r\\nSome type checks fail with cuDF pandas objects.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nThe following examples fail with assertion errors:\\r\\n```\\r\\nimport cudf.pandas\\r\\ncudf.pandas.install()\\r\\nimport pandas as pd\\r\\n\\r\\nfreq = \"D\"\\r\\nassert isinstance(pd.tseries.frequencies.to_offset(freq), pd.tseries.offsets.BaseOffset)\\r\\n```\\r\\n\\r\\n```\\r\\nimport cudf.pandas\\r\\nimport numpy as np\\r\\ncudf.pandas.install()\\r\\nimport pandas as pd\\r\\n\\r\\ndf = pd.DataFrame([0, 1, 2])\\r\\n\\r\\nassert isinstance(df.to_numpy(), np.ndarray)\\r\\n```\\r\\n\\r\\nBoth of these examples pass if we remove the `cudf.pandas.install()` line.\\r\\n\\r\\n**Expected behavior**\\r\\nI expected the code blocks above to run so that I could use the accelerated version of pandas with zero code changes. The errors I\\'m facing make it difficult to work with cuDF pandas and other libraries (e.g. https://github.com/Nixtla/statsforecast).\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Bare-metal\\r\\n - Method of cuDF install: conda\\r\\n\\r\\n**Environment details**\\r\\n\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n     \\r\\n     **git***\\r\\n     Not inside a git repository\\r\\n     \\r\\n     ***OS Information***\\r\\n     DISTRIB_ID=Ubuntu\\r\\n     DISTRIB_RELEASE=20.04\\r\\n     DISTRIB_CODENAME=focal\\r\\n     DISTRIB_DESCRIPTION=\"Ubuntu 20.04.4 LTS\"\\r\\n     NAME=\"Ubuntu\"\\r\\n     VERSION=\"20.04.4 LTS (Focal Fossa)\"\\r\\n     ID=ubuntu\\r\\n     ID_LIKE=debian\\r\\n     PRETTY_NAME=\"Ubuntu 20.04.4 LTS\"\\r\\n     VERSION_ID=\"20.04\"\\r\\n     HOME_URL=\"https://www.ubuntu.com/\"\\r\\n     SUPPORT_URL=\"https://help.ubuntu.com/\"\\r\\n     BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\\r\\n     PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\\r\\n     VERSION_CODENAME=focal\\r\\n     UBUNTU_CODENAME=focal\\r\\n     Linux TurinTech-0004 5.15.0-91-generic #101~20.04.1-Ubuntu SMP Thu Nov 16 14:22:28 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\\r\\n     \\r\\n     ***GPU Information***\\r\\n     Wed Dec 27 21:18:49 2023\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\\r\\n     |-------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                               |                      |               MIG M. |\\r\\n     |===============================+======================+======================|\\r\\n     |   0  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\\r\\n     |  0%   54C    P8    22W / 170W |   1681MiB / 12288MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     \\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | Processes:                                                                  |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n     |        ID   ID                                                   Usage      |\\r\\n     |=============================================================================|\\r\\n     |    0   N/A  N/A      1512      G   /usr/lib/xorg/Xorg                198MiB |\\r\\n     |    0   N/A  N/A      2685      G   /usr/lib/xorg/Xorg               1239MiB |\\r\\n     |    0   N/A  N/A      2814      G   /usr/bin/gnome-shell               22MiB |\\r\\n     |    0   N/A  N/A      3403      G   ...AAAAAAAAA= --shared-files      198MiB |\\r\\n     |    0   N/A  N/A      5817      G   gnome-control-center                2MiB |\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     \\r\\n     ***CPU***\\r\\n     Architecture:                       x86_64\\r\\n     CPU op-mode(s):                     32-bit, 64-bit\\r\\n     Byte Order:                         Little Endian\\r\\n     Address sizes:                      48 bits physical, 48 bits virtual\\r\\n     CPU(s):                             24\\r\\n     On-line CPU(s) list:                0-23\\r\\n     Thread(s) per core:                 2\\r\\n     Core(s) per socket:                 12\\r\\n     Socket(s):                          1\\r\\n     NUMA node(s):                       1\\r\\n     Vendor ID:                          AuthenticAMD\\r\\n     CPU family:                         25\\r\\n     Model:                              33\\r\\n     Model name:                         AMD Ryzen 9 5900X 12-Core Processor\\r\\n     Stepping:                           0\\r\\n     Frequency boost:                    enabled\\r\\n     CPU MHz:                            3597.987\\r\\n     CPU max MHz:                        3700.0000\\r\\n     CPU min MHz:                        2200.0000\\r\\n     BogoMIPS:                           7386.52\\r\\n     Virtualisation:                     AMD-V\\r\\n     L1d cache:                          384 KiB\\r\\n     L1i cache:                          384 KiB\\r\\n     L2 cache:                           6 MiB\\r\\n     L3 cache:                           64 MiB\\r\\n     NUMA node0 CPU(s):                  0-23\\r\\n     Vulnerability Gather data sampling: Not affected\\r\\n     Vulnerability Itlb multihit:        Not affected\\r\\n     Vulnerability L1tf:                 Not affected\\r\\n     Vulnerability Mds:                  Not affected\\r\\n     Vulnerability Meltdown:             Not affected\\r\\n     Vulnerability Mmio stale data:      Not affected\\r\\n     Vulnerability Retbleed:             Not affected\\r\\n     Vulnerability Spec rstack overflow: Mitigation; safe RET, no microcode\\r\\n     Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp\\r\\n     Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\r\\n     Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP always-on, RSB filling, PBRSB-eIBRS Not affected\\r\\n     Vulnerability Srbds:                Not affected\\r\\n     Vulnerability Tsx async abort:      Not affected\\r\\n     Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm\\r\\n     \\r\\n     ***CMake***\\r\\n     \\r\\n     ***g++***\\r\\n     /usr/bin/g++\\r\\n     g++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\\r\\n     Copyright (C) 2019 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n     \\r\\n     \\r\\n     ***nvcc***\\r\\n     /home/paul/anaconda3/envs/rapids-23.12/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2022 NVIDIA Corporation\\r\\n     Built on Mon_Oct_24_19:12:58_PDT_2022\\r\\n     Cuda compilation tools, release 12.0, V12.0.76\\r\\n     Build cuda_12.0.r12.0/compiler.31968024_0\\r\\n     \\r\\n     ***Python***\\r\\n     /home/paul/anaconda3/envs/rapids-23.12/bin/python\\r\\n     Python 3.9.18\\r\\n     \\r\\n     ***Environment Variables***\\r\\n     PATH                            : /home/paul/.local/bin:/home/paul/.cargo/bin:/home/paul/anaconda3/envs/rapids-23.12/bin:/home/paul/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\\r\\n     LD_LIBRARY_PATH                 :\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /home/paul/anaconda3/envs/rapids-23.12\\r\\n     PYTHON_PATH                     :\\r\\n     \\r\\n     ***conda packages***\\r\\n     /home/paul/anaconda3/condabin/conda\\r\\n     # packages in environment at /home/paul/anaconda3/envs/rapids-23.12:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                       2_gnu    conda-forge\\r\\n     accelerate                0.19.0                   pypi_0    pypi\\r\\n     adagio                    0.2.4                    pypi_0    pypi\\r\\n     aiohttp                   3.9.1            py39hd1e30aa_0    conda-forge\\r\\n     aiosignal                 1.3.1              pyhd8ed1ab_0    conda-forge\\r\\n     alabaster                 0.7.13                   pypi_0    pypi\\r\\n     alembic                   1.13.1                   pypi_0    pypi\\r\\n     antlr4-python3-runtime    4.11.1                   pypi_0    pypi\\r\\n     anyio                     4.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     aom                       3.7.1                h59595ed_0    conda-forge\\r\\n     appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge\\r\\n     argon2-cffi               23.1.0             pyhd8ed1ab_0    conda-forge\\r\\n     argon2-cffi-bindings      21.2.0           py39hd1e30aa_4    conda-forge\\r\\n     arrow                     1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     astroid                   2.15.8                   pypi_0    pypi\\r\\n     async-timeout             4.0.3              pyhd8ed1ab_0    conda-forge\\r\\n     attrs                     23.1.0             pyh71513ae_1    conda-forge\\r\\n     aws-c-auth                0.7.8                hcf8cf63_3    conda-forge\\r\\n     aws-c-cal                 0.6.9                h5d48c4d_2    conda-forge\\r\\n     aws-c-common              0.9.10               hd590300_0    conda-forge\\r\\n     aws-c-compression         0.2.17               h7f92143_7    conda-forge\\r\\n     aws-c-event-stream        0.3.2                h0bcb0bb_8    conda-forge\\r\\n     aws-c-http                0.7.15               hd268abd_0    conda-forge\\r\\n     aws-c-io                  0.13.36              he0cd244_2    conda-forge\\r\\n     aws-c-mqtt                0.10.0               hbafccad_1    conda-forge\\r\\n     aws-c-s3                  0.4.5                h47b1690_1    conda-forge\\r\\n     aws-c-sdkutils            0.1.13               h7f92143_0    conda-forge\\r\\n     aws-checksums             0.1.17               h7f92143_6    conda-forge\\r\\n     aws-crt-cpp               0.25.0               h169d4cb_3    conda-forge\\r\\n     aws-sdk-cpp               1.11.210             h0853bfa_5    conda-forge\\r\\n     azure-core-cpp            1.10.3               h91d86a7_0    conda-forge\\r\\n     azure-storage-blobs-cpp   12.10.0              h00ab1b0_0    conda-forge\\r\\n     azure-storage-common-cpp  12.5.0               hb858b4b_2    conda-forge\\r\\n     babel                     2.14.0                   pypi_0    pypi\\r\\n     beautifulsoup4            4.12.2             pyha770c72_0    conda-forge\\r\\n     black                     23.7.0                   pypi_0    pypi\\r\\n     bleach                    6.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     blosc                     1.21.5               h0f2a231_0    conda-forge\\r\\n     bokeh                     3.3.2              pyhd8ed1ab_0    conda-forge\\r\\n     branca                    0.7.0              pyhd8ed1ab_1    conda-forge\\r\\n     brotli                    1.1.0                hd590300_1    conda-forge\\r\\n     brotli-bin                1.1.0                hd590300_1    conda-forge\\r\\n     brotli-python             1.1.0            py39h3d6467e_1    conda-forge\\r\\n     brunsli                   0.1                  h9c3ff4c_0    conda-forge\\r\\n     bzip2                     1.0.8                hd590300_5    conda-forge\\r\\n     c-ares                    1.24.0               hd590300_0    conda-forge\\r\\n     c-blosc2                  2.11.3               hb4ffafa_0    conda-forge\\r\\n     ca-certificates           2023.11.17           hbcca054_0    conda-forge\\r\\n     cached-property           1.5.2                hd8ed1ab_1    conda-forge\\r\\n     cached_property           1.5.2              pyha770c72_1    conda-forge\\r\\n     cachetools                5.3.2              pyhd8ed1ab_0    conda-forge\\r\\n     cairo                     1.18.0               h3faef2a_0    conda-forge\\r\\n     catboost                  1.2.2                    pypi_0    pypi\\r\\n     category-encoders         2.6.3                    pypi_0    pypi\\r\\n     certifi                   2023.11.17         pyhd8ed1ab_0    conda-forge\\r\\n     cffi                      1.16.0           py39h7a31438_0    conda-forge\\r\\n     cfgv                      3.4.0                    pypi_0    pypi\\r\\n     cfitsio                   4.3.1                hbdc6101_0    conda-forge\\r\\n     charls                    2.4.2                h59595ed_0    conda-forge\\r\\n     charset-normalizer        3.3.2              pyhd8ed1ab_0    conda-forge\\r\\n     click                     8.0.4                    pypi_0    pypi\\r\\n     click-plugins             1.1.1                      py_0    conda-forge\\r\\n     cligj                     0.7.2              pyhd8ed1ab_1    conda-forge\\r\\n     cloudpickle               3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     cmaes                     0.10.0                   pypi_0    pypi\\r\\n     colorama                  0.4.6              pyhd8ed1ab_0    conda-forge\\r\\n     colorcet                  3.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     colorlog                  6.8.0                    pypi_0    pypi\\r\\n     contourpy                 1.2.0            py39h7633fee_0    conda-forge\\r\\n     coverage                  7.3.4                    pypi_0    pypi\\r\\n     cryptography              41.0.7                   pypi_0    pypi\\r\\n     cucim                     23.12.01        cuda12_py39_231211_ga3445df_0    rapidsai\\r\\n     cuda-cccl_linux-64        12.0.90              ha770c72_1    conda-forge\\r\\n     cuda-cudart               12.0.107             hd3aeb46_8    conda-forge\\r\\n     cuda-cudart-dev           12.0.107             hd3aeb46_8    conda-forge\\r\\n     cuda-cudart-dev_linux-64  12.0.107             h59595ed_8    conda-forge\\r\\n     cuda-cudart-static        12.0.107             hd3aeb46_8    conda-forge\\r\\n     cuda-cudart-static_linux-64 12.0.107             h59595ed_8    conda-forge\\r\\n     cuda-cudart_linux-64      12.0.107             h59595ed_8    conda-forge\\r\\n     cuda-nvcc-dev_linux-64    12.0.76              ha770c72_1    conda-forge\\r\\n     cuda-nvcc-impl            12.0.76              h59595ed_1    conda-forge\\r\\n     cuda-nvcc-tools           12.0.76              h59595ed_1    conda-forge\\r\\n     cuda-nvrtc                12.0.76              hd3aeb46_2    conda-forge\\r\\n     cuda-nvtx                 12.0.76              h59595ed_1    conda-forge\\r\\n     cuda-profiler-api         12.0.76              ha770c72_0    conda-forge\\r\\n     cuda-python               12.0.0           py39h2d39e0c_4    conda-forge\\r\\n     cuda-version              12.0                 hffde075_2    conda-forge\\r\\n     cudf                      23.12.01        cuda12_py39_231208_g2ce46216b5_0    rapidsai\\r\\n     cudf_kafka                23.12.01        cuda12_py39_231208_g2ce46216b5_0    rapidsai\\r\\n     cugraph                   23.12.00        cuda12_py39_231206_g1309813f_0    rapidsai\\r\\n     cuml                      23.12.00        cuda12_py39_231206_gad2bd2b65_0    rapidsai\\r\\n     cuproj                    23.12.00        cuda12_py39_231206_g3a357729_0    rapidsai\\r\\n     cupy                      12.3.0           py39hc7c1505_0    conda-forge\\r\\n     cuspatial                 23.12.01        cuda12_py39_231207_g16727064_0    rapidsai\\r\\n     custreamz                 23.12.01        cuda12_py39_231208_g2ce46216b5_0    rapidsai\\r\\n     cuxfilter                 23.12.00        cuda12_py39_231206_g63dabeb_0    rapidsai\\r\\n     cycler                    0.12.1             pyhd8ed1ab_0    conda-forge\\r\\n     cyrus-sasl                2.1.27               h54b06d7_7    conda-forge\\r\\n     cython                    3.0.7                    pypi_0    pypi\\r\\n     cytoolz                   0.12.2           py39hd1e30aa_1    conda-forge\\r\\n     daal                      2023.2.0                 pypi_0    pypi\\r\\n     daal4py                   2023.2.0                 pypi_0    pypi\\r\\n     darts                     0.27.1                   pypi_0    pypi\\r\\n     dask                      2023.11.0          pyhd8ed1ab_0    conda-forge\\r\\n     dask-core                 2023.11.0          pyhd8ed1ab_0    conda-forge\\r\\n     dask-cuda                 23.12.00        py39_231206_ge1638ae_0    rapidsai\\r\\n     dask-cudf                 23.12.01        cuda12_py39_231208_g2ce46216b5_0    rapidsai\\r\\n     datasets                  2.15.0                   pypi_0    pypi\\r\\n     datashader                0.16.0             pyhd8ed1ab_0    conda-forge\\r\\n     dav1d                     1.2.1                hd590300_0    conda-forge\\r\\n     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     deprecated                1.2.14                   pypi_0    pypi\\r\\n     dill                      0.3.7                    pypi_0    pypi\\r\\n     distlib                   0.3.8                    pypi_0    pypi\\r\\n     distributed               2023.11.0          pyhd8ed1ab_0    conda-forge\\r\\n     dlpack                    0.5                  h9c3ff4c_0    conda-forge\\r\\n     docutils                  0.18.1                   pypi_0    pypi\\r\\n     entrypoints               0.4                pyhd8ed1ab_0    conda-forge\\r\\n     exceptiongroup            1.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     execnet                   2.0.2                    pypi_0    pypi\\r\\n     expat                     2.5.0                hcb278e6_1    conda-forge\\r\\n     fastrlock                 0.8.2            py39h3d6467e_2    conda-forge\\r\\n     filelock                  3.13.1                   pypi_0    pypi\\r\\n     fiona                     1.9.5            py39hcfcd403_2    conda-forge\\r\\n     flake8                    6.0.0                    pypi_0    pypi\\r\\n     fmt                       9.1.0                h924138e_0    conda-forge\\r\\n     folium                    0.15.1             pyhd8ed1ab_0    conda-forge\\r\\n     font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge\\r\\n     font-ttf-inconsolata      3.000                h77eed37_0    conda-forge\\r\\n     font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge\\r\\n     font-ttf-ubuntu           0.83                 h77eed37_1    conda-forge\\r\\n     fontconfig                2.14.2               h14ed4e7_0    conda-forge\\r\\n     fonts-conda-ecosystem     1                             0    conda-forge\\r\\n     fonts-conda-forge         1                             0    conda-forge\\r\\n     fonttools                 4.47.0           py39hd1e30aa_0    conda-forge\\r\\n     fqdn                      1.5.1              pyhd8ed1ab_0    conda-forge\\r\\n     freetype                  2.12.1               h267a509_2    conda-forge\\r\\n     freexl                    2.0.0                h743c826_0    conda-forge\\r\\n     frozendict                2.3.10                   pypi_0    pypi\\r\\n     frozenlist                1.4.1            py39hd1e30aa_0    conda-forge\\r\\n     fs                        2.4.16                   pypi_0    pypi\\r\\n     fsspec                    2023.10.0                pypi_0    pypi\\r\\n     fugue                     0.8.7                    pypi_0    pypi\\r\\n     fugue-sql-antlr           0.2.0                    pypi_0    pypi\\r\\n     gdal                      3.8.2            py39h14df8fe_0    conda-forge\\r\\n     gdk-pixbuf                2.42.10              h829c605_4    conda-forge\\r\\n     geopandas                 0.14.1             pyhd8ed1ab_0    conda-forge\\r\\n     geopandas-base            0.14.1             pyha770c72_0    conda-forge\\r\\n     geos                      3.12.1               h59595ed_0    conda-forge\\r\\n     geotiff                   1.7.1               h6b2125f_15    conda-forge\\r\\n     gettext                   0.21.1               h27087fc_0    conda-forge\\r\\n     gflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\n     giflib                    5.2.1                h0b41bf4_3    conda-forge\\r\\n     glog                      0.6.0                h6f12383_0    conda-forge\\r\\n     gmock                     1.14.0               ha770c72_1    conda-forge\\r\\n     greenlet                  3.0.3                    pypi_0    pypi\\r\\n     gtest                     1.14.0               h00ab1b0_1    conda-forge\\r\\n     hdf4                      4.2.15               h2a13503_7    conda-forge\\r\\n     hdf5                      1.14.3          nompi_h4f84152_100    conda-forge\\r\\n     holidays                  0.27                     pypi_0    pypi\\r\\n     holoviews                 1.18.1             pyhd8ed1ab_0    conda-forge\\r\\n     huggingface-hub           0.20.1                   pypi_0    pypi\\r\\n     icu                       73.2                 h59595ed_0    conda-forge\\r\\n     identify                  2.5.33                   pypi_0    pypi\\r\\n     idna                      3.6                pyhd8ed1ab_0    conda-forge\\r\\n     imagecodecs               2023.9.18        py39hf9b8f0e_2    conda-forge\\r\\n     imageio                   2.33.1             pyh8c1a49c_0    conda-forge\\r\\n     imagesize                 1.4.1                    pypi_0    pypi\\r\\n     imbalanced-learn          0.11.0                   pypi_0    pypi\\r\\n     importlib-metadata        7.0.0              pyha770c72_0    conda-forge\\r\\n     importlib-resources       6.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     importlib_metadata        7.0.0                hd8ed1ab_0    conda-forge\\r\\n     importlib_resources       6.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     iniconfig                 2.0.0                    pypi_0    pypi\\r\\n     isoduration               20.11.0            pyhd8ed1ab_0    conda-forge\\r\\n     isort                     5.13.2                   pypi_0    pypi\\r\\n     jaraco-classes            3.3.0                    pypi_0    pypi\\r\\n     jbig                      2.1               h7f98852_2003    conda-forge\\r\\n     jeepney                   0.8.0                    pypi_0    pypi\\r\\n     jinja2                    3.1.2              pyhd8ed1ab_1    conda-forge\\r\\n     joblib                    1.3.2              pyhd8ed1ab_0    conda-forge\\r\\n     json-c                    0.17                 h7ab15ed_0    conda-forge\\r\\n     jsonpointer               2.4              py39hf3d152e_3    conda-forge\\r\\n     jsonschema                4.20.0             pyhd8ed1ab_0    conda-forge\\r\\n     jsonschema-specifications 2023.11.2          pyhd8ed1ab_0    conda-forge\\r\\n     jsonschema-with-format-nongpl 4.20.0             pyhd8ed1ab_0    conda-forge\\r\\n     jupyter-server-proxy      4.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_client            8.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_core              5.5.1            py39hf3d152e_0    conda-forge\\r\\n     jupyter_events            0.9.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_server            2.12.1             pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_server_terminals  0.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyterlab_pygments       0.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     jxrlib                    1.1                  h7f98852_2    conda-forge\\r\\n     kealib                    1.5.3                h2f55d51_0    conda-forge\\r\\n     keyring                   24.3.0                   pypi_0    pypi\\r\\n     keyutils                  1.6.1                h166bdaf_0    conda-forge\\r\\n     kiwisolver                1.4.5            py39h7633fee_1    conda-forge\\r\\n     krb5                      1.21.2               h659d440_0    conda-forge\\r\\n     lazy-object-proxy         1.10.0                   pypi_0    pypi\\r\\n     lazy_loader               0.3                pyhd8ed1ab_0    conda-forge\\r\\n     lcms2                     2.16                 hb7c19ff_0    conda-forge\\r\\n     ld_impl_linux-64          2.40                 h41732ed_0    conda-forge\\r\\n     lerc                      4.0.0                h27087fc_0    conda-forge\\r\\n     libabseil                 20230802.1      cxx17_h59595ed_0    conda-forge\\r\\n     libaec                    1.1.2                h59595ed_1    conda-forge\\r\\n     libarchive                3.7.2                h2aa1ff5_1    conda-forge\\r\\n     libarrow                  14.0.2           hfb4d3a9_0_cpu    conda-forge\\r\\n     libarrow-acero            14.0.2           h59595ed_0_cpu    conda-forge\\r\\n     libarrow-dataset          14.0.2           h59595ed_0_cpu    conda-forge\\r\\n     libarrow-flight           14.0.2           h120cb0d_0_cpu    conda-forge\\r\\n     libarrow-flight-sql       14.0.2           h61ff412_0_cpu    conda-forge\\r\\n     libarrow-gandiva          14.0.2           hacb8726_0_cpu    conda-forge\\r\\n     libarrow-substrait        14.0.2           h61ff412_0_cpu    conda-forge\\r\\n     libavif16                 1.0.3                hef5bec9_1    conda-forge\\r\\n     libblas                   3.9.0           20_linux64_openblas    conda-forge\\r\\n     libboost-headers          1.84.0               ha770c72_0    conda-forge\\r\\n     libbrotlicommon           1.1.0                hd590300_1    conda-forge\\r\\n     libbrotlidec              1.1.0                hd590300_1    conda-forge\\r\\n     libbrotlienc              1.1.0                hd590300_1    conda-forge\\r\\n     libcblas                  3.9.0           20_linux64_openblas    conda-forge\\r\\n     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge\\r\\n     libcublas                 12.0.1.189           hd3aeb46_3    conda-forge\\r\\n     libcublas-dev             12.0.1.189           hd3aeb46_3    conda-forge\\r\\n     libcucim                  23.12.01        cuda12_231211_ga3445df_0    rapidsai\\r\\n     libcudf                   23.12.01        cuda12_231208_g2ce46216b5_0    rapidsai\\r\\n     libcudf_kafka             23.12.01        cuda12_231208_g2ce46216b5_0    rapidsai\\r\\n     libcufft                  11.0.0.21            hd3aeb46_2    conda-forge\\r\\n     libcufile                 1.5.0.59             hd3aeb46_1    conda-forge\\r\\n     libcufile-dev             1.5.0.59             hd3aeb46_1    conda-forge\\r\\n     libcugraph                23.12.00        cuda12_231206_g1309813f_0    rapidsai\\r\\n     libcugraph_etl            23.12.00        cuda12_231206_g1309813f_0    rapidsai\\r\\n     libcugraphops             23.12.00        cuda12_231206_g42d08202_0    nvidia\\r\\n     libcuml                   23.12.00        cuda12_231206_gad2bd2b65_0    rapidsai\\r\\n     libcumlprims              23.12.00        cuda12_231206_gc120fe0_0    nvidia\\r\\n     libcurand                 10.3.1.50            hd3aeb46_1    conda-forge\\r\\n     libcurand-dev             10.3.1.50            hd3aeb46_1    conda-forge\\r\\n     libcurl                   8.5.0                hca28451_0    conda-forge\\r\\n     libcusolver               11.4.2.57            hd3aeb46_2    conda-forge\\r\\n     libcusolver-dev           11.4.2.57            hd3aeb46_2    conda-forge\\r\\n     libcusparse               12.0.0.76            hd3aeb46_2    conda-forge\\r\\n     libcusparse-dev           12.0.0.76            hd3aeb46_2    conda-forge\\r\\n     libcuspatial              23.12.01        cuda12_231207_g16727064_0    rapidsai\\r\\n     libdeflate                1.19                 hd590300_0    conda-forge\\r\\n     libedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\n     libev                     4.33                 hd590300_2    conda-forge\\r\\n     libevent                  2.1.12               hf998b51_1    conda-forge\\r\\n     libexpat                  2.5.0                hcb278e6_1    conda-forge\\r\\n     libffi                    3.4.2                h7f98852_5    conda-forge\\r\\n     libgcc-ng                 13.2.0               h807b86a_3    conda-forge\\r\\n     libgdal                   3.8.2                hed8bd54_0    conda-forge\\r\\n     libgfortran-ng            13.2.0               h69a702a_3    conda-forge\\r\\n     libgfortran5              13.2.0               ha4646dd_3    conda-forge\\r\\n     libglib                   2.78.3               h783c2da_0    conda-forge\\r\\n     libgomp                   13.2.0               h807b86a_3    conda-forge\\r\\n     libgoogle-cloud           2.12.0               h5206363_4    conda-forge\\r\\n     libgrpc                   1.59.3               hd6c4280_0    conda-forge\\r\\n     libiconv                  1.17                 hd590300_2    conda-forge\\r\\n     libjpeg-turbo             3.0.0                hd590300_1    conda-forge\\r\\n     libkml                    1.3.0             h01aab08_1018    conda-forge\\r\\n     libkvikio                 23.12.00        cuda12_231206_gf90bfbe_0    rapidsai\\r\\n     liblapack                 3.9.0           20_linux64_openblas    conda-forge\\r\\n     libllvm14                 14.0.6               hcd5def8_4    conda-forge\\r\\n     libllvm15                 15.0.7               hb3ce162_4    conda-forge\\r\\n     libnetcdf                 4.9.2           nompi_h9612171_113    conda-forge\\r\\n     libnghttp2                1.58.0               h47da74e_1    conda-forge\\r\\n     libnl                     3.9.0                hd590300_0    conda-forge\\r\\n     libnsl                    2.0.1                hd590300_0    conda-forge\\r\\n     libntlm                   1.4               h7f98852_1002    conda-forge\\r\\n     libnuma                   2.0.16               h0b41bf4_1    conda-forge\\r\\n     libnvjitlink              12.0.76              hd3aeb46_2    conda-forge\\r\\n     libnvjpeg                 12.0.0.28            h59595ed_1    conda-forge\\r\\n     libopenblas               0.3.25          pthreads_h413a1c8_0    conda-forge\\r\\n     libparquet                14.0.2           h352af49_0_cpu    conda-forge\\r\\n     libpng                    1.6.39               h753d276_0    conda-forge\\r\\n     libpq                     16.1                 h33b98f1_7    conda-forge\\r\\n     libprotobuf               4.24.4               hf27288f_0    conda-forge\\r\\n     libraft                   23.12.00        cuda12_231206_g9e2d6277_0    rapidsai\\r\\n     libraft-headers           23.12.00        cuda12_231206_g9e2d6277_0    rapidsai\\r\\n     libraft-headers-only      23.12.00        cuda12_231206_g9e2d6277_0    rapidsai\\r\\n     librdkafka                1.9.2                ha5a0de0_2    conda-forge\\r\\n     libre2-11                 2023.06.02           h7a70373_0    conda-forge\\r\\n     librmm                    23.12.00        cuda12_231206_g2db5cbb3_0    rapidsai\\r\\n     librttopo                 1.1.0               h8917695_15    conda-forge\\r\\n     libsodium                 1.0.18               h36c2ea0_1    conda-forge\\r\\n     libspatialindex           1.9.3                h9c3ff4c_4    conda-forge\\r\\n     libspatialite             5.1.0                h7bd4643_4    conda-forge\\r\\n     libsqlite                 3.44.2               h2797004_0    conda-forge\\r\\n     libssh2                   1.11.0               h0841786_0    conda-forge\\r\\n     libstdcxx-ng              13.2.0               h7e041cc_3    conda-forge\\r\\n     libthrift                 0.19.0               hb90f79a_1    conda-forge\\r\\n     libtiff                   4.6.0                ha9c0a0a_2    conda-forge\\r\\n     libutf8proc               2.8.0                h166bdaf_0    conda-forge\\r\\n     libuuid                   2.38.1               h0b41bf4_0    conda-forge\\r\\n     libuv                     1.46.0               hd590300_0    conda-forge\\r\\n     libwebp                   1.3.2                h658648e_1    conda-forge\\r\\n     libwebp-base              1.3.2                hd590300_0    conda-forge\\r\\n     libxcb                    1.15                 h0b41bf4_0    conda-forge\\r\\n     libxgboost                1.7.6           rapidsai_h52ede06_7    rapidsai\\r\\n     libxml2                   2.12.3               h232c23b_0    conda-forge\\r\\n     libzip                    1.10.1               h2629f0a_3    conda-forge\\r\\n     libzlib                   1.2.13               hd590300_5    conda-forge\\r\\n     libzopfli                 1.0.3                h9c3ff4c_0    conda-forge\\r\\n     lightgbm                  3.3.5                    pypi_0    pypi\\r\\n     lightning-utilities       0.10.0                   pypi_0    pypi\\r\\n     linkify-it-py             2.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     llvmlite                  0.41.1                   pypi_0    pypi\\r\\n     locket                    1.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     lz4                       4.3.2            py39h79d96da_1    conda-forge\\r\\n     lz4-c                     1.9.4                hcb278e6_0    conda-forge\\r\\n     lzo                       2.10              h516909a_1000    conda-forge\\r\\n     mako                      1.3.0                    pypi_0    pypi\\r\\n     mapclassify               2.6.1              pyhd8ed1ab_0    conda-forge\\r\\n     markdown                  3.5.1              pyhd8ed1ab_0    conda-forge\\r\\n     markdown-it-py            3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     markupsafe                2.1.3            py39hd1e30aa_1    conda-forge\\r\\n     matplotlib-base           3.8.2            py39he9076e7_0    conda-forge\\r\\n     mccabe                    0.7.0                    pypi_0    pypi\\r\\n     mdit-py-plugins           0.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     mdurl                     0.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     metaml                    1.0.19rc0                pypi_0    pypi\\r\\n     minizip                   4.0.3                h0ab5242_0    conda-forge\\r\\n     mistune                   3.0.2              pyhd8ed1ab_0    conda-forge\\r\\n     more-itertools            10.1.0                   pypi_0    pypi\\r\\n     mpmath                    1.3.0                    pypi_0    pypi\\r\\n     mrmr-selection            0.2.8                    pypi_0    pypi\\r\\n     msgpack-python            1.0.7            py39h7633fee_0    conda-forge\\r\\n     multidict                 6.0.4            py39hd1e30aa_1    conda-forge\\r\\n     multipledispatch          0.6.0                      py_0    conda-forge\\r\\n     multiprocess              0.70.15                  pypi_0    pypi\\r\\n     munkres                   1.1.4              pyh9f0ad1d_0    conda-forge\\r\\n     mypy                      1.4.1                    pypi_0    pypi\\r\\n     mypy-extensions           1.0.0                    pypi_0    pypi\\r\\n     nbclient                  0.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert-core            7.13.1             pyhd8ed1ab_0    conda-forge\\r\\n     nbformat                  5.9.2              pyhd8ed1ab_0    conda-forge\\r\\n     nccl                      2.19.4.1             h3a97aeb_0    conda-forge\\r\\n     ncurses                   6.4                  h59595ed_2    conda-forge\\r\\n     networkx                  3.2                      pypi_0    pypi\\r\\n     nfoursid                  1.0.1                    pypi_0    pypi\\r\\n     nh3                       0.2.15                   pypi_0    pypi\\r\\n     nodeenv                   1.8.0                    pypi_0    pypi\\r\\n     nodejs                    20.9.0               hb753e55_0    conda-forge\\r\\n     nspr                      4.35                 h27087fc_0    conda-forge\\r\\n     nss                       3.96                 h1d7d5a4_0    conda-forge\\r\\n     nuitka                    1.7.5                    pypi_0    pypi\\r\\n     numba                     0.58.1                   pypi_0    pypi\\r\\n     numpy                     1.24.4           py39h6183b62_0    conda-forge\\r\\n     nvcomp                    3.0.4                h10b603f_1    conda-forge\\r\\n     nvidia-cublas-cu12        12.1.3.1                 pypi_0    pypi\\r\\n     nvidia-cuda-cupti-cu12    12.1.105                 pypi_0    pypi\\r\\n     nvidia-cuda-nvrtc-cu12    12.1.105                 pypi_0    pypi\\r\\n     nvidia-cuda-runtime-cu12  12.1.105                 pypi_0    pypi\\r\\n     nvidia-cudnn-cu12         8.9.2.26                 pypi_0    pypi\\r\\n     nvidia-cufft-cu12         11.0.2.54                pypi_0    pypi\\r\\n     nvidia-curand-cu12        10.3.2.106               pypi_0    pypi\\r\\n     nvidia-cusolver-cu12      11.4.5.107               pypi_0    pypi\\r\\n     nvidia-cusparse-cu12      12.1.0.106               pypi_0    pypi\\r\\n     nvidia-nccl-cu12          2.18.1                   pypi_0    pypi\\r\\n     nvidia-nvjitlink-cu12     12.3.101                 pypi_0    pypi\\r\\n     nvidia-nvtx-cu12          12.1.105                 pypi_0    pypi\\r\\n     nvtx                      0.2.8            py39hd1e30aa_1    conda-forge\\r\\n     openjpeg                  2.5.0                h488ebb8_3    conda-forge\\r\\n     openslide                 3.4.1               h58ba908_12    conda-forge\\r\\n     openssl                   3.2.0                hd590300_1    conda-forge\\r\\n     optuna                    3.3.0                    pypi_0    pypi\\r\\n     orc                       1.9.2                h4b38347_0    conda-forge\\r\\n     ordered-set               4.1.0                    pypi_0    pypi\\r\\n     overrides                 7.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     packaging                 23.2               pyhd8ed1ab_0    conda-forge\\r\\n     pandas                    1.5.3            py39h2ad29b5_1    conda-forge\\r\\n     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     panel                     1.3.4              pyhd8ed1ab_0    conda-forge\\r\\n     param                     2.0.1              pyhca7485f_0    conda-forge\\r\\n     partd                     1.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     pathspec                  0.12.1                   pypi_0    pypi\\r\\n     patsy                     0.5.4                    pypi_0    pypi\\r\\n     pcre2                     10.42                hcad00b1_0    conda-forge\\r\\n     pillow                    10.1.0           py39had0adad_0    conda-forge\\r\\n     pip                       23.3.2             pyhd8ed1ab_0    conda-forge\\r\\n     pipdeptree                2.10.2                   pypi_0    pypi\\r\\n     pixman                    0.42.2               h59595ed_0    conda-forge\\r\\n     pkginfo                   1.9.6                    pypi_0    pypi\\r\\n     pkgutil-resolve-name      1.3.10             pyhd8ed1ab_1    conda-forge\\r\\n     platformdirs              4.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     plotly                    5.18.0                   pypi_0    pypi\\r\\n     pluggy                    1.3.0                    pypi_0    pypi\\r\\n     pmdarima                  2.0.4                    pypi_0    pypi\\r\\n     polars                    0.20.2                   pypi_0    pypi\\r\\n     poppler                   23.12.0              h590f24d_0    conda-forge\\r\\n     poppler-data              0.4.12               hd8ed1ab_0    conda-forge\\r\\n     portion                   2.4.2                    pypi_0    pypi\\r\\n     postgresql                16.1                 h7387d8b_7    conda-forge\\r\\n     pre-commit                3.3.3                    pypi_0    pypi\\r\\n     proj                      9.3.1                h1d62c97_0    conda-forge\\r\\n     prometheus_client         0.19.0             pyhd8ed1ab_0    conda-forge\\r\\n     protobuf                  3.20.3                   pypi_0    pypi\\r\\n     psutil                    5.9.7            py39hd1e30aa_0    conda-forge\\r\\n     pthread-stubs             0.4               h36c2ea0_1001    conda-forge\\r\\n     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\\r\\n     py-xgboost                1.7.6           rapidsai_py39h84d37f7_7    rapidsai\\r\\n     pyarrow                   14.0.2          py39h6925388_0_cpu    conda-forge\\r\\n     pyarrow-hotfix            0.6                pyhd8ed1ab_0    conda-forge\\r\\n     pycodestyle               2.10.0                   pypi_0    pypi\\r\\n     pycparser                 2.21               pyhd8ed1ab_0    conda-forge\\r\\n     pyct                      0.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     pydantic                  1.10.13                  pypi_0    pypi\\r\\n     pyee                      8.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     pyflakes                  3.0.1                    pypi_0    pypi\\r\\n     pygments                  2.17.2             pyhd8ed1ab_0    conda-forge\\r\\n     pylibcugraph              23.12.00        cuda12_py39_231206_g1309813f_0    rapidsai\\r\\n     pylibraft                 23.12.00        cuda12_py39_231206_g9e2d6277_0    rapidsai\\r\\n     pylint                    2.17.4                   pypi_0    pypi\\r\\n     pynndescent               0.5.11                   pypi_0    pypi\\r\\n     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyod                      1.1.2                    pypi_0    pypi\\r\\n     pyparsing                 3.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     pyppeteer                 1.0.2              pyhd8ed1ab_0    conda-forge\\r\\n     pyproj                    3.6.1            py39h15b0fa6_5    conda-forge\\r\\n     pysocks                   1.7.1              pyha2e5f31_6    conda-forge\\r\\n     pytest                    7.4.0                    pypi_0    pypi\\r\\n     pytest-cov                4.1.0                    pypi_0    pypi\\r\\n     pytest-split              0.8.1                    pypi_0    pypi\\r\\n     pytest-xdist              3.3.1                    pypi_0    pypi\\r\\n     python                    3.9.18          h0755675_0_cpython    conda-forge\\r\\n     python-confluent-kafka    1.9.2            py39hb9d737c_2    conda-forge\\r\\n     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\\r\\n     python-fastjsonschema     2.19.0             pyhd8ed1ab_0    conda-forge\\r\\n     python-graphviz           0.20.1                   pypi_0    pypi\\r\\n     python-json-logger        2.0.7              pyhd8ed1ab_0    conda-forge\\r\\n     python_abi                3.9                      4_cp39    conda-forge\\r\\n     pytorch-lightning         2.1.3                    pypi_0    pypi\\r\\n     pytz                      2023.3.post1       pyhd8ed1ab_0    conda-forge\\r\\n     pyviz_comms               3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     pywavelets                1.4.1            py39h44dd56e_1    conda-forge\\r\\n     pyyaml                    6.0.1            py39hd1e30aa_1    conda-forge\\r\\n     pyzmq                     25.1.2           py39h8c080ef_0    conda-forge\\r\\n     qpd                       0.4.4                    pypi_0    pypi\\r\\n     raft-dask                 23.12.00        cuda12_py39_231206_g9e2d6277_0    rapidsai\\r\\n     rapids                    23.12.00        cuda12_py39_231206_g1d8bed4_0    rapidsai\\r\\n     rapids-dask-dependency    23.12.01                      0    rapidsai\\r\\n     rapids-xgboost            23.12.00        cuda12_py39_231206_g1d8bed4_0    rapidsai\\r\\n     rav1e                     0.6.6                he8a937b_2    conda-forge\\r\\n     rdma-core                 49.0                 hd3aeb46_2    conda-forge\\r\\n     re2                       2023.06.02           h2873b5e_0    conda-forge\\r\\n     readline                  8.2                  h8228510_1    conda-forge\\r\\n     readme-renderer           42.0                     pypi_0    pypi\\r\\n     referencing               0.32.0             pyhd8ed1ab_0    conda-forge\\r\\n     regex                     2023.10.3                pypi_0    pypi\\r\\n     requests                  2.31.0             pyhd8ed1ab_0    conda-forge\\r\\n     requests-toolbelt         1.0.0                    pypi_0    pypi\\r\\n     rfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge\\r\\n     rfc3986                   2.0.0                    pypi_0    pypi\\r\\n     rfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge\\r\\n     rich                      13.7.0             pyhd8ed1ab_0    conda-forge\\r\\n     rmm                       23.12.00        cuda12_py39_231206_g2db5cbb3_0    rapidsai\\r\\n     rpds-py                   0.15.2           py39h9fdd4d6_0    conda-forge\\r\\n     rtree                     1.1.0            py39hb102c33_0    conda-forge\\r\\n     ruamel-yaml               0.18.5                   pypi_0    pypi\\r\\n     ruamel-yaml-clib          0.2.8                    pypi_0    pypi\\r\\n     s2n                       1.4.0                h06160fa_0    conda-forge\\r\\n     scikit-image              0.21.0           py39h3d6467e_0    conda-forge\\r\\n     scikit-learn              1.1.3                    pypi_0    pypi\\r\\n     scikit-learn-intelex      2023.2.0                 pypi_0    pypi\\r\\n     scipy                     1.11.4           py39h474f0d3_0    conda-forge\\r\\n     secretstorage             3.3.3                    pypi_0    pypi\\r\\n     send2trash                1.8.2              pyh41d4057_0    conda-forge\\r\\n     setuptools                68.2.2             pyhd8ed1ab_0    conda-forge\\r\\n     shap                      0.44.0                   pypi_0    pypi\\r\\n     shapely                   2.0.2            py39h6404dd3_1    conda-forge\\r\\n     simpervisor               1.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     six                       1.16.0             pyh6c4a22f_0    conda-forge\\r\\n     sklearn-contrib-lightning 0.6.2.post0              pypi_0    pypi\\r\\n     sktime                    0.17.1                   pypi_0    pypi\\r\\n     slicer                    0.0.7                    pypi_0    pypi\\r\\n     snappy                    1.1.10               h9fff704_0    conda-forge\\r\\n     sniffio                   1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     snowballstemmer           2.2.0                    pypi_0    pypi\\r\\n     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     soupsieve                 2.5                pyhd8ed1ab_1    conda-forge\\r\\n     spdlog                    1.11.0               h9b3ece8_1    conda-forge\\r\\n     sphinx                    6.2.1                    pypi_0    pypi\\r\\n     sphinx-rtd-theme          1.2.2                    pypi_0    pypi\\r\\n     sphinxcontrib-applehelp   1.0.7                    pypi_0    pypi\\r\\n     sphinxcontrib-devhelp     1.0.5                    pypi_0    pypi\\r\\n     sphinxcontrib-htmlhelp    2.0.4                    pypi_0    pypi\\r\\n     sphinxcontrib-jquery      4.1                      pypi_0    pypi\\r\\n     sphinxcontrib-jsmath      1.0.1                    pypi_0    pypi\\r\\n     sphinxcontrib-qthelp      1.0.6                    pypi_0    pypi\\r\\n     sphinxcontrib-serializinghtml 1.1.9                    pypi_0    pypi\\r\\n     sqlalchemy                2.0.23                   pypi_0    pypi\\r\\n     sqlglot                   20.4.0                   pypi_0    pypi\\r\\n     sqlite                    3.44.2               h2c6b66d_0    conda-forge\\r\\n     statsforecast             1.7.0                    pypi_0    pypi\\r\\n     statsmodels               0.14.1                   pypi_0    pypi\\r\\n     streamz                   0.6.4              pyh6c4a22f_0    conda-forge\\r\\n     svt-av1                   1.8.0                h59595ed_0    conda-forge\\r\\n     sympy                     1.12                     pypi_0    pypi\\r\\n     tbats                     1.1.3                    pypi_0    pypi\\r\\n     tbb                       2021.11.0                pypi_0    pypi\\r\\n     tblib                     3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     tenacity                  8.2.3                    pypi_0    pypi\\r\\n     tensorboardx              2.6                      pypi_0    pypi\\r\\n     terminado                 0.18.0             pyh0d859eb_0    conda-forge\\r\\n     threadpoolctl             3.2.0              pyha21a80b_0    conda-forge\\r\\n     tifffile                  2023.12.9          pyhd8ed1ab_0    conda-forge\\r\\n     tiledb                    2.18.3               hc1131af_1    conda-forge\\r\\n     tinycss2                  1.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     tk                        8.6.13          noxft_h4845f30_101    conda-forge\\r\\n     tokenizers                0.13.3                   pypi_0    pypi\\r\\n     tomli                     2.0.1                    pypi_0    pypi\\r\\n     tomlkit                   0.12.3                   pypi_0    pypi\\r\\n     toolz                     0.12.0             pyhd8ed1ab_0    conda-forge\\r\\n     torch                     2.1.2                    pypi_0    pypi\\r\\n     torchmetrics              1.2.1                    pypi_0    pypi\\r\\n     tornado                   6.3.3            py39hd1e30aa_1    conda-forge\\r\\n     tqdm                      4.66.1             pyhd8ed1ab_0    conda-forge\\r\\n     traitlets                 5.14.0             pyhd8ed1ab_0    conda-forge\\r\\n     transformers              4.28.1                   pypi_0    pypi\\r\\n     treelite                  3.9.1            py39h9b5fa3e_0    conda-forge\\r\\n     treelite-runtime          3.9.1                    pypi_0    pypi\\r\\n     triad                     0.9.3                    pypi_0    pypi\\r\\n     triton                    2.1.0                    pypi_0    pypi\\r\\n     twine                     4.0.2                    pypi_0    pypi\\r\\n     types-python-dateutil     2.8.19.14          pyhd8ed1ab_0    conda-forge\\r\\n     typing-extensions         4.9.0                hd8ed1ab_0    conda-forge\\r\\n     typing_extensions         4.9.0              pyha770c72_0    conda-forge\\r\\n     typing_utils              0.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     tzcode                    2023c                h0b41bf4_0    conda-forge\\r\\n     tzdata                    2023c                h71feb2d_0    conda-forge\\r\\n     uc-micro-py               1.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     ucx                       1.15.0               h6d2d1ec_2    conda-forge\\r\\n     ucx-proc                  1.0.0                       gpu    rapidsai\\r\\n     ucx-py                    0.35.00         py39_231206_gb5f60ca_0    rapidsai\\r\\n     umap-learn                0.5.5                    pypi_0    pypi\\r\\n     unicodedata2              15.1.0           py39hd1e30aa_0    conda-forge\\r\\n     uri-template              1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     uriparser                 0.9.7                hcb278e6_1    conda-forge\\r\\n     urllib3                   1.26.18            pyhd8ed1ab_0    conda-forge\\r\\n     utilsforecast             0.0.23                   pypi_0    pypi\\r\\n     vecstack                  0.4.0                    pypi_0    pypi\\r\\n     virtualenv                20.25.0                  pypi_0    pypi\\r\\n     webcolors                 1.13               pyhd8ed1ab_0    conda-forge\\r\\n     webencodings              0.5.1              pyhd8ed1ab_2    conda-forge\\r\\n     websocket-client          1.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     websockets                10.4             py39hb9d737c_1    conda-forge\\r\\n     wheel                     0.42.0             pyhd8ed1ab_0    conda-forge\\r\\n     wrapt                     1.16.0                   pypi_0    pypi\\r\\n     xarray                    2023.12.0          pyhd8ed1ab_0    conda-forge\\r\\n     xerces-c                  3.2.5                hac6953d_0    conda-forge\\r\\n     xgboost                   1.7.6           rapidsai_py39h0b6c2bb_7    rapidsai\\r\\n     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge\\r\\n     xorg-libice               1.1.1                hd590300_0    conda-forge\\r\\n     xorg-libsm                1.2.4                h7391055_0    conda-forge\\r\\n     xorg-libx11               1.8.7                h8ee46fc_0    conda-forge\\r\\n     xorg-libxau               1.0.11               hd590300_0    conda-forge\\r\\n     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\\r\\n     xorg-libxext              1.3.4                h0b41bf4_2    conda-forge\\r\\n     xorg-libxrender           0.9.11               hd590300_0    conda-forge\\r\\n     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge\\r\\n     xorg-xextproto            7.3.0             h0b41bf4_1003    conda-forge\\r\\n     xorg-xproto               7.0.31            h7f98852_1007    conda-forge\\r\\n     xxhash                    3.4.1                    pypi_0    pypi\\r\\n     xyzservices               2023.10.1          pyhd8ed1ab_0    conda-forge\\r\\n     xz                        5.2.6                h166bdaf_0    conda-forge\\r\\n     yaml                      0.2.5                h7f98852_2    conda-forge\\r\\n     yarl                      1.9.3            py39hd1e30aa_0    conda-forge\\r\\n     zeromq                    4.3.5                h59595ed_0    conda-forge\\r\\n     zfp                       1.0.1                h59595ed_0    conda-forge\\r\\n     zict                      3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     zipp                      3.17.0             pyhd8ed1ab_0    conda-forge\\r\\n     zlib                      1.2.13               hd590300_5    conda-forge\\r\\n     zlib-ng                   2.0.7                h0b41bf4_0    conda-forge\\r\\n     zstandard                 0.22.0                   pypi_0    pypi\\r\\n     zstd                      1.5.5                hfc55251_0    conda-forge\\r\\n\\r\\n\\r\\n\\r\\n**Additional context**\\r\\nAdd any other context about the problem here.\\ncreatedAt: 2023-12-27T21:20:01Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Paul Brookes\\ncompany: UCL', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 322}),\n",
       " Document(page_content=': 724\\ntitle: [BUG] `str.character_ngrams` produces <NA> with strings < ngram length\\nbody: **Describe the bug**\\r\\nThe `str.character_ngrams` function produces token `<NA>` for strings which are lesser than the provided `n` (shown in image for the case of bigrams).\\r\\n![result output](https://github.com/rapidsai/cudf/assets/68988130/946aeebb-6be3-4719-91e7-25eb9e2c0091)\\r\\n\\r\\nI have debugged this and as far as I understand it, it is being caused by an empty list returned by the `libstrings.generate_character_ngrams` function. This causes <NA> to be a part of the result when it is exploded in the problematic function.\\r\\nThis issue causes several bugs in downstream tasks (like when using cuml for `CountVectorizer` etc).\\r\\n\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nMinimum code required to reproduce the bug:\\r\\n```\\r\\nimport cudf\\r\\nstr_series = cudf.Series([\\'1744\\', \\'4\\'])\\r\\nstr_series.str.character_ngrams(2)\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n<NA> should not be a part of the output. This causes several downstream tasks to fail because <NA> is not a valid token in the actual input string series.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Cloud GCP\\r\\n - Method of cuDF install: pip\\r\\n \\r\\n**Environment details**\\r\\n```\\r\\n**git***\\r\\n     Not inside a git repository\\r\\n     \\r\\n     ***OS Information***\\r\\n     PRETTY_NAME=\"Debian GNU/Linux 11 (bullseye)\"\\r\\n     NAME=\"Debian GNU/Linux\"\\r\\n     VERSION_ID=\"11\"\\r\\n     VERSION=\"11 (bullseye)\"\\r\\n     VERSION_CODENAME=bullseye\\r\\n     ID=debian\\r\\n     HOME_URL=\"https://www.debian.org/\"\\r\\n     SUPPORT_URL=\"https://www.debian.org/support\"\\r\\n     BUG_REPORT_URL=\"https://bugs.debian.org/\"\\r\\n     Linux janmey-gpu-c2 5.10.0-26-cloud-amd64 #1 SMP Debian 5.10.197-1 (2023-09-29) x86_64 GNU/Linux\\r\\n     \\r\\n     ***GPU Information***\\r\\n     Fri Dec 29 10:21:54 2023\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\\r\\n     |-------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                               |                      |               MIG M. |\\r\\n     |===============================+======================+======================|\\r\\n     |   0  Tesla T4            On   | 00000000:00:04.0 Off |                    0 |\\r\\n     | N/A   70C    P0    33W /  70W |    459MiB / 15360MiB |      0%      Default |\\r\\n     |                               |                      |                  N/A |\\r\\n     +-------------------------------+----------------------+----------------------+\\r\\n     \\r\\n     +-----------------------------------------------------------------------------+\\r\\n     | Processes:                                                                  |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\\r\\n     |        ID   ID                                                   Usage      |\\r\\n     |=============================================================================|\\r\\n     |    0   N/A  N/A    316341      C   ..._log_ner/.venv/bin/python      454MiB |\\r\\n     +-----------------------------------------------------------------------------+\\r\\n     \\r\\n     ***CPU***\\r\\n     Architecture:                       x86_64\\r\\n     CPU op-mode(s):                     32-bit, 64-bit\\r\\n     Byte Order:                         Little Endian\\r\\n     Address sizes:                      46 bits physical, 48 bits virtual\\r\\n     CPU(s):                             16\\r\\n     On-line CPU(s) list:                0-15\\r\\n     Thread(s) per core:                 2\\r\\n     Core(s) per socket:                 8\\r\\n     Socket(s):                          1\\r\\n     NUMA node(s):                       1\\r\\n     Vendor ID:                          GenuineIntel\\r\\n     CPU family:                         6\\r\\n     Model:                              79\\r\\n     Model name:                         Intel(R) Xeon(R) CPU @ 2.20GHz\\r\\n     Stepping:                           0\\r\\n     CPU MHz:                            2199.998\\r\\n     BogoMIPS:                           4399.99\\r\\n     Hypervisor vendor:                  KVM\\r\\n     Virtualization type:                full\\r\\n     L1d cache:                          256 KiB\\r\\n     L1i cache:                          256 KiB\\r\\n     L2 cache:                           2 MiB\\r\\n     L3 cache:                           55 MiB\\r\\n     NUMA node0 CPU(s):                  0-15\\r\\n     Vulnerability Gather data sampling: Not affected\\r\\n     Vulnerability Itlb multihit:        Not affected\\r\\n     Vulnerability L1tf:                 Mitigation; PTE Inversion\\r\\n     Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT Host state unknown\\r\\n     Vulnerability Meltdown:             Mitigation; PTI\\r\\n     Vulnerability Mmio stale data:      Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown\\r\\n     Vulnerability Retbleed:             Mitigation; IBRS\\r\\n     Vulnerability Spec rstack overflow: Not affected\\r\\n     Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp\\r\\n     Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\r\\n     Vulnerability Spectre v2:           Mitigation; IBRS, IBPB conditional, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected\\r\\n     Vulnerability Srbds:                Not affected\\r\\n     Vulnerability Tsx async abort:      Mitigation; Clear CPU buffers; SMT Host state unknown\\r\\n     Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\\r\\n     \\r\\n     ***CMake***\\r\\n     /usr/bin/cmake\\r\\n     cmake version 3.18.4\\r\\n     \\r\\n     CMake suite maintained and supported by Kitware (kitware.com/cmake).\\r\\n     \\r\\n     ***g++***\\r\\n     /usr/bin/g++\\r\\n     g++ (Debian 10.2.1-6) 10.2.1 20210110\\r\\n     Copyright (C) 2020 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n     \\r\\n     \\r\\n     ***nvcc***\\r\\n     /usr/local/cuda/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2022 NVIDIA Corporation\\r\\n     Built on Wed_Sep_21_10:33:58_PDT_2022\\r\\n     Cuda compilation tools, release 11.8, V11.8.89\\r\\n     Build cuda_11.8.r11.8/compiler.31833905_0\\r\\n     \\r\\n     ***Python***\\r\\n     /home/janmeysandeepshukla/datasci/transaction_log_ner/.venv/bin/python\\r\\n     Python 3.10.13\\r\\n     \\r\\n     ***Environment Variables***\\r\\n     PATH                            : /home/janmeysandeepshukla/datasci/transaction_log_ner/.venv/bin:/home/janmeysandeepshukla/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/usr/local/cuda/bin:/opt/conda/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\\r\\n     LD_LIBRARY_PATH                 : /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /opt/conda\\r\\n     PYTHON_PATH                     :\\r\\n     \\r\\n     ***conda packages***\\r\\n     /opt/conda/bin/conda\\r\\n     # packages in environment at /opt/conda:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                       2_gnu    conda-forge\\r\\n     absl-py                   2.0.0                    pypi_0    pypi\\r\\n     aiofiles                  22.1.0                   pypi_0    pypi\\r\\n     aiohttp                   3.9.1                    pypi_0    pypi\\r\\n     aiohttp-cors              0.7.0                    pypi_0    pypi\\r\\n     aiorwlock                 1.3.0                    pypi_0    pypi\\r\\n     aiosignal                 1.3.1                    pypi_0    pypi\\r\\n     aiosqlite                 0.19.0                   pypi_0    pypi\\r\\n     anyio                     3.7.1                    pypi_0    pypi\\r\\n     archspec                  0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     argon2-cffi               23.1.0             pyhd8ed1ab_0    conda-forge\\r\\n     argon2-cffi-bindings      21.2.0          py310h2372a71_4    conda-forge\\r\\n     arrow                     1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     asttokens                 2.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     async-lru                 2.0.4              pyhd8ed1ab_0    conda-forge\\r\\n     async-timeout             4.0.3                    pypi_0    pypi\\r\\n     attrs                     23.1.0             pyh71513ae_1    conda-forge\\r\\n     babel                     2.13.1             pyhd8ed1ab_0    conda-forge\\r\\n     backoff                   2.2.1                    pypi_0    pypi\\r\\n     beatrix-jupyterlab        2023.128.151533          pypi_0    pypi\\r\\n     beautifulsoup4            4.12.2             pyha770c72_0    conda-forge\\r\\n     bleach                    6.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     blessed                   1.20.0                   pypi_0    pypi\\r\\n     boltons                   23.0.0             pyhd8ed1ab_0    conda-forge\\r\\n     brotli-python             1.1.0           py310hc6cd4ac_1    conda-forge\\r\\n     bzip2                     1.0.8                hd590300_5    conda-forge\\r\\n     c-ares                    1.23.0               hd590300_0    conda-forge\\r\\n     ca-certificates           2023.11.17           hbcca054_0    conda-forge\\r\\n     cached-property           1.5.2                hd8ed1ab_1    conda-forge\\r\\n     cached_property           1.5.2              pyha770c72_1    conda-forge\\r\\n     cachetools                5.3.2                    pypi_0    pypi\\r\\n     certifi                   2023.11.17         pyhd8ed1ab_0    conda-forge\\r\\n     cffi                      1.16.0          py310h2fee648_0    conda-forge\\r\\n     charset-normalizer        3.3.2              pyhd8ed1ab_0    conda-forge\\r\\n     click                     8.1.7                    pypi_0    pypi\\r\\n     cloud-tpu-client          0.10                     pypi_0    pypi\\r\\n     cloudpickle               3.0.0                    pypi_0    pypi\\r\\n     colorama                  0.4.6              pyhd8ed1ab_0    conda-forge\\r\\n     colorful                  0.5.5                    pypi_0    pypi\\r\\n     comm                      0.2.0                    pypi_0    pypi\\r\\n     conda                     23.11.0         py310hff52083_1    conda-forge\\r\\n     conda-libmamba-solver     23.11.1            pyhd8ed1ab_0    conda-forge\\r\\n     conda-package-handling    2.2.0              pyh38be061_0    conda-forge\\r\\n     conda-package-streaming   0.9.0              pyhd8ed1ab_0    conda-forge\\r\\n     contourpy                 1.2.0                    pypi_0    pypi\\r\\n     cryptography              41.0.7                   pypi_0    pypi\\r\\n     cycler                    0.12.1                   pypi_0    pypi\\r\\n     cython                    3.0.6                    pypi_0    pypi\\r\\n     dacite                    1.8.1                    pypi_0    pypi\\r\\n     dataproc-jupyter-plugin   0.1.59                   pypi_0    pypi\\r\\n     db-dtypes                 1.1.1                    pypi_0    pypi\\r\\n     debugpy                   1.8.0           py310hc6cd4ac_1    conda-forge\\r\\n     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     deprecated                1.2.14                   pypi_0    pypi\\r\\n     distlib                   0.3.7                    pypi_0    pypi\\r\\n     distro                    1.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     dlenv-base                1.0.20231210            py310_0    file:///tmp/conda-pkgs\\r\\n     dm-tree                   0.1.8                    pypi_0    pypi\\r\\n     docker                    7.0.0                    pypi_0    pypi\\r\\n     docstring-parser          0.15                     pypi_0    pypi\\r\\n     entrypoints               0.4                pyhd8ed1ab_0    conda-forge\\r\\n     exceptiongroup            1.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     executing                 2.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     farama-notifications      0.0.4                    pypi_0    pypi\\r\\n     fastapi                   0.104.1                  pypi_0    pypi\\r\\n     filelock                  3.13.1                   pypi_0    pypi\\r\\n     fmt                       10.1.1               h00ab1b0_1    conda-forge\\r\\n     fonttools                 4.46.0                   pypi_0    pypi\\r\\n     fqdn                      1.5.1              pyhd8ed1ab_0    conda-forge\\r\\n     frozenlist                1.4.0                    pypi_0    pypi\\r\\n     fsspec                    2023.12.1                pypi_0    pypi\\r\\n     gcsfs                     2023.12.1                pypi_0    pypi\\r\\n     gitdb                     4.0.11                   pypi_0    pypi\\r\\n     gitpython                 3.1.40                   pypi_0    pypi\\r\\n     google-api-core           1.34.0                   pypi_0    pypi\\r\\n     google-api-python-client  1.8.0                    pypi_0    pypi\\r\\n     google-auth               2.25.2                   pypi_0    pypi\\r\\n     google-auth-httplib2      0.1.1                    pypi_0    pypi\\r\\n     google-auth-oauthlib      1.1.0                    pypi_0    pypi\\r\\n     google-cloud-aiplatform   1.37.0                   pypi_0    pypi\\r\\n     google-cloud-artifact-registry 1.10.0                   pypi_0    pypi\\r\\n     google-cloud-bigquery     3.13.0                   pypi_0    pypi\\r\\n     google-cloud-bigquery-storage 2.23.0                   pypi_0    pypi\\r\\n     google-cloud-core         2.4.1                    pypi_0    pypi\\r\\n     google-cloud-datastore    1.15.5                   pypi_0    pypi\\r\\n     google-cloud-jupyter-config 0.0.5                    pypi_0    pypi\\r\\n     google-cloud-language     2.12.0                   pypi_0    pypi\\r\\n     google-cloud-monitoring   2.17.0                   pypi_0    pypi\\r\\n     google-cloud-resource-manager 1.11.0                   pypi_0    pypi\\r\\n     google-cloud-storage      2.13.0                   pypi_0    pypi\\r\\n     google-crc32c             1.5.0                    pypi_0    pypi\\r\\n     google-resumable-media    2.6.0                    pypi_0    pypi\\r\\n     googleapis-common-protos  1.62.0                   pypi_0    pypi\\r\\n     gpustat                   1.0.0                    pypi_0    pypi\\r\\n     greenlet                  3.0.2                    pypi_0    pypi\\r\\n     grpc-google-iam-v1        0.13.0                   pypi_0    pypi\\r\\n     grpcio                    1.60.0                   pypi_0    pypi\\r\\n     grpcio-status             1.48.2                   pypi_0    pypi\\r\\n     gymnasium                 0.28.1                   pypi_0    pypi\\r\\n     h11                       0.14.0                   pypi_0    pypi\\r\\n     htmlmin                   0.1.12                   pypi_0    pypi\\r\\n     httplib2                  0.22.0                   pypi_0    pypi\\r\\n     httptools                 0.6.1                    pypi_0    pypi\\r\\n     icu                       73.2                 h59595ed_0    conda-forge\\r\\n     idna                      3.6                pyhd8ed1ab_0    conda-forge\\r\\n     imagehash                 4.3.1                    pypi_0    pypi\\r\\n     imageio                   2.33.0                   pypi_0    pypi\\r\\n     importlib-metadata        6.11.0                   pypi_0    pypi\\r\\n     importlib_metadata        7.0.0                hd8ed1ab_0    conda-forge\\r\\n     importlib_resources       6.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     ipykernel                 6.27.1                   pypi_0    pypi\\r\\n     ipython                   8.18.1             pyh707e725_3    conda-forge\\r\\n     ipython-genutils          0.2.0                    pypi_0    pypi\\r\\n     ipython-sql               0.5.0                    pypi_0    pypi\\r\\n     ipywidgets                8.1.1                    pypi_0    pypi\\r\\n     isoduration               20.11.0            pyhd8ed1ab_0    conda-forge\\r\\n     jaraco-classes            3.3.0                    pypi_0    pypi\\r\\n     jax-jumpy                 1.0.0                    pypi_0    pypi\\r\\n     jedi                      0.19.1             pyhd8ed1ab_0    conda-forge\\r\\n     jeepney                   0.8.0                    pypi_0    pypi\\r\\n     jinja2                    3.1.2              pyhd8ed1ab_1    conda-forge\\r\\n     joblib                    1.3.2                    pypi_0    pypi\\r\\n     json5                     0.9.14             pyhd8ed1ab_0    conda-forge\\r\\n     jsonpatch                 1.33               pyhd8ed1ab_0    conda-forge\\r\\n     jsonpointer               2.4             py310hff52083_3    conda-forge\\r\\n     jsonschema                4.20.0             pyhd8ed1ab_0    conda-forge\\r\\n     jsonschema-specifications 2023.11.2          pyhd8ed1ab_0    conda-forge\\r\\n     jsonschema-with-format-nongpl 4.20.0             pyhd8ed1ab_0    conda-forge\\r\\n     jupyter-client            7.4.9                    pypi_0    pypi\\r\\n     jupyter-http-over-ws      0.0.8                    pypi_0    pypi\\r\\n     jupyter-lsp               2.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter-server-fileid     0.9.0                    pypi_0    pypi\\r\\n     jupyter-server-mathjax    0.2.6                    pypi_0    pypi\\r\\n     jupyter-server-proxy      4.1.0                    pypi_0    pypi\\r\\n     jupyter-server-ydoc       0.8.0                    pypi_0    pypi\\r\\n     jupyter-ydoc              0.2.5                    pypi_0    pypi\\r\\n     jupyter_client            8.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_core              5.5.0           py310hff52083_0    conda-forge\\r\\n     jupyter_events            0.9.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_server            2.12.1             pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_server_terminals  0.4.4              pyhd8ed1ab_1    conda-forge\\r\\n     jupyterlab                3.6.6                    pypi_0    pypi\\r\\n     jupyterlab-git            0.44.0                   pypi_0    pypi\\r\\n     jupyterlab-widgets        3.0.9                    pypi_0    pypi\\r\\n     jupyterlab_pygments       0.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     jupyterlab_server         2.25.2             pyhd8ed1ab_0    conda-forge\\r\\n     jupytext                  1.16.0                   pypi_0    pypi\\r\\n     kernels-mixer             0.0.7                    pypi_0    pypi\\r\\n     keyring                   24.3.0                   pypi_0    pypi\\r\\n     keyrings-google-artifactregistry-auth 1.1.2                    pypi_0    pypi\\r\\n     keyutils                  1.6.1                h166bdaf_0    conda-forge\\r\\n     kfp                       2.4.0                    pypi_0    pypi\\r\\n     kfp-pipeline-spec         0.2.2                    pypi_0    pypi\\r\\n     kfp-server-api            2.0.5                    pypi_0    pypi\\r\\n     kiwisolver                1.4.5                    pypi_0    pypi\\r\\n     krb5                      1.21.2               h659d440_0    conda-forge\\r\\n     kubernetes                26.1.0                   pypi_0    pypi\\r\\n     lazy-loader               0.3                      pypi_0    pypi\\r\\n     ld_impl_linux-64          2.40                 h41732ed_0    conda-forge\\r\\n     libarchive                3.7.2                h2aa1ff5_1    conda-forge\\r\\n     libcurl                   8.5.0                hca28451_0    conda-forge\\r\\n     libedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\n     libev                     4.33                 hd590300_2    conda-forge\\r\\n     libffi                    3.4.2                h7f98852_5    conda-forge\\r\\n     libgcc-ng                 13.2.0               h807b86a_3    conda-forge\\r\\n     libgomp                   13.2.0               h807b86a_3    conda-forge\\r\\n     libiconv                  1.17                 h166bdaf_0    conda-forge\\r\\n     libmamba                  1.5.4                had39da4_0    conda-forge\\r\\n     libmambapy                1.5.4           py310h39ff949_0    conda-forge\\r\\n     libnghttp2                1.58.0               h47da74e_1    conda-forge\\r\\n     libnsl                    2.0.1                hd590300_0    conda-forge\\r\\n     libsodium                 1.0.18               h36c2ea0_1    conda-forge\\r\\n     libsolv                   0.7.27               hfc55251_0    conda-forge\\r\\n     libsqlite                 3.44.2               h2797004_0    conda-forge\\r\\n     libssh2                   1.11.0               h0841786_0    conda-forge\\r\\n     libstdcxx-ng              13.2.0               h7e041cc_3    conda-forge\\r\\n     libuuid                   2.38.1               h0b41bf4_0    conda-forge\\r\\n     libuv                     1.46.0               hd590300_0    conda-forge\\r\\n     libxml2                   2.12.2               h232c23b_0    conda-forge\\r\\n     libzlib                   1.2.13               hd590300_5    conda-forge\\r\\n     llvmlite                  0.41.1                   pypi_0    pypi\\r\\n     lz4                       4.3.2                    pypi_0    pypi\\r\\n     lz4-c                     1.9.4                hcb278e6_0    conda-forge\\r\\n     lzo                       2.10              h516909a_1000    conda-forge\\r\\n     markdown-it-py            3.0.0                    pypi_0    pypi\\r\\n     markupsafe                2.1.3           py310h2372a71_1    conda-forge\\r\\n     matplotlib                3.7.3                    pypi_0    pypi\\r\\n     matplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge\\r\\n     mdit-py-plugins           0.4.0                    pypi_0    pypi\\r\\n     mdurl                     0.1.2                    pypi_0    pypi\\r\\n     menuinst                  2.0.0           py310hff52083_1    conda-forge\\r\\n     mistune                   3.0.2              pyhd8ed1ab_0    conda-forge\\r\\n     more-itertools            10.1.0                   pypi_0    pypi\\r\\n     msgpack                   1.0.7                    pypi_0    pypi\\r\\n     multidict                 6.0.4                    pypi_0    pypi\\r\\n     multimethod               1.10                     pypi_0    pypi\\r\\n     nb_conda                  2.2.1                    unix_6    conda-forge\\r\\n     nb_conda_kernels          2.3.1              pyhd8ed1ab_3    conda-forge\\r\\n     nbclassic                 1.0.0                    pypi_0    pypi\\r\\n     nbclient                  0.9.0                    pypi_0    pypi\\r\\n     nbconvert-core            7.12.0             pyhd8ed1ab_0    conda-forge\\r\\n     nbdime                    3.2.0                    pypi_0    pypi\\r\\n     nbformat                  5.9.2              pyhd8ed1ab_0    conda-forge\\r\\n     ncurses                   6.4                  h59595ed_2    conda-forge\\r\\n     nest-asyncio              1.5.8              pyhd8ed1ab_0    conda-forge\\r\\n     networkx                  3.2.1                    pypi_0    pypi\\r\\n     nodejs                    20.9.0               hb753e55_0    conda-forge\\r\\n     notebook                  6.5.6                    pypi_0    pypi\\r\\n     notebook-executor         0.2                      pypi_0    pypi\\r\\n     notebook-shim             0.2.3              pyhd8ed1ab_0    conda-forge\\r\\n     numba                     0.58.1                   pypi_0    pypi\\r\\n     numpy                     1.25.2                   pypi_0    pypi\\r\\n     nvidia-ml-py              11.495.46                pypi_0    pypi\\r\\n     oauth2client              4.1.3                    pypi_0    pypi\\r\\n     oauthlib                  3.2.2                    pypi_0    pypi\\r\\n     opencensus                0.11.3                   pypi_0    pypi\\r\\n     opencensus-context        0.1.3                    pypi_0    pypi\\r\\n     openssl                   3.2.0                hd590300_1    conda-forge\\r\\n     opentelemetry-api         1.21.0                   pypi_0    pypi\\r\\n     opentelemetry-exporter-otlp 1.21.0                   pypi_0    pypi\\r\\n     opentelemetry-exporter-otlp-proto-common 1.21.0                   pypi_0    pypi\\r\\n     opentelemetry-exporter-otlp-proto-grpc 1.21.0                   pypi_0    pypi\\r\\n     opentelemetry-exporter-otlp-proto-http 1.21.0                   pypi_0    pypi\\r\\n     opentelemetry-proto       1.21.0                   pypi_0    pypi\\r\\n     opentelemetry-sdk         1.21.0                   pypi_0    pypi\\r\\n     opentelemetry-semantic-conventions 0.42b0                   pypi_0    pypi\\r\\n     overrides                 7.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     packaging                 23.2               pyhd8ed1ab_0    conda-forge\\r\\n     pandas                    2.0.3                    pypi_0    pypi\\r\\n     pandas-profiling          3.6.6                    pypi_0    pypi\\r\\n     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     papermill                 2.5.0                    pypi_0    pypi\\r\\n     parso                     0.8.3              pyhd8ed1ab_0    conda-forge\\r\\n     patsy                     0.5.4                    pypi_0    pypi\\r\\n     pexpect                   4.9.0                    pypi_0    pypi\\r\\n     phik                      0.12.3                   pypi_0    pypi\\r\\n     pickleshare               0.7.5                   py_1003    conda-forge\\r\\n     pillow                    10.1.0                   pypi_0    pypi\\r\\n     pip                       23.3.1             pyhd8ed1ab_0    conda-forge\\r\\n     pkgutil-resolve-name      1.3.10             pyhd8ed1ab_1    conda-forge\\r\\n     platformdirs              3.11.0                   pypi_0    pypi\\r\\n     plotly                    5.18.0                   pypi_0    pypi\\r\\n     pluggy                    1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     prettytable               3.9.0                    pypi_0    pypi\\r\\n     prometheus_client         0.19.0             pyhd8ed1ab_0    conda-forge\\r\\n     prompt-toolkit            3.0.41             pyha770c72_0    conda-forge\\r\\n     proto-plus                1.23.0                   pypi_0    pypi\\r\\n     protobuf                  3.20.3                   pypi_0    pypi\\r\\n     psutil                    5.9.3                    pypi_0    pypi\\r\\n     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\\r\\n     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     py-spy                    0.3.14                   pypi_0    pypi\\r\\n     pyarrow                   14.0.1                   pypi_0    pypi\\r\\n     pyasn1                    0.5.1                    pypi_0    pypi\\r\\n     pyasn1-modules            0.3.0                    pypi_0    pypi\\r\\n     pybind11-abi              4                    hd8ed1ab_3    conda-forge\\r\\n     pycosat                   0.6.6           py310h2372a71_0    conda-forge\\r\\n     pycparser                 2.21               pyhd8ed1ab_0    conda-forge\\r\\n     pydantic                  1.10.13                  pypi_0    pypi\\r\\n     pygments                  2.17.2             pyhd8ed1ab_0    conda-forge\\r\\n     pyjwt                     2.8.0                    pypi_0    pypi\\r\\n     pyparsing                 3.1.1                    pypi_0    pypi\\r\\n     pysocks                   1.7.1              pyha2e5f31_6    conda-forge\\r\\n     python                    3.10.13         hd12c33a_0_cpython    conda-forge\\r\\n     python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\\r\\n     python-dotenv             1.0.0                    pypi_0    pypi\\r\\n     python-fastjsonschema     2.19.0             pyhd8ed1ab_0    conda-forge\\r\\n     python-json-logger        2.0.7              pyhd8ed1ab_0    conda-forge\\r\\n     python_abi                3.10                    4_cp310    conda-forge\\r\\n     pytz                      2023.3.post1       pyhd8ed1ab_0    conda-forge\\r\\n     pywavelets                1.5.0                    pypi_0    pypi\\r\\n     pyyaml                    6.0.1           py310h2372a71_1    conda-forge\\r\\n     pyzmq                     24.0.1                   pypi_0    pypi\\r\\n     ray                       2.8.1                    pypi_0    pypi\\r\\n     ray-cpp                   2.8.1                    pypi_0    pypi\\r\\n     readline                  8.2                  h8228510_1    conda-forge\\r\\n     referencing               0.32.0             pyhd8ed1ab_0    conda-forge\\r\\n     reproc                    14.2.4.post0         hd590300_1    conda-forge\\r\\n     reproc-cpp                14.2.4.post0         h59595ed_1    conda-forge\\r\\n     requests                  2.31.0             pyhd8ed1ab_0    conda-forge\\r\\n     requests-oauthlib         1.3.1                    pypi_0    pypi\\r\\n     requests-toolbelt         0.10.1                   pypi_0    pypi\\r\\n     retrying                  1.3.4                    pypi_0    pypi\\r\\n     rfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge\\r\\n     rfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge\\r\\n     rich                      13.7.0                   pypi_0    pypi\\r\\n     rpds-py                   0.13.2          py310hcb5633a_0    conda-forge\\r\\n     ruamel.yaml               0.18.5          py310h2372a71_0    conda-forge\\r\\n     ruamel.yaml.clib          0.2.7           py310h2372a71_2    conda-forge\\r\\n     scikit-image              0.22.0                   pypi_0    pypi\\r\\n     scikit-learn              1.3.2                    pypi_0    pypi\\r\\n     scipy                     1.11.4                   pypi_0    pypi\\r\\n     seaborn                   0.12.2                   pypi_0    pypi\\r\\n     secretstorage             3.3.3                    pypi_0    pypi\\r\\n     send2trash                1.8.2              pyh41d4057_0    conda-forge\\r\\n     setuptools                68.2.2             pyhd8ed1ab_0    conda-forge\\r\\n     shapely                   2.0.2                    pypi_0    pypi\\r\\n     simpervisor               1.0.0                    pypi_0    pypi\\r\\n     six                       1.16.0             pyh6c4a22f_0    conda-forge\\r\\n     smart-open                6.4.0                    pypi_0    pypi\\r\\n     smmap                     5.0.1                    pypi_0    pypi\\r\\n     sniffio                   1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     soupsieve                 2.5                pyhd8ed1ab_1    conda-forge\\r\\n     sqlalchemy                2.0.23                   pypi_0    pypi\\r\\n     sqlparse                  0.4.4                    pypi_0    pypi\\r\\n     stack-data                0.6.3                    pypi_0    pypi\\r\\n     stack_data                0.6.2              pyhd8ed1ab_0    conda-forge\\r\\n     starlette                 0.27.0                   pypi_0    pypi\\r\\n     statsmodels               0.14.0                   pypi_0    pypi\\r\\n     tabulate                  0.9.0                    pypi_0    pypi\\r\\n     tangled-up-in-unicode     0.2.0                    pypi_0    pypi\\r\\n     tenacity                  8.2.3                    pypi_0    pypi\\r\\n     tensorboardx              2.6.2.2                  pypi_0    pypi\\r\\n     terminado                 0.18.0             pyh0d859eb_0    conda-forge\\r\\n     threadpoolctl             3.2.0                    pypi_0    pypi\\r\\n     tifffile                  2023.12.9                pypi_0    pypi\\r\\n     tinycss2                  1.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     tk                        8.6.13          noxft_h4845f30_101    conda-forge\\r\\n     toml                      0.10.2                   pypi_0    pypi\\r\\n     tomli                     2.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     tornado                   6.3.3           py310h2372a71_1    conda-forge\\r\\n     tqdm                      4.66.1             pyhd8ed1ab_0    conda-forge\\r\\n     traitlets                 5.14.0             pyhd8ed1ab_0    conda-forge\\r\\n     truststore                0.8.0              pyhd8ed1ab_0    conda-forge\\r\\n     typeguard                 4.1.5                    pypi_0    pypi\\r\\n     typer                     0.9.0                    pypi_0    pypi\\r\\n     types-python-dateutil     2.8.19.14          pyhd8ed1ab_0    conda-forge\\r\\n     typing-extensions         4.8.0                hd8ed1ab_0    conda-forge\\r\\n     typing_extensions         4.8.0              pyha770c72_0    conda-forge\\r\\n     typing_utils              0.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     tzdata                    2023.3                   pypi_0    pypi\\r\\n     uri-template              1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     uritemplate               3.0.1                    pypi_0    pypi\\r\\n     urllib3                   1.26.18                  pypi_0    pypi\\r\\n     uvicorn                   0.24.0.post1             pypi_0    pypi\\r\\n     uvloop                    0.19.0                   pypi_0    pypi\\r\\n     virtualenv                20.21.0                  pypi_0    pypi\\r\\n     visions                   0.7.5                    pypi_0    pypi\\r\\n     watchfiles                0.21.0                   pypi_0    pypi\\r\\n     wcwidth                   0.2.12             pyhd8ed1ab_0    conda-forge\\r\\n     webcolors                 1.13               pyhd8ed1ab_0    conda-forge\\r\\n     webencodings              0.5.1              pyhd8ed1ab_2    conda-forge\\r\\n     websocket-client          1.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     websockets                12.0                     pypi_0    pypi\\r\\n     wheel                     0.42.0             pyhd8ed1ab_0    conda-forge\\r\\n     widgetsnbextension        4.0.9                    pypi_0    pypi\\r\\n     wordcloud                 1.9.3                    pypi_0    pypi\\r\\n     wrapt                     1.16.0                   pypi_0    pypi\\r\\n     xz                        5.2.6                h166bdaf_0    conda-forge\\r\\n     y-py                      0.6.2                    pypi_0    pypi\\r\\n     yaml                      0.2.5                h7f98852_2    conda-forge\\r\\n     yaml-cpp                  0.8.0                h59595ed_0    conda-forge\\r\\n     yarl                      1.9.4                    pypi_0    pypi\\r\\n     ydata-profiling           4.6.0                    pypi_0    pypi\\r\\n     ypy-websocket             0.8.4                    pypi_0    pypi\\r\\n     zeromq                    4.3.5                h59595ed_0    conda-forge\\r\\n     zipp                      3.17.0             pyhd8ed1ab_0    conda-forge\\r\\n     zlib                      1.2.13               hd590300_5    conda-forge\\r\\n     zstandard                 0.22.0          py310h1275a96_0    conda-forge\\r\\n     zstd                      1.5.5                hfc55251_0    conda-forge\\r\\n     ```\\ncreatedAt: 2023-12-29T10:26:09Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Janmey Shukla\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 323}),\n",
       " Document(page_content=\": 725\\ntitle: pd.concat() of dictionaries [FEA]\\nbody: **Missing Pandas Feature Request**\\r\\n\\r\\nPlease implement concatenation of dictionaries, as shown at the very bottom of the page in the [Pandas package](https://pandas.pydata.org/docs/reference/api/pandas.concat.html). Currently, cudf only supports DataFrame and Series objects; dictionaries would be a very useful addition.\\r\\n\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nThe following should return a cudf DataFrame stored in GPU ram.\\r\\n\\r\\nInput >> `cudf.concat({'a': 1.1, 'b': 2.2}, axis=1)`\\r\\n\\r\\nStored variable >>\\r\\n\\r\\n'a' | 1.1\\r\\n'b' | 2.2\\ncreatedAt: 2024-01-10T19:34:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 324}),\n",
       " Document(page_content=': 731\\ntitle: MixedTypeError when there is no mixed type [BUG]\\nbody: **Describe the bug**\\r\\nI load a pandas dataframe into cudf using cudf.from_pandas(originaldataframe) and it gives me a mixed type error.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nOriginal Dataframe: \\r\\n```\\r\\n     symbol                                               name STOCK_TYPE  first_date   last_date    AGE                INDUSTRY   marketcap\\r\\n0     WHFBZ      WhiteHorse Finance, Inc. 6.50% Notes due 2025     common  2018-11-30  2021-12-16   1112                 Unknown    0.000000\\r\\n1       ANH                 Anworth Mortgage Asset Corporation     common  1998-03-12  2021-03-19   8408                 Unknown    0.000000\\r\\n2       CEE          The Central and Eastern Europe Fund, Inc.     common  1990-02-28  2024-01-09  12368        Asset Management    0.062059\\r\\n3      SEMR                             SEMrush Holdings, Inc.     common  2021-03-24  2024-01-09   1021  Software - Application    1.780361\\r\\n4      BWMX  Betterware de Mexico, S.A.P.I. de C.V. Ordinar...     common  2020-03-16  2024-01-09   1394        Specialty Retail    0.470934\\r\\n...     ...                                                ...        ...         ...         ...    ...                     ...         ...\\r\\n9281    GHI  Greystone Housing Impact Investors LP Benefici...     common  1986-04-02  2024-01-09  13796        Mortgage Finance    0.387465\\r\\n9282    LMT                              Lockheed Martin Corp.     common  1977-01-03  2024-01-09  17172     Aerospace & Defense  113.205101\\r\\n9283   ^DJI                                          Dow Jones      index  1970-01-02  2024-01-08  19729                   Index    0.000000\\r\\n9284   ^INX                                            S&P 500      index  1970-01-02  2024-01-08  19729                   Index    0.000000\\r\\n9285  ^IXIC                                             NASDAQ      index  1971-02-05  2024-01-08  19330                   Index    0.000000\\r\\n```\\r\\nI created the following function to create a dictionary of all the unique datatypes found for each column, even if there are more than one type in a single column.  Here\\'s the function:\\r\\n```\\r\\ndef get_column_data_types(dataframe):\\r\\n    column_data_types = {}\\r\\n    \\r\\n    for column in dataframe.columns:\\r\\n        unique_types = set(type(value) for value in dataframe[column])\\r\\n        column_data_types[column] = unique_types\\r\\n    \\r\\n    return column_data_types\\r\\n```\\r\\nHere\\'s the output of the column data types:\\r\\n```\\r\\n{\\r\\n    \\'AGE\\': set([<class \\'int\\'>]),\\r\\n    \\'INDUSTRY\\': set([<class \\'str\\'>]),\\r\\n    \\'STOCK_TYPE\\': set([<class \\'str\\'>]),\\r\\n    \\'first_date\\': set([<class \\'datetime.date\\'>]),\\r\\n    \\'last_date\\': set([<class \\'datetime.date\\'>]),\\r\\n    \\'marketcap\\': set([<class \\'float\\'>]),\\r\\n    \\'name\\': set([<class \\'str\\'>]),\\r\\n    \\'symbol\\': set([<class \\'str\\'>]),\\r\\n}\\r\\n```\\r\\n\\r\\nAs you can see, the function only found one datatype for each column.\\r\\n\\r\\nAlternatively, if I use pandas built in datatype command `dataframe.dtypes` I get the following:\\r\\n```\\r\\nsymbol         object\\r\\nname           object\\r\\nSTOCK_TYPE     object\\r\\nfirst_date     object\\r\\nlast_date      object\\r\\nAGE             int64\\r\\nINDUSTRY       object\\r\\nmarketcap     float64\\r\\ndtype: object\\r\\n```\\r\\nSo by both tests, each column has only one data type.  Though the .dtypes command shows \"object\" as the datatype.  Perhaps that\\'s causing cudf to throw the error?\\r\\n\\r\\nHere is another example:\\r\\n```\\r\\n            date        NVDA\\r\\n0     1999-01-22    0.376356\\r\\n1     1999-01-25    0.415730\\r\\n2     1999-01-26    0.383428\\r\\n3     1999-01-27    0.382281\\r\\n4     1999-01-28    0.381134\\r\\n...          ...         ...\\r\\n6277  2024-01-03  475.690000\\r\\n6278  2024-01-04  479.980000\\r\\n6279  2024-01-05  490.970000\\r\\n6280  2024-01-08  522.530000\\r\\n6281  2024-01-09  531.400000\\r\\n```\\r\\nRunning the following:\\r\\n\\r\\n```\\r\\npprint(get_column_data_types(df))\\r\\npprint(df.dtypes)\\r\\n```\\r\\ngives you the following:\\r\\n\\r\\n```\\r\\n{\\'NVDA\\': set([<class \\'float\\'>]), \\'date\\': set([<class \\'datetime.date\\'>])}\\r\\n\\r\\ndate     object\\r\\nNVDA    float64\\r\\ndtype: object\\r\\n```\\r\\nAs you can see, each column has only one data type.  Yet when I try to convert df to a cudf using cudf.from_pandas(df), it throws the same mixed type error.\\r\\n\\r\\n\\r\\n**Expected behavior**\\r\\nThere\\'s no apparent mixtype column in the dataframe so it should be able to open the dataframe without throwing the mixedtype error.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Local machine.  PC running Win 11 using WSL2 Ubuntu\\r\\n - Method of cuDF install: pip\\r\\n\\r\\nCUDA 12 installed\\r\\nNVIDIA GTX 1080 graphics card\\r\\n\\r\\n\\r\\n**Environment details**\\r\\nError thrown in detail:\\r\\n```\\r\\nTraceback (most recent call last):\\r\\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\\r\\n    return _run_code(code, main_globals, None,\\r\\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\\r\\n    exec(code, run_globals)\\r\\n  File \"/home/notwopr/.local/lib/python3.10/site-packages/cudf/pandas/__main__.py\", line 91, in <module>\\r\\n    main()\\r\\n  File \"/home/notwopr/.local/lib/python3.10/site-packages/cudf/pandas/__main__.py\", line 87, in main\\r\\n    runpy.run_path(args.args[0], run_name=\"__main__\")\\r\\n  File \"/usr/lib/python3.10/runpy.py\", line 289, in run_path\\r\\n    return _run_module_code(code, init_globals, run_name,\\r\\n  File \"/usr/lib/python3.10/runpy.py\", line 96, in _run_module_code\\r\\n    _run_code(code, mod_globals, init_globals,\\r\\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\\r\\n    exec(code, run_globals)\\r\\n  File \"scratchp7.py\", line 29, in <module>\\r\\n    stockdatastats = FileOperations().readpkl(oldfn, DirPaths().full_info_db)\\r\\n  File \"/home/notwopr/beluga/beluga3/file_functions.py\", line 57, in readpkl\\r\\n    data = cudf.from_pandas(data)\\r\\n  File \"/home/notwopr/.local/lib/python3.10/site-packages/nvtx/nvtx.py\", line 115, in inner\\r\\n    result = func(*args, **kwargs)\\r\\n  File \"/home/notwopr/.local/lib/python3.10/site-packages/cudf/core/dataframe.py\", line 7891, in from_pandas\\r\\n    return DataFrame.from_pandas(obj, nan_as_null=nan_as_null)\\r\\n  File \"/home/notwopr/.local/lib/python3.10/site-packages/nvtx/nvtx.py\", line 115, in inner\\r\\n    result = func(*args, **kwargs)\\r\\n  File \"/home/notwopr/.local/lib/python3.10/site-packages/cudf/core/dataframe.py\", line 5237, in from_pandas\\r\\n    data[col_name] = column.as_column(\\r\\n  File \"/home/notwopr/.local/lib/python3.10/site-packages/cudf/core/column/column.py\", line 2279, in as_column\\r\\n    raise MixedTypeError(\"Cannot create column with mixed types\")\\r\\ncudf.errors.MixedTypeError: Cannot create column with mixed types\\r\\n```\\r\\n\\r\\n**Additional context**\\r\\nAdd any other context about the problem here.\\ncreatedAt: 2024-01-19T06:53:54Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: David Choi\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 325}),\n",
       " Document(page_content=\": 736\\ntitle: [BUG] `RollingGroupBy` objects cannot be pickled\\nbody: I noticed that `RollingGroupby` objects in cuDF cannot be pickled:\\r\\n\\r\\n```python\\r\\nIn [5]: df = cudf.DataFrame({'a': [1, 1, 2], 'b': [1, 2, 3]})\\r\\n\\r\\nIn [6]: pickle.dumps(df.groupby('a').rolling(2))\\r\\n---------------------------------------------------------------------------\\r\\nValueError                                Traceback (most recent call last)\\r\\nCell In[6], line 1\\r\\n----> 1 pickle.dumps(df.groupby('a').rolling(2))\\r\\n\\r\\nValueError: ctypes objects containing pointers cannot be pickled\\r\\n```\\r\\n\\r\\nThis has something to do with the `.window` attribute being a numba DeviceArray, and the latter being unpicklable.\\ncreatedAt: 2024-01-23T20:18:08Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 326}),\n",
       " Document(page_content=': 737\\ntitle: [BUG][JNI] java.lang.IllegalArgumentException: Unknown scalar type: STRUCT\\nbody: **Describe the bug**\\r\\ncuDF Java supports creating Scalar types to represent structs, but printing them for debug purposes causes an exception.\\r\\n\\r\\n```\\r\\njava.lang.IllegalArgumentException: Unknown scalar type: STRUCT\\r\\n```\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nCreate a scalar using `Scalar.structFromNull` or `Scalar.structFromColumnViews` and then call its `toString` method or try and print it using `System.out.println`\\r\\n\\r\\n**Expected behavior**\\r\\nShould print some useful debug info as per other scalar types, rather than throw an exception.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\nN/A\\r\\n\\r\\n**Environment details**\\r\\n\\r\\n**Additional context**\\ncreatedAt: 2024-01-23T23:50:46Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Andy Grove\\ncompany: @Apple', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 327}),\n",
       " Document(page_content=': 741\\ntitle: [FEA] Consolidate python code-style checking and formatting to just use `ruff`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nWe have already migrated to using [ruff](https://docs.astral.sh/ruff/) to replace flake8 and pyflakes. A previous barrier to using ruff\\'s `isort` lint was lack of support for custom sections, [that is now supported](https://docs.astral.sh/ruff/settings/#isort-sections). Similarly, `ruff format` (which produces effectively black-compatible formatting) is now in \"stable\" beta and very usable.\\r\\n\\r\\nWe should consider migrating the separate `isort` and `black` configs to use `ruff check --fix` and `ruff format` respectively.\\r\\n\\r\\nThe advantage here is that ruff is orders of magnitude faster than both isort and black. For those of us that use format-on-save this is a significant quality of life improvement (formatting a large python file when editing cudf can easily take a few seconds with black).\\r\\n\\r\\nWe would also reduce our tool configuration options.\\r\\n\\r\\nWe might also at the same time consider increasing the default line length from the current (somewhat miserly) 79 characters.\\ncreatedAt: 2024-01-25T12:30:01Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 328}),\n",
       " Document(page_content=\": 743\\ntitle: [FEA] Produce and Consume ArrowDeviceArray struct from cudf::table / cudf::column\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nI would like to generate Arrow IPC payloads from a `cudf::table` without copying the data off of the GPU device. Currently the `to_arrow` and `from_arrow` functions explicitly perform copies to and from the GPU device. There is not currently any efficient way to generate Arrow IPC payloads from libcudf without copying all of the data off of the device.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nIn addition to the existing `to_arrow` and `from_arrow` functions, we could have a `to_arrow_device_arr` function that populates an `ArrowDeviceArray` struct from a `cudf::table` or `cudf::column`. We'd also create a `from_arrow_device_arr` function that could construct a `cudf::table` / `cudf::column` from an `ArrowDeviceArray` that describes Arrow data which is already on the device. Once you have the `ArrowDeviceArray` struct, the Arrow C++ library itself can be used to generate the IPC payloads without needing to copy the data off the device. This would also increase the interoperability options that libcudf has, as anything which produces or consumes `ArrowDeviceArray` structs could hand data off to libcudf and vice versa.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nAn alternative would be to implement Arrow IPC creating inside of the libcudf library, but I saw that this was explicitly removed from libcudf due to the requirement of linking against `libarrow_cuda.so`. (https://github.com/rapidsai/cudf/issues/10994). Implementing conversions to and from `ArrowDeviceArray` wouldn't require linking against `libarrow_cuda.so` at all and would provide an easy way to allow any consumers to create Arrow IPC payloads, or whatever else they want to do with the resulting Arrow data. Such as leveraging CUDA IPC with the data.\\r\\n\\r\\n**Additional context**\\r\\nWhen designing the `ArrowDeviceArray` struct, I created https://github.com/zeroshade/arrow-non-cpu as a POC which used Python numba to generate and operate on some GPU data before handing it off to libcudf, and then getting it back without copying off the device. Using `ArrowDeviceArray` as the way it handed the data off.\\r\\n\\r\\nMore recently I've been working on creating a protocol for sending Arrow IPC data that is located on GPUs across high-performance transports like UCX. To this end, I created a POC using libcudf to pass the data. As a result I have a partial implementation of the `to_arrow_device_arr` which can be found [here](https://github.com/zeroshade/cudf-flight-ucx/blob/main/to_arrow.cc). There's likely better ways than what I'm doing in there, but at least for my POC it was working.\\r\\n\\r\\nThe contribution guidelines say I should file this issue first for discussion rather than just submitting a PR, so that's where I'm at. I plan on trying to create a full implementation that I can contribute but wanted to have this discussion and get feedback here first. \\r\\n\\r\\nThanks for hearing me out everyone!\\ncreatedAt: 2024-01-29T21:39:04Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Matt Topol\\ncompany: @voltrondata\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 329}),\n",
       " Document(page_content=': 744\\ntitle: [BUG] dask_cudf pivot_table function is broken: TypeError: StringIndex object is not iterable.\\nbody: **Describe the bug**\\r\\nPivot_table fails on a dask_cudf dataframe due to an unimplemented Index iteration function:\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n```python\\r\\nddf = dask_cudf.from_cudf(cudf.DataFrame(\\r\\n    data={\\r\\n        \"A\": [\"foo\", \"bar\", \"bar\"],\\r\\n        \"B\": [\"one\", \"two\", \"one\"],\\r\\n        \"C\": [1, 2, 3]\\r\\n    }\\r\\n), npartitions=1)\\r\\nddf = ddf.categorize(\"B\")\\r\\nddf.pivot_table(index=\"A\", columns=\"B\", values=\"C\")\\r\\n```\\r\\n\\r\\nError:\\r\\n```python\\r\\nTypeError                                 Traceback (most recent call last)\\r\\nCell In[3], line 9\\r\\n      1 ddf = dask_cudf.from_cudf(cudf.DataFrame(\\r\\n      2     data={\\r\\n      3         \"A\": [\"foo\", \"bar\", \"bar\"],\\r\\n   (...)\\r\\n      6     }\\r\\n      7 ), npartitions=1)\\r\\n      8 ddf = ddf.categorize(\"B\")\\r\\n----> 9 ddf.pivot_table(index=\"A\", columns=\"B\", values=\"C\")\\r\\n\\r\\nFile lib/python3.10/site-packages/dask/dataframe/core.py:6373, in DataFrame.pivot_table(self, index, columns, values, aggfunc)\\r\\n   6352 \"\"\"\\r\\n   6353 Create a spreadsheet-style pivot table as a DataFrame. Target ``columns``\\r\\n   6354 must have category dtype to infer result\\'s ``columns``.\\r\\n   (...)\\r\\n   6369 table : DataFrame\\r\\n   6370 \"\"\"\\r\\n   6371 from dask.dataframe.reshape import pivot_table\\r\\n-> 6373 return pivot_table(\\r\\n   6374     self, index=index, columns=columns, values=values, aggfunc=aggfunc\\r\\n   6375 )\\r\\n\\r\\nFile lib/python3.10/site-packages/dask/dataframe/reshape.py:233, in pivot_table(df, index, columns, values, aggfunc)\\r\\n    226     raise ValueError(\\r\\n    227         \"aggfunc must be either \" + \", \".join(f\"\\'{x}\\'\" for x in available_aggfuncs)\\r\\n    228     )\\r\\n    230 # _emulate can\\'t work for empty data\\r\\n    231 # the result must have CategoricalIndex columns\\r\\n--> 233 columns_contents = pd.CategoricalIndex(df[columns].cat.categories, name=columns)\\r\\n    234 if is_scalar(values):\\r\\n    235     new_columns = columns_contents\\r\\n\\r\\nFile lib/python3.10/site-packages/pandas/core/indexes/category.py:234, in CategoricalIndex.__new__(cls, data, categories, ordered, dtype, copy, name)\\r\\n    231 if is_scalar(data):\\r\\n    232     raise cls._scalar_data_error(data)\\r\\n--> 234 data = Categorical(\\r\\n    235     data, categories=categories, ordered=ordered, dtype=dtype, copy=copy\\r\\n    236 )\\r\\n    238 return cls._simple_new(data, name=name)\\r\\n\\r\\nFile lib/python3.10/site-packages/pandas/core/arrays/categorical.py:410, in Categorical.__init__(self, values, categories, ordered, dtype, fastpath, copy)\\r\\n    408         dtype = CategoricalDtype(values.categories, dtype.ordered)\\r\\n    409 elif not isinstance(values, (ABCIndex, ABCSeries, ExtensionArray)):\\r\\n--> 410     values = com.convert_to_list_like(values)\\r\\n    411     if isinstance(values, list) and len(values) == 0:\\r\\n    412         # By convention, empty lists result in object dtype:\\r\\n    413         values = np.array([], dtype=object)\\r\\n\\r\\nFile lib/python3.10/site-packages/pandas/core/common.py:541, in convert_to_list_like(values)\\r\\n    539     return values\\r\\n    540 elif isinstance(values, abc.Iterable) and not isinstance(values, str):\\r\\n--> 541     return list(values)\\r\\n    543 return [values]\\r\\n\\r\\nFile lib/python3.10/site-packages/cudf/utils/utils.py:242, in NotIterable.__iter__(self)\\r\\n    235 def __iter__(self):\\r\\n    236     \"\"\"\\r\\n    237     Iteration is unsupported.\\r\\n    238 \\r\\n    239     See :ref:`iteration <pandas-comparison/iteration>` for more\\r\\n    240     information.\\r\\n    241     \"\"\"\\r\\n--> 242     raise TypeError(\\r\\n    243         f\"{self.__class__.__name__} object is not iterable. \"\\r\\n    244         f\"Consider using `.to_arrow()`, `.to_pandas()` or `.values_host` \"\\r\\n    245         f\"if you wish to iterate over the values.\"\\r\\n    246     )\\r\\n\\r\\nTypeError: StringIndex object is not iterable. Consider using `.to_arrow()`, `.to_pandas()` or `.values_host` if you wish to iterate over the values.\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nPivot_table succeeds as documented.\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\nInstalled cuDF using pip, using the stable release:\\r\\n```bash\\r\\npip install \\\\\\r\\n    --extra-index-url=https://pypi.nvidia.com \\\\\\r\\n    cudf-cu12==23.12.* dask-cudf-cu12==23.12.* cuml-cu12==23.12.* \\\\\\r\\n    cugraph-cu12==23.12.* cuspatial-cu12==23.12.* cuproj-cu12==23.12.* \\\\\\r\\n    cuxfilter-cu12==23.12.* cucim-cu12==23.12.* pylibraft-cu12==23.12.* \\\\\\r\\n    raft-dask-cu12==23.12.*\\r\\n```\\r\\n\\r\\n**Environment details**\\r\\n```\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n     \\r\\n     **git***\\r\\nfatal: your current branch \\'master\\' does not have any commits yet\\r\\n     **git submodules***\\r\\n     \\r\\n     ***OS Information***\\r\\n     NAME=\"Red Hat Enterprise Linux\"\\r\\n     VERSION=\"8.8 (Ootpa)\"\\r\\n     ID=\"rhel\"\\r\\n     ID_LIKE=\"fedora\"\\r\\n     VERSION_ID=\"8.8\"\\r\\n     PLATFORM_ID=\"platform:el8\"\\r\\n     PRETTY_NAME=\"Red Hat Enterprise Linux 8.8 (Ootpa)\"\\r\\n     ANSI_COLOR=\"0;31\"\\r\\n     CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8::baseos\"\\r\\n     HOME_URL=\"https://www.redhat.com/\"\\r\\n     DOCUMENTATION_URL=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8\"\\r\\n     BUG_REPORT_URL=\"https://bugzilla.redhat.com/\"\\r\\n     \\r\\n     REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\"\\r\\n     REDHAT_BUGZILLA_PRODUCT_VERSION=8.8\\r\\n     REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\"\\r\\n     REDHAT_SUPPORT_PRODUCT_VERSION=\"8.8\"\\r\\n     Red Hat Enterprise Linux release 8.8 (Ootpa)\\r\\n     Red Hat Enterprise Linux release 8.8 (Ootpa)\\r\\n     Linux c1000a-s23.ufhpc 4.18.0-477.27.1.el8_8.x86_64 #1 SMP Thu Aug 31 10:29:22 EDT 2023 x86_64 x86_64 x86_64 GNU/Linux\\r\\n     \\r\\n     ***GPU Information***\\r\\n     Tue Jan 30 11:09:21 2024\\r\\n     +---------------------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\\r\\n     |-----------------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                                         |                      |               MIG M. |\\r\\n     |=========================================+======================+======================|\\r\\n     |   0  NVIDIA A100-SXM4-80GB          On  | 00000000:07:00.0 Off |                    0 |\\r\\n     | N/A   25C    P0              56W / 400W |      4MiB / 81920MiB |      0%      Default |\\r\\n     |                                         |                      |             Disabled |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   1  NVIDIA A100-SXM4-80GB          On  | 00000000:0F:00.0 Off |                    0 |\\r\\n     | N/A   26C    P0              57W / 400W |      4MiB / 81920MiB |      0%      Default |\\r\\n     |                                         |                      |             Disabled |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   2  NVIDIA A100-SXM4-80GB          On  | 00000000:47:00.0 Off |                    0 |\\r\\n     | N/A   24C    P0              54W / 400W |      4MiB / 81920MiB |      0%      Default |\\r\\n     |                                         |                      |             Disabled |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   3  NVIDIA A100-SXM4-80GB          On  | 00000000:4E:00.0 Off |                    0 |\\r\\n     | N/A   24C    P0              56W / 400W |      4MiB / 81920MiB |      0%      Default |\\r\\n     |                                         |                      |             Disabled |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   4  NVIDIA A100-SXM4-80GB          On  | 00000000:87:00.0 Off |                    0 |\\r\\n     | N/A   29C    P0              67W / 400W |    583MiB / 81920MiB |     40%      Default |\\r\\n     |                                         |                      |             Disabled |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   5  NVIDIA A100-SXM4-80GB          On  | 00000000:90:00.0 Off |                    0 |\\r\\n     | N/A   45C    P0             177W / 400W |    775MiB / 81920MiB |     94%      Default |\\r\\n     |                                         |                      |             Disabled |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   6  NVIDIA A100-SXM4-80GB          On  | 00000000:B7:00.0 Off |                    0 |\\r\\n     | N/A   60C    P0             338W / 400W |  76523MiB / 81920MiB |    100%      Default |\\r\\n     |                                         |                      |             Disabled |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   7  NVIDIA A100-SXM4-80GB          On  | 00000000:BD:00.0 Off |                    0 |\\r\\n     | N/A   28C    P0              54W / 400W |      4MiB / 81920MiB |      0%      Default |\\r\\n     |                                         |                      |             Disabled |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     \\r\\n     +---------------------------------------------------------------------------------------+\\r\\n     | Processes:                                                                            |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\\r\\n     |        ID   ID                                                             Usage      |\\r\\n     |=======================================================================================|\\r\\n     |    4   N/A  N/A   2669759      C   python3                                     570MiB |\\r\\n     |    5   N/A  N/A   1903237      C   pmemd.cuda_SPFP                             762MiB |\\r\\n     |    6   N/A  N/A   1446394      C   python                                    76510MiB |\\r\\n     +---------------------------------------------------------------------------------------+\\r\\n     \\r\\n     ***CPU***\\r\\n     Architecture:        x86_64\\r\\n     CPU op-mode(s):      32-bit, 64-bit\\r\\n     Byte Order:          Little Endian\\r\\n     CPU(s):              128\\r\\n     On-line CPU(s) list: 0-127\\r\\n     Thread(s) per core:  1\\r\\n     Core(s) per socket:  64\\r\\n     Socket(s):           2\\r\\n     NUMA node(s):        8\\r\\n     Vendor ID:           AuthenticAMD\\r\\n     CPU family:          23\\r\\n     Model:               49\\r\\n     Model name:          AMD EPYC 7742 64-Core Processor\\r\\n     Stepping:            0\\r\\n     CPU MHz:             3386.055\\r\\n     CPU max MHz:         2250.0000\\r\\n     CPU min MHz:         1500.0000\\r\\n     BogoMIPS:            4491.84\\r\\n     Virtualization:      AMD-V\\r\\n     L1d cache:           32K\\r\\n     L1i cache:           32K\\r\\n     L2 cache:            512K\\r\\n     L3 cache:            16384K\\r\\n     NUMA node0 CPU(s):   0-15\\r\\n     NUMA node1 CPU(s):   16-31\\r\\n     NUMA node2 CPU(s):   32-47\\r\\n     NUMA node3 CPU(s):   48-63\\r\\n     NUMA node4 CPU(s):   64-79\\r\\n     NUMA node5 CPU(s):   80-95\\r\\n     NUMA node6 CPU(s):   96-111\\r\\n     NUMA node7 CPU(s):   112-127\\r\\n     Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip rdpid overflow_recov succor smca sme sev sev_es\\r\\n     \\r\\n     ***CMake***\\r\\n     /apps/jupyter/6.5.4/bin/cmake\\r\\n./print_env.sh: /apps/jupyter/6.5.4/bin/cmake: /apps/jupyter/6.5.4/bin/python3.11: bad interpreter: No such file or directory\\r\\n     \\r\\n     ***g++***\\r\\n     /usr/bin/g++\\r\\n     g++ (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)\\r\\n     Copyright (C) 2018 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n     \\r\\n     \\r\\n     ***nvcc***\\r\\n     /apps/compilers/cuda/12.2.2/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2023 NVIDIA Corporation\\r\\n     Built on Tue_Aug_15_22:02:13_PDT_2023\\r\\n     Cuda compilation tools, release 12.2, V12.2.140\\r\\n     Build cuda_12.2.r12.2/compiler.33191640_0\\r\\n     \\r\\n     ***Python***\\r\\n     /blue/ptighe-rapidsai/pvnick/rapids-test/rapids-test/bin/python\\r\\n     Python 3.10.12\\r\\n     \\r\\n     ***Environment Variables***\\r\\n     PATH                            : /apps/compilers/cuda/12.2.2/bin:/blue/ptighe-rapidsai/pvnick/rapids-test/rapids-test/bin:/opt/slurm/bin:/usr/local/cuda/bin:/opt/bin:/apps/jupyter/6.5.4/bin:/apps/ufrc/ufhpc/bin:/apps/git/2.30.1/bin:/home/pvnick/.local/bin:/home/pvnick/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/bin\\r\\n     LD_LIBRARY_PATH                 : /apps/compilers/cuda/12.2.2/lib64:/opt/slurm/lib64::\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    :\\r\\n     PYTHON_PATH                     :\\r\\n     \\r\\n     conda not found\\r\\n     ***pip packages***\\r\\n     /blue/ptighe-rapidsai/pvnick/rapids-test/rapids-test/bin/pip\\r\\n     Package                   Version\\r\\n     ------------------------- ---------------\\r\\n     aiohttp                   3.9.3\\r\\n     aiosignal                 1.3.1\\r\\n     anyio                     4.2.0\\r\\n     argon2-cffi               23.1.0\\r\\n     argon2-cffi-bindings      21.2.0\\r\\n     arrow                     1.3.0\\r\\n     asttokens                 2.4.1\\r\\n     async-lru                 2.0.4\\r\\n     async-timeout             4.0.3\\r\\n     attrs                     23.2.0\\r\\n     Babel                     2.14.0\\r\\n     beautifulsoup4            4.12.3\\r\\n     bleach                    6.1.0\\r\\n     bokeh                     3.3.4\\r\\n     cachetools                5.3.2\\r\\n     certifi                   2023.11.17\\r\\n     cffi                      1.16.0\\r\\n     charset-normalizer        3.3.2\\r\\n     click                     8.1.7\\r\\n     click-plugins             1.1.1\\r\\n     cligj                     0.7.2\\r\\n     cloudpickle               3.0.0\\r\\n     colorcet                  3.0.1\\r\\n     comm                      0.2.1\\r\\n     contourpy                 1.2.0\\r\\n     cucim-cu12                23.12.1\\r\\n     cuda-python               12.3.0\\r\\n     cudf-cu12                 23.12.1\\r\\n     cugraph-cu12              23.12.0\\r\\n     cuml-cu12                 23.12.0\\r\\n     cuproj-cu12               23.12.1\\r\\n     cupy-cuda12x              13.0.0\\r\\n     cuspatial-cu12            23.12.1\\r\\n     cuxfilter-cu12            23.12.0\\r\\n     dask                      2023.11.0\\r\\n     dask-cuda                 23.12.0\\r\\n     dask-cudf-cu12            23.12.0\\r\\n     datashader                0.16.0\\r\\n     debugpy                   1.8.0\\r\\n     decorator                 5.1.1\\r\\n     defusedxml                0.7.1\\r\\n     distributed               2023.11.0\\r\\n     exceptiongroup            1.2.0\\r\\n     executing                 2.0.1\\r\\n     fastjsonschema            2.19.1\\r\\n     fastrlock                 0.8.2\\r\\n     fiona                     1.9.5\\r\\n     fqdn                      1.5.1\\r\\n     frozenlist                1.4.1\\r\\n     fsspec                    2023.12.2\\r\\n     geopandas                 0.14.2\\r\\n     holoviews                 1.18.1\\r\\n     idna                      3.6\\r\\n     imageio                   2.33.1\\r\\n     importlib-metadata        7.0.1\\r\\n     ipykernel                 6.29.0\\r\\n     ipython                   8.20.0\\r\\n     ipywidgets                8.1.1\\r\\n     isoduration               20.11.0\\r\\n     jedi                      0.19.1\\r\\n     Jinja2                    3.1.3\\r\\n     joblib                    1.3.2\\r\\n     json5                     0.9.14\\r\\n     jsonpointer               2.4\\r\\n     jsonschema                4.21.1\\r\\n     jsonschema-specifications 2023.12.1\\r\\n     jupyter                   1.0.0\\r\\n     jupyter_client            8.6.0\\r\\n     jupyter-console           6.6.3\\r\\n     jupyter_core              5.7.1\\r\\n     jupyter-events            0.9.0\\r\\n     jupyter-lsp               2.2.2\\r\\n     jupyter_server            2.12.5\\r\\n     jupyter_server_proxy      4.1.0\\r\\n     jupyter_server_terminals  0.5.2\\r\\n     jupyterlab                4.0.11\\r\\n     jupyterlab_pygments       0.3.0\\r\\n     jupyterlab_server         2.25.2\\r\\n     jupyterlab-widgets        3.0.9\\r\\n     lazy_loader               0.3\\r\\n     linkify-it-py             2.0.2\\r\\n     llvmlite                  0.40.1\\r\\n     locket                    1.0.0\\r\\n     Markdown                  3.5.2\\r\\n     markdown-it-py            3.0.0\\r\\n     MarkupSafe                2.1.4\\r\\n     matplotlib-inline         0.1.6\\r\\n     mdit-py-plugins           0.4.0\\r\\n     mdurl                     0.1.2\\r\\n     mistune                   3.0.2\\r\\n     msgpack                   1.0.7\\r\\n     multidict                 6.0.4\\r\\n     multipledispatch          1.0.0\\r\\n     nbclient                  0.9.0\\r\\n     nbconvert                 7.14.2\\r\\n     nbformat                  5.9.2\\r\\n     nest-asyncio              1.6.0\\r\\n     networkx                  3.2.1\\r\\n     notebook                  7.0.7\\r\\n     notebook_shim             0.2.3\\r\\n     numba                     0.57.1\\r\\n     numpy                     1.24.4\\r\\n     nvtx                      0.2.8\\r\\n     overrides                 7.7.0\\r\\n     packaging                 23.2\\r\\n     pandas                    1.5.3\\r\\n     pandocfilters             1.5.1\\r\\n     panel                     1.3.8\\r\\n     param                     2.0.2\\r\\n     parso                     0.8.3\\r\\n     partd                     1.4.1\\r\\n     pexpect                   4.9.0\\r\\n     pillow                    10.2.0\\r\\n     pip                       23.0.1\\r\\n     platformdirs              4.1.0\\r\\n     prometheus-client         0.19.0\\r\\n     prompt-toolkit            3.0.43\\r\\n     protobuf                  4.25.2\\r\\n     psutil                    5.9.8\\r\\n     ptyprocess                0.7.0\\r\\n     pure-eval                 0.2.2\\r\\n     pyarrow                   14.0.2\\r\\n     pycparser                 2.21\\r\\n     pyct                      0.5.0\\r\\n     Pygments                  2.17.2\\r\\n     pylibcugraph-cu12         23.12.0\\r\\n     pylibraft-cu12            23.12.0\\r\\n     pynvml                    11.4.1\\r\\n     pyproj                    3.6.1\\r\\n     python-dateutil           2.8.2\\r\\n     python-json-logger        2.0.7\\r\\n     pytz                      2023.4\\r\\n     pyviz_comms               3.0.1\\r\\n     PyWavelets                1.5.0\\r\\n     PyYAML                    6.0.1\\r\\n     pyzmq                     25.1.2\\r\\n     qtconsole                 5.5.1\\r\\n     QtPy                      2.4.1\\r\\n     raft-dask-cu12            23.12.0\\r\\n     rapids-dask-dependency    23.12.1\\r\\n     referencing               0.33.0\\r\\n     requests                  2.31.0\\r\\n     rfc3339-validator         0.1.4\\r\\n     rfc3986-validator         0.1.1\\r\\n     rich                      13.7.0\\r\\n     rmm-cu12                  23.12.0\\r\\n     rpds-py                   0.17.1\\r\\n     scikit-image              0.21.0\\r\\n     scipy                     1.12.0\\r\\n     Send2Trash                1.8.2\\r\\n     setuptools                65.5.0\\r\\n     shapely                   2.0.2\\r\\n     simpervisor               1.0.0\\r\\n     six                       1.16.0\\r\\n     sniffio                   1.3.0\\r\\n     sortedcontainers          2.4.0\\r\\n     soupsieve                 2.5\\r\\n     stack-data                0.6.3\\r\\n     tblib                     3.0.0\\r\\n     terminado                 0.18.0\\r\\n     tifffile                  2024.1.30\\r\\n     tinycss2                  1.2.1\\r\\n     tomli                     2.0.1\\r\\n     toolz                     0.12.1\\r\\n     tornado                   6.4\\r\\n     tqdm                      4.66.1\\r\\n     traitlets                 5.14.1\\r\\n     treelite                  3.9.1\\r\\n     treelite-runtime          3.9.1\\r\\n     types-python-dateutil     2.8.19.20240106\\r\\n     typing_extensions         4.9.0\\r\\n     uc-micro-py               1.0.2\\r\\n     ucx-py-cu12               0.35.0\\r\\n     uri-template              1.3.0\\r\\n     urllib3                   2.1.0\\r\\n     wcwidth                   0.2.13\\r\\n     webcolors                 1.13\\r\\n     webencodings              0.5.1\\r\\n     websocket-client          1.7.0\\r\\n     widgetsnbextension        4.0.9\\r\\n     xarray                    2024.1.1\\r\\n     xyzservices               2023.10.1\\r\\n     yarl                      1.9.4\\r\\n     zict                      3.0.0\\r\\n     zipp                      3.17.0\\r\\n\\r\\n[notice] A new release of pip is available: 23.0.1 -> 23.3.2\\r\\n[notice] To update, run: pip install --upgrade pip\\r\\n     \\r\\n</pre></details>\\r\\n```\\ncreatedAt: 2024-01-30T16:11:19Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: paul\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 330}),\n",
       " Document(page_content=\": 746\\ntitle: [FEA] Implement a templated parquet decoding kernel suitable for reuse in micro-kernel optimization approach.\\nbody: As part of the drive towards implementing the micro-kernel parquet decoding strategy, we would like to start centralizing the core parquet decoding loop into a generic templated implementation that can be reused.  At the high level, all of various parquet kernels are structured similar to this:\\r\\n```\\r\\nkernel(PageInfo p)\\r\\n{\\r\\n    // page setup, bounds checking (for skip_rows/num_rows), etc\\r\\n    setup_code();\\r\\n\\r\\n   while(there are still values to decode in p){\\r\\n      def_levels = def_stream.decode(def_levels);\\r\\n      rep_levels = p.has_lists ? rep_stream.decode(rep_levels);\\r\\n      dict_indices = p.has_dict ? dict_stream.decode(dict_indices);\\r\\n      decode_general_outputs(def_levels, rep_levels, dict_indices);\\r\\n\\r\\n      PROCESS(p, def_levels, rep_levels, dict_indices);\\r\\n   }\\r\\n}\\r\\n```\\r\\nThe various *_stream.decode() functions are the key bottleneck in decoding parquet data. At the moment, the kernels we have mostly utilize the older/slower way of decoding these streams.  The `rle_stream` class was developed to do this in a more parallel (and more confiurable) way, but only a few kernels use it at the moment because it does not currently handle dictionaries.  The work for that is underway and very close to completion (https://github.com/rapidsai/cudf/issues/14950)\\r\\n\\r\\n`decode_general_outputs` is a function that produces validity, list offset information and the mapping of source data (location in the parquet data page) to destination data (location in the final cudf column).  The amount of work this function has to do varies greatly based on the characteristics of the input data - nullability, presence of lists, etc.\\r\\n\\r\\nPROCESS is something that varies from kernel-to-kernel.  Essentially, the user-provided function that actually does the final data decoding.\\r\\n\\r\\nWe would like to implement this high level loop as a templated function that can be tailored to produce multiple, more optimal kernels based on they key data characteristics. For example:\\r\\n\\r\\n```\\r\\ntemplate<// page data characteristics\\r\\n                bool nullable,\\r\\n                bool has_lists,\\r\\n                bool has_dictionary,\\r\\n                etc\\r\\n\\r\\n                // parameters which can be tuned \\r\\n                int decode_buffer_size,\\r\\n                int decode_warp_count,\\r\\n                etc,\\r\\n                \\r\\n                // user provided PROCESS functor\\r\\n                ProcessFunc Proc>\\r\\n```\\r\\n\\r\\nThere are several reasons to do this:\\r\\n- The `rle_stream` class uses shared memory, so it is a big advantage to be able to have kernels that don't need a given feature (say, list decoding) to be able to use less.\\r\\n- It is useful to be able to tune block size per kernel as they tend to get bottlenecked in different ways.  \\r\\n- It would allow us to eliminate the old level decoding path.\\r\\n\\r\\nThe first candidates for using this would be two new micro-kernels:  Fixed-width and fixed-width-with-dictionaries (the non-list case for both of them). We would like to get these in for 24.04 and then later on we can start refactoring the larger mass of existing kernels (especially the general-purpose `gpuDecodePageData` and `gpuDecodeStringPageData`\\ncreatedAt: 2024-02-01T19:09:50Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 331}),\n",
       " Document(page_content=\": 747\\ntitle: [FEA] Zero-copy nested types with other GPU libraries (like Awkward array)\\nbody: In a conversation with @martindurant and @jpivarski, it came up that there's no supported way to exchange data zero copy between cuDF and [Awkward Array](https://awkward-array.org/doc/main/) (which has GPU support).\\r\\n\\r\\nThe standard 0-copy mechanisms like dlpack and `__cuda_array_interface__` don't support nested types like lists or structs. And our `to/from_arrow()` methods convert to and from _host_ data so they're not useful when we want to 0-copy _device_ data.\\r\\n\\r\\n## Option 1\\r\\n\\r\\nWe support a `gpu=True` (or similar) keyword argument in `to_arrow()` which would then return a PyArrow array backed by device data. Now, PyArrow does not seemingly support it, but it's _possible_ to create a PyArrow array backed by device data:\\r\\n\\r\\n```python\\r\\nIn [5]: a = cp.asarray([1, 2, 3])\\r\\n\\r\\nIn [6]: buf = pa.foreign_buffer(a.data.ptr, a.nbytes, a)\\r\\n\\r\\nIn [7]: type(buf)\\r\\nOut[7]: pyarrow.lib.Buffer\\r\\n\\r\\nIn [8]: print(buf)\\r\\n<pyarrow.Buffer address=0x7f2f6fa00200 size=24 is_cpu=True is_mutable=False>\\r\\n```\\r\\n\\r\\nThe problem (as can be seen above) is that PyArrow thinks this is a CPU-backed buffer. So attempting to do anything with it segfaults:\\r\\n\\r\\n```python\\r\\nIn [9]: arr = pa.Array.from_buffers(pa.int64(), len(a), buffers=[None, buf])\\r\\n\\r\\nIn [10]: print(arr)  # segfault\\r\\n```\\r\\n\\r\\n## Option 2\\r\\n\\r\\nWe could expose new `Series.to_buffers()` and `Series.from_buffers()` functions that would produce and consume GPU buffers (along with a schema), presumably in the same order as arrow's [from_buffers](https://arrow.apache.org/docs/python/generated/pyarrow.Array.html#pyarrow.Array.from_buffers) and [buffers](https://arrow.apache.org/docs/python/generated/pyarrow.Array.html#pyarrow.Array.buffers) methods. We could use CuPy arrays to represent the buffers.\\r\\n\\r\\n---\\r\\n\\r\\nCurious what folks think? Interested also in @kkraus14's thoughts here if any.\\ncreatedAt: 2024-02-02T21:21:47Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 332}),\n",
       " Document(page_content=': 749\\ntitle: [FEA] Incorporate chunked parquet reading into cuDF-python\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nlibcudf provides a `chunked_parquet_reader` in its public API. This reader uses new reader options to process the data in a parquet file in sub-file units. The `chunk_read_limit` option limits the table size in bytes to be returned per read by only decoding a subset of pages per chunked read. The `pass_read_limit` option limits the memory used for reading and decompressing data by only decompressing a subset of pages per chunked read.\\r\\n\\r\\nThe chunked parquet reader allows cuDF-python to expose two types of useful functionality:\\r\\n1. an API that acts as an iterator to yield dataframe chunks. This is similar to the `iter_row_groups` behavior in [fastparquet](https://fastparquet.readthedocs.io/en/latest/api.html). This approach would let users work with parquet files that contain more rows than 2.1B rows (see #13159 for more information about the row limit in libcudf). \\r\\n2. a \"low_memory\" mode that reads the full file, but has a lower peak memory footprint thanks to the smaller sizes of intermediate allocations. This is similar to the the `low_memory` argument in [polars](https://docs.pola.rs/py-polars/html/reference/api/polars.read_parquet.html). This approach would make it easier to read large parquet datasets with limited GPU memory.\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nWe should make chunked parquet reading available to cuDF-python users. Perhaps this functionality could be made available to `cudf.pandas` users as well. \\r\\n\\r\\n\\r\\n**Additional context**\\r\\nPandas does not seem to have a method for chunking parquet reads, and I\\'m not sure if pandas makes use of the `iter_row_groups` behavior in fastparquet as a pass-through parameter.\\r\\n\\r\\n\\r\\nAPI docs references:\\r\\n* pandas: [read_parquet](https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html)\\r\\n* pyarrow: [parquet.read_table](https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html)\\r\\n* fastparquet: [read_parquet](https://fastparquet.readthedocs.io/en/latest/api.html)\\r\\n* polars: [read_parquet](https://docs.pola.rs/py-polars/html/reference/api/polars.read_parquet.html)\\r\\n* cudf: [read_parquet](https://docs.rapids.ai/api/cudf/nightly/user_guide/api_docs/api/cudf.read_parquet/)\\ncreatedAt: 2024-02-04T19:10:28Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 333}),\n",
       " Document(page_content=': 753\\ntitle: [FEA] Update JSON reader benchmarks to include JSON lines and normalization\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nFirst pass changes:\\r\\n- [ ] I believe [this line](https://github.com/rapidsai/cudf/blob/bb6ae07079f3c36dca8387bab578b75d06be6b33/cpp/benchmarks/io/json/nested_json.cpp#L91) in the benchmark `nested_json.cpp` should use `max_list_size` instead of `max_struct_size`. We should also add `int64` nvbench axes for these two size values, sticking with a standard value of `{10}`, and adding the ability to sweep these parameters in custom tests.\\r\\n- [ ] Add JSON versus JSON Lines benchmark. We have a `parquet_reader_options` benchmark and we could add something similar e.g. `json_reader_options`. This benchmark can start by choosing a single data type and a device buffer data source. As a follow-on step we would want to allow data type and IO source to be nvbench enum axes.\\r\\n- [ ] Add `_normalize_single_quotes` and `_normalize_whitespace` to the `json_reader_options` benchmark. Since the JSON writer can\\'t generate single quotes or extra whitespace, these normalization steps will not change the resulting table, but we should track the added runtime.\\r\\n- [ ] Add `_recovery_mode` and `_mixed_types_as_string` to the `json_reader_options` benchmark as \"no-op\" tests. The benchmark would use the the existing data generator without invalid records and without mixed types.\\r\\n- [ ] Add post-processing to the generated data to introduce mixed types, and then benchmark against similar data without mixed types. The approach could be using the existing data generator, but then changing one list entry into a struct entry, e.g. `[1,2,3]` => `{\"a\": [1,2,3]}`\\r\\n\\r\\nLower priority ideas. If we have reason to believe these benchmarks would highlight performance issues, then we should raise their priority.\\r\\n- [ ] For the quote and whitespace normalization options, create a modified data generator or character buffer post-processing to introduce un-normalized data. For instance, we could replace `\"` with `\\'` for quote normalization and `:` with ` : ` for whitespace normalization.\\r\\n- [ ] Update the data generator to introduce invalid JSON lines and exercises the `_recovery_mode` as nulls code path. We could add a fraction of invalid records as well as valid records followed by invalid characters.\\r\\n- [ ] Add a normalization benchmark into the `benchmarks/io/json/` suite that measures the runtime of `detail::normalize_single_quotes` and the upcoming detil API for whitespace normalization. This benchmark would not test the overall reader, but only the FST-based normalization functions.\\ncreatedAt: 2024-02-13T21:15:10Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 334}),\n",
       " Document(page_content=\": 755\\ntitle: [FEA] Update chunked parquet reader benchmarks to include `pass_read_limit`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThe `BM_parquet_read_chunks` benchmark in `benchmarks/io/parquet/parquet_reader_input.cpp` includes a `byte_limit` nvbench axis. This axis controls the `chunk_read_limit`. With the new features added in #14360, there is a new `chunked_parquet_reader` API that exposes both `chunk_read_limit` and `pass_read_limit` parameters to control reader behavior. We currently do not have a method for benchmarking `pass_read_limit` values.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n- [ ] Add a new benchmark, such as `BM_parquet_read_subrowgroup_chunks`, that provides nvbench axes for both `chunk_read_limit` and `pass_read_limit`\\r\\n- [ ] Rename `byte_limit` to `chunk_read_limit` in `BM_parquet_read_chunks` for clarity, now that we have both input and output byte limits in chunked parquet reading.\\r\\n- [ ] Also, please consider adding an nvbench axis for `data_size` for at least the chunked parquet reader benchmarks. It would be useful to allow the benchmarks to operate on tables larger than 536 MB.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nn/a\\ncreatedAt: 2024-02-14T21:27:40Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 335}),\n",
       " Document(page_content=\": 756\\ntitle: [FEA] Implement center for offset based windows\\nbody: Suppose I have a Series as follows:\\r\\n```python\\r\\ns = cudf.Series(range(100), index=cudf.date_range('2024', periods=100, freq='D'))\\r\\n```\\r\\nIf I want to perform 3-day rolling window mean, I can do:\\r\\n```python\\r\\nwindow_size = 3\\r\\ns.rolling(f'{window_size}D').mean()\\r\\n```\\r\\nThis is not centered. If I want to set the window labels as the center of the window index (like in pandas):\\r\\n```python\\r\\na = s.rolling(f'{window_size}D', center=True).mean()\\r\\n```\\r\\nthen I get a NotImplementedError.\\r\\n\\r\\nI wish I could do this in cudf.\\r\\n\\r\\nRight now, I can just compute the rolling mean, shift it by half the window size and fill in the NaN values by using a loop over a variable window but it's a little ugly.\\r\\n```python\\r\\nshift = -(window_size-1)//2\\r\\nb = s.rolling(f'{window_size}D').mean().shift(shift)\\r\\nb.iloc[shift:] = [s.loc[i:].mean() for i in s.index[-window_size+1:-window_size-shift+1]]\\r\\n```\\r\\n\\r\\nPandas' `DataFrame.rolling` uses a cython optimized function to implement `center` (and `closed`) parameters. Its function to get variable window indexers is `pandas._libs.window.indexers.calculate_variable_window_bounds`. My suggestion is to implement this function in cudf.\\ncreatedAt: 2024-02-19T07:50:52Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Manlai Amar\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 336}),\n",
       " Document(page_content=\": 757\\ntitle: [BUG] Unlike its pandas counterpart, `cudf.date_range` doesn't include the end if it's specified\\nbody: If I create a DatetimeIndex object using `cudf.date_range()` by passing `start`, `end` and `freq` parameters:\\r\\n```python\\r\\ncudf.date_range('2020-01-01', '2020-01-05', freq='D')\\r\\n\\r\\nDatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04'], \\r\\n              dtype='datetime64[ns]', freq='D')\\r\\n```\\r\\nAs you can see, the result is an object with length 4. The same code in pandas results in an object with length 5:\\r\\n```python\\r\\npd.date_range('2020-01-01', '2020-01-05', freq='D')\\r\\n\\r\\nDatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04', '2020-01-05'],\\r\\n              dtype='datetime64[ns]', freq='D')\\r\\n```\\r\\n\\r\\nIs it possible to make it consistent with pandas' `date_range()` in that the result includes both ends? Because, `closed` parameter is nonfunctional at the moment, to make `cudf.date_range()` produce the same output as its pandas counterpart, we need to add 1 `freq` to `end`, which creates a whole lot of work: convert the string to datetime, convert freq to timedelta and add them to define a new end.\\r\\n\\r\\nAnyway, is it possible to make it clear in the documentation that this is different from its pandas counterpart?\\r\\n\\r\\n<sup>I didn't know how to tag this since it's not really a bug. It's just different from pandas API that results in a subtle bug _in my code_.</sup>\\ncreatedAt: 2024-02-22T04:35:02Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Manlai Amar\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 337}),\n",
       " Document(page_content=': 758\\ntitle: [FEA] NamedAgg in groupby context\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nplease support namedagg in groupby(...).agg\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nto be able to write\\r\\n```python\\r\\ndf.groupby(\"A\").agg(\\r\\n    b_min=cudf.NamedAgg(column=\"B\", aggfunc=\"min\"),\\r\\n    c_sum=cudf.NamedAgg(column=\"C\", aggfunc=\"sum\")\\r\\n)\\r\\n```\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\n\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nhttps://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html\\ncreatedAt: 2024-02-22T12:58:24Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Marco Edward Gorelli\\ncompany: Quansight', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 338}),\n",
       " Document(page_content=': 759\\ntitle: [BUG] Rolling window aggregations are very slow with large windows\\nbody: With large windows, the `.rolling()` function in cuDF can be pathologically slow:\\r\\n\\r\\n```python\\r\\nIn [6]: dt = cudf.date_range(\"2001-01-01\", \"2002-01-01\", freq=\"1s\")\\r\\nIn [7]: df = cudf.DataFrame({\"x\": np.random.rand(len(dt))}, index=dt)\\r\\nIn [8]: %time df.rolling(\"1D\").sum()\\r\\nCPU times: user 10.3 s, sys: 57.1 ms, total: 10.3 s\\r\\nWall time: 10.4 s\\r\\nOut[8]:\\r\\n                                x\\r\\n2001-01-01 00:00:00      0.815418\\r\\n2001-01-01 00:00:01      1.238151\\r\\n2001-01-01 00:00:02      1.811390\\r\\n2001-01-01 00:00:03      2.065794\\r\\n2001-01-01 00:00:04      2.195230\\r\\n...                           ...\\r\\n2001-12-31 23:59:55  43308.909704\\r\\n2001-12-31 23:59:56  43309.098228\\r\\n2001-12-31 23:59:57  43308.658888\\r\\n2001-12-31 23:59:58  43308.790256\\r\\n2001-12-31 23:59:59  43308.915838\\r\\n\\r\\n[31536000 rows x 1 columns]\\r\\n```\\r\\n\\r\\n## Why is it slow?\\r\\n\\r\\nOf the 10s of execution time above, about 8s is spent in computing the window sizes, which is done in a hand-rolled numba CUDA kernel: https://github.com/rapidsai/cudf/blob/6f6e521257dce5732eea7b6b9d56243f8b0a69cc/python/cudf/cudf/utils/cudautils.py#L17. Note that running the code through a profiler will show execution time being spent in the _next_ CUDA kernel (`column.full`) - but that\\'s a red herring I think, because there\\'s no synchronization after the numba kernel call.\\r\\n\\r\\n## What can we do about it?\\r\\n\\r\\nI see a couple of options here:\\r\\n\\r\\n1. I wonder if there\\'s a better way to write that kernel. Currently, it naively launches one thread per element, and does a linear search for the next element that would exceed the window bounds. \\r\\n2. We could make it `libcudf`\\'s responsibility to compute the window sizes. I believe they already do window sizes computation in the context of _grouped_ rolling window aggreagations: see [`grouped_range_rolling_window()`](https://github.com/rapidsai/cudf/blob/6f6e521257dce5732eea7b6b9d56243f8b0a69cc/cpp/include/cudf/rolling.hpp#L542).\\ncreatedAt: 2024-02-22T16:04:49Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 339}),\n",
       " Document(page_content=\": 761\\ntitle: [FEA] Pass column indices as `index_col` in `read_csv`\\nbody: If I want to use the `index_col` parameter to set certain columns as indices when reading a csv file, I cannot pass a list of column indices (like in pandas). I can pass a list of column labels though:\\r\\n```python\\r\\ncudf.read_csv(filepath, index_col=[0])\\r\\nKeyError: 'None of [0] are in the columns'\\r\\n\\r\\ncudf.read_csv(filepath, index_col=['family'])\\r\\n```\\r\\nWhile this is not a huge issue, I imagine the following is a common scenario: You have know that the first 3 columns are index columns, but you don't exactly know how each are spelt (`'date'` vs `'Date'` etc.). In this case, if passing a list of column indices were possible, `index_col=[0,1,2]` would have worked fine; otherwise, you will have to read the file without specifying index columns and set index later (or require trial and error to guess the column labels).\\r\\n\\r\\nIs it possible for `index_col` to accept list of indices like in pandas?\\ncreatedAt: 2024-02-23T08:21:24Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Manlai Amar\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 340}),\n",
       " Document(page_content=\": 766\\ntitle: [FEA] Add python bindings in the parquet reader for `num_rows`/`skiprows`\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nUnfortunately there has been churn in libcudf around support for `num_rows`/`skiprows` in the Parquet and ORC readers. In 22.08 we deprecated these parameters in the parquet reader (#11218) and then in 22.10 we removed them from C++ (#11503) and python (#11480). We also deprecated `num_rows`/`skiprows` in the ORC reader (#11522, see issue #11519).\\r\\n\\r\\nAt this point, we realized that chunked parquet reading (#11867) would require adding `num_rows`/`skiprows` back to the C++ implementation (#11657).\\r\\n\\r\\nLet's stabilize row selection APIs in libcudf by completing these tasks:\\r\\n- [ ] Add python bindings in the parquet reader for `num_rows`/`skiprows`\\r\\n- [ ] Remove the deprecation notice in the ORC reader for `num_rows`/`skiprows` (#11522)\\r\\n\\r\\n**Additional context**\\r\\nWe also dropped `num_rows`/`skiprows` support in the cuDF-python fuzz tests (#11505). My preference is to not include any python fuzz testing changes in the scope of this issue.\\ncreatedAt: 2024-02-26T19:36:33Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 341}),\n",
       " Document(page_content=\": 769\\ntitle: [FEA] Expose memory_resource arguments in pylibcudf\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nAs discussed in #14229, cudf currently relies on fate (working well so far) to ensure there are no use-after-free bugs when calling into, and taking ownership of return values from, libcudf.\\r\\n\\r\\nIn cudf-classic cython wrappers, the memory resource argument is never exposed to cython land. In pylibcudf, it is not currently exposed either.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nAll pylibcudf calls should take a memory resource argument, that is then called with the memory resource cudf considers to be currently active. This needs to go hand-in-hand with #15163, since when both a stream and memory resource are exposed in the public libcudf API, the memory resource is second, so we can't rely on overloaded defaulting for the stream argument.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\nNone.\\ncreatedAt: 2024-02-28T12:48:36Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 342}),\n",
       " Document(page_content=\": 775\\ntitle: [FEA] Provide type stubs for pylibcudf package\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nAs we build out the pylibcudf API, having type stubs for lsp and type-checking integration becomes increasingly useful.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nProvide type stubs (with docstrings) so that lsp/type-checker integration works.\\r\\n\\r\\nWe don't want to replicate docstrings in more than one place, I don't know if the right place for them is the type stub file.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\nHaving the relevant pyx file open in an editor at the same time.\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nThere are a number of half-working auto-generation engines for stubs, but none of them seem to work that well, so we should probably just do this by hand.\\ncreatedAt: 2024-02-29T12:38:48Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 343}),\n",
       " Document(page_content=': 776\\ntitle: [FEA] Implement `closed=` parameter for rolling window\\nbody: The `closed=` parameter to rolling windows is currently unsupported:\\r\\n\\r\\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html\\ncreatedAt: 2024-02-29T15:09:37Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 344}),\n",
       " Document(page_content=\": 777\\ntitle: [FEA] Reduce arrow library dependencies in cudf\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nArrow is in general a difficult dependency to work with, increasing build system complexity and fragility on its own while simultaneously expanding the full dependency tree, which particularly complicates use cases like conda where it leads to meaningful constraints on core system packages like protobuf, abseil, or the AWS SDK. This often hinders developer velocity when builds or CI are broken, but can also have far-reaching impacts when it creates problems with installation or running in specific environments. To prevent this, we would like to reduce or remove our dependence on Arrow libraries entirely.\\r\\n\\r\\nCurrently cudf makes use of Arrow in various ways at different levels of the stack. The primary uses of Arrow boil down to interop with host Arrow data and I/O with specific types of files. This involves interaction at both the Python layer via pyarrow, at the Cython layer (also via pyarrow), and in C++. Both Cython and C++ interactions are particularly problematic because they involve C-level interactions, which sets ABI-level constraints that are significantly tighter than we would like while also significantly complicating build (CMake, Python builds) and packaging (narrow Arrow version support ranges leading to limited support of other packages in the dependency tree). Python interactions are generally less difficult to work around, especially since Python code can be written to dynamically adapt to the pyarrow version.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nWe should look to remove the Arrow dependencies from the various layers of cudf (Java, Python, Cython, C++) to the greatest extent possible, ideally entirely.\\r\\n\\r\\nFor Arrow Array interop code, this can be accomplished by using the Arrow C Data Interface (see #5097), which provides an ABI-stable way to interchange Arrow data without directly using Arrow libraries. To make this even easier, the [nanoarrow](https://github.com/apache/arrow-nanoarrow) library was created to support clients that wish to produce or interpret [Arrow C Data](https://arrow.apache.org/docs/format/CDataInterface.html) and [Arrow C Streams](https://arrow.apache.org/docs/format/CStreamInterface.html) structures, without having to include a dependency on libarrow. We can make use of that (see also #13678 which discusses this in depth). For Python interaction we can use [Arrow's pycapsule interface](https://arrow.apache.org/docs/format/CDataInterface/PyCapsuleInterface.html), which provides a standard way to interchange this data from Python. We can write Cython code leveraging this interface to get Arrow C Data from pyarrow objects without relying directly on pyarrow's Cython, therefore also allowing us to remove this dependency from the Cython layer.\\r\\n\\r\\nFor I/O, the question is a bit trickier. We currently have limited usage of libarrow headers in our C++, and those features largely exist only for Python support for reading Arrow's NativeFiles. We could in principle remove those from the C++ entirely, which would in turn allow us to remove libarrow as a dependency of libcudf. However, libcudf tests would still need libarrow (removing that dependency would require significant additional work). Moreover, those features would still be used by cudf Cython, so we would just be limiting the dependency. However, this could at least allow us to remove Arrow as a build-time dependency for both libcudf and the low-level pylibcudf Python API (#13921) that we are currently developing, which would still be a significant improvement since it would avoid imposing the Arrow dependency on low-level consumers of our APIs at the Python level. Then we could come back to working on replacing the cudf Cython usage.\\r\\n\\r\\nBased on the above, the current plan is the following:\\r\\n1. Remove libarrow as a dependency of libcudf/pylibcudf:\\r\\n    a. Remove the compiled parts of `arrow_io_source.cpp` and make `arrow_io_source.hpp` a standalone header not compiled by anything in libcudf.\\r\\n    b. Rewrite cudf Cython to use the arrow headers directly.\\r\\n    c. Add new interop code that uses the Arrow C Data interface (see #15047)\\r\\n    d. Rewrite Python interop code to call through to the new interfaces\\r\\n    e. Remove the old Cython bindings for interop\\r\\n2. Remove pyarrow Cython linkages from cudf Cython\\r\\n    a. This will require some exploration as to how we can maintain performant file reading. We may have to implement our own minimal version of something like Arrow's NativeFile reader interface.\\r\\n    b. Once the above is done, we'll need to rewrite cuIO C++ to consume this interface and remove the current functions.\\r\\n3. Rewrite libcudf tests to remove libarrow dependence.\\r\\n    a. This will require further investigation into how tests could be rewritten without Arrow. One possibility would be rewriting these tests as pylibcudf tests (see #15133) that use pyarrow instead (only the Python API, no Cython). That would give us access to the same functionality without tying us to linking to the libarrow library\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nCode pointers where libarrow is used in 24.04\\r\\n| Source file | Arrow include | Notes |\\r\\n|---|---|---|\\r\\n| `detail/interop.hpp` | `api.h` | `to_arrow_array` uses many array classes: `arrow::*Array`, `arrow::TimeUnit::*`, `arrow::*Type` also `arrow::MemoryPool`, `arrow::Scalar`, `arrow::Table`. I believe all of these are covered by nanoarrow |\\r\\n| `include/cudf/interop.hpp`  | `api.h` | uses `arrow::Table`, `arrow::MemoryPool`, `arrow::default_memory_pool`, `arrow::Scalar`. I believe all of these are covered by nanoarrow |\\r\\n| `include/cudf/io/arrow_io_source.hpp` | `filesystem/filesystem.h` <br> `io/interfaces.h`  | uses `arrow::io:RandomAccessFile`, `arrow::fs::FileSystem`. See #13698 for the work to refactor `arrow_io_source` out of `datasource` |\\r\\n| `include/cudf/io/arrow_io_source.cpp` | `buffer.h` <br> `filesystem/filesystem.h` <br> `result.h`  | uses `arrow::Buffer`, `arrow::fs::FileSystemFromUri`, |\\r\\n| `src/io/utilities/datasource.cpp` | `io/memory.h` | to be solved by #15189 |\\r\\n\\r\\n| Test file | Arrow include | Notes |\\r\\n|---|---|---|\\r\\n| `tests/interop/arrow_utils.hpp` | `util/bitmap_builders.h` for `arrow::internal::BytesToBits` | Also uses many arrow types such as: `arrow::Array`, `arrow:DictionaryArray`, `arrow::dictionary`, `arrow::Table`,  `arrow::Decimal128Builder`, `arrow::decimal`, `arrow::default_memory_pool`, `arrow::ListArray`, `arrow::list` , `arrow::Buffer`, `arrow::StringBuilder`, `arrow::StringArray` , `arrow::BooleanArray`, `arrow::BooleanBuilder` <br> needs research - can all of these references be migrated to nanoarrow? |\\r\\n| `tests/io/arrow_io_source_test.cpp`  | `io/api.h`  <br> `filesystem/filesystem.h` <br> `filesystem/s3fs.h` <br> `util/config.h` | uses `arrow::fs::FileSystemFromUri`, `arrow::fs::EnsureS3Finalized` |\\r\\n| `tests/io/json_test.cpp` | `io/api.h` | Uses `arrow::io::ReadableFile` as part of a test for reading from an `ArrowFileSource` |\\r\\n| `tests/io/csv_test.cpp` | `io/api.h` | uses `arrow::io::ReadableFile` |\\r\\n| `tests/quantiles/percentile_approx_test.cpp` | `util/tdigest.h` | uses `arrow::internal::TDigest`. presumably we could replace this with our own limited implementation |\\ncreatedAt: 2024-02-29T17:13:26Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 345}),\n",
       " Document(page_content=': 779\\ntitle: [FEA] Add Parquet-to-Arrow dictionary transcoding to the parquet reader\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nUsing a parquet reader option, we could allow the user to specify columns that they would like to receive as dictionary-encoded in the output table. For the specified columns, the Parquet reader would transcode multiple Parquet dictionary-encoded column chunks into an Arrow dictionary-encoded column. \\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n### Part 1 - Confirm correct and efficient dictionary processing in libcudf ###\\r\\n1. Add benchmarks for dictionary `encode` and `decode` with axes including data type, cardinality and row count. Add checks that data is correctly round-tripped through dictionary encoding and decoding.\\r\\n2. Expand unit testing when using dictionary types for reductions, join keys, aggregation keys, aggregation values and other operations. Include string and numeric types as dictionary values. Please note that although libcudf can represent dictionaries of lists (needs to be checked), in Parquet only leaf values can be dictionary-encoded.\\r\\n3. Expand benchmarks for dictionary operations.  As of 24.04 we only have a [dictionary reduction](https://github.com/rapidsai/cudf/blob/branch-24.04/cpp/benchmarks/reduction/dictionary.cpp) benchmarks on `int32` and `float` value types. Benchmarks should include strings data type and axes for varying cardinality and row count.\\r\\n4. Consider signed int for index type. Revisit the int types that can be used as indices. Revisit compatibility differences between libcudf dictionary and Arrow dictionary.\\r\\n5. Consider dropping the sorted key requirement for improved python compatibility. We use natural order of index today and we could add a mapping layer to indexes to stop constraining the indices.\\r\\n\\r\\n### Part 2 - Parquet-to-Arrow dictionary transcoding ###\\r\\n1. Estimate the performance of transcoding Parquet dictionary-encoded column chunks into arrow dictionary-encoded columns. Each Parquet dictionary-encoded column chunk with begins with a dictionary page. To create an Arrow-compliant dictionary column, we need to merge the values from the dictionary page in each column chunk into a single set of values for the arrow dictionary-encoded column. Then to generate the indices data, we need to re-map the indices from each column chunk against the indices in the combined values. \\r\\n2. Please note that [PLAIN_DICTIONARY](https://parquet.apache.org/docs/file-format/data-pages/encodings/#dictionary-encoding-plain_dictionary--2-and-rle_dictionary--8) encoding is deprecated in Parquet 2.0. To support the new default [RLE_DICTIONARY](https://parquet.apache.org/docs/file-format/data-pages/encodings/#dictionary-encoding-plain_dictionary--2-and-rle_dictionary--8), we will need to add a conversion step from Parquet bit-packed indices into Arrow fixed-width indices.\\r\\n3. The parquet format allows different encodings for each column chunk within a column. In the case of dictionaries, the Parquet specification describes cases where PLAIN encoding will be mixed with DICTIONARY encoding, \"If the dictionary grows too big, whether in size or number of distinct values, the encoding will fall back to the plain encoding\". To support this case we would need to add special handling.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nUse `dictionary::encode` to encode target columns immediately after materialization by the Parquet reader. This approach will realize the downstream benefits of dictionary encoding, at the cost of additional work in Parquet decode and dictionary encode. We would benefit from sample queries and profiles that compare materialized column versus dictionary column processing in libcudf workflows. Such profiles could be used to estimate the performance improvement from adding Parquet-to-Arrow dictionary transcoding to the libcudf Parquet reader.\\r\\n\\r\\n### Part 3 - Introduce run-end encoded type in libcudf, and then add Parquet-to-Arrow run-length/run-end transcoding\\r\\nThe Parquet format supports a [run-length encoding / bit-packing hybrid](https://parquet.apache.org/docs/file-format/data-pages/encodings/#run-length-encoding--bit-packing-hybrid-rle--3) and this could be transcoded into a [run-end encoded](https://arrow.apache.org/docs/format/Columnar.html#run-end-encoded-layout) Arrow type. To begin this project, we need to add run-end encoding as a new type to libcudf, introduce decode and encode functions, confirm correctness across libcudf APIs and audit for performance hotspots. A run-end encoded type in libcudf would allow us to support \"constant\" or \"scalar\" columns as requested in #15308. If libcudf supported a run-end encoded type, transcoding into this type from Parquet run-length encoded data would not be a zero-copy operation and would require converting the Parquet bit-packed \"lengths\" to Arrow fixed-width \"ends\".\\ncreatedAt: 2024-03-01T00:10:23Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 346}),\n",
       " Document(page_content=': 781\\ntitle: [BUG] memcheck and racecheck errors in avro reader with `codec=\"deflate\"`\\nbody: **Describe the bug**\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\nimport fastavro\\r\\nimport io\\r\\n\\r\\ntotal_rows = num_rows = rows_per_block = 2048\\r\\ntotal_bytes_per_block = rows_per_block * 7\\r\\n\\r\\nrecords = [{\"0\": f\"{i:0>6}\"} for i in range(total_rows)]\\r\\nschema = {\\r\\n    \"name\": \"root\",\\r\\n    \"type\": \"record\",\\r\\n    \"fields\": [\\r\\n        {\"name\": \"0\", \"type\": \"string\"},\\r\\n    ],\\r\\n}\\r\\n\\r\\nbuffer = io.BytesIO()\\r\\nfastavro.writer(buffer, schema, records, sync_interval=total_bytes_per_block, codec=\"deflate\")\\r\\nbuffer.seek(0)\\r\\n\\r\\nactual_df = cudf.read_avro(buffer, skiprows=0, num_rows=num_rows)\\r\\n```\\r\\n\\r\\nExtracted from `test_avro_reader_fastavro_integration.py::test_avro_reader_multiblock`.\\r\\n\\r\\nNeither\\r\\n```\\r\\ncompute-sanitizer --tool=memcheck python bug.py\\r\\n```\\r\\nnor\\r\\n```\\r\\ncompute-sanitizer --tool=racecheck python bug.py\\r\\n```\\r\\n\\r\\nare clean.\\r\\n\\r\\nExemplar stack traces:\\r\\n\\r\\n<details>\\r\\n<summary> memcheck </summary>\\r\\n\\r\\n```\\r\\n========= COMPUTE-SANITIZER\\r\\n========= Invalid __global__ read of size 1 bytes\\r\\n=========     at 0x2080 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:807:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)\\r\\n=========     by thread (32,0,0) in block (0,0,0)\\r\\n=========     Address 0x7f6078604cb3 is out of bounds\\r\\n=========     and is 2,356 bytes after the nearest allocation at 0x7f6078601600 of size 11,648 bytes\\r\\n=========     Device Frame:/home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1109:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included) [0x6050]\\r\\n=========     Saved host backtrace up to driver entry point at kernel launch time\\r\\n=========     Host Frame: [0x332470]\\r\\n=========                in /usr/lib/x86_64-linux-gnu/libcuda.so.1\\r\\n=========     Host Frame: [0x14fb4]\\r\\n=========                in /home/coder/.conda/envs/rapids/lib/libcudart.so.12\\r\\n=========     Host Frame:cudaLaunchKernel [0x70aae]\\r\\n=========                in /home/coder/.conda/envs/rapids/lib/libcudart.so.12\\r\\n=========     Host Frame:/home/coder/.conda/envs/rapids/targets/x86_64-linux/include/cuda_runtime.h:216:cudaError cudaLaunchKernel<char>(char const*, dim3, dim3, void**, unsigned long, CUstream_st*) [0x12a5605]\\r\\n=========                in /home/coder/cudf/cpp/build/release/libcudf.so\\r\\n=========     Host Frame:/tmp/tmpxft_0003da43_00000000-6_gpuinflate.compute_90.cudafe1.stub.c:1:__device_stub__ZN4cudf2io14inflate_kernelILi128EEEvNS_11device_spanIKNS2_IKhLm18446744073709551615EEELm18446744073709551615EEENS2_IKNS2_IhLm18446744073709551615EEELm18446744073709551615EEENS2_INS0_18compression_resultELm18446744073709551615EEENS0_20gzip_header_includedE(cudf::device_span<cudf::device_span<unsigned char const, 18446744073709551615ul> const, 18446744073709551615ul>&, cudf::device_span<cudf::device_span<unsigned char, 18446744073709551615ul> const, 18446744073709551615ul>&, cudf::device_span<cudf::io::compression_result, 18446744073709551615ul>&, cudf::io::gzip_header_included) [0x12a4de6]\\r\\n=========                in /home/coder/cudf/cpp/build/release/libcudf.so\\r\\n=========     Host Frame:/tmp/tmpxft_0003da43_00000000-6_gpuinflate.compute_90.cudafe1.stub.c:4:void cudf::io::__wrapper__device_stub_inflate_kernel<128>(cudf::device_span<cudf::device_span<unsigned char const, 18446744073709551615ul> const, 18446744073709551615ul>&, cudf::device_span<cudf::device_span<unsigned char, 18446744073709551615ul> const, 18446744073709551615ul>&, cudf::device_span<cudf::io::compression_result, 18446744073709551615ul>&, cudf::io::gzip_header_included&) [0x12a4e1e]\\r\\n=========                in /home/coder/cudf/cpp/build/release/libcudf.so\\r\\n=========     Host Frame:/home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1145:void cudf::io::inflate_kernel<128>(cudf::device_span<cudf::device_span<unsigned char const, 18446744073709551615ul> const, 18446744073709551615ul>, cudf::device_span<cudf::device_span<unsigned char, 18446744073709551615ul> const, 18446744073709551615ul>, cudf::device_span<cudf::io::compression_result, 18446744073709551615ul>, cudf::io::gzip_header_included) [0x12a5598]\\r\\n=========                in /home/coder/cudf/cpp/build/release/libcudf.so\\r\\n=========     Host Frame:/home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1214:cudf::io::gpuinflate(cudf::device_span<cudf::device_span<unsigned char const, 18446744073709551615ul> const, 18446744073709551615ul>, cudf::device_span<cudf::device_span<unsigned char, 18446744073709551615ul> const, 18446744073709551615ul>, cudf::device_span<cudf::io::compression_result, 18446744073709551615ul>, cudf::io::gzip_header_included, rmm::cuda_stream_view) [0x12a49ef]\\r\\n=========                in /home/coder/cudf/cpp/build/release/libcudf.so\\r\\n=========     Host Frame:/home/coder/cudf/cpp/src/io/avro/reader_impl.cu:227:cudf::io::detail::avro::decompress_data(cudf::io::datasource&, cudf::io::detail::avro::metadata&, rmm::device_buffer const&, rmm::cuda_stream_view) [0x123db3c]\\r\\n=========                in /home/coder/cudf/cpp/build/release/libcudf.so\\r\\n=========     Host Frame:/home/coder/cudf/cpp/src/io/avro/reader_impl.cu:528:cudf::io::detail::avro::read_avro(std::unique_ptr<cudf::io::datasource, std::default_delete<cudf::io::datasource> >&&, cudf::io::avro_reader_options const&, rmm::cuda_stream_view, rmm::mr::device_memory_resource*) [0x123fa1f]\\r\\n=========                in /home/coder/cudf/cpp/build/release/libcudf.so\\r\\n=========     Host Frame:cudf::io::read_avro(cudf::io::avro_reader_options const&, rmm::mr::device_memory_resource*) [0x13019ee]\\r\\n=========                in /home/coder/cudf/cpp/build/release/libcudf.so\\r\\n=========     Host Frame: [0x2ba3c]\\r\\n=========                in /home/coder/.conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/avro.cpython-310-x86_64-linux-gnu.so\\r\\n=========     Host Frame: [0x2d29f]\\r\\n=========                in /home/coder/.conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/avro.cpython-310-x86_64-linux-gnu.so\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/ceval.c:4181:_PyEval_EvalFrameDefault [0x139022]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Objects/call.c:342:_PyFunction_Vectorcall [0x1448cc]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/ceval.c:4231:_PyEval_EvalFrameDefault [0x1357dc]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/ceval.c:5067:_PyEval_Vector [0x1d7870]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/ceval.c:1135:PyEval_EvalCode [0x1d77b7]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:1292:run_eval_code_obj [0x207d1a]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:1313:run_mod [0x203123]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:1208:pyrun_file.cold [0x9a4d1]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:456:_PyRun_SimpleFileObject [0x1fd60e]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Python/pythonrun.c:90:_PyRun_AnyFileObject [0x1fd1a4]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Modules/main.c:670:Py_RunMain [0x1fa39b]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame:/usr/local/src/conda/python-3.10.13/Modules/main.c:1091:Py_BytesMain [0x1cae17]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n=========     Host Frame: [0x29d90]\\r\\n=========                in /usr/lib/x86_64-linux-gnu/libc.so.6\\r\\n=========     Host Frame:__libc_start_main [0x29e40]\\r\\n=========                in /usr/lib/x86_64-linux-gnu/libc.so.6\\r\\n=========     Host Frame: [0x1cad11]\\r\\n=========                in /home/coder/.conda/envs/rapids/bin/python\\r\\n========= \\r\\n```\\r\\n\\r\\n</details>\\r\\n\\r\\n<details>\\r\\n<summary> racecheck </summary>\\r\\n\\r\\n```\\r\\n========= COMPUTE-SANITIZER\\r\\n========= Error: Race reported between Read access at 0xe00 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:789:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)\\r\\n=========     and Write access at 0x1930 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:543:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [16132 hazards]\\r\\n=========     and Write access at 0x5660 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:661:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [16156 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Write access at 0xd90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:957:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)\\r\\n=========     and Read access at 0x33c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:590:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1144 hazards]\\r\\n=========     and Read access at 0x5250 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:642:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [6592 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Read access at 0x810 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:954:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)\\r\\n=========     and Write access at 0x59c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:665:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1032 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Read access at 0xa70 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:784:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)\\r\\n=========     and Write access at 0x5930 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:663:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1028 hazards]\\r\\n=========     and Write access at 0x5f90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:671:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [4 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Write access at 0x11c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:793:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)\\r\\n=========     and Read access at 0xf90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:523:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [500 hazards]\\r\\n=========     and Read access at 0x5dd0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:670:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [4 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Write access at 0xf60 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:962:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)\\r\\n=========     and Read access at 0xdb0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:522:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [272 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Write access at 0x5d70 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1104:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included)\\r\\n=========     and Read access at 0x5d0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:951:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int) [8 hazards]\\r\\n========= \\r\\n========= Warning: Race reported between Read access at 0x3b0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:775:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)\\r\\n=========     and Write access at 0x3000 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:826:cudf::io::process_symbols(cudf::io::inflate_state_s *, int) [8 hazards]\\r\\n========= \\r\\n========= Warning: Race reported between Read access at 0x31a0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1068:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included)\\r\\n=========     and Write access at 0x4900 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1081:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included) [4 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Read access at 0xe00 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:789:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)\\r\\n=========     and Write access at 0x1930 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:543:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [16132 hazards]\\r\\n=========     and Write access at 0x5660 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:661:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [16156 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Write access at 0xd90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:957:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)\\r\\n=========     and Read access at 0x33c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:590:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1144 hazards]\\r\\n=========     and Read access at 0x5250 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:642:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [6592 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Read access at 0x810 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:954:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)\\r\\n=========     and Write access at 0x59c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:665:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1032 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Read access at 0xa70 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:784:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)\\r\\n=========     and Write access at 0x5930 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:663:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [1028 hazards]\\r\\n=========     and Write access at 0x5f90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:671:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [4 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Write access at 0x11c0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:793:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)\\r\\n=========     and Read access at 0xf90 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:523:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [500 hazards]\\r\\n=========     and Read access at 0x5dd0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:670:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [4 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Write access at 0xf60 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:962:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int)\\r\\n=========     and Read access at 0xdb0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:522:cudf::io::decode_symbols(cudf::io::inflate_state_s *) [272 hazards]\\r\\n========= \\r\\n========= Error: Race reported between Write access at 0x5d70 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1104:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included)\\r\\n=========     and Read access at 0x5d0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:951:cudf::io::prefetch_warp(volatile cudf::io::inflate_state_s *, int) [8 hazards]\\r\\n========= \\r\\n========= Warning: Race reported between Read access at 0x3b0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:775:cudf::io::process_symbols(cudf::io::inflate_state_s *, int)\\r\\n=========     and Write access at 0x3000 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:826:cudf::io::process_symbols(cudf::io::inflate_state_s *, int) [8 hazards]\\r\\n========= \\r\\n========= Warning: Race reported between Read access at 0x31a0 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1068:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included)\\r\\n=========     and Write access at 0x4900 in /home/coder/cudf/cpp/src/io/comp/gpuinflate.cu:1081:void cudf::io::inflate_kernel<(int)128>(cudf::device_span<const cudf::device_span<const unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<const cudf::device_span<unsigned char, (unsigned long)18446744073709551615>, (unsigned long)18446744073709551615>, cudf::device_span<cudf::io::compression_result, (unsigned long)18446744073709551615>, cudf::io::gzip_header_included) [4 hazards]\\r\\n========= \\r\\n========= RACECHECK SUMMARY: 18 hazards displayed (14 errors, 4 warnings)\\r\\n```\\r\\n\\r\\n</details>\\r\\n\\r\\nI do not know if the racecheck warnings are as problematic as the memcheck ones, `gpuinflate.cu` is littered with `volatile` accesses to the inter-warp communication queue without (AFAICT) any synchronisation, but perhaps there are enough spin-waits that it is \"OK\"?\\ncreatedAt: 2024-03-04T11:42:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 347}),\n",
       " Document(page_content=': 786\\ntitle: [QST] Returning from multi-thread. TypeError: a bytes-like object is required, not \\'dict\\'\\nbody: When running my code with `cudf`, I got `TypeError: a bytes-like object is required, not \\'dict\\'` in the multi-thread returning part.\\r\\n1. Running the code without `-m cudf.pandas` option is *fine*.\\r\\n2. It\\'s *okay* if each multi-thread branch returns merely a scalar.\\r\\n3. Program **CRUSHES** if a multi-thread branch returns a dataframe.\\r\\n\\r\\nThis is the code message:\\r\\n```\\r\\nconcurrent.futures.process._RemoteTraceback:\\r\\n\\'\\'\\'\\r\\nTraceback (most recent call last):\\r\\n  File \"/usr/lib64/python3.9/concurrent/futures/process.py\", line 387, in wait_result_broken_or_wakeup\\r\\n    result_item = result_reader.recv()\\r\\n  File \"/usr/lib64/python3.9/multiprocessing/connection.py\", line 255, in recv\\r\\n    return _ForkingPickler.loads(buf.getbuffer())\\r\\n  File \"/usr/local/lib64/python3.9/site-packages/cudf/pandas/fast_slow_proxy.py\", line 742, in __setstate__\\r\\n    unpickled_wrapped_obj = pickle.loads(state)\\r\\nTypeError: a bytes-like object is required, not \\'dict\\'\\r\\n\\'\\'\\'\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/usr/lib64/python3.9/runpy.py\", line 197, in _run_module_as_main\\r\\n    return _run_code(code, main_globals, None,\\r\\n  File \"/usr/lib64/python3.9/runpy.py\", line 87, in _run_code\\r\\n    exec(code, run_globals)\\r\\n  File \"/usr/local/lib64/python3.9/site-packages/cudf/pandas/__main__.py\", line 91, in <module>\\r\\n    main()\\r\\n  File \"/usr/local/lib64/python3.9/site-packages/cudf/pandas/__main__.py\", line 87, in main\\r\\n    runpy.run_path(args.args[0], run_name=\"__main__\")\\r\\n  File \"/usr/lib64/python3.9/runpy.py\", line 288, in run_path\\r\\n    return _run_module_code(code, init_globals, run_name,\\r\\n  File \"/usr/lib64/python3.9/runpy.py\", line 97, in _run_module_code\\r\\n    _run_code(code, mod_globals, init_globals,\\r\\n  File \"/usr/lib64/python3.9/runpy.py\", line 87, in _run_code\\r\\n    exec(code, run_globals)\\r\\n  File \"clean_header.py\", line 48, in <module>\\r\\n    main()\\r\\n  File \"clean_header.py\", line 45, in main\\r\\n    my_func()\\r\\n  File \"clean_header.py\", line 39, in my_func\\r\\n    for obj in r:\\r\\n  File \"/usr/lib64/python3.9/concurrent/futures/process.py\", line 562, in _chain_from_iterable_of_lists\\r\\n    for element in iterable:\\r\\n  File \"/usr/lib64/python3.9/concurrent/futures/_base.py\", line 609, in result_iterator\\r\\n    yield fs.pop().result()\\r\\n  File \"/usr/lib64/python3.9/concurrent/futures/_base.py\", line 439, in result\\r\\n    return self.__get_result()\\r\\n  File \"/usr/lib64/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\\r\\n    raise self._exception\\r\\nconcurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\\r\\n```\\r\\n\\r\\n\\r\\nHere is my code.\\r\\n```\\r\\nfrom datetime import datetime, timedelta, date\\r\\nimport numpy as np\\r\\nimport pandas as pd\\r\\nfrom random import randint\\r\\nimport swifter\\r\\nimport json, sys, os\\r\\nfrom cudf.pandas.module_accelerator import disable_module_accelerator\\r\\n\\r\\nfrom functools import partial\\r\\nfrom concurrent.futures import ProcessPoolExecutor as Pool\\r\\nfrom multiprocessing import set_start_method\\r\\n\\r\\n\\r\\ndef data_generation(nRows: int):\\r\\n################## unimportant, for reproducing purpose ###################\\r\\n# This function generates the dataframe obj, which has 5 columns, and the data are sorted by WorkingDay and Minute ascendingly\\r\\n    my_df = pd.DataFrame(data={\\'WorkingDay\\': [\\'2019-01-02\\', \\'2018-01-02\\', \\'2019-05-02\\', \\'2020-01-02\\', \\'2021-01-02\\'], \\'name\\': [\\'albert\\', \\'alex\\', \\'alice\\', \\'ben\\', \\'bob\\'], \\'Minute\\': [\\'09:00:00\\', \\'09:20:00\\', \\'08:00:00\\', \\'07:00:00\\', \\'09:30:00\\'], \\'aaa\\': np.random.rand(5), \\'bbb\\': np.    random.rand(5)})\\r\\n    my_df = pd.concat([my_df for i in range(int(nRows/5))], axis=0)\\r\\n    my_df[\\'WorkingDay\\'] = my_df[\\'WorkingDay\\'].map(lambda x: (date(randint(2010,2020), randint(1,4), randint(1,5))).strftime(\\'%Y-%m-%d\\'))\\r\\n    my_df[\\'Minute\\'] = np.random.permutation(my_df[\\'Minute\\'].values)\\r\\n    my_df = my_df.sort_values(by=[\\'WorkingDay\\', \\'Minute\\'], inplace=False).reset_index(drop=True,inplace=False)\\r\\n    return my_df\\r\\n\\r\\ndef my_func_single(branchIndex: int):\\r\\n    my_df = data_generation(20-5*branchIndex)\\r\\n# data generated\\r\\n#############################################################################\\r\\n    # The multi-thread return is problematic\\r\\n#############################################################################\\r\\n    #return my_df.shape[0]\\r\\n    return my_df\\r\\n\\r\\n\\r\\ndef my_func():\\r\\n    set_start_method(\\'spawn\\')\\r\\n    my_func_partial = partial(my_func_single)\\r\\n    with Pool(max_workers=2) as pool:\\r\\n        r = pool.map(my_func_partial, range(4))\\r\\n    for obj in r:\\r\\n        #print(\\'df has length: {}.\\'.format(obj))\\r\\n        print(\\'df has length: {}.\\'.format(obj.shape[0]))\\r\\n\\r\\ndef main():\\r\\n    print(\\'-------------------- program starts -----------------------\\')\\r\\n    my_func()\\r\\n\\r\\nif __name__ == \\'__main__\\':\\r\\n    main()\\r\\n```\\r\\n\\r\\nRelevant dependencies:\\r\\n```\\r\\ncuda-python==12.4.0\\r\\ncudf-cu12==24.4.0a516\\r\\ncugraph-cu12==24.4.0a69\\r\\ncuml-cu12==24.4.0a37\\r\\ndask==2024.1.1\\r\\ndask-cuda==24.4.0a11\\r\\ndask-cudf-cu12==24.4.0a516\\r\\npylibcugraph-cu12==24.4.0a69\\r\\npylibraft-cu12==24.4.0a70\\r\\n```\\ncreatedAt: 2024-03-07T07:19:32Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 348}),\n",
       " Document(page_content=\": 790\\ntitle: [FEA] Add shared memory hash map for low-cardinality aggregations\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nlibcudf aggregations show lower throughput when data cardinality is less than ~1000 distinct values. This is due to serializing atomic operations over a small range of global memory. We received some projections that use hash maps that begin in shared memory and then spill to global if they exceed a certain size. The projections indicate 2-10x speedup for cardinalities below 100.\\r\\n\\r\\n![image](https://github.com/rapidsai/cudf/assets/12725111/f28d02c5-f107-4c4a-b44d-687094a0a7a8)\\r\\n(Aggregation throughput data was collected for groupby max over 20M rows of int64 key and int64 payload, based on benchmarks introduced in https://github.com/rapidsai/cudf/pull/15134 and using A100 hardware. Projections were provided as speedup versus cardinality data and were applied to the A100 measured throughput to yield projected throughput.)\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nWe could provide an implementation that uses shared memory hash maps when cardinality is low. [Shared memory as storage](https://github.com/NVIDIA/cuCollections/blob/dev/examples/static_set/shared_memory_example.cu) is supported in [cuCollections](https://github.com/NVIDIA/cuCollections), so we could leverage this option to offer a higher throughput code path when cardinality is low.\\r\\n\\r\\nAs far as the API design, we could add an optional `cardinality` parameter to the `aggregate` API. When [hyperloglog](https://github.com/NVIDIA/cuCollections/pull/429) cardinality estimates are available in cuCollections, we may want to support cardinality estimates as well. Some open questions include:\\r\\n* What is the throughput difference between hyperloglog and count distinct? We expect the memory footprint of hyperloglog to be much lower, but I don't believe throughput has had controlled measurements.\\r\\n* If we accept cardinality estimates, what happens if the cardinality is underestimated and the shared memory hash map fails? \\r\\n* Does it make sense for column objects to track cardinality, or should the application layer track cardinality?\\r\\n\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nWe aren't sure how common low cardinality aggregation keys are in customer workloads. Are there cases where cardinality will be known ahead of time, or will it always need to be computed or estimated before triggering the aggregation? Could we instrument NDS to log cardinality and row count before each aggregation node?\\r\\n\\r\\n**Additional context**\\r\\nWe could also consider using shared memory hash maps for low-cardinality distinct-key joins. This optimization is mentioned in https://github.com/rapidsai/cudf/issues/14948.\\ncreatedAt: 2024-03-08T22:50:19Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 349}),\n",
       " Document(page_content=\": 791\\ntitle: DataFrame.pivot_table not supported in Cudf\\nbody: **Missing Pandas Feature Request**\\r\\nA clear and concise summary of the pandas function(s) you'd like to be able run with cuDF.\\r\\nDataFrame.pivot_table not supported in Cudf\\r\\n\\r\\n**Profiler Output**\\r\\nIf you used the profiler in pandas accelerator mode, please provide the full output of your profiling report.\\r\\n```\\r\\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\\r\\n┃ Function                  ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃\\r\\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\\r\\n│ DataFrame.pivot_table     │ 0          │ 0.000       │ 0.000       │ 1          │ 0.076       │ 0.076       │\\r\\n│ DataFrame.reset_index     │ 1          │ 0.003       │ 0.003       │ 0          │ 0.000       │ 0.000       │\\r\\n│ merge                     │ 1          │ 1.164       │ 1.164       │ 0          │ 0.000       │ 0.000       │\\r\\n│ DataFrame.drop_duplicates │ 1          │ 0.170       │ 0.170       │ 0          │ 0.000       │ 0.000       │\\r\\n│ DataFrame                 │ 1          │ 0.000       │ 0.000       │ 0          │ 0.000       │ 0.000       │\\r\\n│ DataFrame.__repr__        │ 1          │ 0.539       │ 0.539       │ 0          │ 0.000       │ 0.000       │\\r\\n└───────────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\\r\\n```\\r\\nNot all pandas operations ran on the GPU. The following functions required CPU fallback:\\r\\n\\r\\n- DataFrame.pivot_table\\r\\n\\r\\n**Additional context**\\r\\nAdd any other context, code examples, or references to existing implementations about the feature request here.\\ncreatedAt: 2024-03-09T07:00:31Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 350}),\n",
       " Document(page_content=': 793\\ntitle: [FEA] Implement `__hash__` and `__eq__` for pylibcudf Aggregation objecs.\\nbody: libcudf `Aggregation` objects have implementations of hash and equality. We should expose these in pylibcudf so we can put the aggregation objects into dictionaries correctly.\\ncreatedAt: 2024-03-11T18:27:02Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 351}),\n",
       " Document(page_content=': 797\\ntitle: [FEA] Accelerate conversion from `arrow::StringViewType` to `arrow::StringType` in libcudf interop\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThe Arrow 15 specification includes a definition of \"[arrow::StringViewType](https://arrow.apache.org/docs/cpp/api/datatype.html#classarrow_1_1_string_view_type)\" - an alternate representation of the \"[arrow::StringType](https://arrow.apache.org/docs/cpp/api/datatype.html#classarrow_1_1_string_type)\". You may find \"String view\" also referred to as [Umbra string](https://www.cidrdb.org/cidr2020/papers/p29-neumann-cidr20.pdf) or prefix string. \\r\\n\\r\\nA string view consists of two columns:\\r\\n1. A column of 16 byte fixed-width elements. First 4 bytes contain the string size\\r\\n* If size < 12, then the string is stored inline in the remaining 12 bytes (short string optimization)\\r\\n* If size > 12, then the string is stored separately in the second column. Remaining 12 bytes are 8 bytes for pointer to the string + 4 bytes for the first 4 chars of the string\\r\\n2. A column of characters storing the suffix strings\\r\\n\\r\\nString view type enables some performance optimizations:\\r\\n* ability to slice strings (e.g. `left(10)`) in place without a copy\\r\\n* ability to replace with smaller strings (e.g. `replace(\"aa\", \"a\")`) in place without a copy\\r\\n* inlined strings can be written in any order and without knowing the column size\\r\\n* better memory access patterns for the first 4 bytes (e.g. `startswith(\"a\")`)\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nLet\\'s add interop support for string view in `from_arrow` with CUDA C++ code to accept string views and convert them to libcudf strings columns. We may also want to add string view compatibility to `to_arrow`, so we can hand off libcudf strings columns to host libraries that expect string views. We should be able to write CUDA C++ code to efficiently transform `arrow::StringViewType` buffers in to `arrow::StringType` buffers.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nForce libcudf users to convert their string views into strings on the host before passing the data to the device.\\r\\n\\r\\n**Additional context**\\r\\nVelox supports a string view type ([ref1](https://facebookincubator.github.io/velox/develop/vectors.html#flat-vectors-scalar-types), [ref2](https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/)), [Polars has switched](https://pola.rs/posts/polars-string-type/) to a string view representation, and [DuckDB supports](https://15721.courses.cs.cmu.edu/spring2023/slides/22-duckdb.pdf) string view.\\r\\n\\r\\nWe may choose to investigate using string views in libcudf at some point, but for the foreseeable future string view refactoring will be lower priority than [supporting large strings](https://github.com/rapidsai/cudf/issues/13733) and [improving performance with long strings](https://github.com/rapidsai/cudf/issues/13048).\\ncreatedAt: 2024-03-13T23:40:41Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 352}),\n",
       " Document(page_content=\": 804\\ntitle: [BUG] Empty DataFrame object `columns` property doesn't match pandas for `data=None` or `data={}`.\\nbody: **Describe the bug**\\r\\n\\r\\nWhen constructing an empty dataframe where one does not explicitly specify the column names, pandas produces a `RangeIndex` for the `.columns` property.\\r\\n\\r\\nIn contrast, cudf produces an `Index(dtype=object)` if `data={}` or `data=None`.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\n```python\\r\\nimport cudf\\r\\nimport pandas as pd\\r\\n\\r\\nfor data in [{}, None]:\\r\\n    columns = cudf.DataFrame(data=data).columns\\r\\n    expect = pd.DataFrame(data=data).columns\\r\\n\\r\\n    assert type(columns) == type(expect)\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\nMatching pandas. This works if `data` is an empty list-like object (e.g. `data=[]`) so it's probably just another condition to handle.\\ncreatedAt: 2024-03-22T11:45:37Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 353}),\n",
       " Document(page_content=': 805\\ntitle: [QST] How can the performance of chunked reading in Parquet be improved?\\nbody: **What is your question?**\\r\\n![image](https://github.com/rapidsai/cudf/assets/36735914/08a2c7ce-226d-4230-b2a3-ddecb0c5b92c)\\r\\n\\r\\nI am working on a project to improve the performance of reading parquet files using the libcudf library. As shown in the Nsight Systems screenshot, the decompress_page_data event consumes the most time in the read_chunk operation, taking 46.877ms and 41.987ms out of 123.117ms, respectively. I am trying to reduce this decompression time but have found limited material, documentation, or GitHub issues on the subject. Do you have any suggestions? I am also considering using stream technology to accelerate the process but am unsure where to begin. Attached is my code for your reference. Thank you.\\r\\n[parquet_chuncked.txt](https://github.com/rapidsai/cudf/files/14726563/parquet_chuncked.txt)\\ncreatedAt: 2024-03-22T17:44:35Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Guangyu Meng\\ncompany: University of Notre Dame', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 354}),\n",
       " Document(page_content=': 807\\ntitle: [FEA] pandas DatetimeIndex.indexer_between_time\\nbody: I watched @shwina\\'s GTC talk (https://register.nvidia.com/flow/nvidia/gtcs24/attendeeportaldigital/page/sessioncatalog/session/1695219773174001AmnA thanks Ashwin I really enjoyed it!)\\r\\n\\r\\n**Is your feature request related to a problem? Please describe.**\\r\\nNo. I just noticed there wasn\\'t an issue for [`DatetimeIndex.indexer_between_time`](https://github.com/pandas-dev/pandas/blob/main/pandas/core/indexes/datetimes.py#L764). I also enjoyed the user experience that `%%cudf.pandas.profile` points users to raise issues to highlight pandas API that falls back to CPU (https://github.com/rapidsai/cudf/blob/branch-24.06/python/cudf/cudf/pandas/profiler.py#L300).\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n```\\r\\nimport pandas as pd\\r\\npd.date_range(\"2023-01-01\", \"2023-01-02\", freq=\"1h\").indexer_between_time(\"09:00\", \"16:00\")\\r\\nimport cudf\\r\\ncudf.date_range(\"2023-01-01\", \"2023-01-02\", freq=\"1h\").indexer_between_time(\"09:00\", \"16:00\")\\r\\n```\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nThere may be a cudf work around in the meantime for a user who needs indexer_between_time that could be captured at https://docs.rapids.ai/api/cudf/stable/cudf_pandas/\\r\\n\\r\\n**Additional context**\\r\\n~~Could create a new issue template with the \"pandas\" label (https://github.com/rapidsai/cudf/issues?q=is%3Aopen+is%3Aissue+label%3Apandas) to be used at https://github.com/rapidsai/cudf/blob/branch-24.06/python/cudf/cudf/pandas/profiler.py#L297~~ fixed a bug at https://github.com/rapidsai/cudf/pull/15381\\ncreatedAt: 2024-03-23T03:05:32Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ray Bell\\ncompany: DTN', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 355}),\n",
       " Document(page_content=\": 808\\ntitle: [BUG] In cudf.pandas mode, `.array` or `.values` don't actually return views to the underlying data\\nbody: This seems a fundamental issue with the way cuDF is architected and possibly a `wontfix`, but it's important enough that we should consider solutions - and at the very least document the behaviour.\\r\\n\\r\\nIn pandas, `Series.values` (or `Series.array`) gives a reference to the underlying data as some kind of array-like object. Mutations to this object are reflected in the original `Series`:\\r\\n\\r\\n```python\\r\\n\\r\\nIn [1]: import pandas as pd\\r\\n\\r\\nIn [2]: s = pd.Series([1, 2, pd.NA])\\r\\n\\r\\nIn [3]: a = s.array\\r\\n\\r\\nIn [4]: a\\r\\nOut[4]:\\r\\n<PandasArray>\\r\\n[1, 2, <NA>]\\r\\nLength: 3, dtype: object\\r\\n\\r\\nIn [5]: a[:2] = 3\\r\\n\\r\\nIn [6]: a\\r\\nOut[6]:\\r\\n<PandasArray>\\r\\n[3, 3, <NA>]\\r\\nLength: 3, dtype: object\\r\\n\\r\\nIn [7]: s\\r\\nOut[7]:\\r\\n0       3\\r\\n1       3\\r\\n2    <NA>\\r\\ndtype: object\\r\\n```\\r\\n\\r\\nThis doesn't always work when cudf.pandas is enabled:\\r\\n\\r\\n```\\r\\n\\r\\nIn [1]: %load_ext cudf.pandas\\r\\n\\r\\nIn [2]: import pandas as pd\\r\\n\\r\\nIn [3]: s = pd.Series([1, 2, pd.NA])\\r\\n\\r\\nIn [4]: a = s.array  # this executes on CPU (because we don't support `.array` for null ints in cuDF)\\r\\n\\r\\nIn [5]: a\\r\\nOut[5]:\\r\\n<PandasArray>\\r\\n[1.0, 2.0, nan]\\r\\nLength: 3, dtype: float64\\r\\n\\r\\nIn [6]: s.max()  # this moves `s` from CPU to GPU, but `a` is still on CPU\\r\\nOut[6]: 2.0\\r\\n\\r\\nIn [7]: a[:2] = 3  # this mutates `a`, but since `s` now lives on the GPU it doesn't see that mutation\\r\\n\\r\\nIn [8]: s  # `s` is unchanged\\r\\nOut[8]:\\r\\n0    1.0\\r\\n1    2.0\\r\\n2    NaN\\r\\ndtype: float64\\r\\n\\r\\nIn [9]: a  # `a` is changed\\r\\nOut[9]:\\r\\n<PandasArray>\\r\\n[3.0, 3.0, nan]\\r\\nLength: 3, dtype: float64\\r\\n```\\ncreatedAt: 2024-03-25T17:20:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 356}),\n",
       " Document(page_content=\": 809\\ntitle: [BUG] Array proxy in cudf.pandas don't include special casing for `ndarray.flat`\\nbody: The `arr.flat` attribute should return a `flatiter` object, but they currently return a generator. Unlike `flatiter`, generator objects cannot be written to:\\r\\n\\r\\n```python\\r\\nIn [1]: %load_ext cudf.pandas\\r\\n\\r\\nIn [2]: import pandas as pd\\r\\n\\r\\nIn [3]: s = pd.Series([1,2 , 3])\\r\\n\\r\\nIn [4]: arr = s.values\\r\\n\\r\\nIn [5]: arr.flat\\r\\nOut[5]: <generator object _maybe_wrap_result.<locals>.<genexpr> at 0x7f70a82cc310>\\r\\n```\\r\\n\\r\\nIn contrast:\\r\\n\\r\\n```python\\r\\nimport numpy as np\\r\\n\\r\\narr = np.arange(5)\\r\\nprint(type(arr.flat))\\r\\narr.flat[:3] = 100\\r\\nprint(arr)\\r\\n<class 'numpy.flatiter'>\\r\\n[100 100 100   3   4]\\r\\n```\\r\\n\\r\\n```python\\r\\nimport cupy as cp\\r\\narr = cp.arange(5)\\r\\nprint(type(arr.flat))\\r\\narr.flat[:3] = 100\\r\\nprint(arr)\\r\\n<class 'cupy._indexing.iterate.flatiter'>\\r\\n[100 100 100   3   4]\\r\\n```\\ncreatedAt: 2024-03-25T19:06:52Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 357}),\n",
       " Document(page_content=\": 810\\ntitle: [FEA] Report the number of rows read per file in libcudf's Parquet reader\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nI wish libcudf's parquet reader reports the number of rows read per file.\\r\\n\\r\\nConsider the following example, \\r\\n```c++\\r\\n  std::vector<std::string> file_paths;  // defined elsewhere\\r\\n  std::vector<std::string> column_names;  // defined elsewhere\\r\\n\\r\\n  auto source  = cudf::io::source_info(file_paths);\\r\\n  auto options = cudf::io::parquet_reader_options::builder(source);\\r\\n  options.columns(column_names);\\r\\n  auto result = cudf::io::read_parquet(options);\\r\\n```\\r\\n\\r\\nHere, `result` is of type [`table_with_metadata`](https://github.com/rapidsai/cudf/blob/branch-24.02/cpp/include/cudf/io/types.hpp#L249), but the metadata doesn't contain the number of rows read from each file. I wish libcudf can add this functionality.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nReport the number of rows read from each file in `table_with_metadata`.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\nI have tried `cudf::io::read_parquet_metadata` out-of-band, like the following snippet.\\r\\n\\r\\n```c++\\r\\n  std::vector<cudf::size_type> rows_per_file;\\r\\n  rows_per_file.reserve(file_paths.size());\\r\\n\\r\\n  for (auto const& file_path : file_paths) {\\r\\n    auto file_source = cudf::io::source_info(file_path);\\r\\n    auto metadata    = cudf::io::read_parquet_metadata(file_source);\\r\\n    rows_per_file.push_back(metadata.num_rows());\\r\\n  }\\r\\n  result.rows_per_file = std::move(rows_per_file);\\r\\n```\\r\\n\\r\\nBut this has nontrivial overhead in my use case. I believe we can get it for free as part of the Parquet reading process, since the Parquet reader needs to decode the file footers anyway.\\ncreatedAt: 2024-03-26T06:34:07Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 358}),\n",
       " Document(page_content=\": 811\\ntitle: [DOC] update CONTRIBUTING.md to mention devcontainers?\\nbody: **Suggested fix for documentation**\\r\\nI learnt about the https://github.com/rapidsai/devcontainers from @dantegd's GTC talk (https://register.nvidia.com/flow/nvidia/gtcs24/attendeeportaldigital/page/sessioncatalog/session/1697766189600001T2p3) wonder if the build instructions in https://github.com/rapidsai/cudf/blob/branch-24.06/CONTRIBUTING.md could be updated to point to the devcontainers and how to use them.\\ncreatedAt: 2024-03-26T21:13:37Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ray Bell\\ncompany: DTN\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 359}),\n",
       " Document(page_content=': 819\\ntitle: [QST]Custom class with cuDF\\nbody: ```\\r\\nnumba.core.errors.TypingError: Failed in cuda mode pipeline (step: nopython frontend)\\r\\nUntyped global name \\'Master10DH\\': Cannot determine Numba type of <class \\'abc.ABCMeta\\'>\\r\\n\\r\\nFile \"ik_GPU.py\", line 9:\\r\\ndef ik(row):\\r\\n    robot = Master10DH()\\r\\n```\\r\\nHello, I encountered the following error, how can I fix it?\\ncreatedAt: 2024-04-03T11:26:31Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 360}),\n",
       " Document(page_content=': 820\\ntitle: [BUG] Unpickling objects with `pd.read_pickle()` doesn\\'t work with cudf.pandas enabled\\nbody: **Describe the bug**\\r\\nWhen `cudf.pandas` is enabled, we can pickle and unpickle objects using `pickle.dump/load` or `pickle.dumps/loads`. But if we choose to unpickle with `pd.read_pickle`, things go awry. Here\\'s a minimal reproducer:\\r\\n\\r\\n```python\\r\\nimport pandas as pd\\r\\nfrom io import BytesIO\\r\\nimport pickle\\r\\n\\r\\npdf = pd.DataFrame({\\'a\\': [1.0, 2.0, None, 3.0]})\\r\\n\\r\\nwith open(\"pickled_pdf.pkl\", \"wb\") as f:\\r\\n    pickle.dump(pdf, f)\\r\\n\\r\\nwith open(\"pickled_pdf.pkl\", \"rb\") as f:\\r\\n    df = pd.read_pickle(f)\\r\\n\\r\\nprint(df)\\r\\n```\\r\\n\\r\\n<details>\\r\\n\\r\\n```\\r\\nIn [1]: %load_ext cudf.pandas\\r\\n\\r\\nIn [2]: import pandas as pd\\r\\n\\r\\nIn [3]: from io import BytesIO\\r\\n   ...: import pickle\\r\\n   ...: \\r\\n   ...: pdf = pd.DataFrame({\\'a\\': [1.0, 2.0, None, 3.0]})\\r\\n   ...: \\r\\n   ...: with open(\"pickled_pdf.pkl\", \"wb\") as f:\\r\\n   ...:     pickle.dump(pdf, f)\\r\\n   ...: \\r\\n   ...: with open(\"pickled_pdf.pkl\", \"rb\") as f:\\r\\n   ...:     df = pd.read_pickle(f)\\r\\n   ...: \\r\\n   ...: print(df)\\r\\n---------------------------------------------------------------------------\\r\\nAttributeError                            Traceback (most recent call last)\\r\\nFile ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:888, in _fast_slow_function_call(func, *args, **kwargs)\\r\\n    883 with nvtx.annotate(\\r\\n    884     \"EXECUTE_FAST\",\\r\\n    885     color=_CUDF_PANDAS_NVTX_COLORS[\"EXECUTE_FAST\"],\\r\\n    886     domain=\"cudf_pandas\",\\r\\n    887 ):\\r\\n--> 888     fast_args, fast_kwargs = _fast_arg(args), _fast_arg(kwargs)\\r\\n    889     result = func(*fast_args, **fast_kwargs)\\r\\n\\r\\nFile ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:1007, in _fast_arg(arg)\\r\\n   1006 seen: Set[int] = set()\\r\\n-> 1007 return _transform_arg(arg, \"_fsproxy_fast\", seen)\\r\\n\\r\\nFile ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:934, in _transform_arg(arg, attribute_name, seen)\\r\\n    932 if type(arg) is tuple:\\r\\n    933     # Must come first to avoid infinite recursion\\r\\n--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\\r\\n    935 elif hasattr(arg, \"__getnewargs_ex__\"):\\r\\n    936     # Partial implementation of to reconstruct with\\r\\n    937     # transformed pieces\\r\\n    938     # This handles scipy._lib._bunch._make_tuple_bunch\\r\\n\\r\\nFile ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:934, in <genexpr>(.0)\\r\\n    932 if type(arg) is tuple:\\r\\n    933     # Must come first to avoid infinite recursion\\r\\n--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\\r\\n    935 elif hasattr(arg, \"__getnewargs_ex__\"):\\r\\n    936     # Partial implementation of to reconstruct with\\r\\n    937     # transformed pieces\\r\\n    938     # This handles scipy._lib._bunch._make_tuple_bunch\\r\\n\\r\\nFile ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:917, in _transform_arg(arg, attribute_name, seen)\\r\\n    916 if isinstance(arg, (_FastSlowProxy, _FastSlowProxyMeta, _FunctionProxy)):\\r\\n--> 917     typ = getattr(arg, attribute_name)\\r\\n    918     if typ is _Unusable:\\r\\n\\r\\nFile ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:553, in _FastSlowProxy.__getattr__(self, name)\\r\\n    550 if name.startswith(\"_fsproxy\"):\\r\\n    551     # an AttributeError was raised when trying to evaluate\\r\\n    552     # an internal attribute, we just need to propagate this\\r\\n--> 553     _raise_attribute_error(self.__class__.__name__, name)\\r\\n    554 if name in {\\r\\n    555     \"_ipython_canary_method_should_not_exist_\",\\r\\n    556     \"_ipython_display_\",\\r\\n   (...)\\r\\n    568     # This is somewhat delicate to the order in which IPython\\r\\n    569     # implements special display fallbacks.\\r\\n\\r\\nFile ~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py:392, in _raise_attribute_error(obj, name)\\r\\n    387 \"\"\"\\r\\n    388 Raise an AttributeError with a message that is consistent with\\r\\n    389 the error raised by Python for a non-existent attribute on a\\r\\n    390 proxy object.\\r\\n    391 \"\"\"\\r\\n--> 392 raise AttributeError(f\"\\'{obj}\\' object has no attribute \\'{name}\\'\")\\r\\n\\r\\nAttributeError: \\'function\\' object has no attribute \\'_fsproxy_fast\\'\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nAttributeError                            Traceback (most recent call last)\\r\\n<ipython-input-3-deda8b8b446c> in ?()\\r\\n      8 \\r\\n      9 with open(\"pickled_pdf.pkl\", \"rb\") as f:\\r\\n     10     df = pd.read_pickle(f)\\r\\n     11 \\r\\n---> 12 print(df)\\r\\n\\r\\n~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py in ?(self, *args, **kwargs)\\r\\n    836     def __call__(self, *args, **kwargs) -> Any:\\r\\n--> 837         result, _ = _fast_slow_function_call(\\r\\n    838             # We cannot directly call self here because we need it to be\\r\\n    839             # converted into either the fast or slow object (by\\r\\n    840             # _fast_slow_function_call) to avoid infinite recursion.\\r\\n\\r\\n~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py in ?(func, *args, **kwargs)\\r\\n    898             domain=\"cudf_pandas\",\\r\\n    899         ):\\r\\n    900             slow_args, slow_kwargs = _slow_arg(args), _slow_arg(kwargs)\\r\\n    901             with disable_module_accelerator():\\r\\n--> 902                 result = func(*slow_args, **slow_kwargs)\\r\\n    903     return _maybe_wrap_result(result, func, *args, **kwargs), fast\\r\\n\\r\\n~/mroeschke-cudf/python/cudf/cudf/pandas/fast_slow_proxy.py in ?(fn, args, kwargs)\\r\\n     29 def call_operator(fn, args, kwargs):\\r\\n---> 30     return fn(*args, **kwargs)\\r\\n\\r\\n~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/core/frame.py in ?(self)\\r\\n   1199             self.info(buf=buf)\\r\\n   1200             return buf.getvalue()\\r\\n   1201 \\r\\n   1202         repr_params = fmt.get_dataframe_repr_params()\\r\\n-> 1203         return self.to_string(**repr_params)\\r\\n\\r\\n~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/util/_decorators.py in ?(*args, **kwargs)\\r\\n    329                     msg.format(arguments=_format_argument_list(allow_args)),\\r\\n    330                     FutureWarning,\\r\\n    331                     stacklevel=find_stack_level(),\\r\\n    332                 )\\r\\n--> 333             return func(*args, **kwargs)\\r\\n\\r\\n~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/core/frame.py in ?(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)\\r\\n   1361         \"\"\"\\r\\n   1362         from pandas import option_context\\r\\n   1363 \\r\\n   1364         with option_context(\"display.max_colwidth\", max_colwidth):\\r\\n-> 1365             formatter = fmt.DataFrameFormatter(\\r\\n   1366                 self,\\r\\n   1367                 columns=columns,\\r\\n   1368                 col_space=col_space,\\r\\n\\r\\n~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/io/formats/format.py in ?(self, frame, columns, col_space, header, index, na_rep, formatters, justify, float_format, sparsify, index_names, max_rows, min_rows, max_cols, show_dimensions, decimal, bold_rows, escape)\\r\\n    443         bold_rows: bool = False,\\r\\n    444         escape: bool = True,\\r\\n    445     ) -> None:\\r\\n    446         self.frame = frame\\r\\n--> 447         self.columns = self._initialize_columns(columns)\\r\\n    448         self.col_space = self._initialize_colspace(col_space)\\r\\n    449         self.header = header\\r\\n    450         self.index = index\\r\\n\\r\\n~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/io/formats/format.py in ?(self, columns)\\r\\n    552             cols = ensure_index(columns)\\r\\n    553             self.frame = self.frame[cols]\\r\\n    554             return cols\\r\\n    555         else:\\r\\n--> 556             return self.frame.columns\\r\\n\\r\\n~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/core/generic.py in ?(self, name)\\r\\n   6292             and name not in self._accessors\\r\\n   6293             and self._info_axis._can_hold_identifiers_and_holds_name(name)\\r\\n   6294         ):\\r\\n   6295             return self[name]\\r\\n-> 6296         return object.__getattribute__(self, name)\\r\\n\\r\\nproperties.pyx in ?()\\r\\n---> 65 \\'Could not get source, probably due dynamically evaluated source code.\\'\\r\\n\\r\\n~/miniforge3/envs/cudf-dev/lib/python3.11/site-packages/pandas/core/generic.py in ?(self, name)\\r\\n   6292             and name not in self._accessors\\r\\n   6293             and self._info_axis._can_hold_identifiers_and_holds_name(name)\\r\\n   6294         ):\\r\\n   6295             return self[name]\\r\\n-> 6296         return object.__getattribute__(self, name)\\r\\n\\r\\nAttributeError: \\'DataFrame\\' object has no attribute \\'_mgr\\'\\r\\n```\\r\\n</details>\\r\\n \\r\\nWe can (and do) control what happens when objects are pickled and unpickled via the pickle protocol (`pickle.dump` and `pickle.load`) [here](https://github.com/rapidsai/cudf/blob/5192b608eeed4bda9317c657253c3a5630aa4c5d/python/cudf/cudf/pandas/fast_slow_proxy.py#L722-L741). \\r\\n\\r\\nAnd pandas\\' `read_pickle` does call the \"regular\" [`pickle.load` function](https://github.com/pandas-dev/pandas/blob/05ab1af783f6590b8a2d9fbea6d39793e88dfb04/pandas/io/pickle.py#L203). \\r\\n\\r\\nSo what\\'s going on?\\r\\n\\r\\nWhen we call `pd.read_pickle` in `cudf.pandas` mode, that will first call `cudf.read_pickle` (doesn\\'t exist) and then fall back to the real `pandas.read_pickle`. Importantly, during fallback, we [disable ourselves](https://github.com/rapidsai/cudf/blob/5192b608eeed4bda9317c657253c3a5630aa4c5d/python/cudf/cudf/pandas/fast_slow_proxy.py#L901). Which means that our special pickle protocol handling doesn\\'t kick in and that messes everything up. \\r\\n\\r\\n### Solutions\\r\\n\\r\\nThe only solution I could think of is we vendor `pandas.read_pickle`, so we can keep ourselves enabled when it is called.\\ncreatedAt: 2024-04-03T20:24:39Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 361}),\n",
       " Document(page_content=': 821\\ntitle: [BUG] Incorrect proxying of functions with no matching fast counterpart in cudf.pandas\\nbody: **Describe the bug**\\r\\n\\r\\nFunctions in the pandas source tree which do not have a matching counterpart in the cudf source tree are proxied with a `FunctionProxy` object whose `_fsproxy_fast` attribute is an `_Unusable` object.\\r\\n\\r\\nUnfortunately, although accessing an `_Unusuable` object in a fast-slow chained method call fails, it does so too late and already provokes slow-to-fast and fast-to-slow copies. This ends up breaking the link between the fast and slow types inside a proxied object.\\r\\n\\r\\nThis raises its head particularly in the pandas test suite where there are functions that are used to parameterise over (for example) `iloc` vs `loc` indexing, like `pandas._testing.iloc`.\\r\\n\\r\\nTo see the problem consider the following:\\r\\n\\r\\n```python\\r\\nimport cudf.pandas\\r\\ncudf.pandas.install()\\r\\n\\r\\nimport pandas as pd\\r\\n\\r\\ns = pd.Series(range(10))\\r\\ns._fsproxy_state # => FAST\\r\\n# pd._testing.iloc has no matching fast counterpart, so this function-call will provoke\\r\\n# a fast to slow copy\\r\\nindexer = pd._testing.iloc(s)\\r\\ns._fsproxy_state # => SLOW\\r\\n# We want setitem to keep the object as  slow,\\r\\n# but this is a `_FastSlowAttribute` so it provokes (if it can) a slow-to-fast copy\\r\\ngetattr(indexer, \"__setitem__\")\\r\\ns._fsproxy_state # => FAST\\r\\n# Now we are in an inconsistent state.\\r\\n```\\r\\n\\r\\nIn `_transform_arg` we have a carveout early exit if the fast or slow attribute we\\'re asking for is  `_Unusable`, but not if it is an instance of `_Unusable`.\\r\\n\\r\\nThis patch helps a bit:\\r\\n```patch\\r\\ndiff --git a/python/cudf/cudf/pandas/fast_slow_proxy.py b/python/cudf/cudf/pandas/fast_slow_proxy.py\\r\\nindex e811ba1351..9d07d236bb 100644\\r\\n--- a/python/cudf/cudf/pandas/fast_slow_proxy.py\\r\\n+++ b/python/cudf/cudf/pandas/fast_slow_proxy.py\\r\\n@@ -915,7 +915,7 @@ def _transform_arg(\\r\\n \\r\\n     if isinstance(arg, (_FastSlowProxy, _FastSlowProxyMeta, _FunctionProxy)):\\r\\n         typ = getattr(arg, attribute_name)\\r\\n-        if typ is _Unusable:\\r\\n+        if typ is _Unusable or isinstance(typ, _Unusable):\\r\\n             raise Exception(\"Cannot transform _Unusable\")\\r\\n         return typ\\r\\n     elif isinstance(arg, types.ModuleType) and attribute_name in arg.__dict__:\\r\\n```\\r\\n\\r\\nBut is observed to cause the pandas test suite run to take significantly longer (indicating, probably, more fast-to-slow transfers than necessary).\\r\\n\\r\\nNote that this change works for `pd._testing.iloc` but _not_ `pd._testing.setitem` which is just the identity function, since wrapping the identity function produces a new function which is _not_ the identity.\\ncreatedAt: 2024-04-08T09:44:10Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 362}),\n",
       " Document(page_content=\": 822\\ntitle: [BUG] cudf.read_parquet takes too much time(due to cudaMallocHost overhead etc.) to load the zstd compressed parquet files with few thousands to millions of rows\\nbody: **Describe the bug**\\r\\nPerformance improvement proposal for cudf parquet file reading efficiency.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\n```python\\r\\nimport pandas as pd\\r\\n\\r\\ndf = pd.DataFrame({'jnac': [None] * 1000})\\r\\ndf.to_parquet('/dev/shm/jnac.parquet', compression='ZSTD')\\r\\n\\r\\n# cd to /dev/shm now\\r\\n\\r\\nimport cudf\\r\\nimport pandas\\r\\nimport pyarrow.parquet\\r\\n\\r\\nimport time\\r\\n\\r\\n# not accurate timing, while the diff is so obvious which do not require more accurate timing temporrally\\r\\n\\r\\nts = time.time(); tb = cudf.read_parquet('/dev/shm/jnac.parquet'); te = time.time()\\r\\ntime.sleep(1)\\r\\nts = time.time(); tb = cudf.read_parquet('/dev/shm/jnac.parquet'); te = time.time()\\r\\nprint(te - ts)\\r\\n\\r\\nts = time.time(); tb = pandas.read_parquet('/dev/shm/jnac.parquet'); te = time.time()\\r\\ntime.sleep(1)\\r\\nts = time.time(); tb = pandas.read_parquet('/dev/shm/jnac.parquet'); te = time.time()\\r\\nprint(te - ts)\\r\\n\\r\\nts = time.time(); tb = pyarrow.parquet.read_table('/dev/shm/jnac.parquet'); te = time.time()\\r\\ntime.sleep(1)\\r\\nts = time.time(); tb = pyarrow.parquet.read_table('/dev/shm/jnac.parquet'); te = time.time()\\r\\nprint(te - ts)\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\n\\r\\n```python\\r\\n>>> ts = time.time(); tb = cudf.read_parquet('jnac.parquet'); te = time.time()\\r\\n>>> print(te - ts)\\r\\n0.006829023361206055\\r\\n>>>\\r\\n>>> ts = time.time(); tb = pandas.read_parquet('jnac.parquet'); te = time.time()\\r\\n>>> time.sleep(1)\\r\\n\\r\\n>>> ts = time.time(); tb = pandas.read_parquet('jnac.parquet'); te = time.time()\\r\\n>>> print(te - ts)\\r\\n0.003950357437133789\\r\\n>>>\\r\\n>>> ts = time.time(); tb = pyarrow.parquet.read_table('jnac.parquet'); te = time.time()\\r\\n>>> time.sleep(1)\\r\\n>>> ts = time.time(); tb = pyarrow.parquet.read_table('jnac.parquet'); te = time.time()\\r\\n>>> print(te - ts)\\r\\n0.0013420581817626953\\r\\n>>>\\r\\n\\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\ninternal T4 node, py3.9, cudf 24.02.02\\r\\n\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nIt just takes too much time to process <NA> entries, especially for cudf when num rows is just 1K(similar latency cost for 10M rows NA though).\\ncreatedAt: 2024-04-08T10:05:14Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: 黄(Huáng)瓒(Zàn)\\ncompany: Georgia Institute of Technology\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 363}),\n",
       " Document(page_content=\": 823\\ntitle: [FEA] cudf.pandas profiler should show time taken by other, non-pandas functions to run.\\nbody: This is a bit different from https://github.com/rapidsai/cudf/issues/14499.\\r\\n\\r\\nThe `cudf.pandas` profiler only shows the time it takes for pandas functions and methods to run; but it doesn't report the time it takes for other functions and methods. It would be useful if the total time reported by the profiler matched up roughly with the actual total wall clock time of the program.\\r\\n\\r\\nFor example:\\r\\n\\r\\n```\\r\\nIn [1]: %load_ext cudf.pandas\\r\\n\\r\\nIn [2]: import pandas as pd\\r\\n\\r\\nIn [3]: import time\\r\\n\\r\\nIn [4]: def fun1():\\r\\n   ...:     time.sleep(5)\\r\\n   ...:\\r\\n\\r\\nIn [5]: def fun2():\\r\\n   ...:     s = pd.Series([1, 2, 3])\\r\\n   ...:     s.max()\\r\\n   ...:     s.min()\\r\\n   ...:\\r\\n\\r\\nIn [6]: %%cudf.pandas.profile\\r\\n   ...: fun1()\\r\\n   ...: fun2()\\r\\n   ...:\\r\\n   ...:\\r\\n\\r\\n                                   Total time elapsed: 6.345 seconds\\r\\n                                 3 GPU function calls in 1.090 seconds\\r\\n                                 0 CPU function calls in 0.000 seconds\\r\\n\\r\\n                                                 Stats\\r\\n\\r\\n┏━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\\r\\n┃ Function   ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃\\r\\n┡━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\\r\\n│ Series     │ 1          │ 1.088       │ 1.088       │ 0          │ 0.000       │ 0.000       │\\r\\n│ Series.max │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │\\r\\n│ Series.min │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │\\r\\n└────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\\r\\n``` \\r\\n\\r\\nIt would be great if the result was something like:\\r\\n\\r\\n```\\r\\n                                   Total time elapsed: 6.345 seconds\\r\\n                                 3 GPU function calls in 1.090 seconds\\r\\n                                 0 CPU function calls in 0.000 seconds\\r\\n\\r\\n                                                 Stats\\r\\n\\r\\n┏━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\\r\\n┃ Function   ┃ GPU ncalls ┃ GPU cumtime ┃ GPU percall ┃ CPU ncalls ┃ CPU cumtime ┃ CPU percall ┃\\r\\n┡━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\\r\\n│ Series     │ 1          │ 1.088       │ 1.088       │ 0          │ 0.000       │ 0.000       │\\r\\n│ Series.max │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │\\r\\n│ Series.min │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │\\r\\n│ Others     │ -          │ -           │ -           │ -          │ 5.000       │ 5.000       │\\r\\n└────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\\r\\n```\\ncreatedAt: 2024-04-08T13:17:03Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Ashwin Srinath\\ncompany: Voltron Data\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 364}),\n",
       " Document(page_content=\": 825\\ntitle: [FEA] Improve occupancy during hash table build\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\ncuco insert kernel has poor occupancy due to high register usage during hash table build operation executed by cuDF. If I disable some of the code paths for complex types(commenting out dict, string, list, struct, decimal) in https://github.com/rapidsai/cudf/blob/434df44d9fe1c94e8047bcc37266ae663eae8a8d/cpp/include/cudf/utilities/type_dispatcher.hpp#L456 the type dispatcher, then the register usage per thread drops from 75 -> 46 and leads to a significant occupancy bump. It seems that the insert kernel has to pay the cost of high register usage even for simpler types since the compiler has to account for all code paths.\\r\\n\\r\\nI did some experiments by disabling different subsets of types, list has types I disable -> register count for insert kernel\\r\\n- decimal -> 72\\r\\n- struct -> 73\\r\\n- list -> 73\\r\\n- string -> 73\\r\\n- dict -> 68\\r\\n- struct, list -> 64\\r\\n- list, decimal, struct -> 63\\r\\n- dict, string, list, struct -> 58\\r\\n- string, dict, struct, list, decimal -> 46\\r\\n\\r\\nHere is the speedup I see on mixed semi join kernel by improving occupancy for int32 keys obtained by disabling complex types\\r\\n![image](https://github.com/rapidsai/cudf/assets/23545205/553e66bc-0fce-4954-868b-cd8a7163eedf)\\r\\n\\r\\n**Describe the solution you'd like**\\r\\nImprove occupancy by disabling codepaths for complex types.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n1. Add more template params to the hasher/comparator which allow us to separate codepaths for complex types and simpler types, or \\r\\n2. Add JIT compilation to only consider the types necessary for hasher/comparator for a row\\r\\n\\r\\n**Additional context**\\r\\nAdd any other context, code examples, or references to existing implementations about the feature request here.\\ncreatedAt: 2024-04-10T15:57:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Tanmay Gujar\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 365}),\n",
       " Document(page_content=': 827\\ntitle: [FEA] Allow groupby scan aggregations to return listified results\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nTo match the way scan aggregation results in groupby operations are returned in pandas, libcudf returns scan-based aggregations in the same shape as the input table (these are then optionally reordered to mimic pandas order).\\r\\n\\r\\nFor the cudf-polars executor, it would be useful to also have a mode where the result of a scan aggregation is collected, group-wise, into a list column. This would mean that both scan-like and reduction-like groupby aggregations always produce an output table with a number of rows equal to the number of unique group keys.\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\n\\r\\nFor scan-only aggregations, this is relatively easy to achieve by taking the sorted grouped result and calling `make_lists_column` with the group offsets. When mixing scan and hash-based aggregations it is tricker (since those would spit things out in a different order and would then need a join). Ideally one the scan aggs have a \"collect as list\" option, then one would be able to do scan and reduce- aggs in the same call on the sorted table.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\n\\r\\nI can post-process the result (and then do a join if I have any hash-based aggs in addition).\\r\\n\\r\\n**Additional context**\\r\\n\\r\\nRight now, polars guarantees that although the order of groups in the result is implementation dependent, within a group, the rows show up in original dataframe order. I think this is also guaranteed by libcudf, since the sort-by-key before the aggregations is stable.\\ncreatedAt: 2024-04-16T11:18:38Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 366}),\n",
       " Document(page_content=\": 829\\ntitle: [FEA] Allow cudf::thread_pool to restrict the number of threads available.\\nbody: I have a benchmarking use case where it would be nice to be able to use a single thread pool across multiple benchmarks for ease of viewing in nsys.  Imagine a benchmark where one of your testing axes is the number of threads used to split up the work. Say, 2, 4 and 8 threads.  The way you would do this today is you would create a new `thread_pool` in each instance of the benchmark with the appropriate number of threads.  The problem with this is that each thread gets it's own line of data in nsys.  So you end up with 14 total threads that you have to expand and hunt down.  This gets worse if you have other axes.  You can very quickly get up into 64 or more threads, which is a bit of a headache to sort through.\\r\\n\\r\\nInstead, it would be nice if we could create a thread pool and temporarily restrict the number of threads it would use for newly submitted jobs.   So what your benchmark could do is create a single global thread pool (say, 8 threads above). And then just set the thread count restriction in each benchmark.   So you would have a nice clean timeline with a tractable number of threads in nsys.\\r\\n\\r\\nAlternately, a way to sub-allocate  out of an existing pool (temporarily funding one thread_pool with the threads from another)  would work as well.\\ncreatedAt: 2024-04-19T19:35:34Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 367}),\n",
       " Document(page_content=': 834\\ntitle: [FEA] Improve performance of strings matching in libcudf\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\nThe issue documents a few performance ideas for the libcudf regular expression engine ([code pointer](https://github.com/rapidsai/cudf/tree/branch-24.06/cpp/src/strings/regex)) and strings APIs. In particular, these performance ideas came from investigation of multi-string pattern matching commonly used for IP addresses in DPUs. The DPU use case involves checking dozens (?) of string patterns against millions (?) of input strings, and most matches are negative.\\r\\n\\r\\n| Idea | API scope | Initial scoping |\\r\\n|---|---|---|\\r\\n| Avoid regex and instead replace with strings contains or strings startswith/endswith whenever possible. | regex utilities | For now we encourage libcudf applications to add pattern inspection and avoid calling the regex engine if that is an important optimization in their use case. We may consider upstreaming a tool similar to the [regex parsing approach in Spark-RAPIDS](https://github.com/NVIDIA/spark-rapids/pull/10715) at some point. |\\r\\n| Add a non-regex multi-string match function to the strings API, as a way to fused multiple string matches into a single kernel  |  strings | We have an investigation of this idea in #15536. Performance analysis is in progress |\\r\\n| Use a shared memory Shift-Or approach to speed up strings contains.  | strings | Initial scoping suggests this method could deliver 3x throughput (~1000 GB/s on A100). However this optimization will have a larger memory footprint (256 bytes/thread) that could create other issues when integrated with libcudf. ([link to algorithm demonstration](https://www.educative.io/answers/shift-or-string-matching-algorithm)) |\\r\\n| Fuse sequences of regex pattern characters into a single \"regex literal\" token | regex | After initial scoping, multi-character pattern tokens are unlikely to be compatible with the existing regex engine. Significant refactoring would be required and the benefits are uncertain. |\\r\\n| ASCII-only strings `contains` | strings | There may be benefit to an ASCII-only implementation of string matching for some use cases. The potential performance benefit has not yet been evaluated. | \\r\\n| ASCII-only `match_re` | strings | There may be benefit to an ASCII-only implementation of regex pattern matching for some use cases. The potential performance benefit has not yet been evaluated. |\\r\\n| [Sitaridi et al 2016](https://dl.acm.org/doi/pdf/10.1007/s00778-015-0409-y) suggests to use Knuth–Morris–Pratt (KMP) for string pattern matching | strings | Stores a partial match table that improves GPU L2 cache utilization |\\r\\n| add aligned strings for vector loading | strings | add padding in the byte array, add sizes child column. always use aligned strings by default?  |\\r\\n| prefix strings | strings | see Arrow (TBD) |  \\r\\n\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nTBD\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nTBD\\r\\n\\r\\n**Additional context**\\r\\nRegex performance ideas have come out of collaboration between SM-based and DPU-based regular expression processing. For more information about DPU-based regex, please see the [NVIDIA Bluefield-2](https://docs.nvidia.com/networking/display/bluefielddpuosv385/regex+acceleration) docs.\\ncreatedAt: 2024-04-29T18:29:30Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Gregory Kimball\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 368}),\n",
       " Document(page_content=': 839\\ntitle: [BUG] Enabling cudf.pandas leads to exception when using a Numpy array\\nbody: **Describe the bug**\\r\\nWhen `cudf.pandas` is enabled then passing a Numpy array to `ExponentialSmoothing` from `statsmodels.tsa.holtwinters` involves the pandas accelerator (odd no?) and leads to an exception.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\n\\r\\n```python\\r\\nimport cudf.pandas\\r\\ncudf.pandas.install()\\r\\nimport numpy as np\\r\\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\\r\\nairpassengers = [\\r\\n    112,\\r\\n    118,\\r\\n    132,\\r\\n    129,\\r\\n    121,\\r\\n    135,\\r\\n    148,\\r\\n    148,\\r\\n    136,\\r\\n    119,\\r\\n    104,\\r\\n    118,\\r\\n    115,\\r\\n    126,\\r\\n    141,\\r\\n    135,\\r\\n    125,\\r\\n    149,\\r\\n    170,\\r\\n    170,\\r\\n    158,\\r\\n    133,\\r\\n    114,\\r\\n    140,\\r\\n    145,\\r\\n    150,\\r\\n    178,\\r\\n    163,\\r\\n    172,\\r\\n    178,\\r\\n    199,\\r\\n    199,\\r\\n    184,\\r\\n    162,\\r\\n    146,\\r\\n    166,\\r\\n    171,\\r\\n    180,\\r\\n    193,\\r\\n    181,\\r\\n    183,\\r\\n    218,\\r\\n    230,\\r\\n    242,\\r\\n    209,\\r\\n    191,\\r\\n    172,\\r\\n    194,\\r\\n    196,\\r\\n    196,\\r\\n    236,\\r\\n    235,\\r\\n    229,\\r\\n    243,\\r\\n    264,\\r\\n    272,\\r\\n    237,\\r\\n    211,\\r\\n    180,\\r\\n    201,\\r\\n    204,\\r\\n    188,\\r\\n    235,\\r\\n    227,\\r\\n    234,\\r\\n    264,\\r\\n    302,\\r\\n    293,\\r\\n    259,\\r\\n    229,\\r\\n    203,\\r\\n    229,\\r\\n    242,\\r\\n    233,\\r\\n    267,\\r\\n    269,\\r\\n    270,\\r\\n    315,\\r\\n    364,\\r\\n    347,\\r\\n    312,\\r\\n    274,\\r\\n    237,\\r\\n    278,\\r\\n    284,\\r\\n    277,\\r\\n    317,\\r\\n    313,\\r\\n    318,\\r\\n    374,\\r\\n    413,\\r\\n    405,\\r\\n    355,\\r\\n    306,\\r\\n    271,\\r\\n    306,\\r\\n    315,\\r\\n    301,\\r\\n    356,\\r\\n    348,\\r\\n    355,\\r\\n    422,\\r\\n    465,\\r\\n    467,\\r\\n    404,\\r\\n    347,\\r\\n    305,\\r\\n    336,\\r\\n    340,\\r\\n    318,\\r\\n    362,\\r\\n    348,\\r\\n    363,\\r\\n    435,\\r\\n    491,\\r\\n    505,\\r\\n    404,\\r\\n    359,\\r\\n    310,\\r\\n    337,\\r\\n]\\r\\nairpassengers = np.asarray(airpassengers, dtype=np.float64)\\r\\n\\r\\n# this line leads to the traceback\\r\\nExponentialSmoothing(airpassengers, initialization_method=\\'heuristic\\', seasonal=\\'additive\\', seasonal_periods=12)\\r\\n```\\r\\n\\r\\n<details>\\r\\n<summary>Full traceback</summary>\\r\\n\\r\\n---------------------------------------------------------------------------\\r\\nNotImplementedError                       Traceback (most recent call last)\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:888, in _fast_slow_function_call(func, *args, **kwargs)\\r\\n    883 with nvtx.annotate(\\r\\n    884     \"EXECUTE_FAST\",\\r\\n    885     color=_CUDF_PANDAS_NVTX_COLORS[\"EXECUTE_FAST\"],\\r\\n    886     domain=\"cudf_pandas\",\\r\\n    887 ):\\r\\n--> 888     fast_args, fast_kwargs = _fast_arg(args), _fast_arg(kwargs)\\r\\n    889     result = func(*fast_args, **fast_kwargs)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1007, in _fast_arg(arg)\\r\\n   1006 seen: Set[int] = set()\\r\\n-> 1007 return _transform_arg(arg, \"_fsproxy_fast\", seen)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:934, in _transform_arg(arg, attribute_name, seen)\\r\\n    932 if type(arg) is tuple:\\r\\n    933     # Must come first to avoid infinite recursion\\r\\n--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\\r\\n    935 elif hasattr(arg, \"__getnewargs_ex__\"):\\r\\n    936     # Partial implementation of to reconstruct with\\r\\n    937     # transformed pieces\\r\\n    938     # This handles scipy._lib._bunch._make_tuple_bunch\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:934, in <genexpr>(.0)\\r\\n    932 if type(arg) is tuple:\\r\\n    933     # Must come first to avoid infinite recursion\\r\\n--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\\r\\n    935 elif hasattr(arg, \"__getnewargs_ex__\"):\\r\\n    936     # Partial implementation of to reconstruct with\\r\\n    937     # transformed pieces\\r\\n    938     # This handles scipy._lib._bunch._make_tuple_bunch\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:917, in _transform_arg(arg, attribute_name, seen)\\r\\n    916 if isinstance(arg, (_FastSlowProxy, _FastSlowProxyMeta, _FunctionProxy)):\\r\\n--> 917     typ = getattr(arg, attribute_name)\\r\\n    918     if typ is _Unusable:\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:528, in _FastSlowProxy._fsproxy_fast(self)\\r\\n    523 \"\"\"\\r\\n    524 Returns the wrapped object. If the wrapped object is of \"slow\"\\r\\n    525 type, replaces it with the corresponding \"fast\" object before\\r\\n    526 returning it.\\r\\n    527 \"\"\"\\r\\n--> 528 self._fsproxy_wrapped = self._fsproxy_slow_to_fast()\\r\\n    529 return self._fsproxy_wrapped\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n    115 libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 116 result = func(*args, **kwargs)\\r\\n    117 libnvtx_pop_range(self.domain.handle)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:786, in _IntermediateProxy._fsproxy_slow_to_fast(self)\\r\\n    785 func, args, kwargs = self._method_chain\\r\\n--> 786 args, kwargs = _fast_arg(args), _fast_arg(kwargs)\\r\\n    787 return func(*args, **kwargs)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1007, in _fast_arg(arg)\\r\\n   1006 seen: Set[int] = set()\\r\\n-> 1007 return _transform_arg(arg, \"_fsproxy_fast\", seen)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:934, in _transform_arg(arg, attribute_name, seen)\\r\\n    932 if type(arg) is tuple:\\r\\n    933     # Must come first to avoid infinite recursion\\r\\n--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\\r\\n    935 elif hasattr(arg, \"__getnewargs_ex__\"):\\r\\n    936     # Partial implementation of to reconstruct with\\r\\n    937     # transformed pieces\\r\\n    938     # This handles scipy._lib._bunch._make_tuple_bunch\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:934, in <genexpr>(.0)\\r\\n    932 if type(arg) is tuple:\\r\\n    933     # Must come first to avoid infinite recursion\\r\\n--> 934     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\\r\\n    935 elif hasattr(arg, \"__getnewargs_ex__\"):\\r\\n    936     # Partial implementation of to reconstruct with\\r\\n    937     # transformed pieces\\r\\n    938     # This handles scipy._lib._bunch._make_tuple_bunch\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:917, in _transform_arg(arg, attribute_name, seen)\\r\\n    916 if isinstance(arg, (_FastSlowProxy, _FastSlowProxyMeta, _FunctionProxy)):\\r\\n--> 917     typ = getattr(arg, attribute_name)\\r\\n    918     if typ is _Unusable:\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:528, in _FastSlowProxy._fsproxy_fast(self)\\r\\n    523 \"\"\"\\r\\n    524 Returns the wrapped object. If the wrapped object is of \"slow\"\\r\\n    525 type, replaces it with the corresponding \"fast\" object before\\r\\n    526 returning it.\\r\\n    527 \"\"\"\\r\\n--> 528 self._fsproxy_wrapped = self._fsproxy_slow_to_fast()\\r\\n    529 return self._fsproxy_wrapped\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n    115 libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 116 result = func(*args, **kwargs)\\r\\n    117 libnvtx_pop_range(self.domain.handle)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:787, in _IntermediateProxy._fsproxy_slow_to_fast(self)\\r\\n    786 args, kwargs = _fast_arg(args), _fast_arg(kwargs)\\r\\n--> 787 return func(*args, **kwargs)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:30, in call_operator(fn, args, kwargs)\\r\\n     29 def call_operator(fn, args, kwargs):\\r\\n---> 30     return fn(*args, **kwargs)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:76, in _Unusable.__call__(self, *args, **kwds)\\r\\n     75 def __call__(self, *args: Any, **kwds: Any) -> Any:\\r\\n---> 76     raise NotImplementedError(\\r\\n     77         \"Fast implementation not available. \"\\r\\n     78         \"Falling back to the slow implementation\"\\r\\n     79     )\\r\\n\\r\\nNotImplementedError: Fast implementation not available. Falling back to the slow implementation\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nTypeError                                 Traceback (most recent call last)\\r\\nCell In[1], line 130\\r\\n    127 airpassengers = np.asarray(airpassengers, dtype=np.float64)\\r\\n    129 # this line leads to the traceback\\r\\n--> 130 ExponentialSmoothing(airpassengers, initialization_method=\\'heuristic\\', seasonal=\\'additive\\', seasonal_periods=12)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:837, in _CallableProxyMixin.__call__(self, *args, **kwargs)\\r\\n    836 def __call__(self, *args, **kwargs) -> Any:\\r\\n--> 837     result, _ = _fast_slow_function_call(\\r\\n    838         # We cannot directly call self here because we need it to be\\r\\n    839         # converted into either the fast or slow object (by\\r\\n    840         # _fast_slow_function_call) to avoid infinite recursion.\\r\\n    841         # TODO: When Python 3.11 is the minimum supported Python version\\r\\n    842         # this can use operator.call\\r\\n    843         call_operator,\\r\\n    844         self,\\r\\n    845         args,\\r\\n    846         kwargs,\\r\\n    847     )\\r\\n    848     return result\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:902, in _fast_slow_function_call(func, *args, **kwargs)\\r\\n    900         slow_args, slow_kwargs = _slow_arg(args), _slow_arg(kwargs)\\r\\n    901         with disable_module_accelerator():\\r\\n--> 902             result = func(*slow_args, **slow_kwargs)\\r\\n    903 return _maybe_wrap_result(result, func, *args, **kwargs), fast\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:30, in call_operator(fn, args, kwargs)\\r\\n     29 def call_operator(fn, args, kwargs):\\r\\n---> 30     return fn(*args, **kwargs)\\r\\n\\r\\nFile /nvme/1/thead/miniconda/envs/cuml-dev-24.06/lib/python3.11/site-packages/pandas/util/_decorators.py:213, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)\\r\\n    211         raise TypeError(msg)\\r\\n    212     kwargs[new_arg_name] = new_arg_value\\r\\n--> 213 return func(*args, **kwargs)\\r\\n\\r\\nTypeError: ExponentialSmoothing.__init__() missing 1 required positional argument: \\'endog\\'\\r\\n\\r\\n</details>\\r\\n\\r\\n**Expected behavior**\\r\\nNo error\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\nSetup cuml dev environment using a conda env\\r\\n\\r\\n**Environment details**\\r\\nPlease run and paste the output of the `cudf/print_env.sh` script here, to gather any other relevant environment details\\r\\n\\r\\n<details><summary>Click here to see environment details</summary><pre>\\r\\n\\r\\n     **git***\\r\\n     Not inside a git repository\\r\\n\\r\\n     ***OS Information***\\r\\n     DISTRIB_ID=Ubuntu\\r\\n     DISTRIB_RELEASE=22.04\\r\\n     DISTRIB_CODENAME=jammy\\r\\n     DISTRIB_DESCRIPTION=\"Ubuntu 22.04.2 LTS\"\\r\\n     PRETTY_NAME=\"Ubuntu 22.04.2 LTS\"\\r\\n     NAME=\"Ubuntu\"\\r\\n     VERSION_ID=\"22.04\"\\r\\n     VERSION=\"22.04.2 LTS (Jammy Jellyfish)\"\\r\\n     VERSION_CODENAME=jammy\\r\\n     ID=ubuntu\\r\\n     ID_LIKE=debian\\r\\n     HOME_URL=\"https://www.ubuntu.com/\"\\r\\n     SUPPORT_URL=\"https://help.ubuntu.com/\"\\r\\n     BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\\r\\n     PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\\r\\n     UBUNTU_CODENAME=jammy\\r\\n     Linux dt05 5.15.0-94-generic #104-Ubuntu SMP Tue Jan 9 15:25:40 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux\\r\\n\\r\\n     ***GPU Information***\\r\\n     Thu May  2 08:41:30 2024\\r\\n     +---------------------------------------------------------------------------------------+\\r\\n     | NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\\r\\n     |-----------------------------------------+----------------------+----------------------+\\r\\n     | GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\\r\\n     | Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\\r\\n     |                                         |                      |               MIG M. |\\r\\n     |=========================================+======================+======================|\\r\\n     |   0  Tesla T4                       On  | 00000000:3B:00.0 Off |                    0 |\\r\\n     | N/A   36C    P8              15W /  70W |      2MiB / 15360MiB |      0%      Default |\\r\\n     |                                         |                      |                  N/A |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   1  Tesla T4                       On  | 00000000:5E:00.0 Off |                    0 |\\r\\n     | N/A   35C    P8              10W /  70W |      2MiB / 15360MiB |      0%      Default |\\r\\n     |                                         |                      |                  N/A |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   2  Tesla T4                       On  | 00000000:AF:00.0 Off |                    0 |\\r\\n     | N/A   29C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |\\r\\n     |                                         |                      |                  N/A |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n     |   3  Tesla T4                       On  | 00000000:D8:00.0 Off |                    0 |\\r\\n     | N/A   29C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |\\r\\n     |                                         |                      |                  N/A |\\r\\n     +-----------------------------------------+----------------------+----------------------+\\r\\n\\r\\n     +---------------------------------------------------------------------------------------+\\r\\n     | Processes:                                                                            |\\r\\n     |  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\\r\\n     |        ID   ID                                                             Usage      |\\r\\n     |=======================================================================================|\\r\\n     |  No running processes found                                                           |\\r\\n     +---------------------------------------------------------------------------------------+\\r\\n\\r\\n     ***CPU***\\r\\n     Architecture:                       x86_64\\r\\n     CPU op-mode(s):                     32-bit, 64-bit\\r\\n     Address sizes:                      46 bits physical, 48 bits virtual\\r\\n     Byte Order:                         Little Endian\\r\\n     CPU(s):                             64\\r\\n     On-line CPU(s) list:                0-63\\r\\n     Vendor ID:                          GenuineIntel\\r\\n     Model name:                         Intel(R) Xeon(R) Gold 6130 CPU @ 2.10GHz\\r\\n     CPU family:                         6\\r\\n     Model:                              85\\r\\n     Thread(s) per core:                 2\\r\\n     Core(s) per socket:                 16\\r\\n     Socket(s):                          2\\r\\n     Stepping:                           4\\r\\n     CPU max MHz:                        3700.0000\\r\\n     CPU min MHz:                        1000.0000\\r\\n     BogoMIPS:                           4200.00\\r\\n     Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts pku ospke md_clear flush_l1d arch_capabilities\\r\\n     Virtualization:                     VT-x\\r\\n     L1d cache:                          1 MiB (32 instances)\\r\\n     L1i cache:                          1 MiB (32 instances)\\r\\n     L2 cache:                           32 MiB (32 instances)\\r\\n     L3 cache:                           44 MiB (2 instances)\\r\\n     NUMA node(s):                       2\\r\\n     NUMA node0 CPU(s):                  0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62\\r\\n     NUMA node1 CPU(s):                  1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63\\r\\n     Vulnerability Gather data sampling: Mitigation; Microcode\\r\\n     Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled\\r\\n     Vulnerability L1tf:                 Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable\\r\\n     Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT vulnerable\\r\\n     Vulnerability Meltdown:             Mitigation; PTI\\r\\n     Vulnerability Mmio stale data:      Mitigation; Clear CPU buffers; SMT vulnerable\\r\\n     Vulnerability Retbleed:             Mitigation; IBRS\\r\\n     Vulnerability Spec rstack overflow: Not affected\\r\\n     Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp\\r\\n     Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\r\\n     Vulnerability Spectre v2:           Mitigation; IBRS, IBPB conditional, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected\\r\\n     Vulnerability Srbds:                Not affected\\r\\n     Vulnerability Tsx async abort:      Mitigation; Clear CPU buffers; SMT vulnerable\\r\\n\\r\\n     ***CMake***\\r\\n     /nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin/cmake\\r\\n     cmake version 3.29.2\\r\\n\\r\\n     CMake suite maintained and supported by Kitware (kitware.com/cmake).\\r\\n\\r\\n     ***g++***\\r\\n     /nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin/g++\\r\\n     g++ (conda-forge gcc 11.4.0-6) 11.4.0\\r\\n     Copyright (C) 2021 Free Software Foundation, Inc.\\r\\n     This is free software; see the source for copying conditions.  There is NO\\r\\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\r\\n\\r\\n\\r\\n     ***nvcc***\\r\\n     /nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin/nvcc\\r\\n     nvcc: NVIDIA (R) Cuda compiler driver\\r\\n     Copyright (c) 2005-2023 NVIDIA Corporation\\r\\n     Built on Tue_Aug_15_22:02:13_PDT_2023\\r\\n     Cuda compilation tools, release 12.2, V12.2.140\\r\\n     Build cuda_12.2.r12.2/compiler.33191640_0\\r\\n\\r\\n     ***Python***\\r\\n     /nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin/python\\r\\n     Python 3.11.9\\r\\n\\r\\n     ***Environment Variables***\\r\\n     PATH                            : /home/nfs/thead/.local/bin:/home/nfs/thead/.local/bin:/nvme/1/thead/miniconda/envs/cuml-dev-24.06/bin:/nvme/1/thead/miniconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\\r\\n     LD_LIBRARY_PATH                 :\\r\\n     NUMBAPRO_NVVM                   :\\r\\n     NUMBAPRO_LIBDEVICE              :\\r\\n     CONDA_PREFIX                    : /nvme/1/thead/miniconda/envs/cuml-dev-24.06\\r\\n     PYTHON_PATH                     :\\r\\n\\r\\n     ***conda packages***\\r\\n     /nvme/1/thead/miniconda/condabin/conda\\r\\n     # packages in environment at /nvme/1/thead/miniconda/envs/cuml-dev-24.06:\\r\\n     #\\r\\n     # Name                    Version                   Build  Channel\\r\\n     _libgcc_mutex             0.1                 conda_forge    conda-forge\\r\\n     _openmp_mutex             4.5                       2_gnu    conda-forge\\r\\n     _sysroot_linux-64_curr_repodata_hack 3                   h69a702a_14    conda-forge\\r\\n     accessible-pygments       0.0.4              pyhd8ed1ab_0    conda-forge\\r\\n     alabaster                 0.7.16             pyhd8ed1ab_0    conda-forge\\r\\n     asttokens                 2.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     atk-1.0                   2.38.0               h04ea711_2    conda-forge\\r\\n     attrs                     23.2.0             pyh71513ae_0    conda-forge\\r\\n     aws-c-auth                0.7.18               he0b1f16_0    conda-forge\\r\\n     aws-c-cal                 0.6.11               heb1d5e4_0    conda-forge\\r\\n     aws-c-common              0.9.15               hd590300_0    conda-forge\\r\\n     aws-c-compression         0.2.18               hce8ee76_3    conda-forge\\r\\n     aws-c-event-stream        0.4.2                h01f5eca_8    conda-forge\\r\\n     aws-c-http                0.8.1               hdb68c23_10    conda-forge\\r\\n     aws-c-io                  0.14.7               hbfbeace_6    conda-forge\\r\\n     aws-c-mqtt                0.10.4               h50844eb_0    conda-forge\\r\\n     aws-c-s3                  0.5.7                h6be9164_2    conda-forge\\r\\n     aws-c-sdkutils            0.1.15               hce8ee76_3    conda-forge\\r\\n     aws-checksums             0.1.18               hce8ee76_3    conda-forge\\r\\n     aws-crt-cpp               0.26.8               h2150271_2    conda-forge\\r\\n     aws-sdk-cpp               1.11.267             hddb5a97_7    conda-forge\\r\\n     babel                     2.14.0             pyhd8ed1ab_0    conda-forge\\r\\n     backports.zoneinfo        0.2.1           py311h38be061_8    conda-forge\\r\\n     beautifulsoup4            4.12.3             pyha770c72_0    conda-forge\\r\\n     binutils                  2.40                 h4852527_0    conda-forge\\r\\n     binutils_impl_linux-64    2.40                 ha885e6a_0    conda-forge\\r\\n     binutils_linux-64         2.40                 hdade7a5_3    conda-forge\\r\\n     bleach                    6.1.0              pyhd8ed1ab_0    conda-forge\\r\\n     bokeh                     3.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     brotli                    1.1.0                hd590300_1    conda-forge\\r\\n     brotli-bin                1.1.0                hd590300_1    conda-forge\\r\\n     brotli-python             1.1.0           py311hb755f60_1    conda-forge\\r\\n     bzip2                     1.0.8                hd590300_5    conda-forge\\r\\n     c-ares                    1.28.1               hd590300_0    conda-forge\\r\\n     c-compiler                1.5.2                h0b41bf4_0    conda-forge\\r\\n     ca-certificates           2024.2.2             hbcca054_0    conda-forge\\r\\n     cachetools                5.3.3              pyhd8ed1ab_0    conda-forge\\r\\n     cairo                     1.18.0               h3faef2a_0    conda-forge\\r\\n     certifi                   2024.2.2           pyhd8ed1ab_0    conda-forge\\r\\n     charset-normalizer        3.3.2              pyhd8ed1ab_0    conda-forge\\r\\n     click                     8.1.7           unix_pyh707e725_0    conda-forge\\r\\n     cloudpickle               3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     cmake                     3.29.2               hcfe8598_0    conda-forge\\r\\n     colorama                  0.4.6              pyhd8ed1ab_0    conda-forge\\r\\n     comm                      0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     commonmark                0.9.1                      py_0    conda-forge\\r\\n     contourpy                 1.2.1           py311h9547e67_0    conda-forge\\r\\n     coverage                  7.5.0           py311h331c9d8_0    conda-forge\\r\\n     cuda-cccl_linux-64        12.2.140             ha770c72_0    conda-forge\\r\\n     cuda-crt-dev_linux-64     12.2.140             ha770c72_1    conda-forge\\r\\n     cuda-crt-tools            12.2.140             ha770c72_1    conda-forge\\r\\n     cuda-cudart               12.2.140             hd3aeb46_0    conda-forge\\r\\n     cuda-cudart-dev           12.2.140             hd3aeb46_0    conda-forge\\r\\n     cuda-cudart-dev_linux-64  12.2.140             h59595ed_0    conda-forge\\r\\n     cuda-cudart-static        12.2.140             hd3aeb46_0    conda-forge\\r\\n     cuda-cudart-static_linux-64 12.2.140             h59595ed_0    conda-forge\\r\\n     cuda-cudart_linux-64      12.2.140             h59595ed_0    conda-forge\\r\\n     cuda-driver-dev_linux-64  12.2.140             h59595ed_0    conda-forge\\r\\n     cuda-nvcc                 12.2.140             hcdd1206_0    conda-forge\\r\\n     cuda-nvcc-dev_linux-64    12.2.140             ha770c72_1    conda-forge\\r\\n     cuda-nvcc-impl            12.2.140             hd3aeb46_1    conda-forge\\r\\n     cuda-nvcc-tools           12.2.140             hd3aeb46_1    conda-forge\\r\\n     cuda-nvcc_linux-64        12.2.140             h8a487aa_0    conda-forge\\r\\n     cuda-nvrtc                12.2.140             hd3aeb46_0    conda-forge\\r\\n     cuda-nvvm-dev_linux-64    12.2.140             ha770c72_1    conda-forge\\r\\n     cuda-nvvm-impl            12.2.140             h59595ed_1    conda-forge\\r\\n     cuda-nvvm-tools           12.2.140             h59595ed_1    conda-forge\\r\\n     cuda-profiler-api         12.2.140             ha770c72_0    conda-forge\\r\\n     cuda-python               12.4.0          py311h7f239a6_1    conda-forge\\r\\n     cuda-version              12.2                 he2b69de_3    conda-forge\\r\\n     cudf                      24.06.00a164    cuda12_py311_240430_gab5e3f3bc8_164    rapidsai-nightly\\r\\n     cuml                      24.6.0                   pypi_0    pypi\\r\\n     cupy                      13.1.0          py311hf829483_4    conda-forge\\r\\n     cupy-core                 13.1.0          py311he1e6e68_4    conda-forge\\r\\n     cxx-compiler              1.5.2                hf52228f_0    conda-forge\\r\\n     cycler                    0.12.1             pyhd8ed1ab_0    conda-forge\\r\\n     cython                    3.0.10          py311hb755f60_0    conda-forge\\r\\n     cytoolz                   0.12.3          py311h459d7ec_0    conda-forge\\r\\n     dask                      2024.4.3a240423  py_g5a588aee_1    dask/label/dev\\r\\n     dask-core                 2024.4.3a240429 py_gb958ce2dc_9    dask/label/dev\\r\\n     dask-cuda                 24.06.00a12     py311_240430_g85cbd00_12    rapidsai-nightly\\r\\n     dask-cudf                 24.06.00a164    cuda12_py311_240430_gab5e3f3bc8_164    rapidsai-nightly\\r\\n     dask-expr                 1.0.13a240425     py_g301c1a6_5    dask/label/dev\\r\\n     dask-glm                  0.3.0                    pypi_0    pypi\\r\\n     dask-ml                   2024.3.20          pyhd8ed1ab_0    conda-forge\\r\\n     debugpy                   1.8.1           py311hb755f60_0    conda-forge\\r\\n     decopatch                 1.4.10             pyhd8ed1ab_0    conda-forge\\r\\n     decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     distributed               2024.4.3a240423  py_g5a588aee_1    dask/label/dev\\r\\n     dlpack                    0.8                  h59595ed_3    conda-forge\\r\\n     docutils                  0.19            py311h38be061_1    conda-forge\\r\\n     doxygen                   1.9.1                hb166930_1    conda-forge\\r\\n     entrypoints               0.4                pyhd8ed1ab_0    conda-forge\\r\\n     exceptiongroup            1.2.0              pyhd8ed1ab_2    conda-forge\\r\\n     execnet                   2.1.1              pyhd8ed1ab_0    conda-forge\\r\\n     executing                 2.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     expat                     2.6.2                h59595ed_0    conda-forge\\r\\n     fastrlock                 0.8.2           py311hb755f60_2    conda-forge\\r\\n     fmt                       10.2.1               h00ab1b0_0    conda-forge\\r\\n     font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge\\r\\n     font-ttf-inconsolata      3.000                h77eed37_0    conda-forge\\r\\n     font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge\\r\\n     font-ttf-ubuntu           0.83                 h77eed37_1    conda-forge\\r\\n     fontconfig                2.14.2               h14ed4e7_0    conda-forge\\r\\n     fonts-conda-ecosystem     1                             0    conda-forge\\r\\n     fonts-conda-forge         1                             0    conda-forge\\r\\n     fonttools                 4.51.0          py311h459d7ec_0    conda-forge\\r\\n     freetype                  2.12.1               h267a509_2    conda-forge\\r\\n     fribidi                   1.0.10               h36c2ea0_0    conda-forge\\r\\n     fsspec                    2024.3.1           pyhca7485f_0    conda-forge\\r\\n     future                    1.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     gcc                       11.4.0               h602e360_6    conda-forge\\r\\n     gcc_impl_linux-64         11.4.0               h7abf839_6    conda-forge\\r\\n     gcc_linux-64              11.4.0               h0f0c6b6_3    conda-forge\\r\\n     gdk-pixbuf                2.42.11              hb9ae30d_0    conda-forge\\r\\n     gflags                    2.2.2             he1b5a44_1004    conda-forge\\r\\n     giflib                    5.2.2                hd590300_0    conda-forge\\r\\n     glog                      0.7.0                hed5481d_0    conda-forge\\r\\n     graphite2                 1.3.13            h59595ed_1003    conda-forge\\r\\n     graphviz                  9.0.0                h78e8752_1    conda-forge\\r\\n     gtk2                      2.24.33              h280cfa0_4    conda-forge\\r\\n     gts                       0.7.6                h977cf35_4    conda-forge\\r\\n     gxx                       11.4.0               h602e360_6    conda-forge\\r\\n     gxx_impl_linux-64         11.4.0               h7abf839_6    conda-forge\\r\\n     gxx_linux-64              11.4.0               h2730b16_3    conda-forge\\r\\n     harfbuzz                  8.4.0                h3d44ed6_0    conda-forge\\r\\n     hdbscan                   0.8.30          py311h1f0f07a_0    conda-forge\\r\\n     hypothesis                6.100.2            pyha770c72_0    conda-forge\\r\\n     icu                       73.2                 h59595ed_0    conda-forge\\r\\n     idna                      3.7                pyhd8ed1ab_0    conda-forge\\r\\n     imagesize                 1.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     importlib-metadata        7.1.0              pyha770c72_0    conda-forge\\r\\n     importlib-resources       6.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     importlib_metadata        7.1.0                hd8ed1ab_0    conda-forge\\r\\n     importlib_resources       6.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     iniconfig                 2.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     ipykernel                 6.29.3             pyhd33586a_0    conda-forge\\r\\n     ipython                   8.22.2             pyh707e725_0    conda-forge\\r\\n     jedi                      0.19.1             pyhd8ed1ab_0    conda-forge\\r\\n     jinja2                    3.1.3              pyhd8ed1ab_0    conda-forge\\r\\n     joblib                    1.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     jsonschema                4.21.1             pyhd8ed1ab_0    conda-forge\\r\\n     jsonschema-specifications 2023.12.1          pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_client            8.6.1              pyhd8ed1ab_0    conda-forge\\r\\n     jupyter_core              5.7.2           py311h38be061_0    conda-forge\\r\\n     jupyterlab_pygments       0.3.0              pyhd8ed1ab_1    conda-forge\\r\\n     kernel-headers_linux-64   3.10.0              h4a8ded7_14    conda-forge\\r\\n     keyutils                  1.6.1                h166bdaf_0    conda-forge\\r\\n     kiwisolver                1.4.5           py311h9547e67_1    conda-forge\\r\\n     krb5                      1.21.2               h659d440_0    conda-forge\\r\\n     lcms2                     2.16                 hb7c19ff_0    conda-forge\\r\\n     ld_impl_linux-64          2.40                 h55db66e_0    conda-forge\\r\\n     lerc                      4.0.0                h27087fc_0    conda-forge\\r\\n     libabseil                 20240116.2      cxx17_h59595ed_0    conda-forge\\r\\n     libarrow                  14.0.2          hefa796f_19_cpu    conda-forge\\r\\n     libarrow-acero            14.0.2          hbabe93e_19_cpu    conda-forge\\r\\n     libarrow-dataset          14.0.2          hbabe93e_19_cpu    conda-forge\\r\\n     libarrow-flight           14.0.2          hc4f8a93_19_cpu    conda-forge\\r\\n     libarrow-flight-sql       14.0.2          he4f5ca8_19_cpu    conda-forge\\r\\n     libarrow-gandiva          14.0.2          hc1954e9_19_cpu    conda-forge\\r\\n     libarrow-substrait        14.0.2          he4f5ca8_19_cpu    conda-forge\\r\\n     libblas                   3.9.0           22_linux64_openblas    conda-forge\\r\\n     libbrotlicommon           1.1.0                hd590300_1    conda-forge\\r\\n     libbrotlidec              1.1.0                hd590300_1    conda-forge\\r\\n     libbrotlienc              1.1.0                hd590300_1    conda-forge\\r\\n     libcblas                  3.9.0           22_linux64_openblas    conda-forge\\r\\n     libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge\\r\\n     libcublas                 12.2.5.6             hd3aeb46_0    conda-forge\\r\\n     libcublas-dev             12.2.5.6             hd3aeb46_0    conda-forge\\r\\n     libcudf                   24.06.00a164    cuda12_240430_gab5e3f3bc8_164    rapidsai-nightly\\r\\n     libcufft                  11.0.8.103           hd3aeb46_0    conda-forge\\r\\n     libcufft-dev              11.0.8.103           hd3aeb46_0    conda-forge\\r\\n     libcufile                 1.7.2.10             hd3aeb46_0    conda-forge\\r\\n     libcufile-dev             1.7.2.10             hd3aeb46_0    conda-forge\\r\\n     libcumlprims              24.06.00a       cuda12_240429_g98a3699_7    rapidsai-nightly\\r\\n     libcurand                 10.3.3.141           hd3aeb46_0    conda-forge\\r\\n     libcurand-dev             10.3.3.141           hd3aeb46_0    conda-forge\\r\\n     libcurl                   8.7.1                hca28451_0    conda-forge\\r\\n     libcusolver               11.5.2.141           hd3aeb46_0    conda-forge\\r\\n     libcusolver-dev           11.5.2.141           hd3aeb46_0    conda-forge\\r\\n     libcusparse               12.1.2.141           hd3aeb46_0    conda-forge\\r\\n     libcusparse-dev           12.1.2.141           hd3aeb46_0    conda-forge\\r\\n     libdeflate                1.20                 hd590300_0    conda-forge\\r\\n     libedit                   3.1.20191231         he28a2e2_2    conda-forge\\r\\n     libev                     4.33                 hd590300_2    conda-forge\\r\\n     libevent                  2.1.12               hf998b51_1    conda-forge\\r\\n     libexpat                  2.6.2                h59595ed_0    conda-forge\\r\\n     libffi                    3.4.2                h7f98852_5    conda-forge\\r\\n     libgcc-devel_linux-64     11.4.0             hc2b0fca_106    conda-forge\\r\\n     libgcc-ng                 13.2.0               hc881cc4_6    conda-forge\\r\\n     libgd                     2.3.3                h119a65a_9    conda-forge\\r\\n     libgfortran-ng            13.2.0               h69a702a_6    conda-forge\\r\\n     libgfortran5              13.2.0               h43f5ff8_6    conda-forge\\r\\n     libglib                   2.80.0               hf2295e7_6    conda-forge\\r\\n     libgomp                   13.2.0               hc881cc4_6    conda-forge\\r\\n     libgoogle-cloud           2.23.0               h9be4e54_1    conda-forge\\r\\n     libgoogle-cloud-storage   2.23.0               hc7a4891_1    conda-forge\\r\\n     libgrpc                   1.62.2               h15f2491_0    conda-forge\\r\\n     libhwloc                  2.10.0          default_h2fb2949_1000    conda-forge\\r\\n     libiconv                  1.17                 hd590300_2    conda-forge\\r\\n     libjpeg-turbo             3.0.0                hd590300_1    conda-forge\\r\\n     libkvikio                 24.06.00a       cuda12_240430_g7b0231c_11    rapidsai-nightly\\r\\n     liblapack                 3.9.0           22_linux64_openblas    conda-forge\\r\\n     libllvm14                 14.0.6               hcd5def8_4    conda-forge\\r\\n     libllvm15                 15.0.7               hb3ce162_4    conda-forge\\r\\n     libnghttp2                1.58.0               h47da74e_1    conda-forge\\r\\n     libnl                     3.9.0                hd590300_0    conda-forge\\r\\n     libnsl                    2.0.1                hd590300_0    conda-forge\\r\\n     libnvjitlink              12.2.140             hd3aeb46_0    conda-forge\\r\\n     libopenblas               0.3.27          pthreads_h413a1c8_0    conda-forge\\r\\n     libparquet                14.0.2          hacf5a1f_19_cpu    conda-forge\\r\\n     libpng                    1.6.43               h2797004_0    conda-forge\\r\\n     libprotobuf               4.25.3               h08a7969_0    conda-forge\\r\\n     libraft                   24.06.00a42     cuda12_240429_gd4d92ce9_42    rapidsai-nightly\\r\\n     libraft-headers           24.06.00a42     cuda12_240429_gd4d92ce9_42    rapidsai-nightly\\r\\n     libraft-headers-only      24.06.00a42     cuda12_240429_gd4d92ce9_42    rapidsai-nightly\\r\\n     libre2-11                 2023.09.01           h5a48ba9_2    conda-forge\\r\\n     librmm                    24.06.00a14     cuda12_240430_g9e6db746_14    rapidsai-nightly\\r\\n     librsvg                   2.58.0               hadf69e7_1    conda-forge\\r\\n     libsanitizer              11.4.0               hc2b0fca_6    conda-forge\\r\\n     libsodium                 1.0.18               h36c2ea0_1    conda-forge\\r\\n     libsqlite                 3.45.3               h2797004_0    conda-forge\\r\\n     libssh2                   1.11.0               h0841786_0    conda-forge\\r\\n     libstdcxx-devel_linux-64  11.4.0             hc2b0fca_106    conda-forge\\r\\n     libstdcxx-ng              13.2.0               h95c4c6d_6    conda-forge\\r\\n     libthrift                 0.19.0               hb90f79a_1    conda-forge\\r\\n     libtiff                   4.6.0                h1dd3fc0_3    conda-forge\\r\\n     libutf8proc               2.8.0                h166bdaf_0    conda-forge\\r\\n     libuuid                   2.38.1               h0b41bf4_0    conda-forge\\r\\n     libuv                     1.48.0               hd590300_0    conda-forge\\r\\n     libwebp                   1.3.2                h658648e_1    conda-forge\\r\\n     libwebp-base              1.3.2                hd590300_1    conda-forge\\r\\n     libxcb                    1.15                 h0b41bf4_0    conda-forge\\r\\n     libxcrypt                 4.4.36               hd590300_1    conda-forge\\r\\n     libxml2                   2.12.6               h232c23b_2    conda-forge\\r\\n     libzlib                   1.2.13               hd590300_5    conda-forge\\r\\n     llvmlite                  0.42.0          py311ha6695c7_1    conda-forge\\r\\n     locket                    1.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     lz4                       4.3.3           py311h38e4bf4_0    conda-forge\\r\\n     lz4-c                     1.9.4                hcb278e6_0    conda-forge\\r\\n     makefun                   1.15.2             pyhd8ed1ab_0    conda-forge\\r\\n     markdown                  3.6                pyhd8ed1ab_0    conda-forge\\r\\n     markdown-it-py            3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     markupsafe                2.1.5           py311h459d7ec_0    conda-forge\\r\\n     matplotlib-base           3.8.4           py311h54ef318_0    conda-forge\\r\\n     matplotlib-inline         0.1.7              pyhd8ed1ab_0    conda-forge\\r\\n     mdurl                     0.1.2              pyhd8ed1ab_0    conda-forge\\r\\n     mistune                   3.0.2              pyhd8ed1ab_0    conda-forge\\r\\n     msgpack-python            1.0.7           py311h9547e67_0    conda-forge\\r\\n     multipledispatch          0.6.0                      py_0    conda-forge\\r\\n     munkres                   1.1.4              pyh9f0ad1d_0    conda-forge\\r\\n     nbclient                  0.10.0             pyhd8ed1ab_0    conda-forge\\r\\n     nbconvert                 7.16.3               hd8ed1ab_1    conda-forge\\r\\n     nbconvert-core            7.16.3             pyhd8ed1ab_1    conda-forge\\r\\n     nbconvert-pandoc          7.16.3               hd8ed1ab_1    conda-forge\\r\\n     nbformat                  5.10.4             pyhd8ed1ab_0    conda-forge\\r\\n     nbsphinx                  0.9.3              pyhd8ed1ab_0    conda-forge\\r\\n     nccl                      2.21.5.1             h3a97aeb_0    conda-forge\\r\\n     ncurses                   6.4.20240210         h59595ed_0    conda-forge\\r\\n     nest-asyncio              1.6.0              pyhd8ed1ab_0    conda-forge\\r\\n     ninja                     1.12.0               h00ab1b0_0    conda-forge\\r\\n     nltk                      3.8.1              pyhd8ed1ab_0    conda-forge\\r\\n     numba                     0.59.1          py311h96b013e_0    conda-forge\\r\\n     numpy                     1.26.4          py311h64a7726_0    conda-forge\\r\\n     numpydoc                  1.7.0              pyhd8ed1ab_0    conda-forge\\r\\n     nvcomp                    3.0.6                h10b603f_0    conda-forge\\r\\n     nvtx                      0.2.10          py311h459d7ec_0    conda-forge\\r\\n     openjpeg                  2.5.2                h488ebb8_0    conda-forge\\r\\n     openssl                   3.2.1                hd590300_1    conda-forge\\r\\n     orc                       2.0.0                h17fec99_1    conda-forge\\r\\n     packaging                 24.0               pyhd8ed1ab_0    conda-forge\\r\\n     pandas                    2.2.2           py311h320fe9a_0    conda-forge\\r\\n     pandoc                    3.1.13               ha770c72_0    conda-forge\\r\\n     pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     pango                     1.52.2               ha41ecd1_0    conda-forge\\r\\n     parso                     0.8.4              pyhd8ed1ab_0    conda-forge\\r\\n     partd                     1.4.1              pyhd8ed1ab_0    conda-forge\\r\\n     pathspec                  0.12.1             pyhd8ed1ab_0    conda-forge\\r\\n     patsy                     0.5.6              pyhd8ed1ab_0    conda-forge\\r\\n     pcre2                     10.43                hcad00b1_0    conda-forge\\r\\n     pexpect                   4.9.0              pyhd8ed1ab_0    conda-forge\\r\\n     pickleshare               0.7.5                   py_1003    conda-forge\\r\\n     pillow                    10.3.0          py311h18e6fac_0    conda-forge\\r\\n     pip                       24.0               pyhd8ed1ab_0    conda-forge\\r\\n     pixman                    0.43.2               h59595ed_0    conda-forge\\r\\n     pkgutil-resolve-name      1.3.10             pyhd8ed1ab_1    conda-forge\\r\\n     platformdirs              4.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     pluggy                    1.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     prompt-toolkit            3.0.42             pyha770c72_0    conda-forge\\r\\n     psutil                    5.9.8           py311h459d7ec_0    conda-forge\\r\\n     pthread-stubs             0.4               h36c2ea0_1001    conda-forge\\r\\n     ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\\r\\n     pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\\r\\n     py-cpuinfo                9.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     pyarrow                   14.0.2          py311hd5e4297_19_cpu    conda-forge\\r\\n     pydata-sphinx-theme       0.15.2             pyhd8ed1ab_0    conda-forge\\r\\n     pygments                  2.17.2             pyhd8ed1ab_0    conda-forge\\r\\n     pylibraft                 24.06.00a42     cuda12_py311_240429_gd4d92ce9_42    rapidsai-nightly\\r\\n     pynndescent               0.5.8              pyh1a96a4e_0    conda-forge\\r\\n     pynvjitlink               0.2.2           py311hdaa3023_0    rapidsai\\r\\n     pynvml                    11.4.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyparsing                 3.1.2              pyhd8ed1ab_0    conda-forge\\r\\n     pysocks                   1.7.1              pyha2e5f31_6    conda-forge\\r\\n     pytest                    7.4.4              pyhd8ed1ab_0    conda-forge\\r\\n     pytest-benchmark          4.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     pytest-cases              3.8.5              pyhd8ed1ab_0    conda-forge\\r\\n     pytest-cov                5.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     pytest-xdist              3.5.0              pyhd8ed1ab_0    conda-forge\\r\\n     python                    3.11.9          hb806964_0_cpython    conda-forge\\r\\n     python-dateutil           2.9.0              pyhd8ed1ab_0    conda-forge\\r\\n     python-fastjsonschema     2.19.1             pyhd8ed1ab_0    conda-forge\\r\\n     python-tzdata             2024.1             pyhd8ed1ab_0    conda-forge\\r\\n     python_abi                3.11                    4_cp311    conda-forge\\r\\n     pytz                      2024.1             pyhd8ed1ab_0    conda-forge\\r\\n     pyyaml                    6.0.1           py311h459d7ec_1    conda-forge\\r\\n     pyzmq                     26.0.2          py311h08a0b41_0    conda-forge\\r\\n     raft-dask                 24.06.00a42     cuda12_py311_240429_gd4d92ce9_42    rapidsai-nightly\\r\\n     rapids-dask-dependency    24.06.00a20                py_0    rapidsai-nightly\\r\\n     rdma-core                 51.0                 hd3aeb46_0    conda-forge\\r\\n     re2                       2023.09.01           h7f4b329_2    conda-forge\\r\\n     readline                  8.2                  h8228510_1    conda-forge\\r\\n     recommonmark              0.7.1              pyhd8ed1ab_0    conda-forge\\r\\n     referencing               0.35.0             pyhd8ed1ab_0    conda-forge\\r\\n     regex                     2024.4.28       py311h331c9d8_0    conda-forge\\r\\n     requests                  2.31.0             pyhd8ed1ab_0    conda-forge\\r\\n     rhash                     1.4.4                hd590300_0    conda-forge\\r\\n     rich                      13.7.1             pyhd8ed1ab_0    conda-forge\\r\\n     rmm                       24.06.00a14     cuda12_py311_240430_g9e6db746_14    rapidsai-nightly\\r\\n     rpds-py                   0.18.0          py311h46250e7_0    conda-forge\\r\\n     s2n                       1.4.12               h06160fa_0    conda-forge\\r\\n     scikit-build-core         0.9.2              pyh4af843d_0    conda-forge\\r\\n     scikit-learn              1.2.0           py311h67c5ca5_0    conda-forge\\r\\n     scipy                     1.13.0          py311h64a7726_0    conda-forge\\r\\n     seaborn                   0.13.2               hd8ed1ab_0    conda-forge\\r\\n     seaborn-base              0.13.2             pyhd8ed1ab_0    conda-forge\\r\\n     setuptools                69.5.1             pyhd8ed1ab_0    conda-forge\\r\\n     six                       1.16.0             pyh6c4a22f_0    conda-forge\\r\\n     snappy                    1.2.0                hdb0a2a9_1    conda-forge\\r\\n     snowballstemmer           2.2.0              pyhd8ed1ab_0    conda-forge\\r\\n     sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge\\r\\n     soupsieve                 2.5                pyhd8ed1ab_1    conda-forge\\r\\n     sparse                    0.15.1             pyhd8ed1ab_1    conda-forge\\r\\n     spdlog                    1.12.0               hd2e6256_2    conda-forge\\r\\n     sphinx                    5.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     sphinx-copybutton         0.5.2              pyhd8ed1ab_0    conda-forge\\r\\n     sphinx-markdown-tables    0.0.17             pyh6c4a22f_0    conda-forge\\r\\n     sphinxcontrib-applehelp   1.0.8              pyhd8ed1ab_0    conda-forge\\r\\n     sphinxcontrib-devhelp     1.0.6              pyhd8ed1ab_0    conda-forge\\r\\n     sphinxcontrib-htmlhelp    2.0.5              pyhd8ed1ab_0    conda-forge\\r\\n     sphinxcontrib-jsmath      1.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     sphinxcontrib-qthelp      1.0.7              pyhd8ed1ab_0    conda-forge\\r\\n     sphinxcontrib-serializinghtml 1.1.10             pyhd8ed1ab_0    conda-forge\\r\\n     stack_data                0.6.2              pyhd8ed1ab_0    conda-forge\\r\\n     statsmodels               0.14.1          py311h1f0f07a_0    conda-forge\\r\\n     sysroot_linux-64          2.17                h4a8ded7_14    conda-forge\\r\\n     tabulate                  0.9.0              pyhd8ed1ab_1    conda-forge\\r\\n     tbb                       2021.12.0            h00ab1b0_0    conda-forge\\r\\n     tblib                     3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     threadpoolctl             3.5.0              pyhc1e730c_0    conda-forge\\r\\n     tinycss2                  1.3.0              pyhd8ed1ab_0    conda-forge\\r\\n     tk                        8.6.13          noxft_h4845f30_101    conda-forge\\r\\n     toml                      0.10.2             pyhd8ed1ab_0    conda-forge\\r\\n     tomli                     2.0.1              pyhd8ed1ab_0    conda-forge\\r\\n     toolz                     0.12.1             pyhd8ed1ab_0    conda-forge\\r\\n     tornado                   6.4             py311h459d7ec_0    conda-forge\\r\\n     tqdm                      4.66.2             pyhd8ed1ab_0    conda-forge\\r\\n     traitlets                 5.14.3             pyhd8ed1ab_0    conda-forge\\r\\n     treelite                  4.1.2           py311he8f9275_1    conda-forge\\r\\n     typing-extensions         4.11.0               hd8ed1ab_0    conda-forge\\r\\n     typing_extensions         4.11.0             pyha770c72_0    conda-forge\\r\\n     tzdata                    2024a                h0c530f3_0    conda-forge\\r\\n     ucx                       1.15.0               hda83522_8    conda-forge\\r\\n     ucx-proc                  1.0.0                       gpu    rapidsai\\r\\n     ucx-py                    0.38.00a4       py311_240430_g03c864b_4    rapidsai-nightly\\r\\n     umap-learn                0.5.3           py311h38be061_1    conda-forge\\r\\n     urllib3                   2.2.1              pyhd8ed1ab_0    conda-forge\\r\\n     wcwidth                   0.2.13             pyhd8ed1ab_0    conda-forge\\r\\n     webencodings              0.5.1              pyhd8ed1ab_2    conda-forge\\r\\n     wheel                     0.43.0             pyhd8ed1ab_1    conda-forge\\r\\n     xorg-kbproto              1.0.7             h7f98852_1002    conda-forge\\r\\n     xorg-libice               1.1.1                hd590300_0    conda-forge\\r\\n     xorg-libsm                1.2.4                h7391055_0    conda-forge\\r\\n     xorg-libx11               1.8.9                h8ee46fc_0    conda-forge\\r\\n     xorg-libxau               1.0.11               hd590300_0    conda-forge\\r\\n     xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\\r\\n     xorg-libxext              1.3.4                h0b41bf4_2    conda-forge\\r\\n     xorg-libxrender           0.9.11               hd590300_0    conda-forge\\r\\n     xorg-renderproto          0.11.1            h7f98852_1002    conda-forge\\r\\n     xorg-xextproto            7.3.0             h0b41bf4_1003    conda-forge\\r\\n     xorg-xproto               7.0.31            h7f98852_1007    conda-forge\\r\\n     xyzservices               2024.4.0           pyhd8ed1ab_0    conda-forge\\r\\n     xz                        5.2.6                h166bdaf_0    conda-forge\\r\\n     yaml                      0.2.5                h7f98852_2    conda-forge\\r\\n     zeromq                    4.3.5                h59595ed_1    conda-forge\\r\\n     zict                      3.0.0              pyhd8ed1ab_0    conda-forge\\r\\n     zipp                      3.17.0             pyhd8ed1ab_0    conda-forge\\r\\n     zlib                      1.2.13               hd590300_5    conda-forge\\r\\n     zstd                      1.5.5                hfc55251_0    conda-forge\\r\\n\\r\\n</pre></details>\\ncreatedAt: 2024-05-02T08:45:18Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Tim Head\\ncompany: Nvidia', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 369}),\n",
       " Document(page_content=': 840\\ntitle: [FEA] Concatenate dictionary of objects along axis=0\\nbody: Following up from https://github.com/rapidsai/cudf/issues/15115 and the implementation for `axis=1`.\\r\\n\\r\\nWe need to implement concatenation of dictionary objects along `axis=0`.\\r\\n\\r\\nSee important context from @shwina here https://github.com/rapidsai/cudf/issues/15115#issuecomment-1961179887\\ncreatedAt: 2024-05-04T00:56:15Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 370}),\n",
       " Document(page_content=': 841\\ntitle: [BUG] Concat `Index` behavior diverts from `pandas`\\nbody: As @wence- points out here https://github.com/rapidsai/cudf/pull/15623#discussion_r1586054947\\r\\n\\r\\nWe allow concatenating indexes whilst `pandas` does not.\\r\\n\\r\\nDo we like this difference in behavior? Do we want parity? Would users be upset if we changed this behavior?\\ncreatedAt: 2024-05-04T04:31:14Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 371}),\n",
       " Document(page_content=': 842\\ntitle: [BUG] `test_concat` file instantiates GPU objects in the parametrize arguments\\nbody: As @bdice points out here: https://github.com/rapidsai/cudf/pull/15623#discussion_r1589362754\\r\\n\\r\\nGPU object instantiation within the parametrize arguments results in the test suite being slower to launch. We should refactor tests as such: https://github.com/rapidsai/cudf/pull/15623/commits/b5b91166a7cb8e865e4c989e0a67f930fe643d63\\r\\n\\r\\nIdeally, this refactor would occur across all test files with this associated issue.\\ncreatedAt: 2024-05-04T04:52:35Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 372}),\n",
       " Document(page_content=\": 843\\ntitle: [QST] Recusively Generating AST Expressions (C++ libcudf)\\nbody: I would like to implement a function that can generate AST expressions, for example, by recursively converting a different expression class, such as an Apache Arrow `arrow::compute::expression` [object](https://github.com/apache/arrow/blob/main/cpp/src/arrow/compute/expression.h), to a `cudf::ast::expression` [object](https://github.com/rapidsai/cudf/blob/branch-24.06/cpp/include/cudf/ast/expressions.hpp). \\r\\n\\r\\nIs this even possible? libcudf's AST expression classes only accept references that are owned by the caller function; this is a problem since we can not recurse anymore. Is there any way to do this, to implement functions that can generate AST expressions instead of hardcoding expressions in a caller?\\ncreatedAt: 2024-05-04T16:10:19Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Shriram Chandran\\ncompany: ETH Zürich\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 373}),\n",
       " Document(page_content=\": 847\\ntitle: [FEA] Explicitly guarantee row group ordering in the parquet reader.\\nbody: From @devavret , the question came up as to whether we guarantee the relative ordering of row groups across multiple input files in the parquet reader.  That is, if you have two files `[f1, f2]` and the row groups within the files (in one column) are specified as `[[r0,r3], [r0,r1]]`, do we guarantee the output ordering would be  `[f1r0, f1r3, f2r0, f2r1]`\\r\\n\\r\\nThe code does in fact do this for both the explicitly specified case and the unspecified (empty user input / all row groups), but we don't make any guarantees about it.   Seems like a safe and easy thing to add.\\r\\n\\r\\nhttps://github.com/rapidsai/cudf/blob/5d244dfc13f4db0b1e41ded3029942fec50c98f6/cpp/src/io/parquet/reader_impl_helpers.cpp#L663\\ncreatedAt: 2024-05-07T21:27:02Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 374}),\n",
       " Document(page_content=\": 850\\ntitle: [QST] aggregate function that operates on vector(array of numeric) data\\nbody: **What is your question?**\\r\\nI am wondering if `cudf` has native or built-in support for aggregate function that run against vector data. Namley, text/image embeddings are stored in the column of csv/parquet file. And I'd like to run various aggregate functions such as `mean`, `max` and so on. All these operations are element-wise, namely, it returns the mean of all the values in same index and return an array with same lenght. What's more, I'd like to run K-Nearest-Neighbor search as well.\\r\\n\\r\\nIf not natively supported, how to achieve these operations with performance efficient?\\r\\n\\r\\nexample code:\\r\\n```\\r\\nimport cudf\\r\\nimport numpy as np\\r\\nimport pandas as pd\\r\\n\\r\\n# Sample DataFrame with Pandas to cuDF conversion\\r\\ndata = {\\r\\n    'category': ['A', 'A', 'B', 'B'],\\r\\n    'values': [np.array([1, 2, 3]), np.array([4, 5, 6]), np.array([7, 8, 9]), np.array([10, 11, 12])]\\r\\n}\\r\\npdf = pd.DataFrame(data)\\r\\ndf = cudf.DataFrame.from_pandas(pdf)\\r\\n\\r\\nresult = df.groupby('category').agg({'values': ['sum', 'mean']})\\r\\n\\r\\nprint(result)\\r\\n\\r\\n# Expected output\\r\\n'''\\r\\ncategory\\r\\nA     [2.5, 3.5, 4.5]\\r\\nB    [8.5, 9.5, 10.5]\\r\\nName: values, dtype: object\\r\\n'''\\r\\n```\\ncreatedAt: 2024-05-14T03:35:37Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Rhett Ying\\ncompany: @aws\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 375}),\n",
       " Document(page_content=': 854\\ntitle: [BUG] Data corruption and strange CUDA memory address errors at the same row index, despite manipulating data, when using `.stack()` on large, wide dataset\\nbody: **Describe the bug**\\r\\nWhenever I\\'m trying to use cudf,stack() on this large wide dataframe, at around the same index location, the data gets corrupted as you stack past that index until it fails to run, or just fails to run.  It happens at index 1159550.   go one index before 1159550, everything is fine. One or two after, you start to see issues or it fails.  Even if you change around the data a bit, it still fails. eventually.  When it fails, it returns `RuntimeError: parallel_for: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered`. \\r\\n\\r\\nHappens on both an A100 80GB and H100 running 24.04.  Completes successfully on pandas. Falls back to pandas and successfully completes on cudf.pandas.\\r\\n\\r\\n**Steps/Code to reproduce bug**\\r\\nThis requires a dataset download, handled in the min repro, and a 32GB GPU or larger to test.\\r\\n\\r\\nYou can actually see the data getting corrupted at the incrementing runs at the end of the min repro, before it finally fails\\r\\n\\r\\n```\\r\\n!if [ ! -f \"job_skills.csv\" ]; then curl https://storage.googleapis.com/rapidsai/colab-data/job_skills.csv.gz -o job_skills.csv.gz; gunzip job_skills.csv.gz; else echo \"unzipped job data found\"; fi\\r\\nimport cudf\\r\\nskills = cudf.read_csv(\"job_skills.csv\")\\r\\n\\r\\nb = skills[\"job_skills\"].str.split(\",\", expand=True)\\r\\n#print(b.iloc[1159550]) # incase you wanted to see what was on that index\\r\\nprint(b.iloc[1159550])\\r\\nb2 = b[:1159549]\\r\\n# b2 = b[:1159550] # Uncommenting this, it will fail\\r\\nstacked_skills = b2.stack()\\r\\nprint(stacked_skills.head())\\r\\n\\r\\n# this will also fail\\r\\n# stacked_skills = b.stack().dropna()\\r\\n\\r\\n# even if you change the dataframe a bit by moving up the indexes incrementally, it will not really change where it fails, as you can start to see the data start glitch\\r\\nprint(skills.count())\\r\\nskills = skills.dropna()\\r\\nprint(skills.count())\\r\\nb = skills[\"job_skills\"].str.split(\",\", expand=True)\\r\\nprint(b.iloc[1159550]) # in case you wanted to see what was on that index\\r\\nb2 = b[:1159549]\\r\\nstacked_skills = b2.stack()\\r\\nprint(1159549)\\r\\nprint(stacked_skills.head())\\r\\nb2 = b[:1159550]\\r\\nstacked_skills = b2.stack()\\r\\nprint(1159550)\\r\\nprint(stacked_skills.head()) # you can start to see data corruption or it just fails\\r\\nb2 = b[:1159551]\\r\\nstacked_skills = b2.stack()\\r\\nprint(1159551)\\r\\nprint(stacked_skills.head())\\r\\nb2 = b[:1159552]\\r\\nstacked_skills = b2.stack()\\r\\nprint(1159552)\\r\\nprint(stacked_skills.head())\\r\\nb2 = b[:1159553]\\r\\nstacked_skills = b2.stack()\\r\\nprint(1159553)\\r\\nprint(stacked_skills.head())\\r\\nb2 = b[:1159554]\\r\\nstacked_skills = b2.stack()\\r\\nprint(1159554)\\r\\nprint(stacked_skills.head()) # by here it should fail\\r\\n```\\r\\nOutputs:\\r\\n```\\r\\n0                         Anesthesiology\\r\\n1                        Medical license\\r\\n2                      BLS certification\\r\\n3                       DEA registration\\r\\n4       Controlled Substance Certificate\\r\\n                     ...                \\r\\n458                                 <NA>\\r\\n459                                 <NA>\\r\\n460                                 <NA>\\r\\n461                                 <NA>\\r\\n462                                 <NA>\\r\\nName: 1159550, Length: 463, dtype: object\\r\\n0  0    Building Custodial Services\\r\\n   1                       Cleaning\\r\\n   2            Janitorial Services\\r\\n   3             Materials Handling\\r\\n   4                   Housekeeping\\r\\ndtype: object\\r\\njob_link      1296381\\r\\njob_skills    1294346\\r\\ndtype: int64\\r\\njob_link      1294346\\r\\njob_skills    1294346\\r\\ndtype: int64\\r\\n0      Project Management\\r\\n1           Communication\\r\\n2           Collaboration\\r\\n3              Leadership\\r\\n4          ProblemSolving\\r\\n              ...        \\r\\n458                  <NA>\\r\\n459                  <NA>\\r\\n460                  <NA>\\r\\n461                  <NA>\\r\\n462                  <NA>\\r\\nName: 1161237, Length: 463, dtype: object\\r\\n1159549\\r\\n0  0    Building Custodial Services\\r\\n   1                       Cleaning\\r\\n   2            Janitorial Services\\r\\n   3             Materials Handling\\r\\n   4                   Housekeeping\\r\\ndtype: object\\r\\n1159550\\r\\n0  0     PCUeel Nurseendek Services\\r\\n   1                       Cleaning\\r\\n   2            Janitorial Services\\r\\n   3             Materials Handling\\r\\n   4                   Housekeeping\\r\\ndtype: object\\r\\n1159551\\r\\n0  0     PCUeel Nursenndek Services\\r\\n   1                       Cleaning\\r\\n   2            Janitorial Services\\r\\n   3             Materials Handling\\r\\n   4                   Housekeeping\\r\\ndtype: object\\r\\n1159552\\r\\n0  0     FoUd Safetyeg certificatio\\r\\n   1                      nCleaning\\r\\n   2            Janitorial Services\\r\\n   3             Materials Handling\\r\\n   4                   Housekeeping\\r\\ndtype: object\\r\\n---------------------------------------------------------------------------\\r\\nRuntimeError                              Traceback (most recent call last)\\r\\nCell In[1], line 40\\r\\n     38 print(stacked_skills.head())\\r\\n     39 b2 = b[:1159553]\\r\\n---> 40 stacked_skills = b2.stack()\\r\\n     41 print(1159553)\\r\\n     42 print(stacked_skills.head())\\r\\n\\r\\nFile /opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)\\r\\n    113 @wraps(func)\\r\\n    114 def inner(*args, **kwargs):\\r\\n    115     libnvtx_push_range(self.attributes, self.domain.handle)\\r\\n--> 116     result = func(*args, **kwargs)\\r\\n    117     libnvtx_pop_range(self.domain.handle)\\r\\n    118     return result\\r\\n\\r\\nFile /opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py:7079, in DataFrame.stack(self, level, dropna, future_stack)\\r\\n   7073     # homogenize the dtypes of the columns\\r\\n   7074     homogenized = [\\r\\n   7075         col.astype(common_type) if col is not None else all_nulls()\\r\\n   7076         for col in columns\\r\\n   7077     ]\\r\\n-> 7079     stacked.append(libcudf.reshape.interleave_columns(homogenized))\\r\\n   7081 # Construct the resulting dataframe / series\\r\\n   7082 if not has_unnamed_levels:\\r\\n\\r\\nFile /opt/conda/lib/python3.10/contextlib.py:79, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\\r\\n     76 @wraps(func)\\r\\n     77 def inner(*args, **kwds):\\r\\n     78     with self._recreate_cm():\\r\\n---> 79         return func(*args, **kwds)\\r\\n\\r\\nFile reshape.pyx:26, in cudf._lib.reshape.interleave_columns()\\r\\n\\r\\nRuntimeError: parallel_for: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered\\r\\n```\\r\\n\\r\\n**Expected behavior**\\r\\nThis should just work, as it does in pandas, without ay data corruption\\r\\n```\\r\\n!if [ ! -f \"job_skills.csv\" ]; then curl https://storage.googleapis.com/rapidsai/colab-data/job_skills.csv.gz -o job_skills.csv.gz; gunzip job_skills.csv.gz; else echo \"unzipped job data found\"; fi\\r\\nimport pandas as pd\\r\\nskills = pd.read_csv(\"job_skills.csv\")\\r\\n\\r\\nb = skills[\"job_skills\"].str.split(\",\", expand=True)\\r\\nprint(b.iloc[1159550])\\r\\nb2 = b # just to keep the copying similar.  it doesn\\'t matter.\\r\\nstacked_skills = b2.stack()\\r\\nprint(stacked_skills.head())\\r\\n```\\r\\nOutputs:\\r\\n```\\r\\n0                         Anesthesiology\\r\\n1                        Medical license\\r\\n2                      BLS certification\\r\\n3                       DEA registration\\r\\n4       Controlled Substance Certificate\\r\\n                     ...                \\r\\n458                                 None\\r\\n459                                 None\\r\\n460                                 None\\r\\n461                                 None\\r\\n462                                 None\\r\\nName: 1159550, Length: 463, dtype: object\\r\\n0  0    Building Custodial Services\\r\\n   1                       Cleaning\\r\\n   2            Janitorial Services\\r\\n   3             Materials Handling\\r\\n   4                   Housekeeping\\r\\ndtype: object\\r\\n```\\r\\n\\r\\n**Environment overview (please complete the following information)**\\r\\n - Environment location: Docker\\r\\n - Method of cuDF install: Docker\\r\\n   - If method of install is [Docker], docker run --user root --gpus all --rm -it --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 9888:8888 -p 9787:8787 -p 9786:8786 -p 9999:9999 rapidsai/notebooks:24.04-cuda11.8-py3.10 jupyter-lab --notebook-dir=/home/rapids/notebooks --ip=0.0.0.0 --no-browser --NotebookApp.token=\\'\\' --NotebookApp.allow_origin=\\'*\\' --allow-root\\r\\n\\r\\n\\r\\n**Environment details**\\r\\nRAPIDS 24.04 cuda 11.8, py 3.9 and 3.10 Docker on ARM SBSA machines\\r\\n\\r\\n**Additional context**\\r\\nWhen running cudf.pandas, this will succeed, but at the costs of taking nearly 30-40% longer than pandas alone.  If and when it succeeds (by reducing it to the last row where it succeeds, it would be 50x+ faster.  I have not done a data integrity test just yet, to see if the corruption happens earlier.\\r\\n@vyasr fyi.\\ncreatedAt: 2024-05-15T10:22:32Z\\nn_body_reactions_thumbs_up: 1\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Taurean Dyer\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 376}),\n",
       " Document(page_content=\": 858\\ntitle: [FEA] Potential optimization:  Batched memset.\\nbody: Under some situations in the Parquet reader (particularly the case with tables containing many columns or deeply nested column) we burn a decent amount of time doing `cudaMemset()` operations on output buffers. A good amount of this overhead seems to stem from the fact that we're simply launching many tiny kernels.  It might be useful to have a batched/multi memset kernel that takes a list of address/sizes/values as a single input and does all the work under a single kernel launch.  Similar to the Cub multi-buffer memcpy or `contiguous_split`.\\ncreatedAt: 2024-05-17T15:43:03Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: \\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 377}),\n",
       " Document(page_content=': 866\\ntitle: [ENH] Use `strict=True` argument to `zip` once py39 support is dropped\\nbody: In many places in the cudf code we zip two (or more) iterables together with the assumption/precondition that they are all of equal length. The pattern is (approximately):\\r\\n\\r\\n```python\\r\\nnames: list[str]\\r\\ncolumns: list[Column]\\r\\ndata: dict[str, Column] = dict(zip(names, columns))\\r\\n```\\r\\n\\r\\nThis has, by design of zip, a potential problem lurking in that if the two inputs are _not_ of equal length, we only keep the first `min(len(names), len(columns))` objects.\\r\\n\\r\\nTo avoid check this at user-input boundaries we need to be careful to check (and then raise if not) that the inputs we are zipping _do_ have equal length. This is easy to forget.\\r\\n\\r\\n[Python 3.10](https://docs.python.org/3/library/functions.html#zip) introduces a new keyword-argument to `zip`, `strict`, which can be used to assert that the inputs have the same length. We should consider using this across the code-base when no longer supporting Python 3.9.\\ncreatedAt: 2024-05-23T09:59:08Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: ', metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 378}),\n",
       " Document(page_content=\": 869\\ntitle: [FEA] Better control over the output dtype in aggregations\\nbody: **Is your feature request related to a problem? Please describe.**\\r\\n\\r\\nFor the cudf-polars work, I'd like to match dtypes with polars where possible, preferably without casting the result of a libcudf call post-hoc if the interface in theory supports specifying an output type.\\r\\n\\r\\nFor whole-frame aggregations (`cudf::reduce`) although one is able to specify an output_dtype, this is not obeyed for a number of aggregations. Specifically:\\r\\n\\r\\n- `MEDIAN` (always returns the datatype matching `double`)\\r\\n- `NUNIQUE` (always returns the datatype matching `cudf::size_type`)\\r\\n- `QUANTILE` (always returns the datatype matching `double`)\\r\\n\\r\\n\\r\\nThe same is true of many grouped aggregations.\\r\\n\\r\\n**Describe the solution you'd like**\\r\\n\\r\\nI'd like that aggregations could support output dtype as specified by the user.\\r\\n\\r\\n**Describe alternatives you've considered**\\r\\n\\r\\npost-hoc unary casting of the result, but this is yet another kernel launch, and produces more memory overhead.\\ncreatedAt: 2024-05-24T13:37:43Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Lawrence Mitchell\\ncompany: \", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 379}),\n",
       " Document(page_content=\": 870\\ntitle: For the overload of replace in libcudf where input/target/repl are columns, there isn't a maxrepl arg.\\nbody: For the overload of replace in libcudf where input/target/repl are columns, there isn't a maxrepl arg.\\r\\n\\r\\nWe should probably support this in libcudf replace (eventually), otherwise we'll have some weirdness in pylibcudf where we'll have to raise for maxrepl despite accepting it as an argument.\\r\\n\\r\\n_Originally posted by @lithomas1 in https://github.com/rapidsai/cudf/pull/15839#discussion_r1611981114_\\ncreatedAt: 2024-05-24T16:46:09Z\\nn_body_reactions_thumbs_up: 0\\nn_body_reactions_thumbs_down: 0\\nauthor.name: Thomas Li\\ncompany: @pandas-dev\", metadata={'source': 'external_issue_details_with_posters_min.csv', 'row': 380})]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      I use Linux at work but at home I have windows...\n",
       "2      <!--\n",
       "\n",
       "Thanks for opening an issue! To help t...\n",
       "3      **Describe the bug**\n",
       "\n",
       "It takes a few seconds...\n",
       "9      In Pandas, DatetimeIndexes can report back the...\n",
       "11     Please add merge_asof to cudf to match pandas ...\n",
       "                             ...                        \n",
       "854    **Describe the bug**\n",
       "Whenever I'm trying to u...\n",
       "858    Under some situations in the Parquet reader (p...\n",
       "866    In many places in the cudf code we zip two (or...\n",
       "869    **Is your feature request related to a problem...\n",
       "870    For the overload of replace in libcudf where i...\n",
       "Name: body, Length: 381, dtype: string"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_issues[\"body\"].astype(\"string[pyarrow]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>n_body_reactions_thumbs_up</th>\n",
       "      <th>n_body_reactions_thumbs_down</th>\n",
       "      <th>author.name</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support for windows?</td>\n",
       "      <td>2017-07-01T05:54:03Z</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>stephenmm</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add clang-tidy for automatic linting</td>\n",
       "      <td>2018-08-29T18:00:18Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrew Seidl</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[BUG] Long import times</td>\n",
       "      <td>2019-01-04T02:46:53Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Matthew Rocklin</td>\n",
       "      <td>@coiled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[FEA] DatetimeIndex Frequency/TZ</td>\n",
       "      <td>2019-06-06T16:09:44Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benjamin Zaitlen</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[FEA]Add merge_asof to cudf</td>\n",
       "      <td>2019-07-12T17:04:59Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>[BUG] Data corruption and strange CUDA memory ...</td>\n",
       "      <td>2024-05-15T10:22:32Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Taurean Dyer</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>[FEA] Potential optimization:  Batched memset.</td>\n",
       "      <td>2024-05-17T15:43:03Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>[ENH] Use `strict=True` argument to `zip` once...</td>\n",
       "      <td>2024-05-23T09:59:08Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lawrence Mitchell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>[FEA] Better control over the output dtype in ...</td>\n",
       "      <td>2024-05-24T13:37:43Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lawrence Mitchell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>For the overload of replace in libcudf where i...</td>\n",
       "      <td>2024-05-24T16:46:09Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thomas Li</td>\n",
       "      <td>@pandas-dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title             createdAt  \\\n",
       "0                                Support for windows?   2017-07-01T05:54:03Z   \n",
       "2                 Add clang-tidy for automatic linting  2018-08-29T18:00:18Z   \n",
       "3                              [BUG] Long import times  2019-01-04T02:46:53Z   \n",
       "9                     [FEA] DatetimeIndex Frequency/TZ  2019-06-06T16:09:44Z   \n",
       "11                         [FEA]Add merge_asof to cudf  2019-07-12T17:04:59Z   \n",
       "..                                                 ...                   ...   \n",
       "854  [BUG] Data corruption and strange CUDA memory ...  2024-05-15T10:22:32Z   \n",
       "858     [FEA] Potential optimization:  Batched memset.  2024-05-17T15:43:03Z   \n",
       "866  [ENH] Use `strict=True` argument to `zip` once...  2024-05-23T09:59:08Z   \n",
       "869  [FEA] Better control over the output dtype in ...  2024-05-24T13:37:43Z   \n",
       "870  For the overload of replace in libcudf where i...  2024-05-24T16:46:09Z   \n",
       "\n",
       "     n_body_reactions_thumbs_up  n_body_reactions_thumbs_down  \\\n",
       "0                            43                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "9                             0                             0   \n",
       "11                            0                             0   \n",
       "..                          ...                           ...   \n",
       "854                           1                             0   \n",
       "858                           0                             0   \n",
       "866                           0                             0   \n",
       "869                           0                             0   \n",
       "870                           0                             0   \n",
       "\n",
       "           author.name      company  \n",
       "0            stephenmm         None  \n",
       "2         Andrew Seidl         None  \n",
       "3      Matthew Rocklin     @coiled   \n",
       "9     Benjamin Zaitlen         None  \n",
       "11                None         None  \n",
       "..                 ...          ...  \n",
       "854       Taurean Dyer         None  \n",
       "858               None         None  \n",
       "866  Lawrence Mitchell         None  \n",
       "869  Lawrence Mitchell         None  \n",
       "870          Thomas Li  @pandas-dev  \n",
       "\n",
       "[381 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_issues.drop(columns=\"body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(\n",
    "    OpenAI_langchain(temperature=0, model=\"gpt-3.5-turbo-instruct\"),\n",
    "    external_issues.drop(columns=\"body\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'381'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"how many rows are there?\")[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[FEA] predicate push down such as bloom filters added to read_orc'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What issues are Walmart most interested in?\")[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
