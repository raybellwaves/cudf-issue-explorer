{"assignees":[{"id":"MDQ6VXNlcjE2MDA1Njkw","login":"vuule","name":"Vukasin Milovanovic"}],"author":{"id":"MDQ6VXNlcjQyNDk0NDc=","is_bot":false,"login":"lmeyerov","name":""},"body":"**Describe the bug**\r\n\r\nSomewhere between `dgdf = dask_cudf.read_csv(..)` and `dgdf.to_parquet()`, the generated files are written in a way that `cudf.read_parquet` and `dask_cudf.read_parquet` will fail to read the data back.\r\n\r\nException:  `cuDF failure at: /opt/conda/envs/rapids/conda-bld/libcudf_1607621803079/work/cpp/src/io/parquet/reader_impl.cu:371: All sources must have the same schemas`\r\n\r\n\r\n\r\n**Steps/Code to reproduce bug**\r\n\r\nMay need to fix paths:\r\n\r\nDownload:\r\n\r\n```bash\r\ncurl -O /tmp/logs.csv.gz \"https://s3.amazonaws.com/botsdataset/botsv1/csv-by-sourcetype/botsv1.WinEventLog%3ASecurity.csv.gz\"\r\n(cd /tmp && gunzip logs.csv.gz)\r\n```\r\n\r\nConvert:\r\n```python\r\nwith dask.distributed.Client(ADDRESS):\r\n  dgdf = dask_cudf.read_csv('/tmp/logs.csv')\r\n  dgdf.to_parquet(\r\n       '/tmp/logs.parquet',\r\n        compression='snappy',\r\n        write_index=False,\r\n        index=False)\r\n```\r\n\r\nTest: Unexpectedly throws exn\r\n```python\r\ncudf.read_parquet('/tmp/logs.parquet')\r\n```\r\n\r\n**Expected behavior**\r\nThe converted file to read back with matching dtypes... but throws an exn\r\n\r\n**Environment overview (please complete the following information)**\r\nRAPIDS 0.18 (conda) in docker (ubuntu); A100's\r\n\r\n**Additional context**\r\n\r\n* Variants where we set `schema`, `dtypes`,  and `use_pandas_metadata` also fail\r\n* Also seeing failures when doing dask_cudf.read_parquet, and doing an intermediate repartition\r\n","closed":false,"closedAt":null,"comments":[{"id":"MDEyOklzc3VlQ29tbWVudDc5OTgzNDgxMQ==","author":{"login":"lmeyerov"},"authorAssociation":"NONE","body":"Still digging in... I think this may have to do with one of the columns being called \"index\"","createdAt":"2021-03-15T23:43:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7602#issuecomment-799834811","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgwMDAyMTE0OA==","author":{"login":"lmeyerov"},"authorAssociation":"NONE","body":"Still not sure what's going on. What does make it through, including with readback testing, is switching to dask/pandas:\r\n\r\n\r\n```python\r\n dgdf = dask_cudf.read_csv(\r\n        f'{DOWNLOAD_DIR}/{file}',\r\n        parse_dates=['_time'],\r\n        dtype=dtypes,\r\n        columns=cols,\r\n        chunksize='64 MiB')\r\n\r\ndgdf2 = dgdf.map_partitions(lambda gdf: gdf.to_pandas(), schema=schema, meta=meta)\r\n\r\ndgdf2.to_parquet(\r\n        '/tmp/out.parquet',\r\n        compression='snappy',\r\n        write_index=False)\r\n```","createdAt":"2021-03-16T07:23:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7602#issuecomment-800021148","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgwODUwNTgyNg==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"I'm guessing this is a case of nulls differing between files that we need to handle.","createdAt":"2021-03-26T21:01:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7602#issuecomment-808505826","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgxMjE3Nzg5OA==","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"From some local testing I did, I looks like the CSV reader is unable to correctly read the file, probably because of the string column that has very large elements that include newline characters. With `byte_range` option (which I assume is what dask is using to split the work), disambiguating actual row ends from in-string newline characters is tricky, and this is probably what is going wrong here.","createdAt":"2021-04-01T21:17:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/7602#issuecomment-812177898","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgxMjIyODg1Mg==","author":{"login":"lmeyerov"},"authorAssociation":"NONE","body":"Thanks for picking up! Fwiw, I also had issues w/ the json versions at the same url. In both cases, I ended up having to do cpu dask read -> write parquet -> gpu dask read. And an unfortunate amount of experimentation to push them through.\r\n\r\nSometimes the failure was silent. To more explicitly test, later, I did a cudf loop like:\r\n\r\n```python\r\n# test opts for dask / dask_cudf configs\r\nvariant.read_csv('abc.csv').to_parquet('abc.parquet')\r\nfor i in range(n_parts - 1):\r\n   # will fail if 2 partitions have mismatching schema\r\n    cudf.read_parquet([f'abc.parquet/part{i}.parquet', f'abc.parquet/part{i+1}.parquet'])\r\n```\r\n\r\nAnd had all sorts of `metadata`, `schema`, `write_index`, `ignore_pandas_metadata` flags. An esp weird one was complaints about not finding `\"index\"` in index/cols.\r\n\r\nThese are big windows log files (and others there) for ~real data, so a good challenge case that's not fake and represents a lot of sec/it data.","createdAt":"2021-04-01T23:22:33Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7602#issuecomment-812228852","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgzMDcxMzE0OA==","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2021-05-02T00:11:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7602#issuecomment-830713148","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgzMDcxNDgwNQ==","author":{"login":"lmeyerov"},"authorAssociation":"NONE","body":"I'm not sure this is fixed\r\n\r\nWe'll be wrapping up the work where this was hit into an OSS repo, so can share when up","createdAt":"2021-05-02T00:28:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7602#issuecomment-830714805","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDg1MTc0NDUwOQ==","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2021-06-01T01:34:18Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7602#issuecomment-851744509","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps49geTV","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-90d` due to no recent activity in the past 90 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed.","createdAt":"2022-02-07T21:05:20Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7602#issuecomment-1031922901","viewerDidAuthor":false}],"createdAt":"2021-03-15T21:02:56Z","id":"MDU6SXNzdWU4MzIxOTAyOTU=","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NTk=","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"}],"milestone":null,"number":7602,"projectCards":[{"project":{"name":"Bug Squashing"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[{"content":"EYES","users":{"totalCount":1}}],"state":"OPEN","title":"[BUG] dask_cudf generates files it cannot read back","updatedAt":"2024-02-23T18:43:06Z","url":"https://github.com/rapidsai/cudf/issues/7602"}
