{"assignees":[{"id":"MDQ6VXNlcjQ1Nzk1OTkx","login":"davidwendt","name":"David Wendt"}],"author":{"id":"MDQ6VXNlcjQ4Mzc1NzE=","is_bot":false,"login":"VibhuJawa","name":"Vibhu Jawa"},"body":"**Is your feature request related to a problem? Please describe.**\r\n\r\nWe currently rely on the hashed vocab file using `cudf.utils.hash_vocab_utils.hash_vocab`, we should move to using the `vocab file` directly. \r\n\r\nThis will be similar to the API we added here: https://github.com/rapidsai/cudf/pull/13930\r\n\r\n**Describe the solution you'd like**\r\n\r\n```python3\r\ncudf_tokenizer = cudf.core.subword_tokenizer.SubwordTokenizer(vocab_file=xyz.txt)\r\n```\r\nInstead of earlier:\r\n\r\n```python3\r\nfrom cudf.utils.hash_vocab_utils import hash_vocab\r\nhash_vocab('bert-base-cased-vocab.txt', 'voc_hash.txt')\r\ncudf_tokenizer = SubwordTokenizer('voc_hash.txt')\r\n```\r\n\r\n**Additional context**\r\nThis should help the switch from hugging face like tokenizer to be easier. \r\n\r\nCC: @davidwendt \r\n\r\n\r\n@MarcRomeijn, @cwharris, @markmotrin - Given your experience with the cuDF tokenizer, we'd value any feedback or suggestions for enhancing the `Subword tokenizer` API and features you would like.  ","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5sTJvW","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Besides accepting the vocab file directly instead of the hashed input, specifically want to ask about the parameters and return values for this function: https://docs.rapids.ai/api/cudf/stable/user_guide/api_docs/api/cudf.core.subword_tokenizer.subwordtokenizer.__call__/#cudf.core.subword_tokenizer.SubwordTokenizer.__call__\r\nI believe some of these pre-date the lists-column support in cuDF and so I'm wondering if that could used as be a better result than returning the three individual arrays.","createdAt":"2023-11-17T19:20:08Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14294#issuecomment-1816959958","viewerDidAuthor":false}],"createdAt":"2023-10-17T20:57:42Z","id":"I_kwDOBWUGps50H_E-","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"}],"milestone":null,"number":14294,"projectCards":[],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] Switch cudf.Subwordtokenizer to use the vocab file directly instead of hash_vocab. ","updatedAt":"2023-11-17T19:20:09Z","url":"https://github.com/rapidsai/cudf/issues/14294"}
