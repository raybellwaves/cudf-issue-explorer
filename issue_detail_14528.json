{"assignees":[],"author":{"id":"MDQ6VXNlcjEzNjA3NjY=","is_bot":false,"login":"jlowe","name":"Jason Lowe"},"body":"**Describe the bug**\r\nWhen rounding single-precision floats to a specified number of decimal places, the result can be slightly inaccurate due to the intermediate computations being forced into FLOAT32 as well.  round.cu has rounding functors for non-fixed-point types, but all of the intermediate results are in the same type as the input rather than the highest precision type, double.  This means more error is introduced during the rounding computation than is necessary.\r\n\r\n**Steps/Code to reproduce bug**\r\nThe following code demonstrates the problem:\r\n```c++\r\n#include <cudf/round.hpp>\r\n#include <cudf_test/column_utilities.hpp>\r\n#include <cudf_test/column_wrapper.hpp>\r\n#include <cudf_test/debug_utilities.hpp>\r\n\r\nint main(int argc, char** argv) {\r\n  auto const input =\r\n    cudf::test::fixed_width_column_wrapper<float>{6.121944898040965e-05f};\r\n  cudf::test::print(input);\r\n  auto const result = cudf::round(input, 10, cudf::rounding_method::HALF_UP);\r\n  cudf::test::print(*result);\r\n  return 0;\r\n}\r\n```\r\n\r\nRounding the value to the tenth decimal place should round _down_ to approximately 6.12194e-05 but instead the value is rounded _up_ to approximately 6.12195e-05 as shown in the output when running the program:\r\n```\r\n6.1219449e-05\r\n6.12194999e-05\r\n```\r\n\r\n**Expected behavior**\r\nFLOAT32 rounding should use FLOAT64 for intermediate results during computation to try to avoid injecting errors beyond what is necessary when dealing with floating point numbers.  When I manually performed the computations on this example input value for round.cu's half_up_positive logic but using double instead of float for the intermediate values, the answer came out rounded down as expected.\r\n\r\nIt seems that the functors for floating point rounding in round.cu should _not_ be using whatever the input type is but rather `double` explicitly to avoid unnecessary additional error during the computation.","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5tPkqM","author":{"login":"bdice"},"authorAssociation":"CONTRIBUTOR","body":"Looking at the implementation of our rounding code (specifically [half_up_positive](https://github.com/rapidsai/cudf/blob/e15290a373ff0c84c85c2c0e940e69377a66cf96/cpp/src/round/round.cu#L103-L112)), I am concerned that it's not just a matter of `float` becoming `double`. I suspect `double` values could see the same type of problem, if the number of decimal places is large enough. I think we may need to use an algorithm that is more numerically stable and has less precision loss due to truncation. See also #14169, which is a separate problem with rounding algorithms in libcudf affecting float-to-decimal conversions.","createdAt":"2023-11-29T22:26:20Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14528#issuecomment-1832798860","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5tPqlH","author":{"login":"jlowe"},"authorAssociation":"MEMBER","body":"Yes, totally agree that double will have similar issues with larger decimal place rounding.  As such I don't see this so much as \"solving\" all the rounding issues as significantly improving the results for FLOAT32 with minimal effort.","createdAt":"2023-11-29T22:49:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14528#issuecomment-1832823111","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5tSTdB","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"I think this might be possible to handle by using appropriately selected CUDA intrinsics for the division step. If we're rounding half-up we should use division with round to positive infinity, rather than round to nearest ties to even (which is the default):\r\n\r\nEdit: I misunderstood the definition of half_up rounding, which only breaks ties. Though one might still be able to get away with _something_ like this\r\n```\r\n#include <cstdio>\r\n#include <cuda_runtime_api.h>\r\n__global__ void test(float val, float *out) {\r\n  float decimals = std::pow(10, 10);\r\n  float ipart;\r\n  float remainder = modff(val, &ipart);\r\n  float scaled = roundf(remainder * decimals);\r\n  out[0] = ipart + __fdiv_ru(scaled, decimals);\r\n  out[1] = ipart + __fdiv_rn(scaled, decimals);\r\n}\r\n\r\nint main(void) {\r\n  float input = 6.121944898040965e-05f;\r\n  float *val;\r\n  cudaMalloc(&val, 2 * sizeof(float));\r\n  test<<<1, 1, 1>>>(input, val);\r\n  float h_val[2];\r\n  cudaMemcpy(&h_val, val, 2*sizeof(float), cudaMemcpyDeviceToHost);\r\n  printf(\"in:      %.20f\\n\", input);\r\n  printf(\"out(ru): %.20f\\n\", h_val[0]);\r\n  printf(\"out(rn): %.20f\\n\", h_val[1]);\r\n  cudaFree(val);\r\n}\r\n```\r\nProduces:\r\n```\r\nin:      0.00006121944898040965\r\nout(ru): 0.00006121950718807057\r\nout(rn): 0.00006121949991211295\r\n```\r\n\r\nBut I haven't thought through all the consequences of this change.\r\n\r\n","createdAt":"2023-11-30T10:46:38Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14528#issuecomment-1833514817","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5tTuMq","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"That said, I claim that `half_up` rounding doesn't make much sense as tiebreaking scheme for binary floating point values since the only fractional floating point values that exactly end in 5 are those of the form $2^{-n}$ for $n \\ge 1$.","createdAt":"2023-11-30T14:29:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14528#issuecomment-1833886506","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5yapaQ","author":{"login":"pmattione-nvidia"},"authorAssociation":"CONTRIBUTOR","body":"I started looking into this, and noticed a problem with our current implementation: HALF_UP rounding is bugged for negative numbers: \r\n\r\nif you round (e.g.) **-0.5f** to zero decimal places, it should round **up** to zero, but instead results in **-1** because it calls roundf(), which rounds **away** from zero. \r\n\r\nDo we want to change the rounding code to round up, or change the name/comment to ROUND_AWAY?","createdAt":"2024-01-31T17:35:59Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14528#issuecomment-1919587984","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5ybLHt","author":{"login":"jlowe"},"authorAssociation":"MEMBER","body":"I think the \"UP\" here refers to higher magnitude rather than higher value.  FWIW Java's `HALF_UP` rounding has same round-away-from-zero semantics (see Javadocs [here](https://docs.oracle.com/javase/8/docs/api/java/math/RoundingMode.html#HALF_UP)), so the HALF_UP semantics match what we want from the Spark perspective.","createdAt":"2024-01-31T18:48:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14528#issuecomment-1919726061","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5ybMT2","author":{"login":"pmattione-nvidia"},"authorAssociation":"CONTRIBUTOR","body":"That's fine with me, I'll fix the code comment then in round.hpp (which should instead point to wikipedia's rounding half away from zero).  ","createdAt":"2024-01-31T18:52:08Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14528#issuecomment-1919730934","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5y7Y4k","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"> When rounding single-precision floats to a specified number of decimal places\r\n\r\nThe above is a nonsense statement, in my book. By now you should know my opinion on this: libcudf should not support `round` to decimal places on binary floating-point types.\r\n\r\nhttps://github.com/rapidsai/cudf/issues/406\r\nhttps://github.com/rapidsai/cudf/issues/1270\r\nhttps://github.com/rapidsai/cudf/issues/1340\r\nhttps://github.com/rapidsai/cudf/issues/7195\r\n\r\nI'm sure there are more.\r\n","createdAt":"2024-02-05T21:59:56Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14528#issuecomment-1928171044","viewerDidAuthor":false}],"createdAt":"2023-11-29T21:46:28Z","id":"I_kwDOBWUGps54QCwh","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NTk=","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"}],"milestone":null,"number":14528,"projectCards":[],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[BUG] FLOAT32 rounding more inaccurate than necessary","updatedAt":"2024-02-05T21:59:57Z","url":"https://github.com/rapidsai/cudf/issues/14528"}
