{"assignees":[],"author":{"id":"MDQ6VXNlcjEyNzI1MTEx","is_bot":false,"login":"GregoryKimball","name":"Gregory Kimball"},"body":"Parquet V1 format supports three types of page encodings: PLAIN, DICTIONARY, and RLE (run-length encoded) ([reference from Spark Jira](https://issues.apache.org/jira/browse/SPARK-36879)). The newer and evolving Parquet V2 specification adds support for several [additional encodings](https://parquet.apache.org/docs/file-format/data-pages/encodings/), including DELTA_BINARY_PACKED for `INT32` and `INT64` types, DELTA_BYTE_ARRAY for `strings` logical type, and DELTA_LENGTH_BYTE_ARRAY for `strings` logical type. \r\n\r\nIn the parquet reader and writer, libcudf should support V2 metadata as well as the three variants of DELTA encoding.\r\n\r\n| Feature | Status | Notes | \r\n|---|---|---|\r\n| Add V2 reader support |  ✅ #11778 | |\r\n| Multi-warp decode of Dremel data streams | ✅ #13203 |  | \r\n| Use efficient strings column factory in decoder | ✅ #13302 |  | \r\n| Implement DELTA_BINARY_PACKED decoding |  ✅  #13637 | see #12948 for reference |\r\n| Implement DELTA_BYTE_ARRAY decoding | ✅ #14101 | see #12948 for reference |\r\n| Add V2 writer support | ✅ #13751 | |\r\n| Implement DELTA_BINARY_PACKED encoding | ✅ #14100 | | \r\n| Add python bindings for V2 header and options | ✅ #14316 | |\r\n| Implement DELTA_BYTE_ARRAY encoding | ✅ #15239 | some outdated reviews in #14938 |\r\n| Implement DELTA_LENGTH_BYTE_ARRAY encoding and decoding for unsorted data | ✅ #14590 | |\r\n| Add C++ API support for specifying encodings | ✅ #15081 | |\r\n| Add cuDF-python API support for specifying encodings |  | |\r\n| Add BYTE_STREAM_SPLIT encoding and decoding  | ✅ #15311 | see issue #15226 and [parquet reference](https://github.com/apache/parquet-format/blob/master/Encodings.md#byte-stream-split-byte_stream_split--9) |\r\n\r\n","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5mbbZu","author":{"login":"etseidl"},"authorAssociation":"CONTRIBUTOR","body":"@GregoryKimball should there be an entry for adding python bindings for the V2 options?","createdAt":"2023-09-14T00:07:10Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/13501#issuecomment-1718466158","viewerDidAuthor":false}],"createdAt":"2023-06-02T03:38:40Z","id":"I_kwDOBWUGps5njsGZ","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMDEzOTg3NTAz","name":"2 - In Progress","description":"Currently a work in progress","color":"fef2c0"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"},{"id":"MDU6TGFiZWwyNTQ2NTIxMDI0","name":"improvement","description":"Improvement / enhancement to an existing function","color":"bfd4f2"}],"milestone":{"number":22,"title":"Parquet continuous improvement","description":"","dueOn":null},"number":13501,"projectCards":[],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] Support V2 encodings in Parquet reader and writer","updatedAt":"2024-05-03T17:26:22Z","url":"https://github.com/rapidsai/cudf/issues/13501"}
