{"assignees":[],"author":{"id":"MDQ6VXNlcjM0NDEzMjE=","is_bot":false,"login":"revans2","name":"Robert (Bobby) Evans"},"body":"**Is your feature request related to a problem? Please describe.**\r\nIn a recent customer query I found that it was rather slow because they were doing a first aggregation along with a number of other small aggregations.  First is translated into an NTH_ELEMENT aggregation, either with or without null handling.  But NTH_ELEMENT is implemented as a sort based aggregation, not a hash based one.  This slows down the entire query. If I replace `first` with `max` the entire query gets to be 18% faster.\r\n\r\nI know in the general case NTH_ELEMENT cannot be a hash based aggregation, but for common SQL operations like `first` and `last` we should be able to make it a hash aggregate.\r\n\r\n**Describe the solution you'd like**\r\nI personally would love for some magic to happen behind the scenes with NTH_ELEMENT where it can become a hash aggregate if `n` is `0` or `-1`.  But I would be happy to have some new FIRST and LAST aggregations instead, if that is simpler.\r\n\r\nThe algorithm I have been thinking about for first, is to do a min aggregation on a counting sequence starting at 0. Then we use the result of that as a gather map to pull in the first value from the original input column.  If we don't want to include nulls, then instead of using the counting iterator directly we also pull in the null mask from the original input column, and we replace nulls in the gather map with -1 before doing the gather.\r\n\r\nFor last we would switch it over to doing max aggregation instead of a min.\r\n\r\n**Describe alternatives you've considered**\r\nWe could writ this ourselves, but the current Spark aggregation code does not make it simple to get access to the original input column after doing the aggregation. I can change that, but I didn't want to do that until I head from CUDF about how hard this might be.  Also the CUDF version is going to be more efficient, because I might not have to materialize as much data depending on how much can use thrust iterators to manipulate the original input data.\r\n\r\n**Additional context**\r\nAdd any other context, code examples, or references to existing implementations about the feature request here.\r\n","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5HHfzv","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2022-07-23T16:03:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/11141#issuecomment-1193147631","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5HxoBA","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"I still want this it would be a good performance boost for anyone in SQL doing a first or a last like operation.","createdAt":"2022-08-03T16:25:44Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/11141#issuecomment-1204191296","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Jp7zz","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2022-09-02T17:07:21Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/11141#issuecomment-1235729651","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5KJCEU","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"Still wanted.","createdAt":"2022-09-12T15:07:14Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/11141#issuecomment-1243881748","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5MFJts","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2022-10-12T16:08:07Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/11141#issuecomment-1276418924","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5MrjF8","author":{"login":"GregoryKimball"},"authorAssociation":"CONTRIBUTOR","body":"#11603 was an attempt to address this issue, but we ran into design challenges. Please refer to the discussion in [this comment](https://github.com/rapidsai/cudf/pull/11603#discussion_r956541461) ","createdAt":"2022-10-21T05:38:00Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/11141#issuecomment-1286484348","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5ZXztI","author":{"login":"ttnghia"},"authorAssociation":"CONTRIBUTOR","body":"Maybe `static_reduction_map` can help this: https://github.com/NVIDIA/cuCollections/pull/98.\r\n\r\nNote that similar mechanism has already been implemented in cudf (https://github.com/rapidsai/cudf/pull/11052). We can adopt the same approach if need this with higher priority.","createdAt":"2023-04-06T17:44:48Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/11141#issuecomment-1499413320","viewerDidAuthor":false}],"createdAt":"2022-06-23T15:57:14Z","id":"I_kwDOBWUGps5Mc1cq","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMzIyMjUyNjE3","name":"Performance","description":"Performance related issue","color":"C2E0C6"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"}],"milestone":{"number":28,"title":"Aggregations continuous improvement","description":"","dueOn":null},"number":11141,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[{"content":"EYES","users":{"totalCount":1}}],"state":"OPEN","title":"[FEA] first and last as hash based aggregates","updatedAt":"2023-07-22T20:31:30Z","url":"https://github.com/rapidsai/cudf/issues/11141"}
