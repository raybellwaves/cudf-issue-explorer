{"assignees":[],"author":{"id":"MDQ6VXNlcjM0NDEzMjE=","is_bot":false,"login":"revans2","name":"Robert (Bobby) Evans"},"body":"**Is your feature request related to a problem? Please describe.**\r\nSpark supports the aggregate function in SQL (Not really standard but we have customers who use it)\r\n\r\nhttps://spark.apache.org/docs/latest/api/sql/index.html#aggregate\r\n\r\nIt takes 4 arguments.\r\n  * **argument** an array/list column to do the aggregation on\r\n  * **initial** an initial value for accumulation\r\n  * **merge** a higher order function that takes two arguments an accumulation value and the current value in the list\r\n  * **finish** an optional higher order function that takes the output of merge and transforms it into a final value\r\n \r\nA higher order function is a function that is written in SQL like `(a, b) -> a + b` to add two things together.\r\n\r\nEven though **finish** is a higher order function we don't have to treat it that way so we can ignore it for now.\r\n\r\n**merge** however is something new that CUDF has not really supported before. It allows the user to specify how they want an aggregation to happen instead of having a declarative aggregation like most SQL does.  So for example if I wanted to do the equivalent of SUM it would look something like\r\n\r\n```\r\nSELECT aggregate(list_of_int_column, 0, (acc, x) -> acc + x) as sum_of_ints_in_list\r\n```\r\n\r\nFor each list in the column it would do essentially the equivalent of\r\n\r\n```\r\nMERGE_OUTPUT_TYPE acc = initial_value;\r\nfor (ELEMENT_TYPE & elem : list_data) {\r\n  acc = merge(acc, elem);\r\n}\r\n```\r\n\r\nThe problem we are running into is that our customers have rather complicated operations, where the higher order function can reach out to other columns in the same row.\r\n\r\n```\r\n(acc, x) -> (\r\n  CASE WHEN other_column - x.struct_sub_column >= acc\r\n                         AND other_column - x.struct_sub_column < 100\r\n                         AND x.struct_string_column = 'FOO'\r\n                         AND yet_another_column <> x.third_struct_sub_column\r\n             THEN other_column - x.struct_sub_column\r\n             ELSE acc\r\n  END))\r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\nI would love something where we could build up an AST tree that represents the higher order function and have cudf provide a list_aggregation function that would do what we need/want. But we know that there are potentially issues with the AST in terms or performance when there are too many operators so this is all open to discussion.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nWe have thought about trying to do pattern matching to decompose the higher order function into something more manageable for CUDF to support.\r\n\r\ni.e.\r\n\r\n```\r\n(acc, x) -> acc + x\r\n```\r\ncould be translated into an SUM aggregation across the values in the list, or \r\n\r\n```\r\n(acc, x) -> CASE WHEN x > acc THEN x ELSE acc END\r\n```\r\n\r\ncould be translated into a MAX aggregation across the values in the list.\r\n\r\nWe could even use pattern matching for things like \r\n\r\n```\r\n(acc, x) -> acc + x.first - x.second\r\n```\r\n\r\nTo translate it into first doing a `x.first - x.second` for all of the struct values within the list, and then doing a SUM aggregation on that resulting list.  But things get much more difficult when we try to support pulling in other columns, and struct columns, etc.\r\n\r\n```\r\n(acc, x) -> acc + x.first + foo\r\n```\r\n\r\nIn this case we would have to do essentially an `explode` on `foo` and the list column so we could execute `x.first + foo` and then finally do the SUM aggregation. This is a bit problematic because of potential memory issues that explode can cause.\r\n\r\nSo if the AST is not a workable solution we would like to request a generic list aggregation operation instead.\r\n\r\n```\r\ncudf::column list_aggregate(cudf::lists_column_view list, std::unique_ptr<aggregation> & aggregation);\r\n```\r\n\r\nWith at a minimum supporting MAX, SUM, and MIN aggregations initially.\r\n\r\nIt would probably be ideal to expand it out to multiple aggregations at once like with `groupby`, but it is not a requirement.\r\n\r\nI also need to add that null handling would have to be a bit different than other aggregations. If the list itself is a null, then the output should be a null, but if a value in the list is a null, then the output should also be a null.\r\n\r\n```\r\nscala> spark.sql(\"SELECT aggregate(array(1, 2, 3), 0, (acc, x) -> acc + x) as A\").show\r\n+---+\r\n|  A|\r\n+---+\r\n|  6|\r\n+---+\r\n\r\n\r\nscala> spark.sql(\"SELECT aggregate(array(1, 2, 3, null), 0, (acc, x) -> acc + x) as A\").show\r\n+----+\r\n|   A|\r\n+----+\r\n|null|\r\n+----+\r\n```\r\n\r\nIdeally we would also love to have some kind of explode that would not make a copy of the array we are exploding on, but instead just do the explode on the columns that need it.\r\n","closed":false,"closedAt":null,"comments":[{"id":"MDEyOklzc3VlQ29tbWVudDg0NjE0NzA0OQ==","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2021-05-21T18:16:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8020#issuecomment-846147049","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDg0NjIzMDk2MA==","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"we still want this","createdAt":"2021-05-21T20:19:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8020#issuecomment-846230960","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5fiM3O","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Just wanted to update this since libcudf has a [cudf::segmented_reduce](https://docs.rapids.ai/api/libcudf/stable/group__aggregation__reduction.html#gaade4393b8cd1fa9ddfec0f3f1e7f63cf) API which supports MIN,MAX,SUM and may be a possible usage here (that is, if you can determine the aggregation type ahead of time).\r\n\r\nAssuming a non-nested list column, the first parameter would be the list's child data column and the second parameter would be the list's offsets.\r\nThe `null_handling` parameter can be set to `INCLUDE` to set the row result to NULL if any element is null.\r\nThe overall nulls could then be computed by using [cudf::bitmask_and](https://docs.rapids.ai/api/libcudf/stable/group__column__nullmask.html#ga81f65c5ef8c216335f02e9f4e4b5ddcc) with the returned result and the original lists column.","createdAt":"2023-06-22T15:02:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/8020#issuecomment-1602801102","viewerDidAuthor":false}],"createdAt":"2021-04-21T17:31:59Z","id":"MDU6SXNzdWU4NjQxMTUzMDc=","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"}],"milestone":null,"number":8020,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] aggregation each list in a column to a single value using a user supplied function","updatedAt":"2023-06-22T15:02:43Z","url":"https://github.com/rapidsai/cudf/issues/8020"}
