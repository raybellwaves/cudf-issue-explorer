{"assignees":[],"author":{"id":"MDQ6VXNlcjE0NDUzNjg=","is_bot":false,"login":"cwharris","name":"Christopher Harris"},"body":"Reader and writer implementations have multiple paths for reading and writing, depending whether data is read-from/written-to the host or the device. This logic could be delegated to `datasource` and `data_sink`, potentially sharing the functionality between all `datasource`s and `data_sink`s.\r\n\r\nThis would eliminate the need for `supports_device_write` and `supports_device_read`, which could also reduce the surface area of testing.\r\n\r\nnote: `supports_device_read` is currently unused.\r\n\r\nExamples:\r\nhttps://github.com/rapidsai/cudf/blob/f4735c7f658da4a157dc09391da899b072878305/cpp/src/io/csv/writer_impl.cu#L412-L442\r\nhttps://github.com/rapidsai/cudf/blob/f4735c7f658da4a157dc09391da899b072878305/cpp/src/io/parquet/writer_impl.cu#L882-L913\r\n\r\nLooks like ORC doesn't have this logic at all, which might be a bug?\r\nhttps://github.com/rapidsai/cudf/blob/f4735c7f658da4a157dc09391da899b072878305/cpp/src/io/orc/writer_impl.cu#L1246\r\n\r\nHypothetical Source/Sink APIs\r\n-\r\n`data_kind` is used to describe the caller-owned buffer.\r\n```C++\r\n// note: data_kind is not used to determine the sink/source buffer's kind.\r\n//       the sink/source buffer kind is an implementation detail of the given sink/source.\r\nenum class data_kind {\r\n  host,  // used when the caller is writing data from host, or reading data to host\r\n  device // used when the caller is writing data from device, or reading data to device\r\n};\r\n```\r\nAn API such as this delegates the read/write logic to the source/sink, but gives enough information for the source/sink to determine how data should be copied, and whether or not a sync is necessary to perform the copies. For instance, if the specific source implementation is reading data on device, and the `read(...)` call is made with `data_kind::device`, then the source has enough information to execute a device-to-device copy, without or without syncing the stream (perhaps an API an optional method should be added to ensure sync has taken place).\r\n```C++\r\nclass base_source_context {\r\n  base_source_context(cudaStream_t stream) : stream(stream) {}\r\n\r\n  virtual size_t read(uint8_t const* data, size_t size, data_kind kind) = 0;\r\n\r\n private:\r\n  cudaStream_t stream;\r\n};\r\n\r\nclass base_source {\r\n public:\r\n  virtual unique_ptr<base_source_context> begin_read(cudaStream_t stream) = 0;\r\n};\r\n```\r\n```C++\r\nclass base_sink_context {\r\n public:\r\n  base_sink_context(cudaStream_t stream) : stream(stream) {}\r\n\r\n  virtual void write(uint8_t const* data, size_t size, data_kind kind) = 0;\r\n\r\n private:\r\n  cudaStream_t stream;\r\n};\r\n\r\nclass base_sink {\r\n public:\r\n  virtual unique_ptr<base_sink_context> begin_write(cudaStream_t stream) = 0;\r\n};\r\n```","closed":false,"closedAt":null,"comments":[{"id":"MDEyOklzc3VlQ29tbWVudDY4OTgwMTcyMw==","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"I had the same suggestion in the PR that added the `supports_device_write` logic. It was rejected because readers/writers have the context to better optimize the IO operations compared to having the host/device logic in the source/sink.\r\n\r\n> Looks like ORC doesn't have this logic at all, which might be a bug?\r\n\r\nYeah, it's a missing feature. In all components but Parquet. We'll be adding this logic to every format soon, including readers. So, `supports_device_read` will also be used very soon :)","createdAt":"2020-09-09T20:24:08Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-689801723","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDY4OTg2MTcwMw==","author":{"login":"cwharris"},"authorAssociation":"CONTRIBUTOR","body":"> because readers/writers have the context to better optimize the IO operations compared to having the host/device logic in the source/sink.\r\n\r\n:(\r\n\r\nAny chance you have the PR number? I'd like to see the reasoning. I imagining the control could still be inverted...","createdAt":"2020-09-09T22:44:46Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-689861703","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDY4OTg2NDU1NQ==","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"@cwharris here you go: https://github.com/rapidsai/cudf/pull/4231#discussion_r384104534","createdAt":"2020-09-09T22:52:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-689864555","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDY4OTg3NjE4Nw==","author":{"login":"cwharris"},"authorAssociation":"CONTRIBUTOR","body":"Is this device or host memory we're concerned with? @nvdbaranec ","createdAt":"2020-09-09T23:26:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-689876187","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDY5MDM0Mzk5Nw==","author":{"login":"nvdbaranec"},"authorAssociation":"CONTRIBUTOR","body":"Are you asking about my comment re: having to alloc/free on the spot for a default implementation?  The thinking there was that it would have to allocate host memory, do a memcpy, then do it's write, then immediately free that memory even though it would probably be doing that multiple times.  If you look at how the code is structured here:  https://github.com/rapidsai/cudf/blob/ac39e372d771b604b64d1c704c2c846ee1edde2d/cpp/src/io/parquet/writer_impl.cu#L835\r\n\r\nIt allocates one worst-case sized buffer and then reuses that for multiple write calls.   A default implementation would have no context what's going on and what have to alloc/free every time which is undesirable from a performance perspective (doubly so because we're using pinned memory here)\r\n\r\n","createdAt":"2020-09-10T14:53:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-690343997","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDY5MTUwNjg1MQ==","author":{"login":"cwharris"},"authorAssociation":"CONTRIBUTOR","body":"If the invocation sites are bifurcated due to the need for multiple passes using the same buffer, we could use a two-step API instead. The first step uses RAII to obtain a worst-case-size buffer, and the second step writes using that buffer. The second step could be called any number of times. Since the buffer type can differ (or simply be unnecessary), we could wrap it in a context to hide the details. For instance:\r\n```c++\r\n{\r\n  // may or may not create a buffer, depending on what type of sink is being used.\r\n  auto sink_context = out_sink->create_write_context(max_chunk_bfr_size);\r\n  for (; r < rnext; r++, global_r++) {\r\n    for (auto i = 0; i < num_columns; i++) {\r\n      ...\r\n      // writes using the worst-case-size buffer, if one was required.\r\n      sink_context.write(dev_bfr + ck->ck_stat_size, ck.compressed_size, state.stream);\r\n      ...\r\n    }\r\n  }   \r\n}\r\n// buffer goes out of scope and associated memory is released\r\n```\r\n\r\nThat `create_write_context` api should accept any relevant information about the data that's going to be written, with regards to the number of passes and size of each pass.\r\n\r\nAlternatively, we could use a memory allocator behind the scenes, but that could be more complicated given that the situation is pretty clearly defined in this case.","createdAt":"2020-09-12T15:34:36Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-691506851","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDY5MjE2NDkwNw==","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"There is a plan to improve performance by processing files in batches (when possible) so that IO can be overlapped with kernels. We don't currently have the infrastructure to make this change. \r\nSince this would significantly change how the sources/sinks are used, I would postpone addressing this issue for now. In addition, I don't think this part of the code is what we need to focus on in the refactoring effort. There are many other components that would benefit more from clean up.","createdAt":"2020-09-14T16:20:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-692164907","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDY5MjIzNDQwMA==","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"IMO this is not a 'tech debt' issue, removed the tag. \r\nDepending on future changes to how IO is pipelined, this issue might not get implemented. Keeping open for now.","createdAt":"2020-09-14T18:31:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-692234400","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDc4MDEyMzU5Nw==","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been marked rotten due to no recent activity in the past 90d. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed.","createdAt":"2021-02-16T21:17:52Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-780123597","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDc4MDg5OTgyNw==","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"Keeping this open, will be potentially addressed at a later date.","createdAt":"2021-02-17T22:35:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/6187#issuecomment-780899827","viewerDidAuthor":false}],"createdAt":"2020-09-09T18:28:07Z","id":"MDU6SXNzdWU2OTcwNDczNTc=","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"}],"milestone":null,"number":6187,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] cuio: allow datasource and data_sink to decide how device/host read/write/copies are handled.","updatedAt":"2022-11-26T17:41:29Z","url":"https://github.com/rapidsai/cudf/issues/6187"}
