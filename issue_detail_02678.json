{"assignees":[],"author":{"id":"MDQ6VXNlcjQ1Nzk1OTkx","is_bot":false,"login":"davidwendt","name":"David Wendt"},"body":"I've been working on improvements to the csv-writer. The changes may require multiple PRs and are as follows:\r\n\r\n1. The current implementation formats the CSV (in row chunks) into CPU memory before writing the file. Profiling should transposing the columns from device memory to host memory was taking more than half the total time to generate the file. Modifying the logic to create the format in device memory first and then copying to host before writing the file improved performance by 20-30%.\r\nThis item requires no change to the API.\r\n2. When chunking the rows, writing the chunks to individual files did not provide performance improvement but generating multiple files may improve read speed. If this becomes an option, the code can launch separate CPU threads when writing each chunk from host memory. This provided a 2-3x speedup over creating a single output file.\r\nThis item would require a new parameter to tell the csv-writer to create individual files for each chunk.\r\n3. After the first 2 are implemented, it would be possible to support gzip compression of the file chunks without too significant of a performance penalty. Adding gzip without these measures increased the write time 3-4x.\r\nThis item would also require a new parameter indicating that compression is desired.\r\n\r\nRecommend adding these improvements in order since each subsequent item gets its advantage from the previous.\r\nThe first item also makes GDS an option for speeding up the actual file write since copying the data to the host would not be required.\r\n\r\n\r\n","closed":false,"closedAt":null,"comments":[{"id":"MDEyOklzc3VlQ29tbWVudDUyNDQ2NzUxNQ==","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"Internal link to my Excel file with breakdown of the csv-writer\r\nhttps://nvidia-my.sharepoint.com/:x:/p/dwendt/EfKmvRq5FR5KhnwkdLfwPm8BG0YhCdMPNv-mZzKPFu-vmA","createdAt":"2019-08-23T21:26:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/2678#issuecomment-524467515","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5GZyJq","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"@davidwendt are items 2 and 3 still something that you plan to pursue?","createdAt":"2022-07-12T00:20:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/2678#issuecomment-1181164138","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5GbljC","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"I've forgotten about this issue so I had no plans to pursue these.\r\nAlso, looks like the improvements made in PR #2706 for step 1 appear to have been discarded in PR #4484.","createdAt":"2022-07-12T11:20:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/2678#issuecomment-1181636802","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Gdju-","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"Do you think it's something that we'll want to pursue again? Was trying to gauge whether these changes would still provide a perf benefit and if it's worth keeping the issue open.","createdAt":"2022-07-12T18:06:13Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/2678#issuecomment-1182153662","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Gd0Xm","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"I think this could morph into just a feature request to enable writing to multiple CSV files. I suspect the performance gain would be similar in today's codebase when using multiple CPU threads. I don't know if there is also an existing issue/request to support gzip compression on CSV write.\r\nIf memory serves, I believe both of these requests originally came from @randerzander ","createdAt":"2022-07-12T18:34:48Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/2678#issuecomment-1182221798","viewerDidAuthor":false}],"createdAt":"2019-08-23T21:08:09Z","id":"MDU6SXNzdWU0ODQ3MTI2NjA=","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"},{"id":"MDU6TGFiZWwxMzIyMjUyNjE3","name":"Performance","description":"Performance related issue","color":"C2E0C6"}],"milestone":{"number":12,"title":"CSV continuous improvement","description":"","dueOn":null},"number":2678,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[{"content":"ROCKET","users":{"totalCount":2}}],"state":"OPEN","title":"[FEA] Performance improvements for csv-writer","updatedAt":"2024-05-17T22:11:31Z","url":"https://github.com/rapidsai/cudf/issues/2678"}
