{"assignees":[{"id":"MDQ6VXNlcjE2MDA1Njkw","login":"vuule","name":"Vukasin Milovanovic"}],"author":{"id":"MDQ6VXNlcjM0NDEzMjE=","is_bot":false,"login":"revans2","name":"Robert (Bobby) Evans"},"body":"**Describe the bug**\r\nNew parquet code was added to support writing nested types.  This is great, but it broke the java build.  As a part of fixing the java build I found that the new code checks for `nullable` on all of the columns to see if it matches what was set when the writer was initially configured.  But Spark can tell that validity is not needed in some cases where cudf apparently cannot, and cudf will add in a validity column in some cases when it is not needed.  because `nullable` only checks to see if there is a column, and not if there are actually any nulls we can run into a situation where spark tells us that there will be no nulls, but cudf blows up because it thinks that there might be.\r\n","closed":false,"closedAt":null,"comments":[{"id":"MDEyOklzc3VlQ29tbWVudDgyNjM4OTc0MQ==","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2021-04-25T21:04:54Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-826389741","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgyNzE2NDY0Mw==","author":{"login":"razajafri"},"authorAssociation":"CONTRIBUTOR","body":"This is still a valid issue","createdAt":"2021-04-26T21:42:53Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-827164643","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgyNzE5NTU5NQ==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"@vuule is this on your radar?","createdAt":"2021-04-26T23:03:49Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-827195595","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgyNzE5NjMwMg==","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"CC @devavret ","createdAt":"2021-04-26T23:05:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-827196302","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDgyNzMxMjE3NA==","author":{"login":"devavret"},"authorAssociation":"CONTRIBUTOR","body":"Do you mean this: https://github.com/rapidsai/cudf/blob/3c050bbcf369c7d6b56e1fd561e1e4efe1b7b64b/cpp/src/io/parquet/writer_impl.cu#L388-L406\r\n\r\nIf so, I'm not sure this is really a bug. We have to check whether there can be nulls otherwise we'd break downstream in the reader. So it either has to be `has_nulls()` or `nullable()`. The former incurs a kernel call for each column. That's why the latter was chosen. With the understanding, that if the user knew there wouldn't be nulls, they'd drop the mask before passing it in.","createdAt":"2021-04-27T04:56:45Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-827312174","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDg0ODI5MTQ2NA==","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"Sorry about the delay in the response. I understand why nullable was chosen, but the issue I run into is that it is very easy to have something that is nullable, but has no nulls. This happens quite often in Spark. We can analyze the query we are able to tell that something will never have a null in it, but the last cudf call was not able to make the same decision and ended up including a validity column. For example we could filter out all of the nulls from a column. In spark we know that all of the nulls are gone, but cudf just called `filter` on it. It has no knowledge that the boolean mask is correlated to the validity column in any way. I just knows that the input has nulls so there is the possibility that the output will have nulls, and it needs to allocate a validity mask. If you don't do this then I have to figure out a way to walk through all of the columns/child columns and strip out the validity mask if it exists for things that I know don't need it, which then I would also want to run a kernel on it to be sure that there was no bug in the code.","createdAt":"2021-05-25T21:55:11Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-848291464","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDg0ODMwNTM4Nw==","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"IMO we can think of this as a perf vs. memory trade off. For ORC/Parquet ATM we generally lean on the side of reducing the memory use, so it would make sense to have a slight perf overhead to avoid allocating the null masks.\r\nI've just realized that the memory use impact would be ~1%, so I'm not sure if my reasoning stands. Still, for your consideration :) \r\nWe could also make it a writer option, but that seems like an overkill to me.","createdAt":"2021-05-25T22:15:24Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-848305387","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDg0ODY2NDk2NQ==","author":{"login":"devavret"},"authorAssociation":"CONTRIBUTOR","body":"@revans2 Then how about a libcudf API (maybe called `prune_masks`) that takes a table and removes null masks from all columns that have no nulls. This API could be optimized to call a single kernel for the table rather than separate kernels for each column. Filter your tables through it before passing to anything. It will be a one stop optimized solution for all cuIO writers and more (like calling joins on it etc.)\r\n\r\n@vuule This doesn't need extra memory because this is the writer. It might create a slightly larger file. But if there are no nulls then all the definition values will be 1 and running it through RLE will all but remove it. Think 8 bytes per 1 MB page.","createdAt":"2021-05-26T10:43:14Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-848664965","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDg0ODY2ODk3Ng==","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"I think a `prune_masks` would be fine. To be clear my concern is not about the size of the file or how much memory/time it takes to compute.  It is about trying to match the same output as Spark does. This is not a high priority right now because if the data is read back in by Spark it will still treat it as nullable, even if all of the input files say that the column is not nullable. I am less sure about other tools, so I want to match it as closely as possible.","createdAt":"2021-05-26T10:50:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-848668976","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps49geSa","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-90d` due to no recent activity in the past 90 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed.","createdAt":"2022-02-07T21:05:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-1031922842","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5grruo","author":{"login":"jlowe"},"authorAssociation":"MEMBER","body":"This issue is still relevant, ran into it again recently.  Seems related to #13010.\r\n\r\nNote that now that null counts are required to be computed on column construction per the recent null_count changes, there's no longer a potential kernel launch cost to checking has_nulls.  Seems like that would be the preferable choice, allow columns with no nulls (validity buffer or not) to meet the criteria of a schema calling for no nulls.","createdAt":"2023-07-05T16:05:16Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-1622064040","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5g7pGx","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"Opened https://github.com/rapidsai/cudf/pull/13675 to fix this limitation.\r\n@jlowe The improvement does not cover sliced columns, is that needed for your use case?","createdAt":"2023-07-07T22:04:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-1626247601","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5hGAg6","author":{"login":"jlowe"},"authorAssociation":"MEMBER","body":"> The improvement does not cover sliced columns, is that needed for your use case?\r\n\r\nThe Java cudf API currently does not provide a way to zero-copy slice columns (it has an interface to slice, but it copies the result to separate columns).  Therefore we should be fine with that limitation.","createdAt":"2023-07-10T13:31:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/7654#issuecomment-1628964922","viewerDidAuthor":false}],"createdAt":"2021-03-19T17:18:52Z","id":"MDU6SXNzdWU4MzYyMTE5MjA=","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NTk=","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"}],"milestone":null,"number":7654,"projectCards":[{"project":{"name":"Bug Squashing"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[BUG] new parquet writer code checks for `nullable` not `has_nulls`","updatedAt":"2023-07-10T13:31:02Z","url":"https://github.com/rapidsai/cudf/issues/7654"}
