{"assignees":[{"id":"MDQ6VXNlcjE5MDEwNTk=","login":"abellina","name":"Alessandro Bellina"},{"id":"MDQ6VXNlcjMxODc5Mzg=","login":"gerashegalov","name":"Gera Shegalov"},{"id":"MDQ6VXNlcjU2Njk1OTMw","login":"nvdbaranec","name":""}],"author":{"id":"MDQ6VXNlcjU2Njk1OTMw","is_bot":false,"login":"nvdbaranec","name":""},"body":"As part of the drive towards implementing the micro-kernel parquet decoding strategy, we would like to start centralizing the core parquet decoding loop into a generic templated implementation that can be reused.  At the high level, all of various parquet kernels are structured similar to this:\r\n```\r\nkernel(PageInfo p)\r\n{\r\n    // page setup, bounds checking (for skip_rows/num_rows), etc\r\n    setup_code();\r\n\r\n   while(there are still values to decode in p){\r\n      def_levels = def_stream.decode(def_levels);\r\n      rep_levels = p.has_lists ? rep_stream.decode(rep_levels);\r\n      dict_indices = p.has_dict ? dict_stream.decode(dict_indices);\r\n      decode_general_outputs(def_levels, rep_levels, dict_indices);\r\n\r\n      PROCESS(p, def_levels, rep_levels, dict_indices);\r\n   }\r\n}\r\n```\r\nThe various *_stream.decode() functions are the key bottleneck in decoding parquet data. At the moment, the kernels we have mostly utilize the older/slower way of decoding these streams.  The `rle_stream` class was developed to do this in a more parallel (and more confiurable) way, but only a few kernels use it at the moment because it does not currently handle dictionaries.  The work for that is underway and very close to completion (https://github.com/rapidsai/cudf/issues/14950)\r\n\r\n`decode_general_outputs` is a function that produces validity, list offset information and the mapping of source data (location in the parquet data page) to destination data (location in the final cudf column).  The amount of work this function has to do varies greatly based on the characteristics of the input data - nullability, presence of lists, etc.\r\n\r\nPROCESS is something that varies from kernel-to-kernel.  Essentially, the user-provided function that actually does the final data decoding.\r\n\r\nWe would like to implement this high level loop as a templated function that can be tailored to produce multiple, more optimal kernels based on they key data characteristics. For example:\r\n\r\n```\r\ntemplate<// page data characteristics\r\n                bool nullable,\r\n                bool has_lists,\r\n                bool has_dictionary,\r\n                etc\r\n\r\n                // parameters which can be tuned \r\n                int decode_buffer_size,\r\n                int decode_warp_count,\r\n                etc,\r\n                \r\n                // user provided PROCESS functor\r\n                ProcessFunc Proc>\r\n```\r\n\r\nThere are several reasons to do this:\r\n- The `rle_stream` class uses shared memory, so it is a big advantage to be able to have kernels that don't need a given feature (say, list decoding) to be able to use less.\r\n- It is useful to be able to tune block size per kernel as they tend to get bottlenecked in different ways.  \r\n- It would allow us to eliminate the old level decoding path.\r\n\r\nThe first candidates for using this would be two new micro-kernels:  Fixed-width and fixed-width-with-dictionaries (the non-list case for both of them). We would like to get these in for 24.04 and then later on we can start refactoring the larger mass of existing kernels (especially the general-purpose `gpuDecodePageData` and `gpuDecodeStringPageData`","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5yj_2D","author":{"login":"nvdbaranec"},"authorAssociation":"CONTRIBUTOR","body":"@mattahrens @abellina ","createdAt":"2024-02-01T19:10:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14953#issuecomment-1922039171","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5ykHjR","author":{"login":"nvdbaranec"},"authorAssociation":"CONTRIBUTOR","body":"@etseidl ","createdAt":"2024-02-01T19:26:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14953#issuecomment-1922070737","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5zFPQ5","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"This makes sense to me. Sounds beneficial even if we don't apply the pattern to all kernels.\r\nCould you help me understand the following? \r\n> The rle_stream class uses shared memory, so it is a big advantage to be able to have kernels that don't need a given feature (say, list decoding) to be able to use less.\r\n\r\nIs this explaining the benefit over `rle_stream`?","createdAt":"2024-02-06T21:08:04Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/14953#issuecomment-1930753081","viewerDidAuthor":false}],"createdAt":"2024-02-01T19:09:50Z","id":"I_kwDOBWUGps599eH3","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"},{"id":"MDU6TGFiZWwxMzIyMjUyNjE3","name":"Performance","description":"Performance related issue","color":"C2E0C6"}],"milestone":{"number":22,"title":"Parquet continuous improvement","description":"","dueOn":null},"number":14953,"projectCards":[],"projectItems":[],"reactionGroups":[{"content":"HEART","users":{"totalCount":2}}],"state":"OPEN","title":"[FEA] Implement a templated parquet decoding kernel suitable for reuse in micro-kernel optimization approach.","updatedAt":"2024-04-11T20:56:42Z","url":"https://github.com/rapidsai/cudf/issues/14953"}
