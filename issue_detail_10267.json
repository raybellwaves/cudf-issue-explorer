{"assignees":[],"author":{"id":"MDQ6VXNlcjEzMjA3MDY=","is_bot":false,"login":"wbo4958","name":"Bobby Wang"},"body":"This is part of FEA of https://github.com/NVIDIA/spark-rapids/issues/9\r\nWe have a JSON file\r\n\r\n``` json\r\n{\"name\":\r\n   \"Reynold Xin\"}\r\n```\r\n\r\nSpark can parse it when enabling `multiLine`\r\n\r\nCUDF parsing will throw an exception\r\n\r\nWe expect there is a configure `multiLine` to control this behavior. ","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps49sePv","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"This is primarily to document what Spark supports. I don't see this being a high priority at any point int he future. This is because Spark cannot split files with this type of processing, and it would make it very difficult for us to be able to do this in an efficient way.","createdAt":"2022-02-10T15:39:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1035068399","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps4-ClrS","author":{"login":"vuule"},"authorAssociation":"CONTRIBUTOR","body":"Is this expected to work with JSON Lines format?","createdAt":"2022-02-15T22:34:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1040866002","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps4-Ggqn","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"By definition it is not the same. https://spark.apache.org/docs/latest/sql-data-sources-json.html explains some of this, but not very well. Even the example file that they point to is not in a multi-line format.\r\n\r\nhttps://github.com/apache/spark/blob/master/python/test_support/sql/people_array.json is a better example of a multi-line format. If we do want to support this, which I have my doubts is worth out time I can get more details about this.","createdAt":"2022-02-16T17:12:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1041894055","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps4_746f","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2022-03-18T18:06:46Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1072664223","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5DPjF5","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"Moved this to low priority to match what we do with CSV where this is low priority.","createdAt":"2022-05-16T21:21:25Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1128149369","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Imyw2","author":{"login":"elstehle"},"authorAssociation":"CONTRIBUTOR","body":"> https://github.com/apache/spark/blob/master/python/test_support/sql/people_array.json is a better example of a multi-line format. If we do want to support this, which I have my doubts is worth out time I can get more details about this.\r\n\r\nThanks for elaborating, @revans2! We plan to have support for `multiline` by default in the new nested parser. \r\n\r\n\r\nin case of `lines=true` (parsing [ndjson](http://ndjson.org/)), we plan to support line breaks within nested structs, treating those newlines as whitespace. We will only parse newlines as _delimiters_ at the _root_ level. The following will parse to three rows of two columns\r\n```\r\n{\"a\":\"col0_row0\", \"b\":\"col1_row0\"}\r\n{\"a\":\"col0_row1\", \r\n\"b\":\"col1_row1\"}\r\n{\"a\":\"col0_row2\", \"b\":\"col1_row2\"}\r\n```\r\n\r\nFor `lines=false` (parsing [regular JSON](http://json.org/) that expects to have _a single_ JSON value at the root of the document): Outside of quotes, newlines are generally treated as part of whitespace and will be ignored. This gives the same data as above, but the enclosing brackets are required `[...]`\r\n\r\n```\r\n[\r\n{\"a\":\"col0_row0\", \"b\":\"col1_row0\"}\r\n{\"a\":\"col0_row1\", \r\n\"b\":\"col1_row1\"}\r\n{\"a\":\"col0_row2\", \"b\":\"col1_row2\"}\r\n]\r\n```\r\n\r\nWhat is still unclear to me in case of Spark is whether `multiline` would also influence whether Spark should expect [ndjson](http://ndjson.org/) or [regular JSON](http://json.org/).\r\n\r\nI've seen the following Spark example (but am not sure about the options that were used while parsing):\r\n```\r\n[{\"a\": 1}, {\"b\": 2}, {\"c\": 3}]\r\n\r\n+----+----+----+\r\n|   a|   b|   c|\r\n+----+----+----+\r\n|   1|null|null|\r\n|null|   2|null|\r\n|null|null|   3|\r\n+----+----+----+\r\n```\r\n\r\nThis would also correspond to the new nested parser for `lines=false` (i.e., [regular JSON](http://json.org/)). \r\n\r\nWhat would Spark output for:\r\n```\r\n[{\"a\": 1}, {\"b\": 2}, {\"c\": 3}]\r\n[{\"a\": 21}, {\"b\": 22}, {\"c\": 23}]\r\n```\r\n","createdAt":"2022-08-17T15:00:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1218128950","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5InOP_","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"A lot of this depends on the schema passed into Spark. Along with the schema that spark picks if you don't provide one.\r\n\r\nFor \r\n```\r\n{\"a\":\"col0_row0\", \"b\":\"col1_row0\"}\r\n{\"a\":\"col0_row1\", \r\n\"b\":\"col1_row1\"}\r\n{\"a\":\"col0_row2\", \"b\":\"col1_row2\"}\r\n```\r\n\r\nIf multi-line is not enabled any line on it's own that is not a valid JSON statement results in an error.  If Spark is asked to generate the schema it is going to use, and it sees an error like this it will insert in a new column. The name of the column is configurable, but by default it is \"_corrupt_record\" so the schema it picks here is.\r\n\r\n```\r\nroot                                                                            \r\n |-- _corrupt_record: string (nullable = true)\r\n |-- a: string (nullable = true)\r\n |-- b: string (nullable = true)\r\n```\r\n\r\nand the data is \r\n```\r\n+------------------+---------+---------+\r\n|   _corrupt_record|        a|        b|\r\n+------------------+---------+---------+\r\n|              null|col0_row0|col1_row0|\r\n|{\"a\":\"col0_row1\", |     null|     null|\r\n|  \"b\":\"col1_row1\"}|     null|     null|\r\n|              null|col0_row2|col1_row2|\r\n+------------------+---------+---------+\r\n```\r\n\r\nIf we see a schema with this _corrupt_record in it we fall back to the CPU for now.  But if someone gives us a schema like `a STRING, b STRING` we end up with the same number of rows 4.\r\n\r\n```\r\n+---------+---------+\r\n|        a|        b|\r\n+---------+---------+\r\n|col0_row0|col1_row0|\r\n|     null|     null|\r\n|     null|     null|\r\n|col0_row2|col1_row2|\r\n+---------+---------+\r\n```\r\n\r\nIf we enable multiline here, only the first full JSON item from the file is parsed, and it does not see any errors.\r\n\r\n```\r\nroot\r\n |-- a: string (nullable = true)\r\n |-- b: string (nullable = true)\r\n\r\n+---------+---------+\r\n|        a|        b|\r\n+---------+---------+\r\n|col0_row0|col1_row0|\r\n+---------+---------+\r\n```\r\n\r\n\r\nIf we switch over to \r\n```\r\n[\r\n{\"a\":\"col0_row0\", \"b\":\"col1_row0\"},\r\n{\"a\":\"col0_row1\", \r\n\"b\":\"col1_row1\"},\r\n{\"a\":\"col0_row2\", \"b\":\"col1_row2\"},\r\n]\r\n```\r\nIt behaves similarly, in that it sees `]` and `[` as corrupt records too.  Note that I added commas after each JSON entry or else it would not be a valid JSON file. Spark sees this and throws an exception when doing schema discovery.\r\n\r\n```\r\n+------------------+---------+---------+                                        \r\n|   _corrupt_record|        a|        b|\r\n+------------------+---------+---------+\r\n|                 [|     null|     null|\r\n|              null|col0_row0|col1_row0|\r\n|{\"a\":\"col0_row1\", |     null|     null|\r\n| \"b\":\"col1_row1\"},|     null|     null|\r\n|              null|col0_row2|col1_row2|\r\n|                 ]|     null|     null|\r\n+------------------+---------+---------+\r\n```\r\n\r\nIf we enable multi-line, then we get back what you expect.\r\n```\r\n+---------+---------+\r\n|        a|        b|\r\n+---------+---------+\r\n|col0_row0|col1_row0|\r\n|col0_row1|col1_row1|\r\n|col0_row2|col1_row2|\r\n+---------+---------+\r\n```\r\n\r\nFor the data set\r\n```\r\n[{\"a\": 1}, {\"b\": 2}, {\"c\": 3}]\r\n[{\"a\": 21}, {\"b\": 22}, {\"c\": 23}]\r\n```\r\n\r\nIf multiline is disabled I get back\r\n\r\n```\r\n+----+----+----+\r\n|   a|   b|   c|\r\n+----+----+----+\r\n|   1|null|null|\r\n|null|   2|null|\r\n|null|null|   3|\r\n|  21|null|null|\r\n|null|  22|null|\r\n|null|null|  23|\r\n+----+----+----+\r\n```\r\n\r\nBut if it is enabled it will only parse the first line of data.\r\n\r\n```\r\n+----+----+----+\r\n|   a|   b|   c|\r\n+----+----+----+\r\n|   1|null|null|\r\n|null|   2|null|\r\n|null|null|   3|\r\n+----+----+----+\r\n```\r\n\r\nSpark is looking at the top level item for each entry. If the top level is an array, then it will treat each item in the array as a separate row.","createdAt":"2022-08-17T16:25:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1218241535","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Iq35t","author":{"login":"elstehle"},"authorAssociation":"CONTRIBUTOR","body":"Thanks so much for putting together these examples, @revans2!\r\n\r\nI'm inferring from these examples that `multiline=true` means parsing [regular JSON](http://json.org/) and `multiline=false` means parsing [ndjson](http://ndjson.org/). \r\n\r\nWhile the data parsed for `multiline=true` seems reasonable to me, I cannot really make sense of all `multiline=false` examples.\r\n\r\n> For \r\n> ```\r\n> {\"a\":\"col0_row0\", \"b\":\"col1_row0\"}\r\n> {\"a\":\"col0_row1\", \r\n> \"b\":\"col1_row1\"}\r\n> {\"a\":\"col0_row2\", \"b\":\"col1_row2\"}\r\n> ```\r\n> \r\n> If multi-line is not enabled any line on it's own that is not a valid JSON statement results in an error.\r\n> \r\n> ```\r\n> root                                                                            \r\n>  |-- _corrupt_record: string (nullable = true)\r\n>  |-- a: string (nullable = true)\r\n>  |-- b: string (nullable = true)\r\n> ```\r\n> \r\n> and the data is \r\n> ```\r\n> +------------------+---------+---------+\r\n> |   _corrupt_record|        a|        b|\r\n> +------------------+---------+---------+\r\n> |              null|col0_row0|col1_row0|\r\n> |{\"a\":\"col0_row1\", |     null|     null|\r\n> |  \"b\":\"col1_row1\"}|     null|     null|\r\n> |              null|col0_row2|col1_row2|\r\n> +------------------+---------+---------+\r\n> ```\r\n\r\nSo far, seems reasonable. You try to parse one value per row. If you fail you put it into the `corrupt` column.\r\n\r\n> If we see a schema with this _corrupt_record in it we fall back to the CPU for now.  But if someone gives us a schema like `a STRING, b STRING` we end up with the same number of rows 4.\r\n> \r\n> ```\r\n> +---------+---------+\r\n> |        a|        b|\r\n> +---------+---------+\r\n> |col0_row0|col1_row0|\r\n> |     null|     null|\r\n> |     null|     null|\r\n> |col0_row2|col1_row2|\r\n> +---------+---------+\r\n> ```\r\n\r\nStill reasonable. Would infer that, if parsing of a line runs into error at _some point_, that row will become null(?).\r\n\r\n> If we enable multiline here, only the first full JSON item from the file is parsed, and it does not see any errors.\r\n> \r\n> ```\r\n> root\r\n>  |-- a: string (nullable = true)\r\n>  |-- b: string (nullable = true)\r\n> \r\n> +---------+---------+\r\n> |        a|        b|\r\n> +---------+---------+\r\n> |col0_row0|col1_row0|\r\n> +---------+---------+\r\n> ```\r\n\r\nData seems fine. Debatable whether you would want to emit a warning that the overall format isn't valid anymore, since you've encountered more than a single top-level item, instead of just silently ignoring all items that follow.\r\n\r\n\r\n> If we switch over to \r\n> ```\r\n> [\r\n> {\"a\":\"col0_row0\", \"b\":\"col1_row0\"},\r\n> {\"a\":\"col0_row1\", \r\n> \"b\":\"col1_row1\"},\r\n> {\"a\":\"col0_row2\", \"b\":\"col1_row2\"},\r\n> ]\r\n> ```\r\n> It behaves similarly, in that it sees `]` and `[` as corrupt records too.  Note that I added commas after each JSON entry or else it would not be a valid JSON file. Spark sees this and throws an exception when doing schema discovery.\r\n> \r\n> ```\r\n> +------------------+---------+---------+                                        \r\n> |   _corrupt_record|        a|        b|\r\n> +------------------+---------+---------+\r\n> |                 [|     null|     null|\r\n> |              null|col0_row0|col1_row0|\r\n> |{\"a\":\"col0_row1\", |     null|     null|\r\n> | \"b\":\"col1_row1\"},|     null|     null|\r\n> |              null|col0_row2|col1_row2|\r\n> |                 ]|     null|     null|\r\n> +------------------+---------+---------+\r\n> ```\r\n\r\nMakes sense. We'll run into an error parsing lines `[0, 2, 3, 5]`. We put those lines as string values into the `_corrupt_record`. _But_ would the commas really be needed for `multiline=false`?\r\n\r\n> If we enable multi-line, then we get back what you expect.\r\n> ```\r\n> +---------+---------+\r\n> |        a|        b|\r\n> +---------+---------+\r\n> |col0_row0|col1_row0|\r\n> |col0_row1|col1_row1|\r\n> |col0_row2|col1_row2|\r\n> +---------+---------+\r\n> ```\r\n\r\nMakes sense. Regular JSON, single top-level `LIST` item. \r\n\r\n> For the data set\r\n> ```\r\n> [{\"a\": 1}, {\"b\": 2}, {\"c\": 3}]\r\n> [{\"a\": 21}, {\"b\": 22}, {\"c\": 23}]\r\n> ```\r\n> \r\n> If multiline is disabled I get back\r\n> \r\n> ```\r\n> +----+----+----+\r\n> |   a|   b|   c|\r\n> +----+----+----+\r\n> |   1|null|null|\r\n> |null|   2|null|\r\n> |null|null|   3|\r\n> |  21|null|null|\r\n> |null|  22|null|\r\n> |null|null|  23|\r\n> +----+----+----+\r\n> ```\r\n\r\nThis is where things get funky for me. I would expect that each JSON line becomes a row. Hence, single column where each row is a `list`. The `list` being a `list-of-{a:int,b:int,c:int}`. This may, however, also relate to the question of how Spark would distribute deeper nesting amongst columns and rows in a table. \r\n\r\n> But if it is enabled it will only parse the first line of data.\r\n> \r\n> ```\r\n> +----+----+----+\r\n> |   a|   b|   c|\r\n> +----+----+----+\r\n> |   1|null|null|\r\n> |null|   2|null|\r\n> |null|null|   3|\r\n> +----+----+----+\r\n> ```\r\n\r\nThis makes sense. Becoming a fan of `multiline=true` ðŸ™‚. It parses a regular JSON, it only respects the very first value it finds in the JSON input which is `[{\"a\": 1}, {\"b\": 2}, {\"c\": 3}]`. Each object becomes a row. Each field becomes a column.","createdAt":"2022-08-18T08:40:04Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1219198573","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5IsT1P","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"> Data seems fine. Debatable whether you would want to emit a warning that the overall format isn't valid anymore, since you've encountered more than a single top-level item, instead of just silently ignoring all items that follow.\r\n\r\nI agree. It would be good for spark to output a warning. I would prefer for Spark to output a warning for any garbage data it finds at the end a record after parsing valid JSON, but it does not do that.  That is why the comma at the end of the lines did not make a difference. In Spark all data after the first valid JSON item per record is ignored. Not put into corrupt anything. It is just ignored.  In multi-line the record is the entire file. In ndjson (multiline=false), then each line is a separate record.  At least that is how I think about it.\r\n\r\n>  This is where things get funky for me. I would expect that each JSON line becomes a row. Hence, single column where each row is a list. The list being a list-of-{a:int,b:int,c:int}. This may, however, also relate to the question of how Spark would distribute deeper nesting amongst columns and rows in a table.\r\n\r\nSpark parses the multi-line and the ndjson records almost identically. The big difference is in how the records are split up. Spark decided that a top level array means a list of records so it does that in all cases.  If I have a ndjson file like.\r\n\r\n```\r\n[\"a\", \"b\", \"c\"]\r\n[\"x\", \"y\", \"z\"]\r\n```\r\n\r\nSpark will not be able to get any data out of it. It sees them as corrupt lines. If I give it a schema to try and force Spark to parse something out of it, it sees them as invalid.  What is more it does not seem them as separate records, which is odd to me.\r\n\r\n```\r\nspark.read.schema(\"a Array<STRING>\").json(\"./test.json\").show()\r\n+----+\r\n|   a|\r\n+----+\r\n|null|\r\n|null|\r\n+----+\r\n```\r\n","createdAt":"2022-08-18T14:36:09Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1219575119","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5JOSbr","author":{"login":"elstehle"},"authorAssociation":"CONTRIBUTOR","body":"Thanks for the additional details!\r\n\r\nMy current understanding of Spark's parsing behaviour is this:\r\n\r\n1. A JSON object (`{...}`) maps to a record. \r\n2. In order to parse a record, Spark parses the document until it encounters the first JSON object (`{...}`), it simply ignores other structures (i.e., enclosing lists) along the path to the first JSON object that will be mapped to the record. After that JSON object, it tries to continue parsing the next record.\r\n3. If `multiline` is enabled, it parses just the first item in the JSON. Within that first item, it probably follows the logic from (2).\r\n\r\nThat's how I could make sense of these examples:\r\n\r\n> ```\r\n> [{\"a\": 1}, {\"b\": 2}, {\"c\": 3}]\r\n> [{\"a\": 21}, {\"b\": 22}, {\"c\": 23}]\r\n> ```\r\n> ```\r\n> multiline disabled\r\n> +----+----+----+\r\n> |   a|   b|   c|\r\n> +----+----+----+\r\n> |   1|null|null|\r\n> |null|   2|null|\r\n> |null|null|   3|\r\n> |  21|null|null|\r\n> |null|  22|null|\r\n> |null|null|  23|\r\n> +----+----+----+\r\n> ```\r\n> multiline enabled\r\n> ```\r\n> +----+----+----+\r\n> |   a|   b|   c|\r\n> +----+----+----+\r\n> |   1|null|null|\r\n> |null|   2|null|\r\n> |null|null|   3|\r\n> +----+----+----+\r\n> ```\r\n\r\nIf that's right, then the question would be, how wild this can be. E.g.:\r\n```\r\n[{\"a\":1.1},\r\n[{\"b\":2.2}]]\r\n```","createdAt":"2022-08-26T13:22:05Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1228482283","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5JQDBi","author":{"login":"revans2"},"authorAssociation":"CONTRIBUTOR","body":"If I enable multiline, then it sees the entire thing as corrupt. I think this is because the second item in the top level list is another list, not an object. If multiline is disabled then just the first line is corrupt and the second line can be parsed.\r\n\r\n```\r\n+---------------+----+\r\n|_corrupt_record|   b|\r\n+---------------+----+\r\n|    [{\"a\":1.1},|null|\r\n|           null| 2.2|\r\n+---------------+----+\r\n```\r\n\r\nI am not sure that we have to make it match perfectly all of the time in all error cases. It really would be nice if we could do that, but I am much more concerned about making it work in the positive use cases.","createdAt":"2022-08-26T21:01:07Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1228943458","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5JQwXm","author":{"login":"elstehle"},"authorAssociation":"CONTRIBUTOR","body":"> If I enable multiline, then it sees the entire thing as corrupt. I think this is because the second item in the top level list is another list, not an object. If multiline is disabled then just the first line is corrupt and the second line can be parsed.\r\n> \r\n> ```\r\n> +---------------+----+\r\n> |_corrupt_record|   b|\r\n> +---------------+----+\r\n> |    [{\"a\":1.1},|null|\r\n> |           null| 2.2|\r\n> +---------------+----+\r\n> ```\r\n> \r\n> I am not sure that we have to make it match perfectly all of the time in all error cases. It really would be nice if we could do that, but I am much more concerned about making it work in the positive use cases.\r\n\r\nThanks, Bobby! Agreed. Let's focus on getting the correct cases right, for now. \r\n\r\nAfter this example, I'm giving up on trying to develop an idea about the underlying logic for not-well-formatted inputs. After all, in case of `multiline=False`, the two lines begin identical, the first row fails the second one succeeds. ðŸ¤· ","createdAt":"2022-08-27T05:44:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1229129190","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5JSEE5","author":{"login":"elstehle"},"authorAssociation":"CONTRIBUTOR","body":"Btw., I suppose that https://github.com/rapidsai/cudf/pull/11574 will make big leaps towards meeting this feature request in the `experimental` parser. \r\n\r\nSpecifically, \r\n- `lines=True` will correspond to `multiline=False`.\r\n- `lines=False` will correspond to `multiline=True`.\r\n\r\nWhat _may_ remain to be addressed are the corner cases raised by the fuzzy behaviour we are seeing from Spark's JSON parser. Mostly related to invalid JSON.\r\n\r\n1. In particular for `multiline=True`, silently ignoring JSON items other than the first JSON item encountered in the input (which I'm not a fan of). Our current behaviour in the `experimental` parser is to fail after the first JSON item instead of ignoring any subsequent input:\r\n> Spark ignores any text content after the end of the JSON record so we would need to be able to support that\r\n\r\n2. The fuzzy logic(ðŸ¤·) that will parse records when they are not at the root of the line: \r\n> ```\r\n> [{\"a\": 1}, {\"b\": 2}, {\"c\": 3}]\r\n> [{\"a\": 21}, {\"b\": 22}, {\"c\": 23}]\r\n> ```\r\n> ```\r\n> multiline disabled\r\n> +----+----+----+\r\n> |   a|   b|   c|\r\n> +----+----+----+\r\n> |   1|null|null|\r\n> |null|   2|null|\r\n> |null|null|   3|\r\n> |  21|null|null|\r\n> |null|  22|null|\r\n> |null|null|  23|\r\n> +----+----+----+\r\n> ```\r\n\r\nCan you comment on how relevant these corner cases are for you?","createdAt":"2022-08-28T14:29:04Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/10267#issuecomment-1229472057","viewerDidAuthor":false}],"createdAt":"2022-02-10T09:18:20Z","id":"I_kwDOBWUGps5DVbTG","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"}],"milestone":{"number":13,"title":"Nested JSON reader","description":"Data-parallel reader for nested JSON text data","dueOn":null},"number":10267,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] JSON reader: support multi-lines","updatedAt":"2023-04-02T22:39:14Z","url":"https://github.com/rapidsai/cudf/issues/10267"}
