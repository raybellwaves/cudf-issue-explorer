{"assignees":[],"author":{"id":"MDQ6VXNlcjMwNjM4MA==","is_bot":false,"login":"mrocklin","name":"Matthew Rocklin"},"body":"**Describe the bug**\r\n\r\nIt takes a few seconds to import cudf today\r\n\r\n**Steps/Code to reproduce bug**\r\n\r\n```\r\nIn [1]: import numpy, pandas\r\n\r\nIn [2]: %time import cudf\r\nCPU times: user 432 ms, sys: 132 ms, total: 564 ms\r\nWall time: 2.44 s\r\n```\r\n\r\n<details>\r\n\r\n```\r\n**git***\r\ncommit ab3f45857f641548f6d64d977908075d63c193bf (HEAD -> repr-html, mrocklin/repr-html)\r\nAuthor: Matthew Rocklin <mrocklin@gmail.com>\r\nDate:   Thu Jan 3 17:35:10 2019 -0800\r\n\r\n    Test repr for both large and small dataframes\r\n\r\n***OS Information***\r\nDGX_NAME=\"DGX Server\"\r\nDGX_PRETTY_NAME=\"NVIDIA DGX Server\"\r\nDGX_SWBUILD_DATE=\"2018-03-20\"\r\nDGX_SWBUILD_VERSION=\"3.1.6\"\r\nDGX_COMMIT_ID=\"1b0f58ecbf989820ce745a9e4836e1de5eea6cfd\"\r\nDGX_SERIAL_NUMBER=QTFCOU8310024\r\n\r\nDGX_OTA_VERSION=\"3.1.7\"\r\nDGX_OTA_DATE=\"Thu Sep 27 20:07:53 PDT 2018\"\r\nDISTRIB_ID=Ubuntu\r\nDISTRIB_RELEASE=16.04\r\nDISTRIB_CODENAME=xenial\r\nDISTRIB_DESCRIPTION=\"Ubuntu 16.04.5 LTS\"\r\nNAME=\"Ubuntu\"\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nID=ubuntu\r\nID_LIKE=debian\r\nPRETTY_NAME=\"Ubuntu 16.04.5 LTS\"\r\nVERSION_ID=\"16.04\"\r\nHOME_URL=\"http://www.ubuntu.com/\"\r\nSUPPORT_URL=\"http://help.ubuntu.com/\"\r\nBUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\r\nVERSION_CODENAME=xenial\r\nUBUNTU_CODENAME=xenial\r\nLinux dgx16 4.4.0-135-generic #161-Ubuntu SMP Mon Aug 27 10:45:01 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n***GPU Information***\r\nThu Jan  3 18:42:10 2019\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\r\n| N/A   42C    P0    59W / 300W |   1085MiB / 32510MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\r\n| N/A   43C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\r\n| N/A   42C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\r\n| N/A   41C    P0    47W / 300W |     11MiB / 32510MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\r\n| N/A   42C    P0    46W / 300W |     11MiB / 32510MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\r\n| N/A   42C    P0    44W / 300W |     11MiB / 32510MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\r\n| N/A   44C    P0    45W / 300W |     11MiB / 32510MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\r\n| N/A   41C    P0    44W / 300W |     11MiB / 32510MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     64394      C   ...klin/miniconda/envs/cudf_dev/bin/python   644MiB |\r\n|    0     65545      C   ...klin/miniconda/envs/cudf_dev/bin/python   430MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n***CPU***\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                80\r\nOn-line CPU(s) list:   0-79\r\nThread(s) per core:    2\r\nCore(s) per socket:    20\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz\r\nStepping:              1\r\nCPU MHz:               2030.789\r\nCPU max MHz:           3600.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4391.76\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              51200K\r\nNUMA node0 CPU(s):     0-19,40-59\r\nNUMA node1 CPU(s):     20-39,60-79\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt ssbd ibrs ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts flush_l1d\r\n\r\n***CMake***\r\n/home/nfs/mrocklin/miniconda/envs/cudf_dev/bin/cmake\r\ncmake version 3.13.2\r\n\r\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\r\n\r\n***g++***\r\n/usr/bin/g++\r\ng++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n***nvcc***\r\n\r\n***Python***\r\n/home/nfs/mrocklin/miniconda/envs/cudf_dev/bin/python\r\nPython 3.5.5\r\n\r\n***Environment Variables***\r\nPATH                            : /home/nfs/mrocklin/miniconda/envs/cudf_dev/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/miniconda/bin:/home/nfs/mrocklin/bin:/home/nfs/mrocklin/.local/bin:/home/nfs/mrocklin/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\r\nLD_LIBRARY_PATH                 :\r\nNUMBAPRO_NVVM                   :\r\nNUMBAPRO_LIBDEVICE              :\r\nCONDA_PREFIX                    : /home/nfs/mrocklin/miniconda/envs/cudf_dev\r\nPYTHON_PATH                     :\r\n\r\n***conda packages***\r\n/home/nfs/mrocklin/miniconda/bin/conda\r\n# packages in environment at /home/nfs/mrocklin/miniconda/envs/cudf_dev:\r\n#\r\n# Name                    Version                   Build  Channel\r\nalabaster                 0.7.12                     py_0    conda-forge\r\narrow-cpp                 0.10.0           py35h70250a7_0    conda-forge\r\nasn1crypto                0.24.0                   py35_3    conda-forge\r\natomicwrites              1.2.1                      py_0    conda-forge\r\nattrs                     18.2.0                     py_0    conda-forge\r\nbabel                     2.6.0                      py_1    conda-forge\r\nbackcall                  0.1.0                      py_0    conda-forge\r\nblas                      1.0                         mkl\r\nbleach                    3.0.2                      py_1    conda-forge\r\nbokeh                     0.13.0                   py35_0\r\nboost                     1.67.0           py35h3e44d54_0    conda-forge\r\nboost-cpp                 1.67.0               h3a22d5f_0    conda-forge\r\nbzip2                     1.0.6                h470a237_2    conda-forge\r\nca-certificates           2018.03.07                    0\r\ncertifi                   2018.8.24                py35_1\r\ncffi                      1.11.5           py35h5e8e0c9_1    conda-forge\r\nchardet                   3.0.4                    py35_3    conda-forge\r\nclick                     7.0                        py_0    conda-forge\r\ncloudpickle               0.6.1                      py_0    conda-forge\r\ncmake                     3.13.2               h011004d_0    conda-forge\r\ncommonmark                0.5.4                      py_2    conda-forge\r\ncryptography              2.3.1            py35hdffb7b8_0    conda-forge\r\ncryptography-vectors      2.3.1                    py35_0    conda-forge\r\ncudatoolkit               9.2                           0\r\ncudf                      0.4.0+385.g81a187d           <pip>\r\ncurl                      7.63.0               h74213dd_0    conda-forge\r\ncython                    0.28.5           py35hfc679d8_0    conda-forge\r\ncytoolz                   0.9.0.1          py35h470a237_0    conda-forge\r\ndask                      1.0.0+51.g2ca205b           <pip>\r\ndask-core                 1.0.0                      py_0    conda-forge\r\ndask-cuda                 0.0.0                     <pip>\r\ndask-cudf                 0.0.1+222.g10a9f90.dirty           <pip>\r\ndecorator                 4.3.0                      py_0    conda-forge\r\ndistributed               1.23.2                   py35_1    conda-forge\r\ndistributed               1.25.1+10.ga0d0ed2           <pip>\r\ndocutils                  0.14                     py35_1    conda-forge\r\nentrypoints               0.2.3                    py35_2    conda-forge\r\nexpat                     2.2.5                hfc679d8_2    conda-forge\r\nfuture                    0.16.0                   py35_2    conda-forge\r\ngmp                       6.1.2                hfc679d8_0    conda-forge\r\nheapdict                  1.0.0                 py35_1000    conda-forge\r\nicu                       58.2                 hfc679d8_0    conda-forge\r\nidna                      2.7                      py35_2    conda-forge\r\nimagesize                 1.1.0                      py_0    conda-forge\r\nintel-openmp              2019.1                      144\r\nipykernel                 5.1.0              pyh24bf2e0_0    conda-forge\r\nipython                   7.0.1            py35h24bf2e0_0    conda-forge\r\nipython_genutils          0.2.0                      py_1    conda-forge\r\njedi                      0.12.1                   py35_0    conda-forge\r\njinja2                    2.10                       py_1    conda-forge\r\njsonschema                2.6.0                    py35_2    conda-forge\r\njupyter_client            5.2.4                      py_0    conda-forge\r\njupyter_core              4.4.0                      py_0    conda-forge\r\nkrb5                      1.16.2               hbb41f41_0    conda-forge\r\nlibcurl                   7.63.0               hbdb9355_0    conda-forge\r\nlibedit                   3.1.20170329         haf1bffa_1    conda-forge\r\nlibffi                    3.2.1                hfc679d8_5    conda-forge\r\nlibgcc-ng                 8.2.0                hdf63c60_1\r\nlibgdf-cffi               0.4.0                     <pip>\r\nlibgfortran-ng            7.2.0                hdf63c60_3    conda-forge\r\nlibrmm-cffi               0.4.0                     <pip>\r\nlibsodium                 1.0.16               h470a237_1    conda-forge\r\nlibssh2                   1.8.0                h5b517e9_3    conda-forge\r\nlibstdcxx-ng              8.2.0                hdf63c60_1\r\nlibuv                     1.24.1               h470a237_0    conda-forge\r\nllvmlite                  0.27.0           py35hf484d3e_0    numba\r\nMarkdown                  2.6.11                    <pip>\r\nmarkupsafe                1.0              py35h470a237_1    conda-forge\r\nmistune                   0.8.3            py35h470a237_2    conda-forge\r\nmkl                       2018.0.3                      1\r\nmkl_fft                   1.0.9                    py35_0    conda-forge\r\nmkl_random                1.0.1                    py35_0    conda-forge\r\nmore-itertools            4.3.0                    py35_0    conda-forge\r\nmsgpack-python            0.5.6            py35h2d50403_3    conda-forge\r\nnbconvert                 5.3.1                      py_1    conda-forge\r\nnbformat                  4.4.0                      py_1    conda-forge\r\nncurses                   6.1                  hfc679d8_2    conda-forge\r\nnotebook                  5.7.0                    py35_0    conda-forge\r\nnumba                     0.42.0          np115py35hf484d3e_0    numba\r\nnumpy                     1.15.2           py35h1d66e8a_0\r\nnumpy-base                1.15.2           py35h81de0dd_0\r\nnumpydoc                  0.8.0                      py_1    conda-forge\r\nnvstrings                 0.1.0            cuda9.2_py35_0    nvidia\r\nopenssl                   1.0.2p               h14c3975_0\r\npackaging                 18.0                       py_0    conda-forge\r\npandas                    0.20.3                   py35_1    conda-forge\r\npandoc                    2.5                           0    conda-forge\r\npandocfilters             1.4.2                      py_1    conda-forge\r\nparquet-cpp               1.5.0.pre            h83d4a3d_0    conda-forge\r\nparso                     0.3.1                      py_0    conda-forge\r\npathlib2                  2.3.2                    py35_0    conda-forge\r\npexpect                   4.6.0                    py35_0    conda-forge\r\npickleshare               0.7.5                    py35_0    conda-forge\r\npip                       18.0                  py35_1001    conda-forge\r\npluggy                    0.8.0                      py_0    conda-forge\r\nprometheus_client         0.5.0                      py_0    conda-forge\r\nprompt_toolkit            2.0.7                      py_0    conda-forge\r\npsutil                    5.4.7            py35h470a237_1    conda-forge\r\nptyprocess                0.6.0                 py35_1000    conda-forge\r\npy                        1.7.0                      py_0    conda-forge\r\npyarrow                   0.10.0           py35hfc679d8_0    conda-forge\r\npycparser                 2.19                       py_0    conda-forge\r\npygments                  2.3.1                      py_0    conda-forge\r\npyopenssl                 18.0.0                   py35_0    conda-forge\r\npyparsing                 2.3.0                      py_0    conda-forge\r\npysocks                   1.6.8                    py35_2    conda-forge\r\npytest                    4.0.2                     <pip>\r\npytest                    3.8.1                    py35_0\r\npython                    3.5.5                h5001a0f_2    conda-forge\r\npython-dateutil           2.7.5                      py_0    conda-forge\r\npytz                      2018.7                     py_0    conda-forge\r\npyyaml                    3.13             py35h470a237_1    conda-forge\r\npyzmq                     17.1.2           py35hae99301_0    conda-forge\r\nreadline                  7.0                  haf1bffa_1    conda-forge\r\nrecommonmark              0.4.0                      py_2    conda-forge\r\nrequests                  2.19.1                   py35_1    conda-forge\r\nrhash                     1.3.6                h470a237_1    conda-forge\r\nsend2trash                1.5.0                      py_0    conda-forge\r\nsetuptools                40.4.3                   py35_0    conda-forge\r\nsimplegeneric             0.8.1                      py_1    conda-forge\r\nsix                       1.11.0                   py35_1    conda-forge\r\nsnowballstemmer           1.2.1                      py_1    conda-forge\r\nsortedcontainers          2.1.0                      py_0    conda-forge\r\nsphinx                    1.8.1                    py35_0    conda-forge\r\nsphinx-markdown-tables    0.0.9                     <pip>\r\nsphinx_rtd_theme          0.4.2                      py_0    conda-forge\r\nsphinxcontrib-websupport  1.1.0                      py_1    conda-forge\r\nsqlite                    3.26.0               hb1c47c0_0    conda-forge\r\ntblib                     1.3.2                      py_1    conda-forge\r\nterminado                 0.8.1                    py35_1    conda-forge\r\ntestpath                  0.3.1                    py35_1    conda-forge\r\ntk                        8.6.9                ha92aebf_0    conda-forge\r\ntoolz                     0.9.0                      py_1    conda-forge\r\ntornado                   5.1.1            py35h470a237_0    conda-forge\r\ntraitlets                 4.3.2                    py35_0    conda-forge\r\nurllib3                   1.23                     py35_1    conda-forge\r\nwcwidth                   0.1.7                      py_1    conda-forge\r\nwebencodings              0.5.1                      py_1    conda-forge\r\nwheel                     0.32.0                py35_1000    conda-forge\r\nxz                        5.2.4                h470a237_1    conda-forge\r\nyaml                      0.1.7                h470a237_1    conda-forge\r\nzeromq                    4.2.5                hfc679d8_6    conda-forge\r\nzict                      0.1.3                      py_0    conda-forge\r\nzlib                      1.2.11               h470a237_3    conda-forge\r\n```\r\n\r\n</details>","closed":false,"closedAt":null,"comments":[{"id":"MDEyOklzc3VlQ29tbWVudDQ2NjU0OTA3Ng==","author":{"login":"mrocklin"},"authorAssociation":"COLLABORATOR","body":"Increasing\r\n\r\n```python\r\nIn [1]: %time import cudf\r\nCPU times: user 556 ms, sys: 204 ms, total: 760 ms\r\nWall time: 3.39 s\r\n```","createdAt":"2019-02-22T21:10:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-466549076","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDQ2NjU0OTM2Mg==","author":{"login":"mrocklin"},"authorAssociation":"COLLABORATOR","body":"Looking at the profile it looks like we're doing a lot of odd things at import time\r\n\r\n```\r\n         367424 function calls (356126 primitive calls) in 3.046 seconds\r\n\r\n   Ordered by: internal time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n      572    0.610    0.001    0.621    0.001 <frozen importlib._bootstrap_external>:914(get_data)\r\n     3250    0.605    0.000    0.605    0.000 {built-in method posix.stat}\r\n        3    0.573    0.191    0.573    0.191 {method 'read' of '_io.BufferedReader' objects}\r\n      599    0.296    0.000    0.296    0.000 {built-in method io.open}\r\n      597    0.256    0.000    0.256    0.000 {method 'close' of '_io.BufferedReader' objects}\r\n    74/73    0.079    0.001    0.082    0.001 {built-in method _imp.create_dynamic}\r\n      572    0.076    0.000    0.076    0.000 {built-in method marshal.loads}\r\n        1    0.040    0.040    0.041    0.041 nvvm.py:106(__new__)\r\n       82    0.039    0.000    0.039    0.000 {built-in method posix.listdir}\r\n2000/1992    0.028    0.000    0.075    0.000 {built-in method builtins.__build_class__}\r\n      547    0.019    0.000    0.019    0.000 ffi.py:106(__call__)\r\n        2    0.017    0.008    0.017    0.008 {method 'dlopen' of 'CompiledFFI' objects}\r\n    74/59    0.015    0.000    0.901    0.015 {built-in method _imp.exec_dynamic}\r\n      921    0.015    0.000    0.015    0.000 {method 'sub' of 're.Pattern' objects}\r\n      613    0.013    0.000    0.013    0.000 {method 'findall' of 're.Pattern' objects}\r\n      572    0.011    0.000    0.011    0.000 {method 'read' of '_io.FileIO' objects}\r\n     1093    0.010    0.000    0.400    0.000 <frozen importlib._bootstrap_external>:1356(find_spec)\r\n        7    0.009    0.001    0.009    0.001 {built-in method posix.read}\r\n        4    0.009    0.002    0.009    0.002 {built-in method _posixsubprocess.fork_exec}\r\n      572    0.009    0.000    0.732    0.001 <frozen importlib._bootstrap_external>:793(get_code)\r\n        1    0.008    0.008    0.008    0.008 {method 'dot' of 'numpy.ndarray' objects}\r\n      211    0.008    0.000    0.008    0.000 sre_compile.py:276(_optimize_charset)\r\n      820    0.007    0.000    0.421    0.001 <frozen importlib._bootstrap>:882(_find_spec)\r\n      592    0.006    0.000    0.586    0.001 __init__.py:78(open_resource)\r\n        4    0.006    0.001    0.006    0.001 {built-in method _ctypes.dlopen}\r\n     8994    0.006    0.000    0.006    0.000 {built-in method builtins.hasattr}\r\n```","createdAt":"2019-02-22T21:11:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-466549362","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxMDQyMjk2OA==","author":{"login":"brandon-b-miller"},"authorAssociation":"CONTRIBUTOR","body":"Profiled this a bit today and on my end it seems like the issue is inside `cudf._cuda.gpu.getDeviceCount()`. ","createdAt":"2020-04-07T14:34:12Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-610422968","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxMDQ0NTA5NA==","author":{"login":"jrhemstad"},"authorAssociation":"CONTRIBUTOR","body":"> Profiled this a bit today and on my end it seems like the issue is inside `cudf._cuda.gpu.getDeviceCount()`.\r\n\r\nI doubt that problem is with that function. My guess is that's just the first function that invokes a CUDA runtime API which initializes the context and other first time setup stuff. ","createdAt":"2020-04-07T15:12:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":3}}],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-610445094","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxMDQ0ODA2OA==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> Profiled this a bit today and on my end it seems like the issue is inside `cudf._cuda.gpu.getDeviceCount()`.\r\n\r\nCould you dump the profile here by any chance?","createdAt":"2020-04-07T15:17:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-610448068","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxMDQ3NDExMQ==","author":{"login":"brandon-b-miller"},"authorAssociation":"CONTRIBUTOR","body":"Here's the top piece of the profile.\r\n\r\n```\r\n         785450 function calls (763821 primitive calls) in 5.156 seconds\r\n\r\n   Ordered by: internal time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    3.047    3.047    3.047    3.047 {cudf._cuda.gpu.getDeviceCount}\r\n      120    0.358    0.003    0.358    0.003 {method 'read' of '_io.BufferedReader' objects}\r\n      945    0.293    0.000    0.307    0.000 <frozen importlib._bootstrap_external>:914(get_data)\r\n     5895    0.280    0.000    0.280    0.000 {built-in method posix.stat}\r\n  204/202    0.143    0.001    0.146    0.001 {built-in method _imp.create_dynamic}\r\n      945    0.109    0.000    0.109    0.000 {built-in method marshal.loads}\r\n      506    0.089    0.000    0.089    0.000 {built-in method posix.listdir}\r\n  204/130    0.045    0.000    0.161    0.001 {built-in method _imp.exec_dynamic}\r\n2851/2818    0.038    0.000    0.133    0.000 {built-in method builtins.__build_class__}\r\n        4    0.025    0.006    0.025    0.006 {built-in method _ctypes.dlopen}\r\n      518    0.024    0.000    0.024    0.000 {built-in method builtins.compile}\r\n     1826    0.016    0.000    0.312    0.000 <frozen importlib._bootstrap_external>:1356(find_spec)\r\n      561    0.015    0.000    0.015    0.000 ffi.py:112(__call__)\r\n      132    0.015    0.000    0.015    0.000 {built-in method io.open}\r\n     1145    0.014    0.000    0.014    0.000 {method 'sub' of 're.Pattern' objects}\r\n      945    0.014    0.000    0.014    0.000 {method 'read' of '_io.FileIO' objects}\r\n        8    0.013    0.002    0.013    0.002 {built-in method posix.read}\r\n  805/193    0.013    0.000    0.035    0.000 sre_parse.py:469(_parse)\r\n        5    0.012    0.002    0.012    0.002 {built-in method _posixsubprocess.fork_exec}\r\n      945    0.011    0.000    0.460    0.000 <frozen importlib._bootstrap_external>:793(get_code)\r\n      614    0.010    0.000    0.012    0.000 sre_compile.py:276(_optimize_charset)\r\n      501    0.010    0.000    0.010    0.000 {method 'findall' of 're.Pattern' objects}\r\n     1215    0.009    0.000    0.333    0.000 <frozen importlib._bootstrap>:882(_find_spec)\r\n16074/16069    0.008    0.000    0.008    0.000 {built-in method builtins.hasattr}\r\n    10147    0.008    0.000    0.020    0.000 <frozen importlib._bootstrap_external>:56(_path_join)\r\n    18447    0.008    0.000    0.009    0.000 {built-in method builtins.getattr}\r\n   1343/1    0.007    0.000    5.158    5.158 {built-in method builtins.exec}\r\n     1578    0.007    0.000    0.021    0.000 version.py:198(__init__)\r\n      114    0.007    0.000    0.021    0.000 __init__.py:1617(_get)\r\n     3039    0.007    0.000    0.010    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\r\n        5    0.007    0.001    0.007    0.001 {built-in method posix.waitpid}\r\n        3    0.007    0.002    0.008    0.003 six.py:1(<module>)\r\n    51125    0.007    0.000    0.008    0.000 {built-in method builtins.isinstance}\r\n     1890    0.007    0.000    0.015    0.000 <frozen importlib._bootstrap_external>:271(cache_from_source)\r\n15643/15615    0.007    0.000    0.011    0.000 abstract.py:121(__hash__)\r\n    10147    0.007    0.000    0.009    0.000 <frozen importlib._bootstrap_external>:58(<listcomp>)\r\n     2850    0.006    0.000    0.006    0.000 {built-in method __new__ of type object at 0x55ed34c9f240}\r\n      349    0.006    0.000    0.007    0.000 templates.py:614(make_overload_template)\r\n   1239/1    0.006    0.000    5.158    5.158 <frozen importlib._bootstrap>:978(_find_and_load)\r\n     3039    0.006    0.000    0.006    0.000 <frozen importlib._bootstrap>:78(acquire)\r\n   1173/1    0.006    0.000    5.157    5.157 <frozen importlib._bootstrap>:663(_load_unlocked)\r\n    18919    0.006    0.000    0.006    0.000 sre_parse.py:233(__next)\r\n     1161    0.005    0.000    0.026    0.000 <frozen importlib._bootstrap>:504(_init_module_attrs)\r\n 1337/180    0.005    0.000    0.018    0.000 sre_compile.py:71(_compile)\r\n   1239/1    0.005    0.000    5.158    5.158 <frozen importlib._bootstrap>:948(_find_and_load_unlocked)\r\n14699/14694    0.005    0.000    0.006    0.000 {method 'join' of 'str' objects}\r\n       40    0.005    0.000    0.023    0.001 castgraph.py:94(propagate)\r\n     3039    0.005    0.000    0.005    0.000 <frozen importlib._bootstrap>:103(release)\r\n     1149    0.005    0.000    0.006    0.000 <frozen importlib._bootstrap_external>:574(spec_from_file_location)\r\n 6132/741    0.004    0.000    1.570    0.002 <frozen importlib._bootstrap>:1009(_handle_fromlist)\r\n    31763    0.004    0.000    0.004    0.000 {method 'startswith' of 'str' objects}\r\n    10345    0.004    0.000    0.004    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\r\n     1208    0.004    0.000    0.317    0.000 <frozen importlib._bootstrap_external>:1240(_get_spec)\r\n    16689    0.004    0.000    0.009    0.000 sre_parse.py:254(get)\r\n       42    0.004    0.000    0.008    0.000 enum.py:135(__new__)\r\n       77    0.004    0.000    0.009    0.000 __init__.py:316(namedtuple)\r\n      790    0.003    0.000    0.004    0.000 version.py:343(_cmpkey)\r\n     1607    0.003    0.000    0.003    0.000 {method 'search' of 're.Pattern' objects}\r\n      945    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:438(_classify_pyc)\r\n    10024    0.003    0.000    0.003    0.000 {method 'rpartition' of 'str' objects}\r\n    945/1    0.003    0.000    5.157    5.157 <frozen importlib._bootstrap_external>:722(exec_module)\r\n      945    0.003    0.000    0.115    0.000 <frozen importlib._bootstrap_external>:523(_compile_bytecode)\r\n     2487    0.003    0.000    0.227    0.000 <frozen importlib._bootstrap_external>:84(_path_is_mode_type)\r\n    13657    0.003    0.000    0.006    0.000 {method 'get' of 'dict' objects}\r\n23704/22175    0.003    0.000    0.003    0.000 {built-in method builtins.len}\r\n2986/2855    0.003    0.000    0.004    0.000 {method 'format' of 'str' objects}\r\n      680    0.003    0.000    0.150    0.000 __init__.py:2126(distributions_from_metadata)\r\n    22762    0.003    0.000    0.003    0.000 {method 'rstrip' of 'str' objects}\r\n     9152    0.003    0.000    0.004    0.000 sre_parse.py:164(__getitem__)\r\n     5258    0.003    0.000    0.250    0.000 <frozen importlib._bootstrap_external>:74(_path_stat)\r\n      689    0.003    0.000    0.003    0.000 functions.py:87(__init__)\r\n     1149    0.003    0.000    0.010    0.000 <frozen importlib._bootstrap_external>:1351(_get_spec)\r\n     1161    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap>:318(__exit__)\r\n    29445    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}\r\n    17714    0.003    0.000    0.003    0.000 abstract.py:99(key)\r\n1161/1158    0.003    0.000    0.177    0.000 <frozen importlib._bootstrap>:576(module_from_spec)\r\n      346    0.003    0.000    0.063    0.000 __init__.py:2585(from_location)\r\n 1568/435    0.003    0.000    0.003    0.000 sre_parse.py:174(getwidth)\r\n      501    0.003    0.000    0.029    0.000 textwrap.py:414(dedent)\r\n     1154    0.003    0.000    0.069    0.000 re.py:271(_compile)\r\n        2    0.002    0.001    0.002    0.001 {method 'poll' of 'select.poll' objects}\r\n     3626    0.002    0.000    0.004    0.000 typing.py:704(__setattr__)\r\n      776    0.002    0.000    0.004    0.000 functools.py:37(update_wrapper)\r\n     7138    0.002    0.000    0.003    0.000 {built-in method builtins.setattr}\r\n      788    0.002    0.000    0.006    0.000 version.py:131(_legacy_cmpkey)\r\n     1800    0.002    0.000    0.010    0.000 <frozen importlib._bootstrap>:194(_lock_unlock_module)\r\n      131    0.002    0.000    0.003    0.000 templates.py:816(make_overload_attribute_template)\r\n      923    0.002    0.000    0.003    0.000 posixpath.py:75(join)\r\n18763/18019    0.002    0.000    0.002    0.000 {built-in method builtins.hash}\r\n     1149    0.002    0.000    0.012    0.000 <frozen importlib._bootstrap_external>:369(_get_cached)\r\n      150    0.002    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:1190(_path_hooks)\r\n      945    0.002    0.000    0.002    0.000 {built-in method _imp._fix_co_filename}\r\n     3092    0.002    0.000    0.003    0.000 {built-in method builtins.any}\r\n     2519    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:416(parent)\r\n     4454    0.002    0.000    0.002    0.000 {method 'match' of 're.Pattern' objects}\r\n     1890    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:62(_path_split)\r\n     2032    0.002    0.000    0.007    0.000 castgraph.py:41(insert)\r\n  580/180    0.002    0.000    0.036    0.000 sre_parse.py:411(_parse_sub)\r\n      481    0.002    0.000    0.007    0.000 typing.py:603(__init__)\r\n     3434    0.002    0.000    0.003    0.000 version.py:114(_parse_version_parts)\r\n     8269    0.002    0.000    0.002    0.000 {method 'group' of 're.Match' objects}\r\n     2835    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:51(_r_long)\r\n     2094    0.002    0.000    0.014    0.000 <frozen importlib._bootstrap>:403(cached)\r\n      454    0.002    0.000    0.019    0.000 __init__.py:1327(safe_version)\r\n     1226    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:176(cb)\r\n2306/2299    0.002    0.000    0.002    0.000 abstract.py:124(__eq__)\r\n     3816    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:859(__exit__)\r\n      960    0.001    0.000    0.004    0.000 typing.py:113(_type_check)\r\n      612    0.001    0.000    0.002    0.000 _inspect.py:67(getargs)\r\n     4435    0.001    0.000    0.001    0.000 {method 'endswith' of 'str' objects}\r\n     2215    0.001    0.000    0.227    0.000 <frozen importlib._bootstrap_external>:93(_path_isfile)\r\n   706/50    0.001    0.000    1.575    0.031 {built-in method builtins.__import__}\r\n     1226    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:58(__init__)\r\n  680/342    0.001    0.000    0.002    0.000 {built-in method _abc._abc_subclasscheck}\r\n     1025    0.001    0.000    0.001    0.000 {method 'split' of 're.Pattern' objects}\r\n       75    0.001    0.000    1.800    0.024 __init__.py:1(<module>)\r\n     1239    0.001    0.000    0.012    0.000 <frozen importlib._bootstrap>:147(__enter__)\r\n  152/132    0.001    0.000    0.023    0.000 {built-in method builtins.sorted}\r\n1410/1302    0.001    0.000    0.018    0.000 typing.py:248(inner)\r\n     4300    0.001    0.000    0.002    0.000 version.py:65(_compare)\r\n  818/815    0.001    0.000    0.009    0.000 abstract.py:63(__call__)\r\n      945    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:471(_validate_timestamp_pyc)\r\n     6786    0.001    0.000    0.001    0.000 {built-in method posix.fspath}\r\n     5184    0.001    0.000    0.001    0.000 {built-in method builtins.min}\r\n     8223    0.001    0.000    0.001    0.000 {built-in method _imp.acquire_lock}\r\n     1910    0.001    0.000    0.007    0.000 <frozen importlib._bootstrap_external>:1203(_path_importer_cache)\r\n     1388    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:369(__init__)\r\n      346    0.001    0.000    0.003    0.000 __init__.py:686(add)\r\n      279    0.001    0.000    0.001    0.000 {built-in method _abc._abc_init}\r\n     1208    0.001    0.000    0.318    0.000 <frozen importlib._bootstrap_external>:1272(find_spec)\r\n      950    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:35(_new_module)\r\n     3118    0.001    0.000    0.001    0.000 version.py:207(<genexpr>)\r\n      454    0.001    0.000    0.003    0.000 version.py:236(__str__)\r\n      886    0.001    0.000    0.002    0.000 __init__.py:2644(key)\r\n     2921    0.001    0.000    0.001    0.000 {built-in method from_bytes}\r\n      286    0.001    0.000    0.005    0.000 overrides.py:72(verify_matching_signatures)\r\n   1768/1    0.001    0.000    5.156    5.156 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\r\n     8223    0.001    0.000    0.001    0.000 {built-in method _imp.release_lock}\r\n      818    0.001    0.000    0.004    0.000 abstract.py:51(_intern)\r\n      945    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:401(_check_name_wrapper)\r\n      590    0.001    0.000    0.041    0.000 __init__.py:2772(_get_metadata)\r\n      496    0.001    0.000    0.002    0.000 posixpath.py:154(dirname)\r\n      349    0.001    0.000    0.002    0.000 extending.py:57(overload)\r\n      584    0.001    0.000    0.002    0.000 enum.py:70(__setitem__)\r\n  344/238    0.001    0.000    0.009    0.000 typing.py:340(__getitem__)\r\n     3626    0.001    0.000    0.002    0.000 typing.py:590(_is_dunder)\r\n       66    0.001    0.000    0.001    0.000 templates.py:667(make_intrinsic_template)\r\n     3816    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:855(__enter__)\r\n      349    0.001    0.000    0.012    0.000 extending.py:111(decorate)\r\n     1124    0.001    0.000    0.015    0.000 version.py:24(parse)\r\n       62    0.001    0.000    0.001    0.000 {built-in method cupy.core._kernel.create_ufunc}\r\n      360    0.001    0.000    0.180    0.000 __init__.py:2039(find_on_path)\r\n     1708    0.001    0.000    0.002    0.000 __init__.py:2071(dist_factory)\r\n      180    0.001    0.000    0.064    0.000 sre_compile.py:759(compile)\r\n      945    0.001    0.000    0.011    0.000 <frozen importlib._bootstrap_external>:951(path_stats)\r\n1533/1102    0.001    0.000    0.001    0.000 typing.py:664(__hash__)\r\n     6095    0.001    0.000    0.001    0.000 {built-in method _thread.get_ident}\r\n     1161    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:311(__enter__)\r\n      471    0.001    0.000    0.002    0.000 copy.py:268(_reconstruct)\r\n     2268    0.001    0.000    0.001    0.000 {method 'split' of 'str' objects}\r\n      150    0.001    0.000    0.025    0.000 <frozen importlib._bootstrap_external>:1404(_fill_cache)\r\n        8    0.001    0.000    0.001    0.000 {method 'read' of '_io.TextIOWrapper' objects}\r\n     2032    0.001    0.000    0.003    0.000 castgraph.py:50(get)\r\n      686    0.001    0.000    0.001    0.000 genericpath.py:121(_splitext)\r\n     2044    0.001    0.000    0.002    0.000 castgraph.py:67(__getitem__)\r\n     4297    0.001    0.000    0.001    0.000 sre_parse.py:249(match)\r\n     1239    0.001    0.000    0.004    0.000 <frozen importlib._bootstrap>:151(__exit__)\r\n      472    0.001    0.000    0.003    0.000 copy.py:66(copy)\r\n      316    0.001    0.000    0.026    0.000 overrides.py:166(decorator)\r\n      180    0.001    0.000    0.006    0.000 sre_compile.py:536(_compile_info)\r\n     1766    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\r\n     2247    0.001    0.000    0.001    0.000 {method 'rfind' of 'str' objects}\r\n     3058    0.001    0.000    0.002    0.000 {method 'add' of 'set' objects}\r\n     1208    0.001    0.000    0.001    0.000 {built-in method _imp.is_frozen}\r\n      807    0.001    0.000    0.002    0.000 ffi.py:56(__getattr__)\r\n     2229    0.001    0.000    0.003    0.000 abstract.py:127(__ne__)\r\n      355    0.001    0.000    0.001    0.000 ntpath.py:122(splitdrive)\r\n      686    0.001    0.000    0.002    0.000 posixpath.py:121(splitext)\r\n      213    0.001    0.000    0.001    0.000 {method 'splitlines' of 'str' objects}\r\n      335    0.001    0.000    0.001    0.000 pyparsing.py:1144(__init__)\r\n     4642    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:321(<genexpr>)\r\n        4    0.001    0.000    0.001    0.000 {method 'readlines' of '_io._IOBase' objects}\r\n     1239    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:143(__init__)\r\n      630    0.001    0.000    0.001    0.000 enum.py:376(__setattr__)\r\n     1080    0.001    0.000    0.001    0.000 {method 'extend' of 'list' objects}\r\n      355    0.001    0.000    0.003    0.000 __init__.py:1494(_validate_resource_path)\r\n      150    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:1319(__init__)\r\n      614    0.001    0.000    0.001    0.000 sre_compile.py:249(_compile_charset)\r\n     2172    0.001    0.000    0.001    0.000 posixpath.py:41(_get_sep)\r\n      353    0.001    0.000    0.001    0.000 posixpath.py:144(basename)\r\n      945    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:884(__init__)\r\n     2594    0.001    0.000    0.001    0.000 sre_parse.py:172(append)\r\n      616    0.001    0.000    0.003    0.000 _inspect.py:98(getargspec)\r\n\r\n```\r\n ","createdAt":"2020-04-07T16:02:22Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-610474111","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxMzkzNzc1MA==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"Was this on a DGX-1 as previously reported?\n\nThe first CUDA call will initialise the context, as Jake pointed out. The time will be higher on multiGPU machines. There is also a cost that is proportional to the sysmem size, I believe. \n\nLoading all the libcudf device code (currently near 300MB) to *each* GPU is also a substantial startup cost. Eliminating legacy should help this. Also we could either move to device-side dispatch where it makes sense (binops, reductions), and/or do more JIT.","createdAt":"2020-04-15T09:48:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-613937750","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNDA3OTcyNQ==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"@harrism running `import cudf` doesn't actually initialize a CUDA context or copy the device code to device memory. It does initialize the driver in validating the GPU architecture / driver version / toolkit version and it looks like that's taking ~3s per above. There's an additional ~2s just in Python imports but I'm not seeing anything stick out in the profile above that's immediately actionable.","createdAt":"2020-04-15T14:39:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-614079725","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNDQ1MDUzOA==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"What does `getDeviceCount` call?","createdAt":"2020-04-16T06:53:22Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-614450538","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNDc0MTM0MQ==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> What does `getDeviceCount` call?\r\n\r\n`cudaGetDeviceCount`: https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f\r\n\r\nThis apparently doesn't actually create a context though.","createdAt":"2020-04-16T15:59:05Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-614741341","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNDc1NDcwOA==","author":{"login":"brandon-b-miller"},"authorAssociation":"CONTRIBUTOR","body":"This was on a DGX-1. I have noticed that subsequent imports don't take nearly as long. Excluding the three seconds up front to call that cuda function, my profile looks fairly similar to the original one in this thread. So I'm actually not sure if 3 seconds spent inside `getDeviceCount` is what the issue was originally raised about, it might have been the rest of the time spent modulo the cuda work.  ","createdAt":"2020-04-16T16:23:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-614754708","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNDk4MjY3NQ==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"> This apparently doesn't actually create a context though.\r\n\r\nWhere do the docs say that?","createdAt":"2020-04-17T01:21:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-614982675","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNDk4OTIzMg==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> > This apparently doesn't actually create a context though.\r\n> \r\n> Where do the docs say that?\r\n\r\nThey don't, an internal slack thread @jrhemstad had with CUDA developers confirmed it though. I can try to dig up a link if you're interested.","createdAt":"2020-04-17T01:42:48Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-614989232","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNDk4OTgxNQ==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"OK, then next question: can we find out if all of the 3s in the profile for that call are in the CUDA runtime/driver? (i.e. is there any Numba overhead?)","createdAt":"2020-04-17T01:44:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-614989815","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNDk5MjI3Mg==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> OK, then next question: can we find out if all of the 3s in the profile for that call are in the CUDA runtime/driver? (i.e. is there any Numba overhead?)\r\n\r\nThese aren't called via Numba, we wrote our own Cython bindings here where there should be basically zero overhead.","createdAt":"2020-04-17T01:51:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-614992272","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNDk5OTY2OA==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"Sorry, misunderstood. Well, I'm guessing the runtime is doing some sort of initialization at that  call...","createdAt":"2020-04-17T02:15:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-614999668","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNTAwMDc3MA==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> Sorry, misunderstood. Well, I'm guessing the runtime is doing some sort of initialization at that call...\r\n\r\nFrom my understanding it does the driver API initialization that happens implicitly when a context is created. Basically a `cuInit(0)` call. https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__INITIALIZE.html","createdAt":"2020-04-17T02:19:25Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-615000770","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNTAwNTQ0OA==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"Can you try compiling this? Compile this code:\r\n\r\n```\r\n#include <stdio.h>\r\n#include <chrono>\r\n\r\nint main()\r\n{\r\n  int numgpus=0;\r\n  printf(\"starting\\n\");\r\n  for (int i = 0;  i < 2; i++) {\r\n    auto start = std::chrono::high_resolution_clock::now();\r\n    cudaGetDeviceCount(&numgpus);\r\n    auto end = std::chrono::high_resolution_clock::now();\r\n    std::chrono::duration<double> elapsed_seconds = end-start;\r\n\r\n    printf(\"iter: %d: GPUs: %d, elapsed time: %lf\\n\", i, numgpus, elapsed_seconds.count());\r\n  }\r\n  return 0;\r\n}\r\n```\r\n\r\nUsing `nvcc test.cu`\r\n\r\nWhen I run on a DGX I get the following. Second result is limiting visible devices to a single GPU (it's faster).\r\n\r\n```\r\n(base) mharris@dgx02:~$ ./a.out\r\nstarting\r\niter: 0: GPUs: 8, elapsed time: 0.394263\r\niter: 1: GPUs: 8, elapsed time: 0.000000\r\n(base) mharris@dgx02:~$ CUDA_VISIBLE_DEVICES=3 ./a.out\r\nstarting\r\niter: 0: GPUs: 1, elapsed time: 0.079943\r\niter: 1: GPUs: 1, elapsed time: 0.000000\r\n```\r\n\r\nSo with 8 GPUs it takes .39s -- not 3s, but still significant. And the second time it takes less than a microsecond. It must be doing something. I think that something is initializing the driver context. And if libcudf is linked into the module, then its 300MB fatbin is probably being loaded.\r\n\r\nYou can try on your DGX to see if its different.","createdAt":"2020-04-17T02:36:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-615005448","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNTAwNzczMg==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> And if libcudf is linked into the module, then its 300MB fatbin is probably being loaded.\r\n\r\n`libcudf` is absolutely linked into the module.","createdAt":"2020-04-17T02:46:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-615007732","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNTAyODQ2MQ==","author":{"login":"jakirkham"},"authorAssociation":"MEMBER","body":"There were some untyped variables in those Cython bindings. Doubt that matters much, but it may affect this a little bit and is easy to fix. Sent PR ( https://github.com/rapidsai/cudf/pull/4925 ) to type them.","createdAt":"2020-04-17T04:02:18Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-615028461","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYxNTU1OTE5MA==","author":{"login":"jakirkham"},"authorAssociation":"MEMBER","body":"Reworked the original proposal as there were some device functions that needed some changes to handle their errors respectively. Otherwise largely the same idea. Submitted as PR ( https://github.com/rapidsai/cudf/pull/4943 ).","createdAt":"2020-04-18T04:49:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-615559190","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYyNDI5NTY1OA==","author":{"login":"jakirkham"},"authorAssociation":"MEMBER","body":"Retested this and it appears to be ~2s now. Longer or shorter depending on the run. Occasionally see an outlier.","createdAt":"2020-05-05T20:43:53Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-624295658","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYyNDMyMTE3Nw==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> Retested this and it appears to be ~2s now. Longer or shorter depending on the run. Occasionally see an outlier.\r\n\r\nWhat kind of machine did you test this on? I suspect this scales somewhat linearly with the number of visible GPUs due to the driver initialization.","createdAt":"2020-05-05T21:40:05Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-624321177","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYyNDMyNDIzMQ==","author":{"login":"jakirkham"},"authorAssociation":"MEMBER","body":"DGX-1. Were the previous measurements all on DGX-1s or did some of them use other machines?","createdAt":"2020-05-05T21:47:11Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-624324231","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYyNDM1NDU5NQ==","author":{"login":"jakirkham"},"authorAssociation":"MEMBER","body":"FWIW the import time appears to be the same if I restrict to a single device. Tested the following on a DGX-1.\r\n\r\nAll GPUs:\r\n\r\n```python\r\n$ ipython\r\nPython 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.14.0 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: %time import cudf                                                       \r\nCPU times: user 4.28 s, sys: 4.02 s, total: 8.29 s\r\nWall time: 2.12 s\r\n\r\nIn [2]: cudf._cuda.gpu.getDeviceCount()                                         \r\nOut[2]: 8\r\n```\r\n\r\nOne GPU:\r\n\r\n```python\r\n$ CUDA_VISIBLE_DEVICES=0 ipython\r\nPython 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.14.0 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: %time import cudf                                                       \r\nCPU times: user 4.28 s, sys: 3.57 s, total: 7.85 s\r\nWall time: 2.14 s\r\n\r\nIn [2]: cudf._cuda.gpu.getDeviceCount()                                         \r\nOut[2]: 1\r\n```\r\n\r\nAgain there is some variability above and below 2s. However this is representative of what I'm seeing.","createdAt":"2020-05-05T23:14:36Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-624354595","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYzNTEwNDA2OA==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"WIth 0.14 and legacy removed, I thought this might have improved... I tried on my linux desktop with a single V100 GPU and importing cudf took 776 ms.  But I also tried running in a container on a DGX-1 with only one of the V100s visible and it took 15.5s!  Could being in a container make it slow?","createdAt":"2020-05-28T05:07:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-635104068","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYzNTM4NDI5Mw==","author":{"login":"kkraus14"},"authorAssociation":"COLLABORATOR","body":"> WIth 0.14 and legacy removed, I thought this might have improved... I tried on my linux desktop with a single V100 GPU and importing cudf took 776 ms. But I also tried running in a container on a DGX-1 with only one of the V100s visible and it took 15.5s! Could being in a container make it slow?\r\n\r\nThat may be that the DGX didn't have persistence mode enabled and it took a long time for the driver to initialize because the GPUs had to \"wake up\".","createdAt":"2020-05-28T14:28:12Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-635384293","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYzNTcwMDA4OQ==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"Persistence mode is on.\r\n","createdAt":"2020-05-29T01:13:24Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-635700089","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDYzNTcwMjI0OA==","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"More data points:\r\n1. `%time from numba import cuda`: 1.04s\r\n2. `%time import rmm`: 1.29s\r\n\r\nI tried importing cudf on the same DGX outside of my rapids-compose container, but presumably my installation isn't quite right because I'm building from source, and it couldn't find a numba submodule. HOWEVER, before it hit that error, I counted for about 12 seconds. That numba loading was inside RMM, which is imported at the beginning of cuDF's `__init__.py`.  \r\n\r\nNot sure if that tells us anything.","createdAt":"2020-05-29T01:20:46Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-635702248","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps48wxU5","author":{"login":"lmeyerov"},"authorAssociation":"NONE","body":"It adds up on real rapids codes, e.g., `4s` for an empty cudf df\r\n\r\nSome observations:\r\n\r\n* `pandas` is `1+ s` on its own and maintainers seem disinterested: https://github.com/pandas-dev/pandas/issues/7282#issuecomment-442637703\r\n\r\n* `cudf` is now `2.7+ s` import, and add another `1-2s` for even an empty df . So `1s` blameable on pandas, but the other ~ `3s+` seems fair game..\r\n\r\n* `dask_cudf` adds another `0.5+ s` for import, and I didn't measure importing a client and connecting to an existing cluster, but presumably much more\r\n\r\nWe've been chasing down why we're seeing 20s-60s starts for a boring rapids web app init that is just setting up routes and running some cudf + udf warmup routines, so thought this may help. It's been frustrating for production b/c slows down first start + autorestarts. More nice-to-have for us, but maybe more important for others, are of course local dev + testing, and longer-term, precluding fast cold starts for GPU FaaS.\r\n\r\n---\r\n\r\nA few more numbers:\r\n\r\n```\r\n(rapids) root@8128f9b31ecd:/opt/graphistry/apps/forge/etl-server-python# time python -c \"1\"\r\n\r\nreal\t0m0.047s\r\nuser\t0m0.043s\r\nsys\t0m0.004s\r\n(rapids) root@8128f9b31ecd:/opt/graphistry/apps/forge/etl-server-python# time python -c \"import logging\"\r\n\r\nreal\t0m0.080s\r\nuser\t0m0.068s\r\nsys\t0m0.012s\r\n(rapids) root@8128f9b31ecd:/opt/graphistry/apps/forge/etl-server-python# time python -c \"import pandas\"\r\n\r\nreal\t0m1.011s\r\nuser\t0m1.059s\r\nsys\t0m0.626s\r\n(rapids) root@8128f9b31ecd:/opt/graphistry/apps/forge/etl-server-python# time python -c \"import cudf\"\r\n\r\nreal\t0m2.692s\r\nuser\t0m2.607s\r\nsys\t0m0.811s\r\n(rapids) root@8128f9b31ecd:/opt/graphistry/apps/forge/etl-server-python# time python -c \"import cudf; cudf.DataFrame({'x': []})\"\r\n\r\nreal\t0m3.558s\r\nuser\t0m3.211s\r\nsys\t0m1.060s\r\n(rapids) root@8128f9b31ecd:/opt/graphistry/apps/forge/etl-server-python# time python -c \"import dask_cudf; import cudf; cudf.DataFrame({'x': []})\"\r\n\r\nreal\t0m4.015s\r\nuser\t0m3.547s\r\nsys\t0m0.794s\r\n```\r\n\r\n--- \r\n\r\nAnd related to the above:\r\n\r\n```\r\n(rapids) root@8128f9b31ecd:/opt/graphistry/apps/forge/etl-server-python# time python -c \"from numba import cuda\"\r\n\r\nreal\t0m1.233s\r\nuser\t0m1.218s\r\nsys\t0m0.757s\r\n(rapids) root@8128f9b31ecd:/opt/graphistry/apps/forge/etl-server-python# time python -c \"import rmm\"\r\n\r\nreal\t0m1.678s\r\nuser\t0m1.688s\r\nsys\t0m0.738s\r\n```\r\n","createdAt":"2022-01-23T05:40:35Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1019417913","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps49fUIJ","author":{"login":"quasiben"},"authorAssociation":"MEMBER","body":"I spent a little time with profiling the import with snakeviz.  gpu_utils is taking close to ~2.5 seconds and a big chunk of that is from `getDeviceCount`. @shwina do you have any thoughts here ?\r\n\r\n<img width=\"1191\" alt=\"Screen Shot 2022-02-07 at 10 45 25 AM\" src=\"https://user-images.githubusercontent.com/1403768/152821700-077555c3-85c6-4800-8995-4c947a8ccb4a.png\">\r\n","createdAt":"2022-02-07T15:50:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1031619081","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps49fbe6","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"Hmm - nothing sticks out to me in the implementation: https://github.com/NVIDIA/cuda-python/blob/746b773c91e1ede708fe9a584b8cdb1c0f32b51d/cuda/_lib/ccudart/ccudart.pyx#L1458-L1466\r\n\r\nI suspect the overhead we're seeing here is from the initialization of the CUDA context.","createdAt":"2022-02-07T16:15:44Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":2}}],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1031649210","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps49gVUB","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"I can't think of a great way around this. It sounds like the lower bound to our import time is the time for CUDA context initialization, which apparently scales as the square of the number of GPUs.\r\n\r\n`validate_setup` sounds like something we definitely want to do at import time (not later), but we could potentially expose something like an environment variable that allows skipping the check altogether? Would that be useful?\r\n\r\nNote that regardless, the CUDA context will eventually need to be initialized at _some_ point if we're going to use the GPU for anything useful.","createdAt":"2022-02-07T20:24:28Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1031886081","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps49grZk","author":{"login":"lmeyerov"},"authorAssociation":"NONE","body":"Googling around suggests C++-level cuda context creation is expected to be closer to `~100ms` than `1s+`. We're all python nowadays so I don't have any C++ handy for seeing if that's still true or maybe there's a different notion of context. (My tests are single GPU, not DGX.)\r\n\r\nMaybe also something about how cpython links stuff at runtime? I've been thinking we might have python import issues around path search or native imports / runtime linking, but haven't dug deep on that.","createdAt":"2022-02-07T22:02:24Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1031976548","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps49gxHx","author":{"login":"jakirkham"},"authorAssociation":"MEMBER","body":"Are your workloads being run on the cloud? If so, it is possible that these are being run on multi-tenant nodes, which have more GPUs than are actually given to any one user. If this is the case, something to play with potentially would be restricting [the `CUDA_VISIBLE_DEVICES` as done above]( https://github.com/rapidsai/cudf/issues/627#issuecomment-624354595 ) to see if that has an effect. This would provide some clue as to whether or not this is the issue.","createdAt":"2022-02-07T22:28:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1031999985","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps49hM73","author":{"login":"lmeyerov"},"authorAssociation":"NONE","body":"I've seen for various local single GPUs, not just cloud: Local, windows -> wsl2 -> ubuntu docker -> rtx3080, local ubuntu docker -> rtx3080, and local ubuntu docker -> some old geforce.\r\n\r\nHappy to test any cpp/py...","createdAt":"2022-02-08T01:20:57Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1032113911","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5FyEdJ","author":{"login":"GregoryKimball"},"authorAssociation":"CONTRIBUTOR","body":"@vyasr Is there a reasonable way to add cudf import time tracking to the [python benchmarks](https://github.com/rapidsai/cudf/tree/branch-22.08/python/cudf/benchmarks/API)? ","createdAt":"2022-06-30T04:38:24Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1170753353","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5F1B0Q","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"I think that would be valuable. The issue is that a lot of the slow parts of the import have to do with initialization logic that only occurs the first time that you import cudf. For example:\r\n\r\n```\r\nIn [1]: %timeit import cudf\r\nThe slowest run took 22.42 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n670 ns ± 1.19 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\r\n\r\nIn [2]: %timeit import cudf\r\n77 ns ± 0.189 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\r\n```\r\n\r\nSince cudf gets imported as part of the collection process for pytest and at the top every module, we'd be obscuring most of that overhead if we tried to incorporate it as part of the same benchmarking suite. If we want to benchmark this, we should just have a separate and very simple script that just times the import and exits.\r\n\r\nIf we really care about accuracy it would be a bit more involved. We would need the script to do something like launch subprocesses (probably serially to avoid any contention issues around NVIDIA driver context creation) that each run the import command and then collect the results. I don't think we need to go that far, though. Even very rough timings will probably tell us what we need.","createdAt":"2022-06-30T18:12:03Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1171528976","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5UuaS6","author":{"login":"jakirkham"},"authorAssociation":"MEMBER","body":"Something we might also consider is using this lazy loader framework\r\n\r\nhttps://github.com/scientific-python/lazy_loader","createdAt":"2023-02-07T21:07:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1421452474","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5UudiA","author":{"login":"jrhemstad"},"authorAssociation":"CONTRIBUTOR","body":"I suspect the addition of [CUDA Lazy Loading](https://docs.nvidia.com/cuda/cuda-c-programming-guide/lazy-loading.html) should dramatically improve this situation. This was added in 11.7 and has been improved in subsequent releases. \r\n\r\nThis is currently an optional feature and can be enabled by specifying the environment variable `CUDA_MODULE_LOADING=LAZY` at runtime. ","createdAt":"2023-02-07T21:18:59Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"ROCKET","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1421465728","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Uun0W","author":{"login":"vyasr"},"authorAssociation":"CONTRIBUTOR","body":"Agreed, CUDA lazy loading should help, although not sure how much. Last I checked import time was distributed across dependencies as well (numba, cupy, rmm) so we'll need to do some careful profiling again with lazy loading enabled to see what else those libraries are doing and how slow other parts of their import are (as well as the validation that cudf does on import, which adds significant overhead).","createdAt":"2023-02-07T21:53:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1421507862","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Vb88T","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"I had a brief look with pyinstrument:\r\n\r\n```\r\n$ pyinstrument importcudf.py\r\n\r\n  _     ._   __/__   _ _  _  _ _/_   Recorded: 16:40:36  Samples:  1201\r\n /_//_/// /_\\ / //_// / //_'/ //     Duration: 2.298     CPU time: 1.758\r\n/   _/                      v4.4.0\r\n\r\nProgram: importcudf.py\r\n\r\n2.297 <module>  importcudf.py:1\r\n└─ 2.297 <module>  cudf/__init__.py:1\r\n   ├─ 1.064 validate_setup  cudf/utils/gpu_utils.py:4\r\n   │  ├─ 0.977 <module>  rmm/__init__.py:1\r\n   │  │  ├─ 0.613 <module>  rmm/rmm.py:1\r\n   │  │  │  ├─ 0.350 <module>  torch/__init__.py:1\r\n   │  │  │  │     [617 frames hidden]  torch, <built-in>, typing, collection...\r\n   │  │  │  └─ 0.261 <module>  cupy/__init__.py:1\r\n   │  │  │        [668 frames hidden]  cupy, pytest, _pytest, attr, <built-i...\r\n   │  │  ├─ 0.330 <module>  rmm/mr.py:1\r\n   │  │  │  └─ 0.330 <module>  rmm/_lib/__init__.py:1\r\n   │  │  │     ├─ 0.280 <module>  numba/__init__.py:1\r\n   │  │  │     │     [739 frames hidden]  numba, numpy, re, sre_compile, sre_pa...\r\n   │  │  │     └─ 0.047 <module>  numba/cuda/__init__.py:1\r\n   │  │  │           [163 frames hidden]  numba, asyncio, ssl, enum, <built-in>...\r\n   │  │  └─ 0.034 get_versions  rmm/_version.py:515\r\n   │  │     └─ 0.034 git_pieces_from_vcs  rmm/_version.py:234\r\n   │  │        └─ 0.034 run_command  rmm/_version.py:71\r\n   │  │           └─ 0.027 Popen.communicate  subprocess.py:1110\r\n   │  │                 [7 frames hidden]  subprocess, <built-in>, selectors\r\n   │  └─ 0.031 getDeviceCount  rmm/_cuda/gpu.py:91\r\n   ├─ 0.390 _setup_numba_linker  cudf/core/udf/utils.py:388\r\n   │  └─ 0.390 safe_get_versions  ptxcompiler/patch.py:212\r\n   │        [12 frames hidden]  ptxcompiler, subprocess, selectors, <...\r\n   ├─ 0.308 <module>  cudf/api/__init__.py:1\r\n   │  └─ 0.301 <module>  cudf/api/extensions/__init__.py:1\r\n   │     └─ 0.301 <module>  cudf/api/extensions/accessor.py:1\r\n   │        └─ 0.300 <module>  pandas/__init__.py:1\r\n   │              [694 frames hidden]  pandas, pyarrow, copy, <built-in>, te...\r\n   ├─ 0.280 <module>  cudf/datasets.py:1\r\n   │  ├─ 0.253 <module>  cudf/_lib/__init__.py:1\r\n   │  │  ├─ 0.124 <module>  cudf/utils/ioutils.py:1\r\n   │  │  │  ├─ 0.096 <module>  pyarrow/fs.py:1\r\n   │  │  │  │     [4 frames hidden]  pyarrow, <built-in>\r\n   │  │  │  └─ 0.026 <module>  fsspec/__init__.py:1\r\n   │  │  │        [79 frames hidden]  fsspec, importlib, pathlib, <built-in...\r\n   │  │  ├─ 0.079 [self]  None\r\n   │  │  └─ 0.043 <module>  cudf/_lib/strings/__init__.py:1\r\n   │  └─ 0.024 <module>  cudf/core/column_accessor.py:1\r\n   │     └─ 0.024 <module>  cudf/core/column/__init__.py:1\r\n   ├─ 0.135 <module>  cudf/core/algorithms.py:1\r\n   │  ├─ 0.097 <module>  cudf/core/indexed_frame.py:1\r\n   │  │  └─ 0.090 <module>  cudf/core/groupby/__init__.py:1\r\n   │  │     └─ 0.090 <module>  cudf/core/groupby/groupby.py:1\r\n   │  │        ├─ 0.053 <module>  cudf/core/udf/groupby_utils.py:1\r\n   │  │        │  └─ 0.053 _get_ptx_file  cudf/core/udf/utils.py:291\r\n   │  │        │     └─ 0.053 get_current_device  numba/cuda/api.py:433\r\n   │  │        │           [10 frames hidden]  numba\r\n   │  │        └─ 0.031 <module>  cudf/core/udf/__init__.py:1\r\n   │  │           └─ 0.027 <module>  cudf/core/udf/row_function.py:1\r\n   │  └─ 0.031 <module>  cudf/core/index.py:1\r\n   │     └─ 0.025 Float32Index.__init_subclass__  cudf/core/mixins/mixin_factory.py:212\r\n   │        └─ 0.023 TimedeltaIndex._should_define_operation  cudf/core/mixins/mixin_factory.py:77\r\n   └─ 0.086 get_versions  cudf/_version.py:515\r\n      └─ 0.085 git_pieces_from_vcs  cudf/_version.py:235\r\n         └─ 0.085 run_command  cudf/_version.py:72\r\n            └─ 0.077 Popen.communicate  subprocess.py:1110\r\n                  [7 frames hidden]  subprocess, <built-in>, selectors\r\n\r\nTo view this report with different options, run:\r\n    pyinstrument --load-prev 2023-02-16T16-40-36 [options]\r\n```\r\n\r\n`CUDA_MODULE_LOADING=LAZY` doesn't really seem to help (I have host driver == cuda-12, and cuda-11.8 in a rapids-compose environment).\r\n\r\nAdding `RAPIDS_NO_INITIALIZE=1` just moves some time around\r\n\r\n```\r\n2.277 <module>  importcudf.py:1\r\n└─ 2.277 <module>  cudf/__init__.py:1\r\n   ├─ 0.453 <module>  rmm/__init__.py:1\r\n   │  ├─ 0.352 <module>  rmm/rmm.py:1\r\n   │  │  └─ 0.351 <module>  torch/__init__.py:1\r\n   │  │        [663 frames hidden]  torch, <built-in>, typing, enum, pick...\r\n   │  ├─ 0.067 <module>  rmm/mr.py:1\r\n   │  │  └─ 0.067 <module>  rmm/_lib/__init__.py:1\r\n   │  │     └─ 0.045 __new__  enum.py:180\r\n   │  │           [15 frames hidden]  enum, <built-in>\r\n   │  └─ 0.034 get_versions  rmm/_version.py:515\r\n   │     └─ 0.034 git_pieces_from_vcs  rmm/_version.py:234\r\n   │        └─ 0.034 run_command  rmm/_version.py:71\r\n   │           └─ 0.027 Popen.communicate  subprocess.py:1110\r\n   │                 [7 frames hidden]  subprocess, <built-in>, selectors\r\n   ├─ 0.407 _setup_numba_linker  cudf/core/udf/utils.py:388\r\n   │  └─ 0.407 safe_get_versions  ptxcompiler/patch.py:212\r\n   │        [11 frames hidden]  ptxcompiler, subprocess, selectors, <...\r\n   ├─ 0.364 <module>  cupy/__init__.py:1\r\n   │     [1068 frames hidden]  cupy, pytest, _pytest, <built-in>, at...\r\n   ├─ 0.356 <module>  cudf/api/__init__.py:1\r\n   │  └─ 0.348 <module>  cudf/api/extensions/__init__.py:1\r\n   │     └─ 0.348 <module>  cudf/api/extensions/accessor.py:1\r\n   │        └─ 0.346 <module>  pandas/__init__.py:1\r\n   │              [700 frames hidden]  pandas, pyarrow, <built-in>, textwrap...\r\n   ├─ 0.286 <module>  cudf/datasets.py:1\r\n   │  ├─ 0.258 <module>  cudf/_lib/__init__.py:1\r\n   │  │  ├─ 0.126 <module>  cudf/utils/ioutils.py:1\r\n   │  │  │  ├─ 0.097 <module>  pyarrow/fs.py:1\r\n   │  │  │  │     [4 frames hidden]  pyarrow, <built-in>\r\n   │  │  │  └─ 0.027 <module>  fsspec/__init__.py:1\r\n   │  │  │        [86 frames hidden]  fsspec, importlib, pathlib, <built-in...\r\n   │  │  ├─ 0.084 [self]  None\r\n   │  │  └─ 0.044 <module>  cudf/_lib/strings/__init__.py:1\r\n   │  └─ 0.025 <module>  cudf/core/column_accessor.py:1\r\n   │     └─ 0.024 <module>  cudf/core/column/__init__.py:1\r\n   ├─ 0.183 <module>  numba/__init__.py:1\r\n   │     [495 frames hidden]  numba, llvmlite, ctypes, <built-in>, ...\r\n   ├─ 0.085 get_versions  cudf/_version.py:515\r\n   │  └─ 0.084 git_pieces_from_vcs  cudf/_version.py:235\r\n   │     └─ 0.084 run_command  cudf/_version.py:72\r\n   │        └─ 0.076 Popen.communicate  subprocess.py:1110\r\n   │              [7 frames hidden]  subprocess, <built-in>, selectors\r\n   ├─ 0.081 <module>  cudf/core/algorithms.py:1\r\n   │  ├─ 0.042 <module>  cudf/core/indexed_frame.py:1\r\n   │  │  └─ 0.036 <module>  cudf/core/groupby/__init__.py:1\r\n   │  │     └─ 0.036 <module>  cudf/core/groupby/groupby.py:1\r\n   │  │        └─ 0.031 <module>  cudf/core/udf/__init__.py:1\r\n   │  │           └─ 0.027 <module>  cudf/core/udf/row_function.py:1\r\n   │  └─ 0.032 <module>  cudf/core/index.py:1\r\n   │     └─ 0.024 UInt64Index.__init_subclass__  cudf/core/mixins/mixin_factory.py:212\r\n   │        └─ 0.024 UInt64Index._should_define_operation  cudf/core/mixins/mixin_factory.py:77\r\n   │           └─ 0.024 dir  None\r\n   │                 [2 frames hidden]  <built-in>\r\n   └─ 0.026 <module>  numba/cuda/__init__.py:1\r\n         [86 frames hidden]  numba, <built-in>, collections, llvml...\r\n```\r\n\r\nNumba forks a subprocess to compile some cuda code to determine if it needs to patch the ptx linker. We can turn that off\r\n```\r\n1.895 <module>  importcudf.py:1\r\n└─ 1.895 <module>  cudf/__init__.py:1\r\n   ├─ 0.468 <module>  rmm/__init__.py:1\r\n   │  ├─ 0.359 <module>  rmm/rmm.py:1\r\n   │  │  └─ 0.358 <module>  torch/__init__.py:1\r\n   │  │        [687 frames hidden]  torch, <built-in>, typing, enum, insp...\r\n   │  ├─ 0.073 <module>  rmm/mr.py:1\r\n   │  │  └─ 0.072 <module>  rmm/_lib/__init__.py:1\r\n   │  │     └─ 0.052 __new__  enum.py:180\r\n   │  │           [23 frames hidden]  enum, <built-in>\r\n   │  └─ 0.036 get_versions  rmm/_version.py:515\r\n   │     └─ 0.036 git_pieces_from_vcs  rmm/_version.py:234\r\n   │        └─ 0.036 run_command  rmm/_version.py:71\r\n   │           └─ 0.029 Popen.communicate  subprocess.py:1110\r\n   │                 [7 frames hidden]  subprocess, <built-in>, selectors\r\n   ├─ 0.363 <module>  cupy/__init__.py:1\r\n   │     [1034 frames hidden]  cupy, pytest, _pytest, <built-in>, at...\r\n   ├─ 0.362 <module>  cudf/api/__init__.py:1\r\n   │  └─ 0.354 <module>  cudf/api/extensions/__init__.py:1\r\n   │     └─ 0.354 <module>  cudf/api/extensions/accessor.py:1\r\n   │        └─ 0.353 <module>  pandas/__init__.py:1\r\n   │              [722 frames hidden]  pandas, pyarrow, textwrap, <built-in>...\r\n   ├─ 0.284 <module>  cudf/datasets.py:1\r\n   │  ├─ 0.257 <module>  cudf/_lib/__init__.py:1\r\n   │  │  ├─ 0.127 <module>  cudf/utils/ioutils.py:1\r\n   │  │  │  ├─ 0.098 <module>  pyarrow/fs.py:1\r\n   │  │  │  │     [4 frames hidden]  pyarrow, <built-in>\r\n   │  │  │  └─ 0.028 <module>  fsspec/__init__.py:1\r\n   │  │  │        [97 frames hidden]  fsspec, importlib, pathlib, <built-in...\r\n   │  │  ├─ 0.082 [self]  None\r\n   │  │  └─ 0.043 <module>  cudf/_lib/strings/__init__.py:1\r\n   │  └─ 0.024 <module>  cudf/core/column_accessor.py:1\r\n   │     └─ 0.024 <module>  cudf/core/column/__init__.py:1\r\n   ├─ 0.194 <module>  numba/__init__.py:1\r\n   │     [490 frames hidden]  numba, llvmlite, ctypes, <built-in>, ...\r\n   ├─ 0.081 <module>  cudf/core/algorithms.py:1\r\n   │  ├─ 0.043 <module>  cudf/core/indexed_frame.py:1\r\n   │  │  └─ 0.036 <module>  cudf/core/groupby/__init__.py:1\r\n   │  │     └─ 0.036 <module>  cudf/core/groupby/groupby.py:1\r\n   │  │        └─ 0.031 <module>  cudf/core/udf/__init__.py:1\r\n   │  │           └─ 0.027 <module>  cudf/core/udf/row_function.py:1\r\n   │  │              └─ 0.021 <module>  cudf/core/udf/utils.py:1\r\n   │  └─ 0.032 <module>  cudf/core/index.py:1\r\n   │     └─ 0.024 GenericIndex.__init_subclass__  cudf/core/mixins/mixin_factory.py:212\r\n   │        └─ 0.022 GenericIndex._should_define_operation  cudf/core/mixins/mixin_factory.py:77\r\n   │           └─ 0.020 dir  None\r\n   │                 [2 frames hidden]  <built-in>\r\n   ├─ 0.078 get_versions  cudf/_version.py:515\r\n   │  └─ 0.078 git_pieces_from_vcs  cudf/_version.py:235\r\n   │     └─ 0.078 run_command  cudf/_version.py:72\r\n   │        └─ 0.071 Popen.communicate  subprocess.py:1110\r\n   │              [7 frames hidden]  subprocess, <built-in>, selectors\r\n   ├─ 0.029 <module>  numba/cuda/__init__.py:1\r\n   │     [110 frames hidden]  numba, collections, re, types, <built...\r\n   └─ 0.022 <module>  cudf/io/__init__.py:1\r\n```\r\n\r\nRMM imports pytorch if it's in the environment\r\n```\r\ntry:\r\n    from torch.cuda.memory import CUDAPluggableAllocator\r\nexcept ImportError:\r\n    rmm_torch_allocator = None\r\nelse:\r\n    import rmm._lib.torch_allocator\r\n\r\n    _alloc_free_lib_path = rmm._lib.torch_allocator.__file__\r\n    rmm_torch_allocator = CUDAPluggableAllocator(\r\n        _alloc_free_lib_path,\r\n        alloc_fn_name=\"allocate\",\r\n        free_fn_name=\"deallocate\",\r\n    )\r\n```\r\nLet's suppose we fix that with lazy-loading.\r\n\r\n```\r\n1.469 <module>  importcudf.py:1\r\n└─ 1.467 <module>  cudf/__init__.py:1\r\n   ├─ 0.360 <module>  cupy/__init__.py:1\r\n   │     [1023 frames hidden]  cupy, pytest, _pytest, <built-in>, at...\r\n   ├─ 0.282 <module>  cudf/api/__init__.py:1\r\n   │  └─ 0.274 <module>  cudf/api/extensions/__init__.py:1\r\n   │     └─ 0.274 <module>  cudf/api/extensions/accessor.py:1\r\n   │        └─ 0.272 <module>  pandas/__init__.py:1\r\n   │              [695 frames hidden]  pandas, pyarrow, <built-in>, textwrap...\r\n   ├─ 0.275 <module>  cudf/datasets.py:1\r\n   │  ├─ 0.249 <module>  cudf/_lib/__init__.py:1\r\n   │  │  ├─ 0.125 <module>  cudf/utils/ioutils.py:1\r\n   │  │  │  ├─ 0.096 <module>  pyarrow/fs.py:1\r\n   │  │  │  │     [4 frames hidden]  pyarrow, <built-in>\r\n   │  │  │  └─ 0.028 <module>  fsspec/__init__.py:1\r\n   │  │  │        [91 frames hidden]  fsspec, importlib, pathlib, <built-in...\r\n   │  │  ├─ 0.077 [self]  None\r\n   │  │  └─ 0.042 <module>  cudf/_lib/strings/__init__.py:1\r\n   │  └─ 0.025 <module>  cudf/core/column_accessor.py:1\r\n   │     └─ 0.024 <module>  cudf/core/column/__init__.py:1\r\n   ├─ 0.182 <module>  numba/__init__.py:1\r\n   │     [446 frames hidden]  numba, llvmlite, ctypes, <built-in>, ...\r\n   ├─ 0.118 <module>  cudf/core/algorithms.py:1\r\n   │  ├─ 0.070 <module>  cudf/core/index.py:1\r\n   │  │  ├─ 0.041 <module>  cudf/core/frame.py:1\r\n   │  │  │  └─ 0.039 Frame  cudf/core/frame.py:51\r\n   │  │  │     └─ 0.039 _cudf_nvtx_annotate  cudf/utils/utils.py:385\r\n   │  │  │        └─ 0.039 annotate.__call__  nvtx/nvtx.py:89\r\n   │  │  │              [2 frames hidden]  nvtx\r\n   │  │  └─ 0.025 Float64Index.__init_subclass__  cudf/core/mixins/mixin_factory.py:212\r\n   │  │     └─ 0.024 Float64Index._should_define_operation  cudf/core/mixins/mixin_factory.py:77\r\n   │  │        └─ 0.023 dir  None\r\n   │  │              [2 frames hidden]  <built-in>\r\n   │  └─ 0.041 <module>  cudf/core/indexed_frame.py:1\r\n   │     └─ 0.035 <module>  cudf/core/groupby/__init__.py:1\r\n   │        └─ 0.035 <module>  cudf/core/groupby/groupby.py:1\r\n   │           └─ 0.030 <module>  cudf/core/udf/__init__.py:1\r\n   │              └─ 0.025 <module>  cudf/core/udf/row_function.py:1\r\n   │                 └─ 0.020 <module>  cudf/core/udf/utils.py:1\r\n   ├─ 0.102 <module>  rmm/__init__.py:1\r\n   │  ├─ 0.066 <module>  rmm/mr.py:1\r\n   │  │  └─ 0.066 <module>  rmm/_lib/__init__.py:1\r\n   │  │     └─ 0.045 __new__  enum.py:180\r\n   │  │           [16 frames hidden]  enum, <built-in>\r\n   │  └─ 0.034 get_versions  rmm/_version.py:515\r\n   │     └─ 0.034 git_pieces_from_vcs  rmm/_version.py:234\r\n   │        └─ 0.034 run_command  rmm/_version.py:71\r\n   │           └─ 0.027 Popen.communicate  subprocess.py:1110\r\n   │                 [7 frames hidden]  subprocess, <built-in>, selectors\r\n   ├─ 0.088 get_versions  cudf/_version.py:515\r\n   │  └─ 0.087 git_pieces_from_vcs  cudf/_version.py:235\r\n   │     └─ 0.087 run_command  cudf/_version.py:72\r\n   │        └─ 0.080 Popen.communicate  subprocess.py:1110\r\n   │              [7 frames hidden]  subprocess, <built-in>, selectors\r\n   ├─ 0.026 <module>  numba/cuda/__init__.py:1\r\n   │     [100 frames hidden]  numba, <built-in>, llvmlite, inspect,...\r\n   └─ 0.021 <module>  cudf/io/__init__.py:1\r\n```\r\n\r\nSo now the largest single cost is importing cupy, which seems unavoidable. With a little bit of trimming one might get down to 1s.","createdAt":"2023-02-16T16:48:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1433390867","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Vb-xq","author":{"login":"lmeyerov"},"authorAssociation":"NONE","body":"It takes an ecosystem with each lib chiseling away at its part, so worth it?\r\n\r\nWe think of scenarios like CPU CI, lazy load, and pay-as-you-go for partial surface use..\r\n\r\n","createdAt":"2023-02-16T16:53:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/627#issuecomment-1433398378","viewerDidAuthor":false}],"createdAt":"2019-01-04T02:46:53Z","id":"MDU6SXNzdWUzOTU3OTI3NjI=","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMTM5NzQxMjEz","name":"cuDF (Python)","description":"Affects Python cuDF API.","color":"1d76db"}],"milestone":{"number":26,"title":"Helps developer velocity","description":"","dueOn":null},"number":627,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[BUG] Long import times","updatedAt":"2023-02-16T16:53:42Z","url":"https://github.com/rapidsai/cudf/issues/627"}
