{"assignees":[],"author":{"id":"MDQ6VXNlcjMxOTA0MDU=","is_bot":false,"login":"shwina","name":"Ashwin Srinath"},"body":"With large windows, the `.rolling()` function in cuDF can be pathologically slow:\r\n\r\n```python\r\nIn [6]: dt = cudf.date_range(\"2001-01-01\", \"2002-01-01\", freq=\"1s\")\r\nIn [7]: df = cudf.DataFrame({\"x\": np.random.rand(len(dt))}, index=dt)\r\nIn [8]: %time df.rolling(\"1D\").sum()\r\nCPU times: user 10.3 s, sys: 57.1 ms, total: 10.3 s\r\nWall time: 10.4 s\r\nOut[8]:\r\n                                x\r\n2001-01-01 00:00:00      0.815418\r\n2001-01-01 00:00:01      1.238151\r\n2001-01-01 00:00:02      1.811390\r\n2001-01-01 00:00:03      2.065794\r\n2001-01-01 00:00:04      2.195230\r\n...                           ...\r\n2001-12-31 23:59:55  43308.909704\r\n2001-12-31 23:59:56  43309.098228\r\n2001-12-31 23:59:57  43308.658888\r\n2001-12-31 23:59:58  43308.790256\r\n2001-12-31 23:59:59  43308.915838\r\n\r\n[31536000 rows x 1 columns]\r\n```\r\n\r\n## Why is it slow?\r\n\r\nOf the 10s of execution time above, about 8s is spent in computing the window sizes, which is done in a hand-rolled numba CUDA kernel: https://github.com/rapidsai/cudf/blob/6f6e521257dce5732eea7b6b9d56243f8b0a69cc/python/cudf/cudf/utils/cudautils.py#L17. Note that running the code through a profiler will show execution time being spent in the _next_ CUDA kernel (`column.full`) - but that's a red herring I think, because there's no synchronization after the numba kernel call.\r\n\r\n## What can we do about it?\r\n\r\nI see a couple of options here:\r\n\r\n1. I wonder if there's a better way to write that kernel. Currently, it naively launches one thread per element, and does a linear search for the next element that would exceed the window bounds. \r\n2. We could make it `libcudf`'s responsibility to compute the window sizes. I believe they already do window sizes computation in the context of _grouped_ rolling window aggreagations: see [`grouped_range_rolling_window()`](https://github.com/rapidsai/cudf/blob/6f6e521257dce5732eea7b6b9d56243f8b0a69cc/cpp/include/cudf/rolling.hpp#L542).","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5013Fg","author":{"login":"mroeschke"},"authorAssociation":"CONTRIBUTOR","body":"For 1, here's pandas implementation for finding the window bounds (defined in terms of start/end indices instead of the end - start difference (?)) https://github.com/pandas-dev/pandas/blob/4ed67ac9ef3d9fde6fb8441bc9ea33c0d786649e/pandas/_libs/window/indexers.pyx#L107. pandas uses a sliding window algorithm for this case\r\n\r\nFor 2, I suppose you could defined the non-grouped case as the 1 large group so that `group_range_rolling_window` could be used","createdAt":"2024-02-22T20:38:37Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1960276320","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps502C50","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"> For 2, I suppose you could defined the non-grouped case as the 1 large group so that group_range_rolling_window could be used\r\n\r\nI did experiment with this and it is still somewhat slow. Perhaps libcudf is serializing within groups.","createdAt":"2024-02-22T21:14:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1960324724","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51QyTs","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"This is not due to the computation of the rolling window sizes, but rather that the libcudf rolling window computation is slow, I think. Here's an example to show that:\r\n\r\n```\r\nimport cudf\r\nimport cudf._lib as libcudf\r\nimport numpy as np\r\ndt = cudf.date_range(\"2001-01-01\", \"2002-01-01\", freq=\"1s\")\r\ndf = cudf.DataFrame({\"x\": np.random.rand(len(dt))}, index=dt)\r\nmax_window_size = 86400\r\npre_window = cudf.core.column.as_column(\r\n    np.concatenate([np.arange(1, max_window_size, dtype=\"int32\"), np.full(len(df) - (max_window_size - 1), max_window_size, dtype=\"int32\")])\r\n)\r\nsource_column = df[\"x\"]._column\r\nfollow_window = cudf.core.column.full(len(df), 0, dtype=\"int32\")\r\nwindow = None\r\nmin_periods = 1\r\ncenter = False\r\nop = \"sum\"\r\nagg_params = {}\r\n\r\nresult = libcudf.rolling.rolling(source_column, pre_window, follow_window, window, min_periods, center, op, agg_params)\r\n```\r\n\r\nThe call to `rolling` takes 10 seconds for me. It's, in this example, linear in the size of the windows (change `max_window_size`).\r\n\r\nI think that scaling kind of makes sense in that irrespective of the window size, one produces the same output windows, but each window is O(window_size) large, and the window-by-window approach implemented then scales in the same way.\r\n\r\nI was wondering if there's some kind of fourier-space approach that one might use, but the potential for non-equispaced samples complicates things (there are non-uniform FFT methods but they are non-exact). And my brain is not sufficiently in gear.\r\n\r\nIn any case, it feels like this should be able to run faster than it does, and I wonder if it can do so by a combination of change in parallelisation strategy and/or clever algorithmic changes.","createdAt":"2024-02-27T18:17:44Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1967334636","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51Q4XW","author":{"login":"davidwendt"},"authorAssociation":"CONTRIBUTOR","body":"cc @mythrocks ","createdAt":"2024-02-27T18:32:36Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1967359446","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51fGFU","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"> I was wondering if there's some kind of fourier-space approach that one might use, but the potential for non-equispaced samples complicates things (there are non-uniform FFT methods but they are non-exact). And my brain is not sufficiently in gear.\r\n\r\nNo FFTs needed I think, this should be solvable in $\\mathcal{O}(n)$ time for an $n$-row column via a summed-area table approach (AKA, in 1D, a prefix scan) for rolling operations whose aggregation op has an inverse.\r\n\r\nThis would be a two-pass algorithm I think, let's take `sum` as the example op.\r\n\r\nPass 1: compute `scan(+, column) -> scan_column`\r\nPass 2: For each row `i`, the result is `scan_column[i + forward_size[i]] - scan_column[i - backward_size[i]]`\r\n\r\nFor things like variance and covariance, one needs to use some suitable adaptation of Welford's online approach. Some relevant recent papers:\r\n\r\n- E. Schubert and M. Gertz, _Numerically stable parallel computation of (co-)variance_ (2018), https://doi.org/10.1145/3221269.3223036\r\n- A. Chmielowiec, _Algorithm for error-free determination of the variance of all contiguous subsequences and fixed-length contiguous subsequences for a sequence of industrial measurement data_ (2021), https://doi.org/10.1007/s00180-021-01096-1\r\n\r\nEdit: one would have to worry (more) about overflow than with the naive approach.","createdAt":"2024-02-29T12:57:48Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1971085652","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51fNF4","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"There's almost definitely two inefficiencies at play here then, computing the window sizes given an offset is slower than we'd like, _and_ the rolling window aggregation implementation is slower than we'd like.","createdAt":"2024-02-29T13:14:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1971114360","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51fO-4","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"> computing the window sizes given an offset is slower than we'd like\r\n\r\nI didn't really manage to measure that part as a noticeable problem, but maybe I was doing something different.","createdAt":"2024-02-29T13:19:01Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1971122104","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51fpaZ","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"In your benchmark you're constructing the inputs to the libcudf `rolling` function by hand. But going through the public API takes you down a code path that uses a numba kernel to do that. ","createdAt":"2024-02-29T14:12:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1971230361","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51gN0u","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"> In your benchmark you're constructing the inputs to the libcudf `rolling` function by hand. But going through the public API takes you down a code path that uses a numba kernel to do that.\r\n\r\nAh sorry, yes, now I see it. I was tricked by the lack of synchronisation in the numba kernel launch.\r\n\r\nYes, that kernel has exactly the same problem the rolling window kernel does. Each row linearly searches backwards in the column until the difference between the preceding entry and the current one is larger than the requested offset.\r\n\r\nI think you can do this by doing a reverse prefix scan of the differences between the entries in the to-be-windowed column, and then ... (brain out of gear again)","createdAt":"2024-02-29T15:25:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"LAUGH","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1971379502","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51hPzH","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"cc @harrism as local scan expert.","createdAt":"2024-02-29T17:47:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1971649735","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51l_vt","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"Just to note one further thing while it is in my thoughts, the (potential) downside to doing a full-column scan to implement this is, in addition to overflow, numerical roundoff if using floating point types[^1].\r\n\r\n\r\n[^1]: The Chiemlowiec paper linked above provides bounds on the number of bits required to compute mean and variance if data are represented in fixed point. If the data are normally distributed with small(ish) variance, these bounds are not too bad, but if they are heavy-tailed they overflow 64bit.","createdAt":"2024-03-01T10:07:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1972894701","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51nsSB","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"The general term of art here is range queries. If the binary operator induces a group structure on the data then these can be done as suggested above (via prefix scans). If it only induces a semigroup structure (no inverse), for example rolling-min, then one needs to build more sophisticated data structures (A.C. Yao, _Space-time tradeoff for answering range queries_ (1982), https://doi.org/10.1145/800070.802185), but can be done in at worse $\\Theta{(c n)}$ space and $\\mathcal{O}(\\alpha_c(n))$ time, where $\\alpha_c$ is the inverse Ackermann function (so effectively constant time for any feasible $n$)).\r\n\r\nSince range minimum queries pop up a lot in geospatial analysis, I wonder if the cuspatial team implemented them.","createdAt":"2024-03-01T14:53:14Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1973339265","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51qad7","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"> Note that running the code through a profiler will show execution time being spent in the next CUDA kernel (column.full) - but that's a red herring I think, because there's no synchronization after the numba kernel call.\n\nI don't think this should be true. I think Nsight systems can distinguish the execution time of kernels even without synchronisation. If you time manually in host code then you need to synchronize to time accurately.","createdAt":"2024-03-01T23:08:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1974052731","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps51qda1","author":{"login":"shwina"},"authorAssociation":"CONTRIBUTOR","body":"Oh sorry, I meant a host profiler (in this case the Python profiler `cprofile`)","createdAt":"2024-03-01T23:24:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1974064821","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps513ps-","author":{"login":"harrism"},"authorAssociation":"MEMBER","body":"Regarding the [numba kernel to find the windows](https://github.com/rapidsai/cudf/blob/6f6e521257dce5732eea7b6b9d56243f8b0a69cc/python/cudf/cudf/utils/cudautils.py#L17), a first step is usually to move this to C++. When I search the codebase for this it only finds the definition, no calls. However the non-numba version is called, here: https://github.com/rapidsai/cudf/blob/d158ccdbe651952bd649cb0f17c41467c5209824/python/cudf/cudf/core/window/rolling.py#L483\r\n\r\nSo is this numba kernel actually being used?\r\n\r\nNext question, is the `arr` data passed to it random, or does it happen to be ordered? If the latter, then this could be replaced by a call to `thrust::lower_bound` in C++ (with fancy iterators).\r\n","createdAt":"2024-03-04T21:50:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1977523006","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5130Fk","author":{"login":"wence-"},"authorAssociation":"CONTRIBUTOR","body":"> Regarding the [numba kernel to find the windows](https://github.com/rapidsai/cudf/blob/6f6e521257dce5732eea7b6b9d56243f8b0a69cc/python/cudf/cudf/utils/cudautils.py#L17), a first step is usually to move this to C++. When I search the codebase for this it only finds the definition, no calls. However the non-numba version is called, here:\r\n> \r\n> https://github.com/rapidsai/cudf/blob/d158ccdbe651952bd649cb0f17c41467c5209824/python/cudf/cudf/core/window/rolling.py#L483\r\n> \r\n> So is this numba kernel actually being used?\r\n> \r\n> Next question, is the `arr` data passed to it random, or does it happen to be ordered? If the latter, then this could be replaced by a call to `thrust::lower_bound` in C++ (with fancy iterators).\r\n\r\nThe non-numba version calls the numba version: https://github.com/rapidsai/cudf/blob/6f6e521257dce5732eea7b6b9d56243f8b0a69cc/python/cudf/cudf/utils/cudautils.py#L32\r\n\r\n\r\nI am not sure if the rolling window API allows non-sorted arrays but I would have thought not, so arr is _probably_ (someone else to confirm) required to be sorted in ascending order.\r\n","createdAt":"2024-03-04T22:18:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/15119#issuecomment-1977565540","viewerDidAuthor":false}],"createdAt":"2024-02-22T16:04:49Z","id":"I_kwDOBWUGps6AHV4i","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NTk=","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMzIyMjUyNjE3","name":"Performance","description":"Performance related issue","color":"C2E0C6"}],"milestone":null,"number":15119,"projectCards":[],"projectItems":[],"reactionGroups":[{"content":"EYES","users":{"totalCount":1}}],"state":"OPEN","title":"[BUG] Rolling window aggregations are very slow with large windows","updatedAt":"2024-03-04T22:18:20Z","url":"https://github.com/rapidsai/cudf/issues/15119"}
