{"assignees":[{"id":"MDQ6VXNlcjczMDQ1ODI=","login":"shrshi","name":"Shruti Shivakumar"}],"author":{"id":"MDQ6VXNlcjM0NDEzMjE=","is_bot":false,"login":"revans2","name":"Robert (Bobby) Evans"},"body":"**Is your feature request related to a problem? Please describe.**\r\nIn Spark we have a requirement to be able to pass in a column of strings and parse them as JSON. Ideally we would just pass this directly to CUDF, but none of the input formats really support this, and neither do any of the pre-processing steps that the JSON reader has put in for us. What we do today is first check to see if a line separator (carriage return) is in the data set. If there is one, then we throw an exception. If not, then we concat the lines together into a single buffer with a line separator in between the inputs. (we do some fixup for NULLs/empty rows too).\r\n\r\nThis has the problem that we throw an exception when we see a bad character in the data, which is valid for Spark to have in the data.\r\n\r\nI think that there are a few options that we have to fix this kind of a problem.\r\n\r\n1. Expose the API that removes unneeded white space. We could then remove the unneeded data from the buffer and replace any remaining line separators with '\\n' because then they should only be in quoted strings. (we might need to do single quote normalization too because I am not sure which one comes first)\r\n2. Provide a way to set a different line separator (Ideally something really unlikely to show up NUL \\0). This would not fix the problem 100%, but it would make it super rare, and I would feel okay with a solution like this.\r\n3. Do nothing and we just take the hit when we see a line with this in it. We would then have to pull back those lines to the CPU and process them on the CPU, and push them back to the GPU afterwards.\r\n\r\nI personally like option 2, but I am likely to implement option 3 in the short term unless I hear from CUDF that this is simple to do and can be done really quickly.","closed":false,"closedAt":null,"comments":[],"createdAt":"2024-03-12T14:59:44Z","id":"I_kwDOBWUGps6CDEU9","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"},{"id":"MDU6TGFiZWwxNDA1MTQ2OTc1","name":"Spark","description":"Functionality that helps Spark RAPIDS","color":"7400ff"}],"milestone":{"number":13,"title":"Nested JSON reader","description":"Data-parallel reader for nested JSON text data","dueOn":null},"number":15277,"projectCards":[],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] Find a way to support String column input/fixup for JSON parsing","updatedAt":"2024-05-03T18:57:52Z","url":"https://github.com/rapidsai/cudf/issues/15277"}
