{"assignees":[],"author":{"id":"MDQ6VXNlcjE5OTQ5MjA3","is_bot":false,"login":"ayushdg","name":"Ayush Dattagupta"},"body":"**Is your feature request related to a problem? Please describe.**\r\nOften, datasets stored in the orc format are partitioned (based on standard hive partitioning format) similar to parquet. Dask_cudf  (and dask_dataframe) currently supports reading partitioned parquet datasets, but does not support reading partitioned orc datasets.\r\n\r\n**Describe the solution you'd like**\r\n`dask_cudf.read_orc` works when provided a path to a partitioned orc dataset, without errors (similar to how this works now for `read_parquet`).\r\nIf the solution is general, this could be upstreamed to dask dataframe as well.\r\n\r\n**Describe alternatives you've considered**\r\nCurrent alternatives would involve walking through subfolders and reading the orc files separately, while using some custom logic (like looking at folder names) to determine the values for the partitioned columns.\r\n\r\n**Additional context**\r\nHere is an example of a partitioned orc dataset.\r\n[test_orc.zip](https://github.com/rapidsai/cudf/files/5070526/test_orc.zip)\r\n\r\nThis is the existing output when trying to read this dataset with dask_cudf\r\n\r\n```python\r\nIn [1]: import dask_cudf                                                                                                                                               \r\nIn [2]: dask_cudf.read_orc(\"test_orc\")                                                                                                                                 \r\n---------------------------------------------------------------------------\r\nIsADirectoryError                         Traceback (most recent call last)\r\n<ipython-input-2-711da5386bc8> in <module>\r\n----> 1 dask_cudf.read_orc(\"test_orc\")\r\n\r\n/opt/conda/envs/rapids/lib/python3.7/site-packages/dask_cudf/io/orc.py in read_orc(path, columns, storage_options, **kwargs)\r\n     47     nstripes_per_file = []\r\n     48     for path in paths:\r\n---> 49         with fs.open(path, \"rb\") as f:\r\n     50             o = orc.ORCFile(f)\r\n     51             if schema is None:\r\n\r\n/opt/conda/envs/rapids/lib/python3.7/site-packages/fsspec/spec.py in open(self, path, mode, block_size, cache_options, **kwargs)\r\n    842                 autocommit=ac,\r\n    843                 cache_options=cache_options,\r\n--> 844                 **kwargs\r\n    845             )\r\n    846             if not ac:\r\n\r\n/opt/conda/envs/rapids/lib/python3.7/site-packages/fsspec/implementations/local.py in _open(self, path, mode, block_size, **kwargs)\r\n    113         if self.auto_mkdir and \"w\" in mode:\r\n    114             self.makedirs(self._parent(path), exist_ok=True)\r\n--> 115         return LocalFileOpener(path, mode, fs=self, **kwargs)\r\n    116 \r\n    117     def touch(self, path, **kwargs):\r\n\r\n/opt/conda/envs/rapids/lib/python3.7/site-packages/fsspec/implementations/local.py in __init__(self, path, mode, autocommit, fs, **kwargs)\r\n    195         self.autocommit = autocommit\r\n    196         self.blocksize = io.DEFAULT_BUFFER_SIZE\r\n--> 197         self._open()\r\n    198 \r\n    199     def _open(self):\r\n\r\n/opt/conda/envs/rapids/lib/python3.7/site-packages/fsspec/implementations/local.py in _open(self)\r\n    200         if self.f is None or self.f.closed:\r\n    201             if self.autocommit or \"w\" not in self.mode:\r\n--> 202                 self.f = open(self.path, mode=self.mode)\r\n    203             else:\r\n    204                 # TODO: check if path is writable?\r\n\r\nIsADirectoryError: [Errno 21] Is a directory: '/workdir/data/test_orc'\r\n```\r\n\r\n","closed":false,"closedAt":null,"comments":[{"id":"MDEyOklzc3VlQ29tbWVudDc4MDEyMzg4Mw==","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been marked rotten due to no recent activity in the past 90d. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed.","createdAt":"2021-02-16T21:18:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/5967#issuecomment-780123883","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps41_rk9","author":{"login":"beckernick"},"authorAssociation":"MEMBER","body":"Will this be closed by https://github.com/rapidsai/cudf/pull/9103 @rjzamora ?","createdAt":"2021-08-25T21:23:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/5967#issuecomment-905886013","viewerDidAuthor":false}],"createdAt":"2020-08-13T17:38:35Z","id":"MDU6SXNzdWU2Nzg2MjExMTE=","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMTM5NzQxMjEz","name":"cuDF (Python)","description":"Affects Python cuDF API.","color":"1d76db"},{"id":"MDU6TGFiZWwxMTg1MjQwODk4","name":"dask","description":"Dask issue","color":"fcc25d"}],"milestone":null,"number":5967,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"state":"OPEN","title":"[FEA] Dask_cudf support to read partitioned orc datasets","updatedAt":"2024-02-23T18:42:47Z","url":"https://github.com/rapidsai/cudf/issues/5967"}
