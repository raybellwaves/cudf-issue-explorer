{"assignees":[],"author":{"id":"MDQ6VXNlcjM4NDc1MTk0","is_bot":false,"login":"alextxu","name":"Alex Xu"},"body":"**Describe the bug**\r\nAfter creating a Dask-cuDF data frame, if I perform multiple .loc operations on it using boolean Dask-cuDF series, then when I compute the data frame, it produces a runtime error with the message `cuDF failure at: ../src/stream_compaction/apply_boolean_mask.cu:73: Column size mismatch`. A similar snippet works as expected on cuDF.\r\n\r\n**Steps/Code to reproduce bug**\r\n```python\r\nimport dask_cudf\r\nimport cudf\r\nddf1 = dask_cudf.from_cudf(cudf.DataFrame({'a':[1,2,3], 'b':[4,5,6]}), npartitions=2)\r\nf1 = dask_cudf.from_cudf(cudf.Series([False, True, True]), npartitions=2)\r\nf2 = dask_cudf.from_cudf(cudf.Series([True, False]), npartitions=2)\r\nddf2 = ddf1.loc[f1]\r\nddf3 = ddf2.loc[f2]\r\nprint(ddf2.compute())\r\nprint(ddf3.compute())\r\n```\r\nThe above code produces the following output:\r\n```\r\n   a  b                        \r\n1  2  5\r\n2  3  6                                                       \r\nTraceback (most recent call last):     \r\n  File \"temp.py\", line 9, in <module>\r\n    print(ddf3.compute())\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/base.py\", line 292, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/base.py\", line 575, in compute\r\n    results = schedule(dsk, keys, **kwargs)    \r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 554, in get_sync\r\n    return get_async(                                         \r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 497, in get_async                                       \r\n    for key, res_info, failed in queue_get(queue).result():\r\n  File \"/opt/conda/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\r\n    return self.__get_result()\r\n  File \"/opt/conda/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\r\n    raise self._exception\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 539, in submit\r\n    fut.set_result(fn(*args, **kwargs))\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 235, in batch_execute_tasks\r\n    return [execute_task(*a) for a in it]\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 235, in <listcomp>\r\n    return [execute_task(*a) for a in it]\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 226, in execute_task\r\n    result = pack_exception(e, dumps)\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/local.py\", line 221, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/optimization.py\", line 990, in __call__\r\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/core.py\", line 149, in get\r\n    result = _execute_task(task, cache)\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/utils.py\", line 39, in apply\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/dataframe/core.py\", line 6330, in apply_and_enforce\r\n    df = func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.8/site-packages/dask/dataframe/methods.py\", line 37, in loc\r\n    return df.loc[iindexer]\r\n  File \"/opt/conda/lib/python3.8/site-packages/cudf/core/dataframe.py\", line 127, in __getitem__\r\n    return self._getitem_tuple_arg(arg)\r\n  File \"/opt/conda/lib/python3.8/site-packages/nvtx/nvtx.py\", line 101, in inner\r\n    result = func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.8/site-packages/cudf/core/dataframe.py\", line 267, in _getitem_tuple_arg\r\n    df = columns_df._apply_boolean_mask(tmp_arg[0])\r\n  File \"/opt/conda/lib/python3.8/site-packages/cudf/core/indexed_frame.py\", line 1696, in _apply_boolean_mask\r\n    libcudf.stream_compaction.apply_boolean_mask(\r\n  File \"cudf/_lib/stream_compaction.pyx\", line 101, in cudf._lib.stream_compaction.apply_boolean_mask\r\nRuntimeError: cuDF failure at: ../src/stream_compaction/apply_boolean_mask.cu:73: Column size mismatch\r\n```\r\n\r\n**Expected behavior**\r\nExpected output (verified with cudf instead of dask-cudf):\r\n```\r\n   a  b\r\n1  2  5\r\n2  3  6\r\n   a  b\r\n1  2  5\r\n```\r\n\r\n**Environment overview (please complete the following information)**\r\n - Environment location: Docker\r\n - Method of cuDF install: Docker\r\n   - `docker run -it --rm --gpus all --ipc=host --network=host -v .`\r\n\r\n**Environment details**\r\ncuDF version 22.4.0a0+306.g0cb75a4913","closed":false,"closedAt":null,"comments":[{"id":"IC_kwDOBWUGps5Hwpfb","author":{"login":"beckernick"},"authorAssociation":"MEMBER","body":"While cuDF could raise a more informative error rather than leaking internals, this is a Dask issue due to not being able to align the indexes.\r\n\r\nWe can leave this issue open to track raising a more user-friendly error, but I recommend filing this issue at https://github.com/dask/dask/issues/ for further discussion as changing this behavior in Dask may have some wider implications.\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\nddf1 = dd.from_pandas(pd.DataFrame({'a':[1,2,3], 'b':[4,5,6]}), npartitions=2)\r\nf1 = dd.from_pandas(pd.Series([False, True, True]), npartitions=2)\r\nf2 = dd.from_pandas(pd.Series([True, False]), npartitions=2)\r\nddf2 = ddf1.loc[f1]\r\nddf3 = ddf2.loc[f2]\r\nprint(ddf2.compute())\r\nprint(ddf3.compute())\r\n   a  b\r\n1  2  5\r\n2  3  6\r\n\r\n---------------------------------------------------------------------------\r\nIndexingError                             Traceback (most recent call last)\r\nInput In [10], in <cell line: 9>()\r\n      7 ddf3 = ddf2.loc[f2]\r\n      8 print(ddf2.compute())\r\n----> 9 print(ddf3.compute())\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/base.py:312, in DaskMethodsMixin.compute(self, **kwargs)\r\n    288 def compute(self, **kwargs):\r\n    289     \"\"\"Compute this dask collection\r\n    290 \r\n    291     This turns a lazy Dask collection into its in-memory equivalent.\r\n   (...)\r\n    310     dask.base.compute\r\n    311     \"\"\"\r\n--> 312     (result,) = compute(self, traverse=False, **kwargs)\r\n    313     return result\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/base.py:600, in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\r\n    597     keys.append(x.__dask_keys__())\r\n    598     postcomputes.append(x.__dask_postcompute__())\r\n--> 600 results = schedule(dsk, keys, **kwargs)\r\n    601 return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/threaded.py:81, in get(dsk, result, cache, num_workers, pool, **kwargs)\r\n     78     elif isinstance(pool, multiprocessing.pool.Pool):\r\n     79         pool = MultiprocessingPoolExecutor(pool)\r\n---> 81 results = get_async(\r\n     82     pool.submit,\r\n     83     pool._max_workers,\r\n     84     dsk,\r\n     85     result,\r\n     86     cache=cache,\r\n     87     get_id=_thread_get_id,\r\n     88     pack_exception=pack_exception,\r\n     89     **kwargs,\r\n     90 )\r\n     92 # Cleanup pools associated to dead threads\r\n     93 with pools_lock:\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/local.py:508, in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\r\n    506         _execute_task(task, data)  # Re-execute locally\r\n    507     else:\r\n--> 508         raise_exception(exc, tb)\r\n    509 res, worker_id = loads(res_info)\r\n    510 state[\"cache\"][key] = res\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/local.py:316, in reraise(exc, tb)\r\n    314 if exc.__traceback__ is not tb:\r\n    315     raise exc.with_traceback(tb)\r\n--> 316 raise exc\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/local.py:221, in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    219 try:\r\n    220     task, data = loads(task_info)\r\n--> 221     result = _execute_task(task, data)\r\n    222     id = get_id()\r\n    223     result = dumps((result, id))\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/core.py:119, in _execute_task(arg, cache, dsk)\r\n    115     func, args = arg[0], arg[1:]\r\n    116     # Note: Don't assign the subtask results to a variable. numpy detects\r\n    117     # temporaries by their reference count and can execute certain\r\n    118     # operations in-place.\r\n--> 119     return func(*(_execute_task(a, cache) for a in args))\r\n    120 elif not ishashable(arg):\r\n    121     return arg\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/optimization.py:990, in SubgraphCallable.__call__(self, *args)\r\n    988 if not len(args) == len(self.inkeys):\r\n    989     raise ValueError(\"Expected %d args, got %d\" % (len(self.inkeys), len(args)))\r\n--> 990 return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/core.py:149, in get(dsk, out, cache)\r\n    147 for key in toposort(dsk):\r\n    148     task = dsk[key]\r\n--> 149     result = _execute_task(task, cache)\r\n    150     cache[key] = result\r\n    151 result = _execute_task(out, cache)\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/core.py:119, in _execute_task(arg, cache, dsk)\r\n    115     func, args = arg[0], arg[1:]\r\n    116     # Note: Don't assign the subtask results to a variable. numpy detects\r\n    117     # temporaries by their reference count and can execute certain\r\n    118     # operations in-place.\r\n--> 119     return func(*(_execute_task(a, cache) for a in args))\r\n    120 elif not ishashable(arg):\r\n    121     return arg\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/utils.py:41, in apply(func, args, kwargs)\r\n     39 def apply(func, args, kwargs=None):\r\n     40     if kwargs:\r\n---> 41         return func(*args, **kwargs)\r\n     42     else:\r\n     43         return func(*args)\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/dataframe/core.py:6533, in apply_and_enforce(*args, **kwargs)\r\n   6531 func = kwargs.pop(\"_func\")\r\n   6532 meta = kwargs.pop(\"_meta\")\r\n-> 6533 df = func(*args, **kwargs)\r\n   6534 if is_dataframe_like(df) or is_series_like(df) or is_index_like(df):\r\n   6535     if not len(df):\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/dask/dataframe/methods.py:38, in loc(df, iindexer, cindexer)\r\n     34 \"\"\"\r\n     35 .loc for known divisions\r\n     36 \"\"\"\r\n     37 if cindexer is None:\r\n---> 38     return df.loc[iindexer]\r\n     39 else:\r\n     40     return df.loc[iindexer, cindexer]\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/pandas/core/indexing.py:967, in _LocationIndexer.__getitem__(self, key)\r\n    964 axis = self.axis or 0\r\n    966 maybe_callable = com.apply_if_callable(key, self.obj)\r\n--> 967 return self._getitem_axis(maybe_callable, axis=axis)\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/pandas/core/indexing.py:1182, in _LocIndexer._getitem_axis(self, key, axis)\r\n   1180     return self._get_slice_axis(key, axis=axis)\r\n   1181 elif com.is_bool_indexer(key):\r\n-> 1182     return self._getbool_axis(key, axis=axis)\r\n   1183 elif is_list_like_indexer(key):\r\n   1184 \r\n   1185     # an iterable multi-selection\r\n   1186     if not (isinstance(key, tuple) and isinstance(labels, MultiIndex)):\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/pandas/core/indexing.py:984, in _LocationIndexer._getbool_axis(self, key, axis)\r\n    981 def _getbool_axis(self, key, axis: int):\r\n    982     # caller is responsible for ensuring non-None axis\r\n    983     labels = self.obj._get_axis(axis)\r\n--> 984     key = check_bool_indexer(labels, key)\r\n    985     inds = key.nonzero()[0]\r\n    986     return self.obj._take_with_is_copy(inds, axis=axis)\r\n\r\nFile ~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/pandas/core/indexing.py:2383, in check_bool_indexer(index, key)\r\n   2381     mask = isna(result._values)\r\n   2382     if mask.any():\r\n-> 2383         raise IndexingError(\r\n   2384             \"Unalignable boolean Series provided as \"\r\n   2385             \"indexer (index of the boolean Series and of \"\r\n   2386             \"the indexed object do not match).\"\r\n   2387         )\r\n   2388     return result.astype(bool)._values\r\n   2389 if is_object_dtype(key):\r\n   2390     # key might be object-dtype bool, check_array_indexer needs bool array\r\n\r\nIndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\r\n```","createdAt":"2022-08-03T13:14:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/11434#issuecomment-1203935195","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5HzCSJ","author":{"login":"alextxu"},"authorAssociation":"NONE","body":"Update: I've realized that the original code snippet I provided should not be expected to produce the output I've given in the expected behavior section. In fact, the code should produce an error, but the error message that Dask-cuDF outputs, namely `cuDF failure at: ../src/stream_compaction/apply_boolean_mask.cu:73: Column size mismatch` is confusing. On the other hand, the indexing error outputted by Dask with Pandas was more informative and led me to a workaround for my intended use. To summarize, **the focus of this issue now is to improve the error message**.","createdAt":"2022-08-03T22:52:11Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/rapidsai/cudf/issues/11434#issuecomment-1204561033","viewerDidAuthor":false},{"id":"IC_kwDOBWUGps5Jq1Bl","author":{"login":"github-actions"},"authorAssociation":"NONE","body":"This issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.","createdAt":"2022-09-02T23:02:57Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/rapidsai/cudf/issues/11434#issuecomment-1235964005","viewerDidAuthor":false}],"createdAt":"2022-08-02T17:46:45Z","id":"I_kwDOBWUGps5PC_qq","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NTk=","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTg1MjQwODk4","name":"dask","description":"Dask issue","color":"fcc25d"}],"milestone":null,"number":11434,"projectCards":[{"project":{"name":"Bug Squashing"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[BUG] Multiple DataFrame.loc operations gives confusing error message upon compute on Dask-cuDF","updatedAt":"2022-10-21T07:14:05Z","url":"https://github.com/rapidsai/cudf/issues/11434"}
