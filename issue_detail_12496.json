{"assignees":[],"author":{"id":"MDQ6VXNlcjExMjY1Mw==","is_bot":false,"login":"mattf","name":"Matthew Farrellee"},"body":"**Is your feature request related to a problem? Please describe.**\r\nwriting code with `import cudf as pd`\r\n\r\n**Describe the solution you'd like**\r\nsame behavior as `import pandas as pd`\r\n\r\n```\r\nIn [1]: import cudf as pd\r\n\r\nIn [2]: pd.__version__\r\nOut[2]: '22.12.01'\r\n\r\nIn [3]: df = pd.DataFrame({'a': ['one','two','three'] * 10})\r\n\r\nIn [4]: df.info()\r\n<class 'cudf.core.dataframe.DataFrame'>\r\nRangeIndex: 30 entries, 0 to 29\r\nData columns (total 1 columns):\r\n #   Column  Non-Null Count  Dtype\r\n---  ------  --------------  -----\r\n 0   a       30 non-null     object\r\ndtypes: object(1)\r\nmemory usage: 234.0+ bytes\r\n\r\nIn [5]: df.a = df.astype('category')\r\n\r\nIn [6]: df.info()\r\n<class 'cudf.core.dataframe.DataFrame'>\r\nRangeIndex: 30 entries, 0 to 29\r\nData columns (total 1 columns):\r\n #   Column  Non-Null Count  Dtype\r\n---  ------  --------------  -----\r\n 0   a       30 non-null     category\r\ndtypes: category(1)\r\nmemory usage: 57.0 bytes\r\n\r\nIn [7]: df.to_parquet('df.parquet')\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[7], line 1\r\n----> 1 df.to_parquet('df.parquet')\r\n\r\nFile .../lib/python3.8/site-packages/cudf/core/dataframe.py:6287, in DataFrame.to_parquet(self, path, engine, compression, index, partition_cols, partition_file_name, partition_offsets, statistics, metadata_file_path, int96_timestamps, row_group_size_bytes, row_group_size_rows, max_page_size_bytes, max_page_size_rows, storage_options, return_metadata, *args, **kwargs)\r\n   6284 \"\"\"{docstring}\"\"\"\r\n   6285 from cudf.io import parquet\r\n-> 6287 return parquet.to_parquet(\r\n   6288     self,\r\n   6289     path=path,\r\n   6290     engine=engine,\r\n   6291     compression=compression,\r\n   6292     index=index,\r\n   6293     partition_cols=partition_cols,\r\n   6294     partition_file_name=partition_file_name,\r\n   6295     partition_offsets=partition_offsets,\r\n   6296     statistics=statistics,\r\n   6297     metadata_file_path=metadata_file_path,\r\n   6298     int96_timestamps=int96_timestamps,\r\n   6299     row_group_size_bytes=row_group_size_bytes,\r\n   6300     row_group_size_rows=row_group_size_rows,\r\n   6301     max_page_size_bytes=max_page_size_bytes,\r\n   6302     max_page_size_rows=max_page_size_rows,\r\n   6303     storage_options=storage_options,\r\n   6304     return_metadata=return_metadata,\r\n   6305     *args,\r\n   6306     **kwargs,\r\n   6307 )\r\n\r\nFile .../lib/python3.8/contextlib.py:75, in ContextDecorator.__call__.<locals>.inner(*args, **kwds)\r\n     72 @wraps(func)\r\n     73 def inner(*args, **kwds):\r\n     74     with self._recreate_cm():\r\n---> 75         return func(*args, **kwds)\r\n\r\nFile .../lib/python3.8/site-packages/cudf/io/parquet.py:700, in to_parquet(df, path, engine, compression, index, partition_cols, partition_file_name, partition_offsets, statistics, metadata_file_path, int96_timestamps, row_group_size_bytes, row_group_size_rows, max_page_size_bytes, max_page_size_rows, storage_options, return_metadata, *args, **kwargs)\r\n    698     if partition_cols is None or col not in partition_cols:\r\n    699         if df[col].dtype.name == \"category\":\r\n--> 700             raise ValueError(\r\n    701                 \"'category' column dtypes are currently not \"\r\n    702                 + \"supported by the gpu accelerated parquet writer\"\r\n    703             )\r\n    705 if partition_cols:\r\n    706     if metadata_file_path is not None:\r\n\r\nValueError: 'category' column dtypes are currently not supported by the gpu accelerated parquet writer\r\n\r\nIn [8]: df.to_pandas().to_parquet('df.parquet')\r\n\r\nIn [9]: %ls df.parquet\r\ndf.parquet\r\n```","closed":false,"closedAt":null,"comments":[],"createdAt":"2023-01-07T13:39:50Z","id":"I_kwDOBWUGps5a096u","labels":[{"id":"MDU6TGFiZWw1OTk2MjY1NjE=","name":"feature request","description":"New feature or request","color":"a2eeef"},{"id":"MDU6TGFiZWwxMDEzOTg3MzUy","name":"0 - Backlog","description":"In queue waiting for assignment","color":"d4c5f9"},{"id":"MDU6TGFiZWwxMTM5NzQwNjY2","name":"libcudf","description":"Affects libcudf (C++/CUDA) code.","color":"c5def5"},{"id":"MDU6TGFiZWwxMTg1MjQ0MTQy","name":"cuIO","description":"cuIO issue","color":"fef2c0"}],"milestone":{"number":5,"title":"Pandas API Alignment and Coverage","description":"","dueOn":null},"number":12496,"projectCards":[{"project":{"name":"Feature Planning"},"column":{"name":"Needs prioritizing"}}],"projectItems":[],"reactionGroups":[],"state":"OPEN","title":"[FEA] category dtype support in parquet writer","updatedAt":"2023-06-06T03:53:00Z","url":"https://github.com/rapidsai/cudf/issues/12496"}
